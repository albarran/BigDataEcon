[
  {
    "objectID": "docs/Proyect01.html",
    "href": "docs/Proyect01.html",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "Este documento debe entenderse como un ejemplo, no la guía única para el proyecto.\n\nAquí muestro algunas cosas que en vuestros trabajos probablemente NO queréis mostrar. Por ejemplo, he incluido la opción de que se muestre o se oculte el código de todo lo que he hecho, pero vosotros debéis pensar qué y cuándo queréis mostrar algo. También muestro algunos resultados que, como se ha discutido en clase, probablemente tampoco queráis mostrar (o no de la misma manera).\nHe omitido muchos detalles de algunas fases del trabajo que ya se han ido comentando y trabajando en clase (características de los datos, procedimientos, tablas con encabezados adecuados, gráficos con ejes correctamente nombrados, comentario de resultados, etc.)\nCada conjunto de datos es diferente y cada análisis es diferente. Se requiere un tratamiento distinto de los datos: (eliminar o imputar valores ausentes, transformar variables, agrupar categorías, discretizar, etc.), diferentes algoritmos y especificaciones (combinaciones de variables a incluir y sus transformaciones). De hecho, se espera que probéis distintas opciones y discutáis los resultados.\n\nEn resumen, este ejemplo incluye pruebas, gráficos y tablas que vosotros no incluiréis. También deberéis probar otras que aquí no he probado. Pero también se espera discusiones algo más detalladas (sin ser excesivas).\n\n\n\nEn este trabajo, se analizará un conjunto de datos con información sobre precios y otros atributos de una muestra de viviendas en Boston. Por un lado, el objetivo es examinar la influencia de varios atributos del vecindario en los precios de la vivienda, en un intento por descubrir las variables explicativas más adecuadas. Por otro lado, la construcción de un modelo de predicción permitirá determinar el valor por el que se puede poner en el mercado una vivienda o detectar si alguna está infravalorada o sobrevalorada dadas sus características.\nEl objetivo del trabajo es un elemento importante que debéis desarrollar adecuadamente. Todo el análisis y comentarios posteriores deben estar orientados a responder a las preguntas planteados por los objetivos."
  },
  {
    "objectID": "docs/Proyect01.html#comentario-general",
    "href": "docs/Proyect01.html#comentario-general",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "Este documento debe entenderse como un ejemplo, no la guía única para el proyecto.\n\nAquí muestro algunas cosas que en vuestros trabajos probablemente NO queréis mostrar. Por ejemplo, he incluido la opción de que se muestre o se oculte el código de todo lo que he hecho, pero vosotros debéis pensar qué y cuándo queréis mostrar algo. También muestro algunos resultados que, como se ha discutido en clase, probablemente tampoco queráis mostrar (o no de la misma manera).\nHe omitido muchos detalles de algunas fases del trabajo que ya se han ido comentando y trabajando en clase (características de los datos, procedimientos, tablas con encabezados adecuados, gráficos con ejes correctamente nombrados, comentario de resultados, etc.)\nCada conjunto de datos es diferente y cada análisis es diferente. Se requiere un tratamiento distinto de los datos: (eliminar o imputar valores ausentes, transformar variables, agrupar categorías, discretizar, etc.), diferentes algoritmos y especificaciones (combinaciones de variables a incluir y sus transformaciones). De hecho, se espera que probéis distintas opciones y discutáis los resultados.\n\nEn resumen, este ejemplo incluye pruebas, gráficos y tablas que vosotros no incluiréis. También deberéis probar otras que aquí no he probado. Pero también se espera discusiones algo más detalladas (sin ser excesivas)."
  },
  {
    "objectID": "docs/Proyect01.html#introducción-y-objetivos",
    "href": "docs/Proyect01.html#introducción-y-objetivos",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "En este trabajo, se analizará un conjunto de datos con información sobre precios y otros atributos de una muestra de viviendas en Boston. Por un lado, el objetivo es examinar la influencia de varios atributos del vecindario en los precios de la vivienda, en un intento por descubrir las variables explicativas más adecuadas. Por otro lado, la construcción de un modelo de predicción permitirá determinar el valor por el que se puede poner en el mercado una vivienda o detectar si alguna está infravalorada o sobrevalorada dadas sus características.\nEl objetivo del trabajo es un elemento importante que debéis desarrollar adecuadamente. Todo el análisis y comentarios posteriores deben estar orientados a responder a las preguntas planteados por los objetivos."
  },
  {
    "objectID": "docs/Proyect01.html#análisis-de-variación",
    "href": "docs/Proyect01.html#análisis-de-variación",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Análisis de variación",
    "text": "Análisis de variación\nComo primer elemento a destacar, estos datos no contiene valores ausentes en ninguna de las variables. En caso contrario, deberíamos identificar cuántas observaciones y qué variables están afectadas. Sabemos que podemos posponer la imputación de valores a una fase posterior (como un paso del pre-procesado antes de estimar un modelo), pero es conveniente tener una visión general y pensar si algunas observaciones probablemente serán descartadas (si tienen muchos valores ausentes y sobre todo afectan a la variable dependiente).\nPodemos centrarnos en describir con más detalles algunas distribuciones. Esto nuevamente es un EJEMPLO dependiendo de las variables que tengamos y de qué observemos. En general, caracterizar la variable dependiente suele ser una buena idea. Visualizamos la distribución y densidad del precio mediano de las viviendas. La curva negra representa la densidad. Vemos que el valor medio del precio de la vivienda está sesgado a la derecha. Es decir, observamos precios muy altos con una frecuencia mayor de la esperada en una distribución simétrica donde existiría la misma proporción por encima y debajo de la media.\n\nBoston %&gt;%  ggplot(aes(x=medv)) + geom_histogram(aes(y=..density..))+ geom_density() + ggtitle(\"Distribución del Precio\") + xlab(\"Precio de las casas\") + ylab(\"Densidad\")\n\n\n\n\nFigura 1. Distribución del precio de la vivienda\n\n\n\n\nDada esta asimetría, quizás debamos considerar modelizar posteriormente esta variable transformada en logaritmos. La razón: se aprecia un comportamiento que puede modelizarse mejor de forma no lineal. También se puede nota una acumulación de valores en 50 mil dólares. Se puede observar en los resultados de describe() que ese valor exacto se repite varias veces, NO es producto de la discretización del gráfico en la que se acumulan varios valores diferentes en un intervalo en torno a 50; también debemos probar distintos anchos de intervalo como se ha discutido en clase.\nTambién podemos representar gráficamente o en un tabla la única variable categórica que tenemos. La conclusión no es particularmente interesante: solo unas pocas zonas de la ciudad están cerca del río.\n\nBoston %&gt;%  count(chas) %&gt;% \n  mutate(freq=n/sum(n)) %&gt;% \n  kbl(col.names=c(\"Casa cercana al río\",\"Número de casos\", \"Frecuencia\"),\n                  caption = \"Tabla 1. Distribución de Casas según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 1. Distribución de Casas según cercanía al río\n\n\nCasa cercana al río\nNúmero de casos\nFrecuencia\n\n\n\n\nNo\n471\n0.93083\n\n\nYes\n35\n0.06917\n\n\n\n\n\nEn el caso de variables binarias las podemos representar de varias maneras: como una distribución o con una sola barra (NOTA: los gráficos siguientes son redundantes en esta caso, con uno de ellos sería más que suficiente en caso de considerar relevante esta información.)\n\nBoston %&gt;%  ggplot() + geom_bar(aes(x=chas)) +  xlab(\"Zona cercana al río\") +ylab(\"Número de casos\")\n\nBoston %&gt;%  ggplot() + geom_bar(aes(x=\"\",fill=chas)) + labs(fill=\"Zona cercana al río\") +ylab(\"Número de casos\")\n\n\n\n\nFigura 2. Distribución de la cercanía al río\n\n\n\n\n\n\n\nFigura 2. Distribución de la cercanía al río\n\n\n\n\nTambién podemos mostrar algunas otras características interesantes mediante gráficos y/o tablas de estadísticos descriptivos. Algunas variables como el número de habitaciones tienen distribuciones bastante simétricas. Mientras que otras, como la edad o el porcentaje de población desfavorecida muestran claras asimetrías: hay una alta concentración de casas “viejas” y de zonas no desfavorecidas. NOTA: Recordad que habría que probar varios anchos de intervalos (binwidth) para asegurarnos de entender la forma de la distribución. También debéis poner nombres suficientemente descriptivos e informativos a los gráficos, los ejes, la leyenda, etc. (Quizás no es el caso en algunos de los que presento aquí).\n\nBoston %&gt;%  ggplot(aes(x=age)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Edad\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=lstat)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Porcentaje de población desfavorecida\") + ylab(\"Densidad\")\n\n\n\n\nFigura 3. Distribuciones\n\n\n\n\n\n\n\nFigura 3. Distribuciones\n\n\n\n\nNotad que en la variable edad nuevamente hay una concentración de valores en 100; en la salida describe() mostrada anteriormente, se aprecia mejor que ese valor exacto está en los datos originales, no resulta de que se agrupen valores en el gráfico.\nEl caso de la distancia a los centros de empleo es similar a las dos anteriores: una gran concentración en zonas bien conectadas, aunque una cola de zonas alejadas. Se podría omitir: no hay que mostrar gráficos o tablas de cada variable ni comentar necesariamente las características de la distribución de todas, solo de aquellas con rasgos interesante o relevantes.\nOtra variable en principio relacionada, el índice de accesibilidad, muestra una distribución “poco continua”: además de un cúmulo de valores en la cola derecha, hay muchos huecos vacíos. Si probáis un transformación logarítmica, veréis que no cambia en esencia. Las variables con este forma en su distribución suelen ser candidatas a ser discretizadas.\n\nBoston %&gt;%  ggplot(aes(x=dis)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Distancia a centro de trabajo\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=rad)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Índice de accesibilidad\") + ylab(\"Densidad\")\n\n\n\n\nFigura 4. Distribuciones\n\n\n\n\n\n\n\nFigura 4. Distribuciones\n\n\n\n\nAlgunas variables tienen distribuciones con características poco reseñables: unas con valores distribuidos de forma relativamente homogénea, otras dispersas, con concentraciones en valores aislados en medio o en los extremos de la distribución, pero no aportan mucho información (se podrían omitir). En este caso, quizás se podría notar una concentración de zonas con altos impuestos, muy diferenciadas del resto.\n\nBoston %&gt;%  ggplot(aes(x=nox)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Concentración de óxidos nítricos\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=ptratio)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Ratio de alumnos por profesor\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=tax)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Impuesto de la propiedad\") + ylab(\"Densidad\")\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\nAlgo más interesantes son algunas variables que muestran polaridad en sus valores o una excesiva acumulación en algunos. Por ejemplo, la criminalidad y el porcentaje de población de color tienen distribuciones muy asimétricas y, en el segundo caso, persiste incluso tras transformar en logaritmos.\n\nBoston %&gt;%  ggplot(aes(x=crim)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Criminalidad\") + ylab(\"Densidad\")\nBoston %&gt;%  ggplot(aes(x=crim)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Criminalidad\") + ylab(\"Densidad\") + scale_x_log10()\n\n\n\n\nFigura 6a. Distribuciones\n\n\n\n\n\n\n\nFigura 6a. Distribuciones\n\n\n\n\n\nBoston %&gt;%  ggplot(aes(x=b)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Población de color\") + ylab(\"Densidad\") \nBoston %&gt;%  ggplot(aes(x=b)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Población de color\") + ylab(\"Densidad\") + scale_x_log10()\n\n\n\n\nFigura 6b. Distribuciones\n\n\n\n\n\n\n\nFigura 6b. Distribuciones\n\n\n\n\nEstas variables y algunas otras anteriores son candidatas a ser discretizadas. La criminalidad, por ejemplo, no solo muestra una concentración en unos pocos valores, sino que una vez transformada en logaritmos se aprecian dos grupos diferenciados, como también pasaba con los impuestos. En el caso de la ratio de profesor/alumno también unos valores con gran concentración de frecuencia y muy pocos por encima de este por lo que podrían agruparse juntos. En el caso de la población de color, vemos que a partir del percentil 75, los valores son prácticamente iguales y antes del percentil 10 son mucho menores que en el resto de la distribución. En estos casos de variables con valores concentrados o infrecuentes y con saltos o huecos, no podemos decir que la variable que observamos en nuestra muestra tenga una apariencia de variable continua, aunque en principio lo sea. Por tanto, agrupar y discretizar es una buena opción. En particular, es más fácil identificar el efecto medio sobre el precio de la vivienda de un rango de valores (ej., zonas de baja criminalidad frente a alta) que el efecto de incrementar en un punto la variable (cuando en los datos no observamos valores con ese punto más). En otras palabras, vamos a modelizar efectos flexibles no lineales.\n\nMUY IMPORTANTE:\nNO mostréis todos los gráficos o tablas que se os ocurran o solo porque los veáis aquí. ELEGID adecuadamente aquellos que consideréis más relevantes o interesantes y aporten información útil para responder a los objetivos planteados."
  },
  {
    "objectID": "docs/Proyect01.html#análisis-de-covariación",
    "href": "docs/Proyect01.html#análisis-de-covariación",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Análisis de covariación",
    "text": "Análisis de covariación\nEmpezamos analizando la relación entre nuestra variable de interés y la única variable categórica que tenemos inicialmente, para lo que podríamos presentar alguna (NO todas) de las siguientes figuras\n\nBoston %&gt;% ggplot(aes(y = medv, x = chas)) +  geom_boxplot() + ylab(\"Densidad\") + xlab(\"Cerca del río\") + ylab(\"Precio\") \nBoston %&gt;% ggplot(aes(x = medv)) + geom_density(mapping = aes(colour = chas)) + xlab(\"Precio\") + ylab(\"Densidad\")  + labs(color = \"Cerca del río\")\n\n\n\n\nFigura 7a. Distribución del precio por cercanía al rio\n\n\n\n\n\n\n\nFigura 7a. Distribución del precio por cercanía al rio\n\n\n\n\n\nBoston %&gt;% ggplot(aes(x = medv)) + geom_density() + facet_wrap(~chas) + ylab(\"Densidad\")  + xlab(\"Precio\")\n\n\n\n\nFigura 7b. Distribución del precio, según cercanía al rio\n\n\n\n\nParece que las casa cercanas al río tienen un precio superior, aunque la diferencia no parece grande. Ambas distribuciones son asimétricas, aunque en el caso de casas cercanas al río la cola derecha no es tan larga. Mediante una regresión simple o calculando las medias podemos comprobar si existen diferencias en media y si son significativas:\nlm(data = Boston, medv ~ chas) %&gt;% broom::tidy() %&gt;%  kbl(digits = 2, caption = \"Tabla 2a. Precio según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\nTabla 2a. Precio según cercanía al río\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n22.09\n0.42\n52.9\n0\n\n\nchasYes\n6.35\n1.59\n4.0\n0\n\n\n\nBoston %&gt;% group_by(chas) %&gt;% describe(medv) %&gt;% select(described_variables:n, mean, se_mean) %&gt;%  kbl(digits = 2, caption = \"Tabla 2b. Precio según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\nTabla 2b. Precio según cercanía al río\n\n\ndescribed_variables\nchas\nn\nmean\nse_mean\n\n\n\n\nmedv\nNo\n471\n22.09\n0.41\n\n\nmedv\nYes\n35\n28.44\n2.00\n\n\n\nTambién podríamos analizar si la variable binaria de cercanía al río está relacionada. (NOTA: esto nuevamente es un código de ejemplo para hacer de forma fácil este proceso. NO es necesario que vosotros lo hagáis así.)\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\ntabla &lt;-list()\nfor (var in vars) {\n  formula &lt;- paste0(var,\" ~ chas\")\n  tabla[[var]] &lt;- lm(data = Boston, formula) %&gt;% tidy() %&gt;% filter(term==\"chasYes\") %&gt;% select(estimate, p.value)\n}\n\ntabla %&gt;% bind_rows(.id=\"Variable\")  %&gt;%  kbl(digits = 2, caption = \"Tabla 2c. Diferencias en variable por cercanía al río\") %&gt;% kable_paper(\"hover\")\n\nTabla 2c. Diferencias en variable por cercanía al río\n\n\nVariable\nestimate\np.value\n\n\n\n\ncrim\n-1.89\n0.21\n\n\nzn\n-3.92\n0.34\n\n\nindus\n1.70\n0.16\n\n\nnox\n0.04\n0.04\n\n\nrm\n0.25\n0.04\n\n\nage\n9.59\n0.05\n\n\ndis\n-0.82\n0.03\n\n\nrad\n-0.25\n0.87\n\n\ntax\n-23.61\n0.42\n\n\nptratio\n-1.04\n0.01\n\n\nb\n17.54\n0.27\n\n\nlstat\n-1.52\n0.23\n\n\n\nVemos que las casas cercanas al rio son más antiguas, con más habitaciones, más cercanas al centro de trabajo, con más contaminación y mejores condiciones escolares.\nA continuación podemos analizar rápidamente si las variables continuas están relacionadas con nuestra variable de interés, precio de la vivienda, y entre ellas. Lo podemos hacer mediante distintos análisis de correlación, en una tabla (excesivamente larga) o visualmente.\n\nBoston %&gt;% correlate() %&gt;% \n  filter(as.integer(var1) &gt; as.integer(var2)) %&gt;% \n  kbl(digits = 2, caption = \"Tabla 3. Correlaciones\") %&gt;% kable_paper(\"hover\")\n\n\nBoston %&gt;% correlate() %&gt;% plot() \n\nBoston %&gt;% mutate(logmedv=log(medv)) %&gt;% select(-medv) %&gt;% correlate() %&gt;% plot()\n\n\n\n\nFigura 8. Correlaciones entre variables continuas\n\n\n\n\n\n\n\nFigura 8. Correlaciones entre variables continuas\n\n\n\n\nHemos considerado la correlación tanto con el precio como con su logaritmo, dado lo discutido anteriormente. Sin embargo, apenas se aprecian diferencias.\nVemos que existe una fuerte correlación (positiva o negativa) entre el precio y varias variables que intuitivamente consideraríamos como importantes. El número de habitaciones tiene la correlación positiva más fuerte con el valor medio del precio de la vivienda, mientras que el porcentaje de la población desfavorecida y el número de alumnos por docente tienen una correlación negativa fuerte. También es evidente que las zonas más industriales y la contaminación están fuertemente correlacionados positivamente entre sí, puesto que los niveles de óxido nítrico tienden a aumentar con el aumento de las industrias. También vemos que las zonas con más población desfavorecida son las más industriales y contaminadas, con casas más antiguas y de menos habitaciones y con escuelas con un mayor ratio de alumnos por profesor. Debemos recordar esto de cara a la especificación de los modelos de regresión lineal.\nSin embargo, esto no considera posibles relaciones no lineales. Para ello vamos a representar varios gráficos de dispersión y un ajuste no lineal. Nuevamente, en vuestro trabajo no mostraréis necesariamente todos estos gráficos sino una selección después de haberlos vistos.\n\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\nfor (v in vars){\n  graf &lt;- Boston %&gt;% \n            ggplot(aes_string(x = v, y = \"medv\")) +\n            geom_point() +  geom_smooth() +\n            labs(x = v, y = \"Precio de las casas ($1000s)\")\n  print(graf)\n}\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\nfor (v in vars) {\n  migraf &lt;-  Boston %&gt;% \n              ggplot(aes_string(x = v, y = \"medv\")) +\n              geom_point() +  geom_smooth() +\n              labs(x = v, y = \"Precio de las casas ($1000s)\")  +\n              scale_y_log10() \n  print(migraf)\n}\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\nEn primer lugar, no se aprecian grandes diferencias entre el modelo con el precio sin transformar o en logaritmos. En segundo lugar, sí se aprecia cierta no linealidad en la relación con las variables de edad, número de habitaciones y porcentaje de población desfavorecida. En el resto de relaciones, no están tan claras por la acumulación de valores.\nTambién se podrían haber probado si este análisis de covariación es distinto según distintos valores de una varible categórica. Por ejemplo, visualizar la relación entre precio y tasa de pobreza cuando la zona está cerca del rio y cuando no está cerca.\nPodemos probar discretizando algunas de las variables comentadas anteriormente. Por ejemplo, hacemos dos grupos de criminalidad; los umbrales para discretizar no tienen una justificación muy formal: se basan en lo que aproximadamente hemos visto.\n\n  Boston %&gt;% \n      mutate(crim.alta = cut(crim, breaks = c(0,1,Inf), \n                             include.lowest = TRUE,\n                             labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n      ggplot(aes(y = medv, x = crim.alta)) +  geom_boxplot() + ylab(\"Densidad\") + xlab(\"Criminalidad alta\") + ylab(\"Precio\") \n\n\n\n\nFigura 10. Gráficos Criminalidad Discreta\n\n\n\n\n  Boston %&gt;% \n      mutate(crim.alta = cut(crim, breaks = c(0,1,Inf), \n                             include.lowest = TRUE,\n                             labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ crim.alta) %&gt;% tidy() %&gt;%  kbl(digits = 2, caption = \"Tabla 4. Precio según criminalidad\") %&gt;% kable_paper(\"hover\")\n\nTabla 4. Precio según criminalidad\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n25.11\n0.47\n53.91\n0\n\n\ncrim.altaAlta\n-7.50\n0.79\n-9.44\n0\n\n\n\nTanto el gráfico como la regresión apuntan a un efecto significativo de la criminalidad sobre los precios. En principio deberíamos probar con otros puntos de corte para discretizar, pero por simplicidad utilizaremos este obtenido a partir del análisis exploratorio.\nPodemos proceder de manera similar con otras variables. Nuevamente, tanto el número de grupos como los valores de corte no se derivan de forma super rigurosa, sino en base al análisis exploratorio. Debería probarse con otras variantes.\nBoston %&gt;% \n  mutate(dis.alta = cut(dis, breaks = c(0,3,Inf), \n                        include.lowest = TRUE,\n                        labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ dis.alta) %&gt;% tidy() %&gt;%\n  kbl(digits = 2, caption = \"Tabla 5. Precio según distancia\") %&gt;% kable_paper(\"hover\")\n\nTabla 5. Precio según distancia\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.73\n0.57\n34.69\n0\n\n\ndis.altaAlta\n5.32\n0.78\n6.79\n0\n\n\n\nBoston %&gt;% \n  mutate(rad.alta = cut(dis, breaks = c(0,10,Inf), \n                        include.lowest = TRUE,\n                        labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ rad.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Tabla 6. Precio según accesibilidad\") %&gt;% kable_paper(\"hover\")\n\nTabla 6. Precio según accesibilidad\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n22.53\n0.41\n54.79\n0.00\n\n\nrad.altaAlta\n-0.21\n4.14\n-0.05\n0.96\n\n\n\nBoston %&gt;% \n  mutate(tax.alta = cut(tax, breaks = c(0,350,500,Inf), \n                        include.lowest = TRUE, \n                        labels = c(\"Baja\",\"Media\",\"Alta\")) ) %&gt;%\n  lm(data = ., medv ~ tax.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Tabla 7. Precio según impuestos\") %&gt;% kable_paper(\"hover\")\n\nTabla 7. Precio según impuestos\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n25.88\n0.51\n51.16\n0\n\n\ntax.altaMedia\n-3.68\n0.96\n-3.83\n0\n\n\ntax.altaAlta\n-9.60\n0.87\n-11.06\n0\n\n\n\nBoston %&gt;% \n  mutate(black.cat = cut(b, breaks = c(0,100, 395,Inf), \n                         include.lowest = TRUE,\n                         labels = c(\"Baja\",\"Media\",\"Alta\")) ) %&gt;%\n  lm(data = ., medv ~ black.cat) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Tabla 8. Precio según población de color\") %&gt;% kable_paper(\"hover\")\n\nTabla 8. Precio según población de color\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n12.33\n1.58\n7.82\n0\n\n\nblack.catMedia\n11.63\n1.65\n7.03\n0\n\n\nblack.catAlta\n9.48\n1.72\n5.52\n0\n\n\n\nBoston %&gt;% \n  mutate(black.alta = cut(b, breaks = c(0, 100,Inf), \n                          include.lowest = TRUE,\n                          labels = c(\"Baja\",\"Alta\")) ) %&gt;% \n  lm(data = ., medv ~ black.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Tabla 8b. Precio según población de color\") %&gt;% kable_paper(\"hover\")\n\nTabla 8b. Precio según población de color\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n12.33\n1.59\n7.77\n0\n\n\nblack.altaAlta\n10.87\n1.64\n6.64\n0\n\n\n\n(NOTA: estas tablas se podrían haber hecho con un bucle. También notad que NO he mantenido la variable discretizada en los datos, aunque podría haberlo hecho.)"
  },
  {
    "objectID": "docs/Proyect01.html#importante",
    "href": "docs/Proyect01.html#importante",
    "title": "Predicción de precios de las casas en Boston",
    "section": "IMPORTANTE",
    "text": "IMPORTANTE\nLa fase de análisis exploratorio puede tener resultados interesantes por sí mismos. Es importante comentarlos y discutirlos adecuadamente, en relación con el objetivo del trabajo.\nPero sobre todo esta fase tiene como objetivo aprender de los datos de cara a la siguiente: modelización. Por tanto, es mucho más importante comentar, aquí o en la fase de modelización cuestiones cómo\n\nqué variables incluir en los modelos: aunque esto no es crucial para algunos algoritmos que seleccionan.\n\nb.cómo las vamos a incorporar: en función de los resultados previos podemos queremos incluir transformaciones no lineales, discretizaciones, agrupando categorías, etc."
  },
  {
    "objectID": "docs/Proyect01.html#muestras-de-entrenamiento-y-prueba",
    "href": "docs/Proyect01.html#muestras-de-entrenamiento-y-prueba",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Muestras de entrenamiento y prueba",
    "text": "Muestras de entrenamiento y prueba\nEn el análsisis exploratorio, hemos visto que varias variables explicativas podrían ser transformadas tomando logaritmos o polinomios, discretizando, etc. Todo esas transformaciones se pueden hacer en el pre-procesado de tidymodels.\nA continuación, hacemos la partición de los datos reservando una proporción del 80% como conjuntos de datos de entrenamiento y el 20% restante como prueba.\n\nset.seed(1)\nbostonPart &lt;- Boston %&gt;% initial_split(prop = .8)"
  },
  {
    "objectID": "docs/Proyect01.html#modelos-de-regresión-lineal",
    "href": "docs/Proyect01.html#modelos-de-regresión-lineal",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Modelos de regresión lineal",
    "text": "Modelos de regresión lineal\nSe pueden probar muchisimo modelos de regresión lineal. Demasiados, como deberiáis saber.1 Si nuestro objetivo es predecir, es preferible estimar, como hemos discutivos, un modelo (o modelos) más “complejos” mediante regresión regularizada (LASSO y/o “ridge regression”); por ejemplo, un modelos con un polinomio de orden grande o muchas interacciones en lugar de ir probando modelos cuadráticos o cúbicos o solo unas pocas interacciones. Por contra, si nuestro objetivo es interpretar qué variables afectan y cuánto a la variables dependiente, podemos estimar el modelo de regresión lineal después de haber estimado mediante LASSO para aprender qué variables parecen ser relevantes.\nEn general, no haremos esto, pero aquí probaremos un modelo de regresión lineal para el precio como variable dependiente y todas las variables restantes como variables independientes; es decir, sin ninguna relación no lineal. Estimamos este modelo aquí como una extensión del análisis exploratorio, pero considerando correlaciones parciales (ceteris paribus): el efecto de cada variable, manteniendo el resto constante. Entrenamos el modelo con el conjunto de datos de entrenamiento. A continuación se muestran todos los coeficientes. \nlm1_receta &lt;- training(bostonPart) %&gt;%            \n  recipe(medv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) \n\nlm1_modelo &lt;- linear_reg(mode= \"regression\", penalty = 0) %&gt;%\n                    set_engine(\"lm\")\n\nlm1_flujo &lt;- workflow() %&gt;%\n  add_recipe(lm1_receta) %&gt;%\n  add_model(lm1_modelo)\n\nlm1_flujo_est &lt;- lm1_flujo %&gt;% fit(data = training(bostonPart)) \n\nlm1_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy() %&gt;% \n   kbl(digits = 2, caption = \"Tabla 9. Modelo de Regresión\") %&gt;% kable_paper(\"hover\")\n\nTabla 9. Modelo de Regresión\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.41\n6.06\n5.35\n0.00\n\n\nchasYes\n3.15\n0.97\n3.24\n0.00\n\n\ncrim\n-0.09\n0.04\n-2.25\n0.02\n\n\nzn\n0.04\n0.02\n2.58\n0.01\n\n\nindus\n0.03\n0.07\n0.43\n0.67\n\n\nnox\n-14.95\n4.42\n-3.38\n0.00\n\n\nrm\n4.07\n0.49\n8.35\n0.00\n\n\nage\n0.00\n0.02\n-0.33\n0.74\n\n\ndis\n-1.44\n0.23\n-6.14\n0.00\n\n\nrad\n0.32\n0.07\n4.37\n0.00\n\n\ntax\n-0.01\n0.00\n-3.18\n0.00\n\n\nptratio\n-0.88\n0.15\n-5.72\n0.00\n\n\nb\n0.01\n0.00\n3.45\n0.00\n\n\nlstat\n-0.55\n0.06\n-9.64\n0.00\n\n\n\nLos resultados del modelo con todas las variables son similares a los anteriores con solo una variable cada vez, aunque la edad NO es significativa (ceteris paribus). \nlm2_receta &lt;- training(bostonPart) %&gt;%            \n                recipe(medv ~ chas + crim + zn + indus + nox + rm + \n                    age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n                step_log(medv)\n\nlm2_flujo &lt;- workflow() %&gt;%\n  add_recipe(lm2_receta) %&gt;%\n  add_model(lm1_modelo)\n\nlm2_flujo_est &lt;- lm2_flujo %&gt;% fit(data = training(bostonPart)) \n\nlm2_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy() %&gt;% \n   kbl(digits = 3, caption = \"Tabla 10. Modelo de Regresión (en logaritmos)\") %&gt;% kable_paper(\"hover\")\n\nTabla 10. Modelo de Regresión (en logaritmos)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n4.133\n0.237\n17.438\n0.000\n\n\nchasYes\n0.108\n0.038\n2.854\n0.005\n\n\ncrim\n-0.012\n0.002\n-7.123\n0.000\n\n\nzn\n0.001\n0.001\n1.821\n0.069\n\n\nindus\n0.002\n0.003\n0.785\n0.433\n\n\nnox\n-0.714\n0.173\n-4.135\n0.000\n\n\nrm\n0.083\n0.019\n4.353\n0.000\n\n\nage\n0.000\n0.001\n-0.154\n0.877\n\n\ndis\n-0.051\n0.009\n-5.589\n0.000\n\n\nrad\n0.016\n0.003\n5.700\n0.000\n\n\ntax\n-0.001\n0.000\n-4.322\n0.000\n\n\nptratio\n-0.036\n0.006\n-5.941\n0.000\n\n\nb\n0.000\n0.000\n3.447\n0.001\n\n\nlstat\n-0.030\n0.002\n-13.213\n0.000\n\n\n\nNotad que la edad sigue sin ser significativa. Pero esto puede deberse a que la relación es no lineal en edad."
  },
  {
    "objectID": "docs/Proyect01.html#modelos-de-regresión-lineal-regularizada",
    "href": "docs/Proyect01.html#modelos-de-regresión-lineal-regularizada",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Modelos de regresión lineal regularizada",
    "text": "Modelos de regresión lineal regularizada\nAquí vamos a considerar solamente un variante de regresión regularizada, LASSO, pero debéis recordar que también existe “ridge regression”. De hecho, hemos discutido que en determinadas situaciones puede ser preferible a LASSO.\nA partir del análisis exploratorio de datos deberíamos decidir tanto qué variables considerare en el modelo como la forma de incluirla (no linealidad, interacciones, etc.). En el caso de LASSO, no es muy crucial puesto que el propio algoritmo se encargará de no seleccionar aquellas no relevantes, así que podemos incluir más variables de las que a priori consideremos más útiles. En otros algoritmos, esto puede tener efectos negativos sobre el funcionamiento del modelo (ej. “overfitting”).\nEn cualquier caso, existen varias cuestiones a tener en cuenta. En primer lugar, tenemos indicios de que puede ser conveniente transformar la variables dependiente en logaritmos. Esto implica que consideraremos estimar los modelos tanto para la variable en niveles como en logaritmos. También tenemos que considerar distintas variantes de transformaciones para las variables explicativas: ¿qué interacciones considerar? ¿qué formas de no linealidad: polinomios o discretización de variables discretas? Para variables categóricas, ¿reagrupamos categorías?\nPor simplicidad, solo considero unas pocas especificaciones (diferentes combinaciones de variables); vosotros debéis considerar más, aunque quizás no tengáis que reportar todas. Lo importante es justificar por qué se ha decidido probar esas variantes (en particular, en función del análsis exploratorio) y por qué se han elegido las que consideréis. NOTAD que podemos partir directamente de un modelo LASSO muy general sin haber hecho ningún modelo de regresión lineal previo.\nEn particular, en los modelos LASSO solo mostraremos resultados para la variable dependiente en logaritmos; pero vosotros debéis probar y mostrar alguno con la variable dependiente en niveles. Sí consideraré algunas especificaciones usando polinomios o discretizando algunas variables continuas para capturar no linealidades y usando interacciones.\nAdemás de especificar las variables dependiente y explicativas del modelo, la receta debe incluir un preprocesado de las variables adecuado a este algoritmo. No se pueden pasar factores a LASSO, por lo que debemos convertirlos en dummies con step_dummy, y las variables continuas se deben estandarizar.\nrecetaLASSO1 &lt;- training(bostonPart) %&gt;%            \n  recipe(lmedv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n  step_cut(b, breaks = c(0, 350, 395, 500), \n           include_outside_range = TRUE) %&gt;% \n  step_normalize(all_predictors(), -all_nominal()) %&gt;%\n  step_poly(lstat, age, degree = 8) %&gt;% \n  step_dummy(b, chas) %&gt;% \n  step_interact(terms = ~ rm:(nox + starts_with(\"age_\") + starts_with(\"lstat_\"))) %&gt;%  \n  step_interact(terms = ~ nox:(crim + starts_with(\"age_\") + starts_with(\"lstat_\"))) %&gt;% \n  step_interact(terms = ~ starts_with(\"b_\"):(crim + starts_with(\"age_\")))\n\nrecetaLASSO2 &lt;- training(bostonPart) %&gt;%            \n                recipe(lmedv ~ chas + crim + zn + indus + nox + rm + \n                    age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n                step_cut(age, breaks = seq(0,100,10), \n                         include_outside_range = TRUE) %&gt;% \n                step_cut(dis, breaks = c(0, 3, 10), \n                         include_outside_range = TRUE) %&gt;% \n                step_cut(b, breaks = c(0, 350, 395, 500), \n                         include_outside_range = TRUE) %&gt;% \n                step_normalize(all_predictors(), -all_nominal()) %&gt;%\n                step_poly(lstat, degree = 8) %&gt;% \n                step_dummy(age, dis, b, chas)  %&gt;% \n                step_interact(terms = ~ rm:(nox + starts_with(\"age_\") + starts_with(\"lstat_\"))) %&gt;%  \n                step_interact(terms = ~ nox:(crim + starts_with(\"age_\") + starts_with(\"lstat_\"))) %&gt;% \n                step_interact(terms = ~ starts_with(\"b_\"):(crim + starts_with(\"age_\")))\nDefinimos los modelos, con el hiperparámetro de penalización para ajustar, y combinamos la receta y el modelo en un flujo.\n\nmodeloLASSO &lt;- linear_reg(mode= \"regression\", penalty = tune()) %&gt;%\n                    set_engine(\"glmnet\")\n\nflujoLASSO1 &lt;- workflow() %&gt;%\n  add_recipe(recetaLASSO1) %&gt;%\n  add_model(modeloLASSO)\n\nflujoLASSO2&lt;- workflow() %&gt;%\n  add_recipe(recetaLASSO1) %&gt;%\n  add_model(modeloLASSO)\n\nLa estimación del modelo implica ajustar el hiperparámetro \\(\\lambda\\) mediante validación cruzada en la muestra de entrenamiento. Necesitamos probar varios varios rangos de valores para el hiperparámetro.\nset.seed(9753)\nBoston_cv &lt;- training(bostonPart) %&gt;% vfold_cv(v=10)\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 1), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso1_flujo_tuned &lt;- flujoLASSO1 %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \nlasso1_flujo_tuned %&gt;% autoplot()\n\n####\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.02), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso1_flujo_tuned &lt;- flujoLASSO1 %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso1_flujo_tuned %&gt;% autoplot()\n\nlasso1_flujo_tuned %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 11. Mejores lambdas en el Modelo 1 de LASSO\") %&gt;% kable_paper(\"hover\")\n\nTabla 11. Mejores lambdas en el Modelo 1 de LASSO\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0036\nrmse\nstandard\n0.1689\n10\n0.0123\npre0_mod10_post0\n\n\n0.0040\nrmse\nstandard\n0.1690\n10\n0.0119\npre0_mod11_post0\n\n\n0.0044\nrmse\nstandard\n0.1692\n10\n0.0116\npre0_mod12_post0\n\n\n0.0032\nrmse\nstandard\n0.1692\n10\n0.0129\npre0_mod09_post0\n\n\n0.0048\nrmse\nstandard\n0.1695\n10\n0.0114\npre0_mod13_post0\n\n\n\n# lambda1 &lt;- 0 #\nlambda1 &lt;- lasso1_flujo_tuned %&gt;% select_best(metric = \"rmse\")\nNotad que muestro dos búsquedas de valores, refinando en la segunda la zona que aparecía como más probable en la primera. En general, se deberían probar varios rangos para el hiper-parámetro buscando una forma de U para el valor con mínimo error; se puede empezar con rangos amplios y luego buscar valores en un rango más fino, entorno al valor donde se ve el mínimo. NO está claro que queráis mostrarlos todos o incluso que queráis mostrar más de uno.\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.2), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso2_flujo_tuned &lt;- flujoLASSO2 %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso2_flujo_tuned %&gt;% autoplot()\n\n\n\nFigura 12. Ajuste de lamdba, modelo 2\n\n\n####\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.02), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso2_flujo_tuned &lt;- flujoLASSO2 %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso2_flujo_tuned %&gt;% autoplot()\n\n\n\nFigura 12. Ajuste de lamdba, modelo 2\n\n\nlasso2_flujo_tuned  %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 12. Mejores lambdas en el Modelo 2 de LASSO\") %&gt;% kable_paper(\"hover\")\n\nTabla 12. Mejores lambdas en el Modelo 2 de LASSO\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0036\nrmse\nstandard\n0.1689\n10\n0.0123\npre0_mod10_post0\n\n\n0.0040\nrmse\nstandard\n0.1690\n10\n0.0119\npre0_mod11_post0\n\n\n0.0044\nrmse\nstandard\n0.1692\n10\n0.0116\npre0_mod12_post0\n\n\n0.0032\nrmse\nstandard\n0.1692\n10\n0.0129\npre0_mod09_post0\n\n\n0.0048\nrmse\nstandard\n0.1695\n10\n0.0114\npre0_mod13_post0\n\n\n\n# lambda2 &lt;- 0 \nlambda2 &lt;- lasso2_flujo_tuned %&gt;% select_best(metric = \"rmse\")\nVamos a finalizar los modelos y ver sus métricas en la muestra de prueba.\nLASSO_final &lt;- list() \nLASSO_final[[1]] &lt;- flujoLASSO1 %&gt;% \n                    finalize_workflow(lambda1) %&gt;% \n                    last_fit(bostonPart)  %&gt;% \n                    collect_metrics()\n\nLASSO_final[[2]] &lt;- flujoLASSO2 %&gt;% \n                    finalize_workflow(lambda2) %&gt;% \n                    last_fit(bostonPart)  %&gt;% \n                    collect_metrics()\n\nLASSO_final %&gt;% bind_rows(.id = \"modelo\") %&gt;% \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 13. Métricas de LASSO\") %&gt;% kable_paper(\"hover\")\n\nTabla 13. Métricas de LASSO\n\n\nmodelo\n.config\nrmse\nrsq\n\n\n\n\n1\npre0_mod0_post0\n0.2411\n0.67\n\n\n2\npre0_mod0_post0\n0.2411\n0.67\n\n\n\nEn este caso, ambos modelos tienen un comportamiento predictivo muy similar. Esto puede deberse a que ambos son muy similares, salvo por usar polinomios en lugar de discretizaciones. No es raro que ambos tengan un comportamiento predictivo similar, puesto que ambas formas aproximan (aunque de forma ligeramente distinta) relaciones no lineales."
  },
  {
    "objectID": "docs/Proyect01.html#knn",
    "href": "docs/Proyect01.html#knn",
    "title": "Predicción de precios de las casas en Boston",
    "section": "kNN",
    "text": "kNN\nConsideremos modelos de k vecinos. Este método es suficientemente flexible para considerar posibles no linealidades en todas las variables. Vamos a ajustar el número de vecinos por validación cruzada con el precio y su logaritmo como variables dependientes. Podríamos considerar otras variantes como usar el absoluto para la distancia o usar más o menos variables explicativas en el modelo; también usar discretizaciones de variables continuas (aunque esto no es muy habitual ni útil en kNN).\nNOTA: como vemos aquí, conviene empezar con un rango amplio de valores para el hiperparámetro, sin probar cada valor del rango (ej., entre 1 y 21 aumentando valores de 2 en 2), y luego refinar en la zona donde parece estar el mínimo.\n\nknn1_receta &lt;- training(bostonPart) %&gt;%            \n  recipe(medv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n  step_normalize(all_predictors(), -all_nominal()) %&gt;%\n  step_dummy(all_nominal_predictors())\n  \nknn1_modelo &lt;- nearest_neighbor(mode = \"regression\",\n                  neighbors = tune(), dist_power = 2) %&gt;% \n                set_engine(\"kknn\")\n\nknn1_flujo &lt;- workflow() %&gt;%\n  add_recipe(knn1_receta) %&gt;%\n  add_model(knn1_modelo)\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 21), trans = NULL),   \n                          levels = 11)                     \n\nset.seed(1)\nknn1_flujo_tuned &lt;- knn1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn1_flujo_tuned  %&gt;% autoplot()\n\n\n\n\nFigura 13. Ajuste de k vecinos, modelo 1\n\n\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 11), trans = NULL),   \n                          levels = 11)                     \n###########\nset.seed(1)\nknn1_flujo_tuned &lt;- knn1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn1_flujo_tuned  %&gt;% autoplot()\n\n\n\n\nFigura 13. Ajuste de k vecinos, modelo 1\n\n\n\n\nknn1_flujo_tuned  %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 14. k-vecinos óptimo en el Modelo 1\") %&gt;% kable_paper(\"hover\")\n\nTabla 14. k-vecinos óptimo en el Modelo 1\n\n\nneighbors\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n4\nrmse\nstandard\n4.0733\n10\n0.3965\npre0_mod04_post0\n\n\n3\nrmse\nstandard\n4.0959\n10\n0.4083\npre0_mod03_post0\n\n\n5\nrmse\nstandard\n4.1115\n10\n0.3893\npre0_mod05_post0\n\n\n6\nrmse\nstandard\n4.1555\n10\n0.3876\npre0_mod06_post0\n\n\n7\nrmse\nstandard\n4.1946\n10\n0.3897\npre0_mod07_post0\n\n\n\nk1 &lt;- knn1_flujo_tuned %&gt;% select_best(metric = \"rmse\")\nknn2_receta &lt;- training(bostonPart) %&gt;%            \n  recipe(lmedv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n  step_normalize(all_predictors(), -all_nominal()) %&gt;%\n  step_dummy(all_nominal_predictors())\n\nknn2_flujo &lt;- workflow() %&gt;%\n  add_recipe(knn2_receta) %&gt;%\n  add_model(knn1_modelo)\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 11), trans = NULL),   \n                          levels = 11)  \n\nset.seed(1)\nknn2_flujo_tuned &lt;- knn2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn2_flujo_tuned  %&gt;% autoplot()\n\n\n\nFigura 14. Ajuste de k vecinos, modelo 2\n\n\nknn2_flujo_tuned  %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 15. k-vecinos óptimo en el Modelo 2\") %&gt;% kable_paper(\"hover\")\n\nTabla 15. k-vecinos óptimo en el Modelo 2\n\n\nneighbors\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n5\nrmse\nstandard\n0.1722\n10\n0.0099\npre0_mod05_post0\n\n\n6\nrmse\nstandard\n0.1726\n10\n0.0104\npre0_mod06_post0\n\n\n4\nrmse\nstandard\n0.1726\n10\n0.0096\npre0_mod04_post0\n\n\n7\nrmse\nstandard\n0.1733\n10\n0.0107\npre0_mod07_post0\n\n\n8\nrmse\nstandard\n0.1745\n10\n0.0110\npre0_mod08_post0\n\n\n\nk2 &lt;- knn2_flujo_tuned %&gt;% select_best(metric = \"rmse\")\nEl número óptimo de vecinos es\n\n\n\nneighbors\n.config\n\n\n\n\n4\npre0_mod04_post0\n\n\n\n\n\n\nneighbors\n.config\n\n\n\n\n5\npre0_mod05_post0\n\n\n\nknn_final &lt;- list() \nknn_final[[1]] &lt;- knn1_flujo %&gt;% \n                    finalize_workflow(k1) %&gt;% \n                    last_fit(bostonPart)  %&gt;% \n                    collect_metrics()\n\nknn_final[[2]] &lt;- knn2_flujo %&gt;% \n                    finalize_workflow(k2) %&gt;% \n                    last_fit(bostonPart)  %&gt;% \n                    collect_metrics()\n\nknn_final %&gt;% bind_rows(.id = \"modelo\") %&gt;% \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 16. Métricas de kNN\") %&gt;% kable_paper(\"hover\")\n\nTabla 16. Métricas de kNN\n\n\nmodelo\n.config\nrmse\nrsq\n\n\n\n\n1\npre0_mod0_post0\n4.2681\n0.7289\n\n\n2\npre0_mod0_post0\n0.2031\n0.7350\n\n\n\nComparando estos resultados con los de la Tabla para LASSO, queda claro que kNN tiene una mejor capacidad predictiva, tanto para la variable de precio como usando el logaritmo del precio. Sin embargo, estos modelos no nos dicen mucho sobre qué factores afectan a esa predicción (no tenemos ni modelo paramétrico y contrastes, ni representación gráficas o medidas de importancia)."
  },
  {
    "objectID": "docs/Proyect01.html#árboles-de-regresión",
    "href": "docs/Proyect01.html#árboles-de-regresión",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Árboles de regresión",
    "text": "Árboles de regresión\nPasamos a considerar modelos de árboles de decisión. Notad que para ajustar el coste de complejidad puede ser necesario varios rangos. Dado que hemos visto que sistemáticamente el modelo con el logaritmo del precio predice mejor, nos centramos en ese modelo (aunque esto es obviamene una elección y quizás deberían probarse más).\narbol2_receta &lt;- training(bostonPart) %&gt;%            \n  recipe(lmedv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) \n\narbol2_modelo &lt;-  decision_tree(mode = \"regression\", \n                                     cost_complexity = tune()) %&gt;% \n                          set_engine(\"rpart\") \n\narbol2_flujo &lt;- workflow() %&gt;%\n  add_recipe(arbol2_receta) %&gt;%\n  add_model(arbol2_modelo)\n\narbol_grid &lt;- grid_regular(cost_complexity(range = c(0, 0.01), trans = NULL),   \n                          levels = 11)                     \nset.seed(1)\narbol2_flujo_tuned &lt;- arbol2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = arbol_grid                          \n                          ) \n\narbol2_flujo_tuned  %&gt;% autoplot()\n\n\n\nFigura 15. Ajuste de árboles, modelo 2\n\n\narbol2_flujo_tuned  %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 17. Coste de complejidad  en el Modelo 1\") %&gt;% kable_paper(\"hover\")\n\nTabla 17. Coste de complejidad en el Modelo 1\n\n\ncost_complexity\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.002\nrmse\nstandard\n0.1898\n10\n0.0119\npre0_mod03_post0\n\n\n0.001\nrmse\nstandard\n0.1898\n10\n0.0122\npre0_mod02_post0\n\n\n0.000\nrmse\nstandard\n0.1899\n10\n0.0123\npre0_mod01_post0\n\n\n0.003\nrmse\nstandard\n0.1935\n10\n0.0123\npre0_mod04_post0\n\n\n0.004\nrmse\nstandard\n0.1971\n10\n0.0117\npre0_mod05_post0\n\n\n\ncost2 &lt;- arbol2_flujo_tuned %&gt;% select_best(metric = \"rmse\")\narbol_final &lt;- arbol2_flujo %&gt;% \n                    finalize_workflow(cost2) %&gt;% \n                    last_fit(bostonPart)  \n\narbol_final %&gt;%  collect_metrics() %&gt;%  \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 18. Métricas del árbol\") %&gt;% kable_paper(\"hover\")\n\nTabla 18. Métricas del árbol\n\n\n.config\nrmse\nrsq\n\n\n\n\npre0_mod0_post0\n0.2064\n0.7394\n\n\n\nVemos que el mejor árbol de regresión es mejor que LASSO y similar a kNN (en logaritmos). Además podemos ver el flujo del árbol para hacernos una idea de qué factores están afectando a la predicción\narb &lt;- arbol_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() \n\nrpart.plot(arb$fit)\n\n\n\nFigura 16a. Mejor árbol de regresión, modelo 2\n\n\nTambién podemos recurrir a medidas de importancia de las variables.\narbol_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\nFigura 16b. Importancia en el mejor árbol de regresión, modelo 2\n\n\nEstos resultado son interesantes, más allá de su capacidad predictiva, porque son informativos son las interacciones entre distintas características. Como sabemos y podemos ver, los árboles trabajan discretizando las variables continuas discretizadas. Pero además implican distintas interacciones entre rangos de las variables para el resultado final. Por ejemplo, vemos que en los niveles superiores del árbol tenemos distintos niveles de población desfavorecida en el barrio, lstat; de hecho, vemos también (como era esperable) que es la variable con mayor valor de la importancia. Pero según los distintos valores de lstat importan diferentes características: cuando lstat es bajo (\\(&lt;10\\)) el precio viene determinado por el número de habitaciones de la vivienda, mientras que cuando es alto por la cantidad de contaminación o la proporición de gente de color en el vecindario."
  },
  {
    "objectID": "docs/Proyect01.html#random-forests",
    "href": "docs/Proyect01.html#random-forests",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Random Forests",
    "text": "Random Forests\nIntentamos ver si un modelo de “random forests” puede mejorar al árbol de regresión u otros modelos.\nrf2_receta &lt;- arbol2_receta \n\nrf2_modelo &lt;-  rand_forest(mode = \"regression\",\n                                       mtry = tune(), trees = 100) %&gt;% \n                          set_engine(\"ranger\", importance = \"impurity\")\n\nrf2_flujo &lt;- workflow() %&gt;%\n  add_recipe(rf2_receta) %&gt;%\n  add_model(rf2_modelo)\n\nrf_grid &lt;- grid_regular(mtry(range = c(1, 12), trans = NULL),   \n                          levels = 12)                     \n\nrf2_flujo_tuned &lt;- rf2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = rf_grid                          \n                          ) \n\nrf2_flujo_tuned %&gt;% autoplot()\n\n\n\nFigura 17. Ajuste de RF, modelo 2\n\n\nrf2_flujo_tuned  %&gt;% show_best(metric = \"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Tabla 19. Ajuste de Random Forest  en el Modelo 2\") %&gt;% kable_paper(\"hover\")\n\nTabla 19. Ajuste de Random Forest en el Modelo 2\n\n\nmtry\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n8\nrmse\nstandard\n0.1366\n10\n0.0095\npre0_mod08_post0\n\n\n6\nrmse\nstandard\n0.1366\n10\n0.0087\npre0_mod06_post0\n\n\n9\nrmse\nstandard\n0.1369\n10\n0.0090\npre0_mod09_post0\n\n\n7\nrmse\nstandard\n0.1374\n10\n0.0088\npre0_mod07_post0\n\n\n5\nrmse\nstandard\n0.1374\n10\n0.0092\npre0_mod05_post0\n\n\n\nmtry2 &lt;- rf2_flujo_tuned %&gt;% select_best(metric = \"rmse\")\nEl número óptimo de variables a usar (aleatoriamente) en cada nodo son\n\n\n\nmtry\n.config\n\n\n\n\n8\npre0_mod08_post0\n\n\n\nPor último finalizamos el modelo\nrf_final &lt;- rf2_flujo %&gt;% \n                    finalize_workflow(mtry2) %&gt;% \n                    last_fit(bostonPart)  \n\nrf_final %&gt;%  collect_metrics() %&gt;%  \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 20. Métricas de RF\") %&gt;% kable_paper(\"hover\")\n\nTabla 20. Métricas de RF\n\n\n.config\nrmse\nrsq\n\n\n\n\npre0_mod0_post0\n0.1627\n0.8225\n\n\n\nEl modelo de “Random Forest” incluso mejora claramente a “kNN”. En este caso, podemos ver qué variables han resultados mejores predictores del precio.\nrf_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\nFigura 18. Importancia en el mejor RF, modelo 2\n\n\nEste gráfico nos indica que la variable más importante (con diferencia) es la relacionada con la “pobreza” de la zona en la que se encuentra la casa. Después nos encontramos una característica de la casa en sí (número de habitaciones, aunque realmente es la media de la zona) y la criminalidad de la zona. No existe un criterio formal para decidir en que punto parar determinar qué variables son importantes. Quizás en este caso se puede “argumentar” que hay una caída mayor de la importancia después de la contaminación de la zona, la calidad de las escuelas y la distancia al centro."
  },
  {
    "objectID": "docs/Proyect01.html#footnotes",
    "href": "docs/Proyect01.html#footnotes",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Notas",
    "text": "Notas\n\n\nTodo esta discusión sobre modelos de regresión lineal aplica a regresión logística para problemas de clasificación.↩︎"
  },
  {
    "objectID": "docs/Tema04.html#de-los-datos-en-bruto-a-la-información",
    "href": "docs/Tema04.html#de-los-datos-en-bruto-a-la-información",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "De los datos en bruto a la información",
    "text": "De los datos en bruto a la información\n\n\n\nEl AED es una fase inicial importante, con dos objetivos:\n\nConocer nuestros datos e identificar problemas → Preprocesamiento\n\nqué variables, tipo de información, calidad (información faltante, inconsistencias, problemas en combinación de datos)\n\nAnálisis descriptivo: identificar patrones y encontrar escenarios de análisis\n\nNO hay una “receta”: el proceso es diferente con distintos datos o con los mismos datos para diferentes objetivos\n\nEs un proceso iterativo para descubrir información"
  },
  {
    "objectID": "docs/Tema04.html#caso-de-estudio-pymes-europeas",
    "href": "docs/Tema04.html#caso-de-estudio-pymes-europeas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Caso de Estudio: PYMES Europeas",
    "text": "Caso de Estudio: PYMES Europeas\n\nUna consultora analiza 500 PYMES europeas fundadas entre 1980-2020 para:\n\nEvaluar salud financiera y solvencia\nIdentificar patrones de productividad\nAnalizar riesgo crediticio\nOfrecer recomendaciones de inversión\n\nFuente de datos: pymes_europa.csv\n\ninformación: diccionario_pymes.csv\n\n\n\n\n28 variables (identificación, financieras, productividad, riesgo)\nSectores: Tecnología, Manufactura, Servicios, Construcción, etc.\nPaíses: España, Alemania, Francia, Italia, Portugal, y Europa del Este\nPeríodo: Empresas fundadas entre 1980-2020\n\n\n\nObjetivo del AED:\n\nLimpiar y preprocesar los datos\nEntender los datos (distribuciones y relaciones entre variables)\nDescubrir patrones (riesgo de las empresa, diferencias por sector y país)"
  },
  {
    "objectID": "docs/Tema04.html#contexto-y-reconomicimiento-de-los-datos",
    "href": "docs/Tema04.html#contexto-y-reconomicimiento-de-los-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Contexto y reconomicimiento de los datos",
    "text": "Contexto y reconomicimiento de los datos\n\n\nContexto: conocimiento previo de los datos (fuente, cómo están almacenados, etc.)\nCargar los datos\n\n\nlibrary(rio)\npymes &lt;- import(\"data/pymes_europa.csv\")\n\n\nReconocimiento inicial de las características: ¿todo como esperamos?\n\nnúmero de observaciones y de variables\ntipo de cada variable\nvisualizar los datos\n\n\n\n\ncontexto:\n\nfuente (de dónde han salido)\ncómo están almacenados (.csv, .xlsx, …)\n\nReconocimiento\n\n\nView(pymes)\nhead(pymes)\nnames(pymes)\ndim(pymes)\n\nstr(pymes)\n\n\n\nConsultar el “diccionario” de datos\n\nDescripción de cada variable y unidades de medida\nTipo de variable esperado\n\n\n\ndiccionario &lt;- read_csv(\"data/diccionario_pymes.csv\")"
  },
  {
    "objectID": "docs/Tema04.html#identificar-problemas-de-calidad-en-los-datos",
    "href": "docs/Tema04.html#identificar-problemas-de-calidad-en-los-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Identificar Problemas de Calidad en los Datos",
    "text": "Identificar Problemas de Calidad en los Datos\n\nVerificar que las variables la información y el tipo adecuado\n\nAlgunas variables deberían ser numéricas:\n\n\n\npymes &lt;- pymes |&gt;\n  mutate( anio_fundacion = as.numeric(anio_fundacion),\n          empleados = as.numeric(empleados),\n          liquidez_ratio = as.numeric(liquidez_ratio)  )\n\n\n\nanio_fundacion es carácter (debería ser numérica)\nempleados es carácter (debería ser numérica)\n\nliquidez_ratio es carácter (debería ser numérica)\n\n\n\nDetectar inconsistencias en texto, fechas, unidades, etc.\n\nEj.: en sector, “Tecnología”, “tecnologia”, “TECNOLOGÍA” son la misma categoría\neste tipo de problemas se puede descubrir más adelante.\n\n\n\n# Homogeneizar texto\npymes &lt;- pymes |&gt; \n  mutate( sector = str_to_lower(sector),\n          sector = str_replace_all(sector, \"tecnologia\", \"tecnología\"),\n          sector = str_replace_all(sector, \"farmaceutico\", \"farmacéutico\"),\n          sector = str_replace_all(sector, \"energia\", \"energía\") )"
  },
  {
    "objectID": "docs/Tema04.html#identificar-problemas-cont.",
    "href": "docs/Tema04.html#identificar-problemas-cont.",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Identificar Problemas (cont.)",
    "text": "Identificar Problemas (cont.)\n\n\nLas variables con información categórica deben ser factores\n\n\npymes &lt;- pymes |&gt;\n  mutate(across(c(sector, pais, tipo_propiedad, tamano_ciudad), \n                ~parse_factor(.x))) |&gt;\n  mutate(rating_credito = factor(rating_credito, \n                           levels = c(\"AAA\", \"AA\", \"A\", \n                                      \"BBB\", \"BB\", \"B\", \n                                      \"CCC\", \"CC\", \"C\", \"D\"),\n                           ordered = TRUE)\n  )\n\n\n\n# Verificar\npymes |&gt; select(where(is.factor)) |&gt; str()\n\n\n\nIdentificar Valores Faltantes (NAs)\n\n\npymes |&gt; summary()\n\npymes |&gt; \n  summarise(across(everything(), ~sum(is.na(.)))) |&gt;\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"NAs\") |&gt;\n  filter(NAs &gt; 0) |&gt;\n  arrange(desc(NAs))\n\n\nInterpretación:\n\nVariables financieras: empresas que no reportan información\nebitda, beneficio_neto: ~40 empresas sin datos\nroe tiene NAs porque depende de beneficio_neto\n\n\n\nPodríamos decidir borrar o reemplazar los NAs, pero se suele preferir decidir al modelizar"
  },
  {
    "objectID": "docs/Tema04.html#identificar-problemas-y-3",
    "href": "docs/Tema04.html#identificar-problemas-y-3",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Identificar Problemas (y 3)",
    "text": "Identificar Problemas (y 3)\n\nDetectar y eliminar filas duplicadas\n\n\ny filas vacias?\n\n\nsum(duplicated(pymes))\npymes &lt;- pymes |&gt; distinct()\n\n\nVariables que contienen información redundante\n\nEj., activos_total y total_recursos son pasivos + patrimonio_neto (igualdad contable)\n\n\n\npymes &lt;- pymes |&gt; select(-total_recursos)\n\n\nRenombrar variables (para mayor claridad), generar nuevas\n¿Mantenemos solo algunas variables u observaciones?\nOtras…\n\n\nNO ES UNA RECETA: más adelante podemos volver atrás, para rehacer o tomar decisiones\n\n\nResumen de Limpieza Realizada\nPreprocesamiento completado:\n\nTipos de variables corregidos (texto → numérico)\nInconsistencias de texto homogeneizadas\nVariables categóricas convertidas a factores\nDuplicados eliminados\nVariables redundantes eliminadas\nNAs identificados (mantener por ahora)\n\nDatos limpios: Ahora podemos comenzar el análisis exploratorio\n\n# Dimensiones finales\ndim(pymes)\n\n\n\n\nDos tipos de preguntas siempre serán útiles para hacer descubrimientos dentro de sus datos\n\n\n¿Qué tipo de variación tiene cada variable? (análisis univariante)\n¿Qué tipo de relaciones se produce entre las variables (covariación)? (análisis multivariante)\n\n\nLa respuesta implica analizar distribuciones, numérica y/o gráficamenente.\n\nEl análisis es diferente si las variables son numéricas o categóricas"
  },
  {
    "objectID": "docs/Tema04.html#patrones-de-variación-en-los-datos",
    "href": "docs/Tema04.html#patrones-de-variación-en-los-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Patrones de variación en los datos",
    "text": "Patrones de variación en los datos\n\nQueremos entender cómo cambian los valores de una variable entre distintas observaciones (p. e., ventas de diferentes empresas), es decir, su distribución\n\ndiferentes técnicas según el tipo de variable (numérica o categórica).\n\n\n\n\n\nAspectos a observar en la distribución\n\nInconsistencias: categorías erróneas (“unknown”), valores fuera de rango\nConcentración de valores: ceros, números redondos o repeticiones excesivas → ¿errores o patrones reales?\nCategorías: ¿tienen sentido? ¿agrupar de manera diferente? ¿reagrupar si hay pocas observaciones?\nContinuas: dispersión o asimetría (usar log?); ¿discretizar (ej. grupos de edad)?\nValores inusuales (“atípicos” o “outliers”): no encajan en el patrón general\n\n¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?\n\n\n\n\n\nNotar que el análisis es diferente para variables categóricas y numéricas: es conveniente describirlas por separado en un documento final\nDetectar inconsistencias en la distribución de valores o en las categorías: p.e., “unknown” en job de Bank\nValores frecuentes, concentración en valores concretos (p.e., ceros, números “redondos”, etc.): ¿por qué se producen? ¿son “esperables”?\n¿Tienen sentido las categorías de las variables cualitativas? agrupar valores con pocas observaciones crear categorías más “finas”o más agregadas (ej. de países a continentes)\n¿Sería preferible discretizar alguna variable continua? Ej., grupos de edad\nVariables con alta dispersión o distribución asimétrica (logs?)\nVariables con información redundante, homogeneizar valores, normalidad(?)\nValores inusuales (“atípicos” o “outliers”): no encajan en el patrón general\n¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?"
  },
  {
    "objectID": "docs/Tema04.html#variables-categóricas",
    "href": "docs/Tema04.html#variables-categóricas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Variables Categóricas",
    "text": "Variables Categóricas\n\nDescribimos la distribución con frecuencias y proporciones: con summary(), table(), mode() o con summarize(), count()\n\n\npymes |&gt; count(sector, sort = TRUE) \n\npymes |&gt; count(sector, sort = TRUE) |&gt; mutate(prop = n / sum(n))\n\n\nEste análisis puede detectar situaciones donde queremos agrupar categorías:\n\ndos clases similares\nclases con pocas observaciones (análisis más difícil: visualizaciones desequilibradas, resultados poco confiables)\n\n\n\n\nEstadísticos poco confiables (muestra pequeña)\nVisualizaciones desequilibradas\nRiesgo de overfitting en modelos posteriores\nDificultan comparaciones robustas\n\n\n\nlibrary(forcats)\npymes &lt;- pymes |&gt;\n  mutate(sector_agrupado = fct_lump_min(sector, min = 15, \n                                  other_level = \"Otros\"), \n         sector_agrupado = fct_collapse(sector, \n                                  Grupo1 = c(\"manufactura\", \"textil\"),\n                                  Grupo2 = c(\"servicios\", \"comercio\")))"
  },
  {
    "objectID": "docs/Tema04.html#variables-categóricas-visualización",
    "href": "docs/Tema04.html#variables-categóricas-visualización",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Variables Categóricas: Visualización",
    "text": "Variables Categóricas: Visualización\n\n\n\nLos gráficos ayudan a entender y explicar mejor la distribución de los datos.\n\n\n\nPara distribuciones discretas, la mejor visualización de la distribución de los datos es un histograma.\n\n\n# frecuencias absolutas\nggplot(data = pymes) + geom_bar(aes(x = tipo_propiedad))  \n# frecuencias relativas (proporciones)\nggplot(data = pymes)+ geom_bar(aes(x = tipo_propiedad, \n                                   y = after_stat(prop), group = 1))\n\n# Variantes\npymes |&gt; count(tipo_propiedad) |&gt; ggplot() + \n  geom_bar(aes(x = tipo_propiedad, y = n), stat = \"identity\")\n\nggplot(data = pymes) + geom_bar(aes(x = tipo_propiedad)) +\n  theme(axis.text.x = element_text(angle = 90))\n\nggplot(data = pymes) + geom_bar(aes(x = tipo_propiedad)) +\n  coord_flip()\n\n# barra vertical\nggplot(data = pymes) + geom_bar(aes(x = \"\", fill = tipo_propiedad))\n\n\nObservación: la mayor parte de las PYMEs son empresas familiares o S.L."
  },
  {
    "objectID": "docs/Tema04.html#variables-cuantitativas",
    "href": "docs/Tema04.html#variables-cuantitativas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Variables Cuantitativas",
    "text": "Variables Cuantitativas\n\n\nEstadísticas descriptivas básicas con summary()\n\n\nsummary(pymes)\n\n\nInformación adicional con funciones para estadísticos (rango, varianza, cuartiles, asimetría)\n\n\nsummary(pymes$ingresos)\npymes |&gt;\n  summarise(\n    media = mean(ingresos, na.rm = TRUE),\n    mediana = median(ingresos, na.rm = TRUE),\n    sd = sd(ingresos, na.rm = TRUE),\n    min = min(ingresos, na.rm = TRUE),\n    max = max(ingresos, na.rm = TRUE),\n    q25 = quantile(ingresos, 0.25, na.rm = TRUE),\n    q75 = quantile(ingresos, 0.75, na.rm = TRUE),\n    NAs = sum(is.na(ingresos)))\n\n\nInterés particular en amplia variabilidad, distribución asimétrica"
  },
  {
    "objectID": "docs/Tema04.html#variables-cuantitativas-visualización",
    "href": "docs/Tema04.html#variables-cuantitativas-visualización",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Variables Cuantitativas: Visualización",
    "text": "Variables Cuantitativas: Visualización\n\nPara distribuciones numéricas, la visualización de la distribución de los datos puede realizarse con un histograma, con la densidad o ambos.\n\n\nggplot(pymes) + geom_histogram(aes(x = empleados), bins = 30)\nggplot(pymes) + geom_density(aes(x = empleados))\n\nggplot(pymes, aes(x=empleados)) + \n  geom_histogram(aes(y=after_stat(density)), bins = 30) + \n  geom_density()\n\n\n\n¿Por qué hay acumulación en los últimos valores?\n\n\n\nDefinición de pyme: si más de 250 empleados, error?\nAcumulación para evitar perder beneficios de pyme\n\n\n\n\n\nProbar varios anchos de intervalo (distintas formas de discretizar la variable continua de )\nSi observamos una distribución muy asimétrica, considerar escala logarítmica\n\n\nggplot(pymes, aes(x = ingresos)) + geom_histogram(bins = 30) \nggplot(pymes, aes(x = ingresos)) + geom_histogram(bins = 30) + \n  scale_x_log10()"
  },
  {
    "objectID": "docs/Tema04.html#variables-cuantitativas-visualización-con-boxplots",
    "href": "docs/Tema04.html#variables-cuantitativas-visualización-con-boxplots",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Variables Cuantitativas: Visualización con Boxplots",
    "text": "Variables Cuantitativas: Visualización con Boxplots\n\nÚtiles para analizar dispersión, identificar outliers y comparar distribuciones\n\n\nggplot(pymes, aes(y = roe)) +\n  geom_boxplot()\n\n\n\n\n¿A qué se deben los valores extremos?\n\nErrores de medición → corregir o eliminar (ej. ¿es consistente el ROE = -31% con otras variables de la empresa?)\nCasos reales extremos → mantener o analizar por separado (empresas excepcionales)\n\n\n\nIdentificar Outliers: Método IQR\nMétodo estándar: IQR (Rango Intercuartílico)\n\n# Calcular límites\nQ1 &lt;- quantile(pymes$roe, 0.25, na.rm = TRUE)\nQ3 &lt;- quantile(pymes$roe, 0.75, na.rm = TRUE)\nIQR &lt;- Q3 - Q1\nlimite_inf &lt;- Q1 - 1.5 * IQR\nlimite_sup &lt;- Q3 + 1.5 * IQR\n\n# Contar outliers\npymes &lt;- pymes |&gt;\n  mutate(roe_outlier = roe &lt; limite_inf | roe &gt; limite_sup)\n\ntable(pymes$roe_outlier)\n\nDecisión: NO eliminar automáticamente, investigar causa\nOutliers pueden ser:\n\nErrores de medición → corregir o eliminar\nCasos reales extremos → mantener o analizar por separado\nEmpresas excepcionales → insights valiosos"
  },
  {
    "objectID": "docs/Tema04.html#herramientas-automáticas",
    "href": "docs/Tema04.html#herramientas-automáticas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Herramientas Automáticas",
    "text": "Herramientas Automáticas\n\ndatasummary_skim(): vista rápida de todas las variables (o algunas seleccionada), distinguiendo automáticamente por tipo\n\nútil para uso personal, no necesariamente para incluir en informe final\n\n\n\n\ninspirada en skim() de skimr\n\ndevuelve un data frame\nVentajas: Visión rápida, histogramas inline, NAs, estadísticos\n\nDataExplorer\nEl paquete janitor contiene herramientas para limpieza de datos\n\n\n\nlibrary(modelsummary)\npymes |&gt; datasummary_skim()\n\n\nDataExplorer\n\n\nlibrary(DataExplorer)\nplot_bar(pymes)        # para TODAS las variables categóricas\nplot_histogram(pymes)  # para TODAS las variables numéricas\n\ncreate_report(pymes)\n\n\ndlookr ofrece heramientas para diagnóstico y exploración de datos\n\n\n\ndevolviendo data frame (para usar con kable())\n\n\n\nTambién podemos subir los datos a un chatbot de IA (ej., chatGPT) y pedir que haga en análisis exploratorio y limpieza"
  },
  {
    "objectID": "docs/Tema04.html#análisis-de-covariación",
    "href": "docs/Tema04.html#análisis-de-covariación",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Análisis de Covariación",
    "text": "Análisis de Covariación\n\n\nLa variación describe el comportamiento dentro de una variable\n\n\n\nLa covariación describe relaciones entre variables: tendencia a que los valores de una variable dependan de la otra\nEstudiamos la distribución condicional de una variable \\(\\small{Y}\\) dados los valores de otra \\(\\small{X}\\)\n\nSi \\(\\small{\\Pr(Y|X=x_1) = \\Pr(Y|X=x_0) =  \\Pr(Y) \\Rightarrow}\\) \\(\\small{Y}\\) NO depende de \\(\\small{X}\\)\n\np.e., el valor esperado de \\(\\small{Y}\\) será el mismo para distintos valores de \\(\\small{X}\\)\n\nSi la probabilidad condicional de que \\(\\small{Y}\\) tome valores altos (o bajos) depende de lo que sabemos de \\(\\small{X}\\), se puede predecir (su valor esperado) a partir del valor de \\(\\small{X}\\)\n\nPunto de partida para formular modelos que explican patrones complejos de los datos\n\n\n\n¿qué explica la relación sugerida por el patrón de covariación?\n¿cómo de fuerte es la relación?\n¿otras variables pueden afectar a la relación? ¿varían por subgrupos?\n¿es la covariación una relación causal?\n\n\n\nLa forma de visualizar la posible existencia de relaciones depende del tipo de variables"
  },
  {
    "objectID": "docs/Tema04.html#dos-variables-categóricas",
    "href": "docs/Tema04.html#dos-variables-categóricas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables categóricas",
    "text": "Dos variables categóricas\n\n\nPartimos de la distribución conjunta de frecuencias absolutas\n\n\npymes |&gt; count(sector, rating) |&gt;\n  pivot_wider(names_from = rating, values_from = n)\n\n\nPERO es más informativo la distribución condicional de frecuencias relativas \n¿Hay la misma proporción de los rating alto y bajo en distintos sectores?\n\n\ndatos &lt;- pymes |&gt; count(sector, rating) |&gt; \n  group_by(sector) |&gt; mutate(prop= n/sum(n)) |&gt; select(-n) \ndatos |&gt; pivot_wider(names_from = sector, values_from = prop)      # tabla\n\ndatos |&gt; ggplot() + geom_bar(aes(x=sector, y=prop, fill = rating), # gráfico\n                      stat = \"identity\")\n\nggplot(pymes, aes(x = sector, fill = rating)) +                    # + directo\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::percent)\n\n\n¿Hay la misma distribución de sectores en distintos paises?\n\n\nggplot(pymes, aes(x = pais, fill = sector )) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::percent)\n\n\n\nla distribución condicional es bastante diferente para varias categorías\nestán relacionadas"
  },
  {
    "objectID": "docs/Tema04.html#dos-variables-numéricas",
    "href": "docs/Tema04.html#dos-variables-numéricas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables numéricas",
    "text": "Dos variables numéricas\n\nLa forma obvia de visualizar relaciones entre variables continuas es un gráfico de dispersión; añadir smoothers ayuda a apreciar un patrón en los puntos\n\n\nggplot(pymes, aes(x = activos_total, y = ingresos)) +\n  geom_point() + geom_smooth(method = \"lm\", se = TRUE) +\n  scale_x_log10() +  scale_y_log10() \n\n\n\nObservamos una relación positiva entre activos e ingresos, pero en logaritmos\nla relación es NO lineal\n\n\n\nCon GGally obtenemos una primera visión de conjunto\n\nPERO la automatización no permite ajustes (ej., escala logarítmica)\n\n\n\nlibrary(GGally)\n#pymes |&gt; select(where(is.numeric)) |&gt; ggpairs()\npymes |&gt; select(empleados:ingresos) |&gt; ggpairs()\n\n\nOtra posibilidad: discretizar una variable continua y usar las técnicas anteriores\n\n\npymes |&gt; mutate(empleados_group = cut(empleados, \n                                      breaks=seq(0, 250, by=25))) |&gt;\n  ggplot() + geom_boxplot(aes(y = ingresos, x = empleados_group)) + \n             scale_y_log10()\n\n\n\nno existe relación entre ingresos y empleados"
  },
  {
    "objectID": "docs/Tema04.html#dos-variables-numéricas-correlación",
    "href": "docs/Tema04.html#dos-variables-numéricas-correlación",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables numéricas: correlación",
    "text": "Dos variables numéricas: correlación\n\nPodemos estimar modelos de regresión con dos variables continuas\n\n\nsummary(lm(data = pymes, ingresos ~ activos_total) )\n\n\nY también correlaciones para dos (o múltiples) variables\n\n\npymes |&gt;\n  select(activos_total, ingresos, empleados, \n         beneficio_neto, roe, roa) |&gt;\n  cor(use = \"complete.obs\")\n\n\nInterpretación:\n\nCorrelación alta entre activos_total e ingresos (0.82)\nROE y ROA moderadamente correlacionados\nempleados correlacionado con tamaño financiero\n\n\n\nO visualizar las correlaciones\n\n\ndatos &lt;- pymes |&gt;\n  select(activos_total, pasivos, patrimonio_neto, ingresos, \n         ebitda, beneficio_neto, liquidez_ratio, roe, roa,\n         deuda_patrimonio, empleados)\n\ndatos |&gt; correlate() |&gt; plot()\n\nlibrary(corrplot)\ndatos |&gt; cor() |&gt; corrplot()\ndatos |&gt; cor() |&gt; corrplot.mixed()"
  },
  {
    "objectID": "docs/Tema04.html#una-variable-numérica-y-una-categórica",
    "href": "docs/Tema04.html#una-variable-numérica-y-una-categórica",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Una variable numérica y una categórica",
    "text": "Una variable numérica y una categórica\n\n\n¿Es diferente la distribución de Y (continua) por categorías de X?\n\nCuidado: podemos necesitar escala logarítmica\nTambién ajustes como reordenar las categorías de un factor (forcats), rotar los ejes, etc.\n\nPodemos usar histogramas o densidades, en un mismo gráfico o con facetas\n\n\ng0 &lt;- ggplot(pymes, aes(x = ingresos)) +  scale_x_log10()\ng0 + geom_density(aes(color = tamano_ciudad))\ng0 + geom_density() + facet_wrap(~sector)\n\n\nCon muchos grupos o uno muy pequeño, es difícil notar diferencias\n\n\npymes &lt;- pymes |&gt; mutate(rating = fct_collapse(rating_credito, \n                        \"Rating Alto\" = c(\"AAA\", \"AA\", \"A\", \"BBB\"),\n                        \"Rating Bajo\" = c(\"BB\", \"B\", \"CCC\", \"CC\", \"C\", \"D\")))\nggplot(pymes, aes(x = ingresos, color = rating)) +     # color = rating_credito\n            geom_density() + scale_x_log10()\n\n\nTambién con gráficos de caja (menos información pero más fácil de comparar)\n\n¿cómo se vería este gráfico si no hubiesemos homogeneizado sector?\n\n\n\nggplot(pymes, aes(x = sector, y = ingresos, fill = sector)) +\n  geom_boxplot() + scale_y_log10()"
  },
  {
    "objectID": "docs/Tema04.html#una-variable-numérica-y-una-categórica-cont.",
    "href": "docs/Tema04.html#una-variable-numérica-y-una-categórica-cont.",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Una variable numérica y una categórica (cont.)",
    "text": "Una variable numérica y una categórica (cont.)\n\n\nTambién podemos calcular estadísticos concretos de la distribución de Y para distintos valores de X\n\n\npymes |&gt; group_by(sector) |&gt;\n  summarise(media = mean(ingresos, na.rm = TRUE),\n            mediana = median(ingresos, na.rm = TRUE),\n            n = n(),\n            sd = sd(ingresos, na.rm = TRUE))\n\n\nNOTA: una regresión simple equivale a calcular la media de la variable continua por grupos\n\n\\[\n\\scriptsize\nE[Y|X]=\\beta_0+\\beta_1 X \\Rightarrow\n\\begin{cases}\nE[Y|X=0] &=\\beta_0 \\\\\nE[Y|X=1]&=\\beta_0+\\beta_1\n\\end{cases}\n\\]\n\nlm(data = pymes, ingresos ~ sector) |&gt; summary()\n\n\n¿Y mediante la correlación? NO tiene sentido cuando una variable es categórica\n\n\npymes |&gt; select(ingresos, sector) |&gt; cor()"
  },
  {
    "objectID": "docs/Tema04.html#crear-variables-derivadas",
    "href": "docs/Tema04.html#crear-variables-derivadas",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Crear Variables Derivadas",
    "text": "Crear Variables Derivadas\n\n\nEl AED puede sugerir creación de nuevas variables y transformación de otras (ej., logaritmos para variables con distribución asimétrica)\n\n\n\nAntigüedad de la empresa:\nTenemos anio_fundacion pero queremos analizar madurez\nAnálisis temporal reveló que empresas fundadas en diferentes décadas se comportan diferente\nPara comparaciones: necesitamos años desde fundación, no año absoluto\n\n\n# Calcular antigüedad\npymes &lt;- pymes |&gt;\n  mutate(antiguedad = 2024 - anio_fundacion)\n\nAhora podemos: - Comparar empresas jóvenes (&lt; 5 años) vs consolidadas (&gt; 15 años) - Analizar relación antigüedad-rentabilidad - Identificar si hay “valle de la muerte” para PYMEs\n\n\nDiscretizar (agrupar) variables continuas: la distribución de empleados tiene un rango muy amplio\n\nDisyuntiva: Discretizar simplifica comunicación (Pequeña vs. Mediana) pero se pierde información (tratamos igual a 11 y 49 empleados)\n\n\n\npymes |&gt; ggplot() + geom_histogram(aes(x = empleados))\npymes &lt;- pymes |&gt;\n  mutate(tamano_empresa = cut(empleados, breaks = c(0, 10, 50, 250, Inf),\n                 labels = c(\"Micro\", \"Pequeña\", \"Mediana\", \"Grande\"),\n                 include.lowest = TRUE) )\n\n\n\nFacilita comparaciones “Micro vs Pequeña vs Mediana”\nTratamos igual empresas de 11 y 49 empleados\nMantener ambas (continua para análisis, categórica para comunicación)\n\n\n\nCaso 3: Productividad laboral\nMotivación del AED:\nDel análisis bivariante vimos: - Ingresos correlacionados con empleados (r = 0.65) - Pero la relación no es proporcional - Queremos medir eficiencia: ingresos por empleado\n\n# Crear variable de productividad\npymes &lt;- pymes |&gt;\n  mutate(productividad_laboral = ingresos / empleados)\n\nEsta variable derivada permite: - Comparar eficiencia entre empresas de distinto tamaño - Identificar empresas sobre/sub-performando - Analizar productividad por sector (tech vs manufactura)\nInsight del AED posterior: Tecnología tiene productividad 3x mayor que Manufactura\n\n\nAgrupar categorías: la distribución de rating financiero mostró algunas categorías con pocas observaciones y otras con comportamiento similar\n\n\nDecisión de negocio: Crear tres grupos significativos\n\n# Agrupar ratings bajos\npymes &lt;- pymes |&gt;\n  mutate(\n    rating_agrupado = fct_collapse(rating_credito,\n      \"Grado Inversión\" = c(\"AAA\", \"AA\", \"A\", \"BBB\"),\n      \"Grado Especulativo\" = c(\"BB\", \"B\"),\n      \"Alto Riesgo\" = c(\"CCC\", \"CC\", \"C\", \"D\")\n    )\n  )\n\nJustificación: - “Grado Inversión”: bajo riesgo, acceso fácil a financiación - “Grado Especulativo”: riesgo moderado, típico de muchas PYMES - “Alto Riesgo”: problemas financieros serios, requiere atención\nEsta agrupación: - Es robusta estadísticamente (suficientes observaciones) - Tiene sentido de negocio (convención del mercado) - Facilita visualización y comunicación - Mantiene poder predictivo (verificado en análisis bivariante)\n\n# Visualización agrupada\nggplot(pymes, aes(x = rating_agrupado, fill = rating_agrupado)) +\n  geom_bar() \n\n\n\\(\\Rightarrow\\) Agrupar/Discretizar cuando:\n\n\n\nEl análisis previo mostró que es necesario\nTiene sentido de negocio\n\n\n\nLas categorías tienen comportamiento similar\nMejora la robustez sin perder información crítica\n\n\n\n\nRelación Rating - Variables Financieras\n\n# Ratio deuda/patrimonio por rating\nggplot(pymes, aes(x = rating_agrupado, y = deuda_patrimonio, \n                  fill = rating_agrupado)) +\n  geom_boxplot() +\n  scale_fill_manual(values = c(\"green3\", \"gold2\", \"red2\")) +\n  coord_cartesian(ylim = c(0, 3)) +\n  theme_minimal() +\n  labs(title = \"Ratio Deuda/Patrimonio por Categoría de Riesgo\",\n       x = \"Categoría de Riesgo\", y = \"Ratio Deuda/Patrimonio\") +\n  theme(legend.position = \"none\")\n\nInsight: Empresas de alto riesgo tienen mayor endeudamiento"
  },
  {
    "objectID": "docs/Tema04.html#la-promesa-de-la-automatización",
    "href": "docs/Tema04.html#la-promesa-de-la-automatización",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "La Promesa de la Automatización",
    "text": "La Promesa de la Automatización\n\nEl AED manualmente consume tiempo. Se pueden automatizar partes del proceso, pero con precaución\nVentajas de herramientas automatizadas: Velocidad, Exahaustividad, Primera Exploración\n\n\n\nVelocidad: generan reportes completos en segundos/minutos\nExhaustividad: revisan sistemáticamente todas las variables\nReproducibilidad: mismo código → mismos resultados\nPunto de partida: excelente para primera exploración\n\n\n\nLimitaciones críticas:\n\nRuido: muchos gráficos irrelevantes\nNo entienden contexto de negocio\nInterpretación superficial → No sugieren acciones específicas\n\nHerramientas de AED Automatizado\n\nHerramientas interactivas: GWalkR, explore, Radiant (también online)\nInformes completos automatizados con DataExplorer, dlookr, smartEDA, DataMaid\n\n\n\ncreate_report(pymes, y = ingresos)\n\n\n\nexplorar datos y/o realizar visualizaciones y tableros interactivos\nRadiant tanto para análisis exploratorio, visualización y transformación como para algunas modelizaciones\n\n\n\nDataExplorer: reporte HTML completo\n\nlibrary(DataExplorer)\n# Reporte completo automatizado\ncreate_report(pymes, \n              output_file = \"reporte_pymes.html\",\n              y = \"rating_agrupado\")\n\nGenera automáticamente:\n\nEstructura del dataset\nVariables con missing values\nDistribuciones univariantes\nCorrelaciones\nAnálisis bivariante con variable objetivo\n\nÚtil para: Primera exploración, compartir con no-técnicos\nLimitación: 100+ páginas sin priorización\ndlookr: Diagnóstico y análisis\nAdemás de diagnose() y describe()\n\nlibrary(dlookr)\n# Reporte web interactivo\npymes |&gt; \n  mutate(across(where(is.character), as.factor)) |&gt; \n  eda_web_report(\n    target = \"rating_agrupado\",\n    output_file = \"eda_pymes.html\",\n    author = \"Tu Nombre\"\n  )\n\nIncluye:\n\nDiagnóstico de calidad\nAnálisis univariante y bivariante\nTests estadísticos automáticos\nTransformaciones sugeridas\n\nÚtil para: Exploración técnica detallada\nLimitación: Requiere entender estadística para interpretar tests\nsmartEDA: Análisis exploratorio inteligente\nÚtil para: Balance entre detalle y usabilidad\n\n\nCuándo usar cada herramienta\n\n\n\n\n\n\n\nSituación\nHerramienta recomendada\n\n\n\n\nPrimera exploración de datos nuevos\nDataExplorer::create_report()\n\n\nDiagnóstico técnico de calidad\ndlookr::diagnose()\n\n\nEstadísticos rápidos con gráficos\nskimr::skim()\n\n\nExploración interactiva\nexplore::explore() o GWalkR\n\n\nReportes para stakeholders\nSmartEDA::ExpReport()\n\n\nAnálisis profundo experto\nManual (lo que hemos hecho)"
  },
  {
    "objectID": "docs/Tema04.html#ia-generativa-para-análisis-de-datos",
    "href": "docs/Tema04.html#ia-generativa-para-análisis-de-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "IA Generativa para Análisis de Datos",
    "text": "IA Generativa para Análisis de Datos\n\nEl prompt efectivo es clave (no solo “analiza”)\n\nAnaliza pymes_europa.csv. Variables clave: ingresos, roe, sector, país. \nContexto: PYMES europeas 2020-2024. ROE típico: 8-12%. \nDame: limpieza, descriptivos, visualizaciones, análisis por sector\nPregunta: ¿Qué características tienen empresas con ROE &gt; 15%?\n\nFortalezas\n\nCódigo rápido y documentado\nSugiere análisis adicionales\n\nLimitaciones críticas\n\nNo conoce el contexto (de negocio)\nAnálisis superficial\nRiesgo de errores: inventar patrones inexistentes, interpretaciones incorrectas, confundir correlación con causalidad\nLimitaciones técnicas: datos &lt; 100-200MB, resultados dependen del prompt\n\n\n\n\nGenerar código estándar rápidamente\n\n“Crea un boxplot de ingresos por sector”\n“Calcula correlaciones entre variables financieras”\n\nSugerir análisis adicionales\n\n“También podrías analizar la distribución por país”\n“Verifica si hay outliers usando el método IQR”\n\nExplicar conceptos\n\n“¿Qué significa un p-valor &lt; 0.05?”\n“¿Cómo interpreto un coeficiente de correlación negativo?”\n\nDocumentación automática\n\nGenera comentarios para el código\nCrea descripciones de hallazgos\n\n\n\n\n\nNo conoce tu contexto de negocio\n❌ IA: \"Un ROE de 5% es bajo\"\n✓ Experto: \"5% es normal en retail pero bajo en tech\"\nAnálisis superficial\n\nHace análisis estándar (correlaciones, medias, etc.)\nNO identifica patrones sutiles específicos del dominio\nNO formula hipótesis de negocio interesantes\n\nRiesgo de “hallucinations”\n❌ IA podría \"inventar\" patrones que no existen\n❌ Interpretaciones estadísticamente incorrectas\n❌ Confundir correlación con causalidad\nLimitación de tamaño\n\nChatGPT: datasets &lt; 100-200MB funcionan bien\nPara datos grandes: necesitas estrategias (sampling, agregación)\n\nDependencia de prompts\n\nResultado depende de cómo preguntes\nRequiere conocer qué preguntar (¡conocimiento previo!)\n\n\n\n\nEjemplo práctico con IA\nPrompt efectivo:\n\"Analiza pymes_europa.csv. Variables clave: ingresos, roe, \nsector, pais. \n\nContexto: son PYMES europeas 2020-2024. Un ROE típico es \n8-12%. Sectores principales: Manufactura, Servicios, Tecnología.\n\nPregunta de negocio: ¿Qué características tienen las empresas \ncon ROE &gt; 15%?\n\nDame: (1) Limpieza necesaria, (2) Estadísticos descriptivos, \n(3) Visualizaciones clave, (4) Análisis por sector\"\nPor qué es bueno: - Da contexto de negocio - Define rangos normales - Pregunta específica de negocio - Solicita análisis estructurado\nPrompt malo:\n\"Analiza este dataset\"\n→ Resultado: análisis genérico sin valor\n\n\nSIEMPRE:\n\nVerifica el código generado\n\n¿Usa las variables correctas?\n¿Maneja NAs apropiadamente?\n¿Las transformaciones tienen sentido?\n\nValida interpretaciones\n# IA sugiere: \"La correlación es 0.85, muy fuerte\"\n# TÚ verificas: ¿Es espuria? ¿Hay outliers influyendo?\n\n# IA dice: \"No hay diferencias entre sectores\"\n# TÚ verificas: ¿Usó el test apropiado? ¿Suficiente muestra?\nCuestiona recomendaciones\n\n¿Tienen sentido de negocio?\n¿Están respaldadas por los datos?\n¿Consideran el contexto del problema?"
  },
  {
    "objectID": "docs/Tema04.html#filosofía-automatización-inteligente",
    "href": "docs/Tema04.html#filosofía-automatización-inteligente",
    "title": "Tema 04 - Análisis Exploratorio de Datos (AED)",
    "section": "Filosofía: Automatización Inteligente",
    "text": "Filosofía: Automatización Inteligente\n\n\nFlujo recomendado\n\nExploración rápida → automatización para empezar\nIdentificar áreas de interés → ¿problemas? ¿relaciones/patrones? ¿sentido?\nAnálisis profundo manual\n\nLimpieza contextualizada\nVisualizaciones específicas\nInterpretación experta\n\nUso de IA como asistente → generar código, sugerir análisis\nValidación crítica SIEMPRE → verifica código, valida decisiones, cuestiona recomendaciones\n\n\n\n\nUsar IA como asistente\n\"Ayúdame a crear una visualización que compare \nROE por sector para empresas con &gt;50 empleados, \ndestacando el top 10% en cada sector\"\n\n\n\nReglas básicas\n\n❌ NO: Reportes automáticos , todas las visualizacion omo análisis final\n✓ SÍ: Automatización como punto de partida\n❌ NO: Confiar ciegamente en IA\n✓ SÍ: Validar críticamente todo\n\nRegla de oro: La automatización acelera, el expertise guía. Nunca al revés.\n\n\n\nEl modelo 80/20 para AED moderno\n20% del tiempo: Automatización - Herramientas de autoEDA para exploración inicial - IA para generar código estándar - Reportes automatizados para stakeholders\n80% del valor: Análisis experto - Interpretación basada en conocimiento del dominio - Decisiones sobre limpieza y transformaciones - Formulación de hipótesis de negocio - Validación y crítica de hallazgos - Recomendaciones accionables\nFlujo de trabajo recomendado\n# 5 minutos\npymes |&gt; skim()\npymes |&gt; diagnose()\ncreate_report(pymes)\n\n\nValidar y documentar\n\nVerificar todos los hallazgos importantes\nDocumentar decisiones y justificaciones\nCrear narrativa de negocio\n\n\n\nAdvertencias Importantes\nNO hagas esto:\n❌ Usar reportes automatizados como análisis final\n❌ Confiar ciegamente en interpretaciones de IA\n❌ Incluir todas las visualizaciones automáticas\n❌ Olvidar validar hallazgos automáticos\nDesarrolla criterio para saber cuándo confiar en automatización\nSÍ haz esto:\n✓ Usar automatización como punto de partida\n✓ Validar críticamente todo output automático\n✓ Combinar velocidad de herramientas con expertise humano\n✓ Mantener el contexto de negocio en el centro\nRegla de oro: La automatización acelera, el expertise guía. Nunca al revés.\n\n\n✓ Documentar por qué una herramienta sugirió algo\n\n\nEjemplo: Análisis Híbrido\nFlujo real de un análisis profesional:\n# 1. Exploración automática (5 min)\npymes |&gt; skim()\ndiagnose(pymes) |&gt; filter(missing_percent &gt; 10)\n\n# 2. Pregunta a IA (2 min)\n\"Sugiere visualizaciones para entender la relación \nentre tamaño de empresa y rentabilidad\"\n\n# 3. Código generado por IA (revisado por ti)\nggplot(pymes, aes(x = empleados, y = roe)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"loess\") +\n  scale_x_log10()\n\n# 4. TÚ interpretas con contexto de negocio (15 min)\n# Observas que empresas 20-50 empleados tienen ROE más alto\n# Investigas por qué: ¿eficiencia operativa? ¿sectores?\n# Validas con análisis adicional por sector\n# Formulas hipótesis de negocio\n\n# 5. TÚ decides acción (5 min)\n# \"Recomendar a inversores: PYMES 20-50 empleados \n# en sector Servicios muestran mejor rentabilidad...\"\n\n\nRecursos para profundizar\n\nautoEDA en R: Journal of Statistical Software paper\nIA para análisis: ChatGPT for EDA guide\nLimitaciones de LLMs: Statistical Modeling blog\n\n\n\nDistribución del Score de Inversión\n\n#| fig-show: asis\n#| fig-width: 10\n#| fig-height: 5\n\n# Visualizar distribución del score\nggplot(pymes, aes(x = factor(score_total))) +\n  geom_bar(fill = \"steelblue\") +\n  theme_minimal() +\n  labs(title = \"Distribución del Score de Inversión (0-9)\",\n       x = \"Score Total\", y = \"Número de empresas\")\n\n\n# Top empresas por score\npymes |&gt;\n  filter(score_total &gt;= 8) |&gt;\n  select(empresa_id, sector_agrupado, pais, roe, \n         liquidez_ratio, deuda_patrimonio, score_total) |&gt;\n  arrange(desc(score_total)) |&gt;\n  head(10) |&gt;\n  kable(digits = 2)\n\n\n\nResumen\nEl AED es fundamental para cualquier proyecto de datos:\n\nLo que logramos en este AED\n\nConocimos nuestros datos profundamente\n\n500 empresas, 28 variables, múltiples sectores y países\nIdentificamos y corregimos 11 tipos de problemas de calidad\n\nIdentificamos patrones de negocio\n\nTecnología lidera en productividad e innovación\nAlemania muestra las PYMES más sólidas financieramente\nRating crediticio correlaciona fuertemente con endeudamiento\n\nFormulamos hipótesis de investigación\n\nInversión en I+D asociada con mejor rentabilidad\nTamaño óptimo: 20-50 empleados para máxima eficiencia\nExportación y éxito correlacionados en ciertos sectores\n\n\n\nLecciones clave\nNO existe una receta única para AED:\n\nCada dataset es diferente (industria, escala, problemas)\nCada objetivo requiere enfoques distintos (predicción vs descripción)\nEs un proceso iterativo: descubrimiento → pregunta → análisis → descubrimiento\n\nEl proceso importa tanto como el resultado:\n\nDocumentar decisiones (por qué agrupaste, por qué eliminaste)\nJustificar transformaciones (qué motivó crear nuevas variables)\nSer transparente sobre limitaciones (qué NO pudimos responder)\n\n\nSobre herramientas automatizadas e IA\nLo que aprendimos:\n\nHerramientas de autoEDA: excelente punto de partida (regla 80/20)\nIA generativa: útil para código y documentación\nPero: interpretación requiere expertise y contexto de negocio\nValidación humana es siempre necesaria\n\nEnfoque profesional:\n\nUsa automatización para velocidad inicial\nAplica criterio experto para profundidad\nValida hallazgos críticamente\nMantén contexto de negocio en el centro\nDocumenta proceso y decisiones\n\n\nLa limpieza consume tiempo, pero es inversión\nTiempo típico en proyectos reales:\n\nLimpieza de datos: 40-50% del tiempo\nExploración y análisis: 30-40% del tiempo\nModelización: 10-20% del tiempo\nComunicación de resultados: 10-15% del tiempo\n\n¿Por qué invertir tanto en limpieza y AED?\nPorque datos limpios = análisis confiable\n\nDecisiones de negocio incorrectas por datos sucios: costosas\n“Garbage in, garbage out” es real\nAED previene sorpresas desagradables después\nTiempo en AED ahorra tiempo (y dinero) después\n\n\nPróximos pasos naturales\nDespués del AED, típicamente:\n\nFeature engineering: crear variables más sofisticadas\nModelización: predicción, clasificación, clustering\nValidación: dividir datos train/test, cross-validation\nDeployment: poner modelos en producción\nMonitoreo: verificar que modelos siguen funcionando\n\nPero todo comienza con un buen AED.\n\nUn AED bien hecho es como…\n\nMédico: Examen completo antes de diagnóstico\nDetective: Investigar escena del crimen antes de acusar\nArquitecto: Estudiar terreno antes de diseñar edificio\n\nNo se puede saltear. No hay atajos. Vale la pena hacerlo bien.\nSiguiente paso: Con datos limpios y entendidos, estamos listos para modelizar. Pero esa es otra historia…"
  },
  {
    "objectID": "docs/Tema02.html#limpieza-y-doma-de-datos",
    "href": "docs/Tema02.html#limpieza-y-doma-de-datos",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Limpieza y “doma” de datos",
    "text": "Limpieza y “doma” de datos\n\n\n\nEl ciclo de vida de los datos\n\n\n\n\n\n\n\n\n\nEl desafío real del análisis de datos:\n\n80% del tiempo de trabajo “sucio” : limpieza y preparación\n20% del tiempo: análisis y modelización\n\ntidyverse incluye una colección de bibliotecas con herramientes eficientes para el proceso de “tratamiento de datos” (“data wrangling”)\nEl objetivo es obtener un conjunto de datos ordenado y limpio para realizar el análisis eficientemente y obtener información útil para la toma de decisiones\n\n\n\nCiclo: Recolectar, unir, limpiar, recodificar, etc.\ntidyverse ofrece herramientas eficientes inspiradas en declaraciones de consulta SQL\nbasadas en una gramática de manipulación de datos"
  },
  {
    "objectID": "docs/Tema02.html#datos-ordenados-tidy-data-principios-fundamentales",
    "href": "docs/Tema02.html#datos-ordenados-tidy-data-principios-fundamentales",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Datos ordenados (‘tidy data’): Principios fundamentales",
    "text": "Datos ordenados (‘tidy data’): Principios fundamentales\n1.- Cada columna es una variable: mide el mismo atributo entre unidades\n2.- Cada fila es una observación (caso): misma unidad a través de atributos\n3.- Cada celda es un valor\n\n\n¿Qué es una unidad en la tabla? ¿a qué nivel medimos la información?\n\na nivel de cada compra realizada por un cliente en cada fecha, o\na nivel de cliente (todas sus compras), de tienda (todas sus ventas), etc.\n\nTenemos información similar y no redundante en una misma tabla\n\n\n\nAtributos o características (cuantitativos o cualitativos) diferentes en columnas diferentes; p.e., nombres de columnas no deben ser valores\n\n\nVariable = vector columna: forma natural para trabajar con datos\n\n\nMismo nivel de agregación en toda la tabla\nNo mezclar tipos de datos Ni almacenar múltiples valores\n\n\nUna tabla puede completar la información con uniones a tablas adicionales (ej., para variables codificadas)\ntidyverse es eficiente con datos ordenados"
  },
  {
    "objectID": "docs/Tema02.html#datos-no-ordenados",
    "href": "docs/Tema02.html#datos-no-ordenados",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Datos no ordenados",
    "text": "Datos no ordenados\n\n\n\n\n\n\n\n\n\nOtras estructuras como esta pueden tener sentido para mostrar información (o por convenciones)\nLa visualización es atractiva, PERO sobran filas para analizar los datos: ej., total de personas con hijos y sin pareja entre 30 y 39 años\n\n\n\nProblemas de estos datos:\n\nMeses están en columnas (son valores, no variables)\nFila “Total” mezcla niveles de agregación\nDifícil filtrar, agrupar o visualizar\n\nPor Qué Importan los Datos Ordenados\nVentajas:\n✓ Consistencia en todas las operaciones\n✓ Fácil manipulación con dplyr\n✓ Visualización directa con ggplot2\n✓ Compatible con modelización\n✓ Facilita colaboración\nEjemplo Práctico:\n\n# Con datos ordenados: FÁCIL\nventas %&gt;%\n  group_by(id_tienda, mes) %&gt;%\n  summarize(ventas_total = sum(total))\n\n# Con datos desordenados: COMPLEJO\n# Requiere reshape, limpieza, etc."
  },
  {
    "objectID": "docs/Tema02.html#caso-de-estudio-retailcorp",
    "href": "docs/Tema02.html#caso-de-estudio-retailcorp",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Caso de Estudio: RetailCorp",
    "text": "Caso de Estudio: RetailCorp\n\nContexto: Cadena de venta al por menor con 12 tiendas en España\nObjetivo: Analizar rendimiento de ventas para toma de decisiones estratégicas\n\n\n\nload(\"data/retail_data.RData\")\n\n\n\n\nRecibe datos de\n\nSistema de ventas (POS)\nCRM de clientes\nInventario de productos\nRRHH de empleados\nInformes Excel de gerentes\n\n\n\nProblemas Típicos:\n\nFormatos inconsistentes\nDatos duplicados\nValores ausentes\nEstructuras inadecuadas\nTablas dispersas"
  },
  {
    "objectID": "docs/Tema02.html#funciones-de-transformación-de-datos",
    "href": "docs/Tema02.html#funciones-de-transformación-de-datos",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Funciones de transformación de datos",
    "text": "Funciones de transformación de datos\n\nLa mayoría de operaciones pueden realizarse combinando 5 “verbos”:\n\nselect(): selecciona columnas (variables)\nfilter(): filtra (extraer) filas\nmutate(): crea nuevas columnas\narrange(): ordena filas\nsummarize(): crea resúmenes de la tabla\n\n\nMás la tubería %&gt;% o |&gt;\ny group_by()\n\nNOTA: existe una colección de “chuletas” de R, p.e., para transformación.\nTodos tienen como primer argumento un data frame, los siguientes describen qué hacer (con columnas o filas) y devuelven otro data frame"
  },
  {
    "objectID": "docs/Tema02.html#select",
    "href": "docs/Tema02.html#select",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "1. select()",
    "text": "1. select()\n\nSelecciona variables por nombres o posiciones de columnas, separados por comas\n\n\n\nEj., un analista solo necesita información básica de ventas\n\n\nselect(ventas, id_venta, fecha, id_tienda, id_producto, total)\n\nselect(ventas, 1:2, 5, 4, 12)\n\n\nAplicación Empresarial: el equipo de marketing solo necesita información de cliente y venta\n\n\nventas_mkt &lt;- select(ventas, \n                fecha, id_cliente, id_producto, total)"
  },
  {
    "objectID": "docs/Tema02.html#filter",
    "href": "docs/Tema02.html#filter",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "2. filter()",
    "text": "2. filter()\n\nConserva filas en las que una condición lógica (o varias separadas por comas) es verdadera\n\n\n\nCaso de Uso: Gerente quiere analizar ventas específicas con determinadas características\n\n\nventas_top      &lt;- filter(ventas, total &gt; 1000)\n\nventas_ene_2024 &lt;- filter(ventas, año == 2024, mes == 1)\n\nventas_mad_bcn  &lt;- filter(ventas, id_tienda %in% c(1, 2))\n\nventas_premium  &lt;- filter(ventas, \n                     total &gt; 1000 & descuento_porcentaje == 0)"
  },
  {
    "objectID": "docs/Tema02.html#encadenando-operaciones-con-tuberías-o",
    "href": "docs/Tema02.html#encadenando-operaciones-con-tuberías-o",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Encadenando operaciones con tuberías: %>% o |>",
    "text": "Encadenando operaciones con tuberías: %&gt;% o |&gt;\n\n\nLas operaciones encadenadas crean objetos intermedios o no son legibles\n\n\nventas_top        &lt;- filter(ventas, total &gt; 1000)\nventas_top_markt  &lt;- select(ventas_top, \n                       fecha, id_cliente, id_producto, total)\n\nventas_top_markt &lt;- select(filter(ventas, total &gt; 1000),\n                      fecha, id_cliente, id_producto, total)\n\n\n\n\n\ndatos %&gt;% filter(condicion) equivale a filter(datos, condicion)\nEl anidamiento con tuberías sigue el flujo natural de lectura\n\nToma una tabla y pásala a un comando que acepta y produce un data frame\nToma la nueva tabla resultante y pásala a otro comando\n\n\n\nventas_top_markt &lt;- ventas |&gt;                   \n                     filter(total &gt; 1000) |&gt;     \n                     select(fecha, id_cliente, id_producto, total)\n\n\n\n\nLos objetos intermedios son innecesarios\nAplicable a cualquier función: 10 |&gt; log() es log(10)\nLegible, fácil anidar operaciones: siempre toman y devuelve un data frame\n\n\nggplot2 + en lugar de %&gt;% (desarrollado antes)\nAtajo de teclado: Cmd / Ctrl + Mays + M\nTambién existe una tubería en R base: |&gt;"
  },
  {
    "objectID": "docs/Tema02.html#funciones-auxiliares-de-selección-de-columnas",
    "href": "docs/Tema02.html#funciones-auxiliares-de-selección-de-columnas",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Funciones auxiliares de selección (de columnas)",
    "text": "Funciones auxiliares de selección (de columnas)\n\n# Por rango de columnas\nventas |&gt; select(id_venta:id_tienda)\n\n# Excluir columnas\nventas |&gt; select(-descuento_porcentaje, -descuento_aplicado)\n\n# Por patrón de nombre\nventas |&gt; select(starts_with(\"id_\"))\nventas |&gt; select(ends_with(\"_porcentaje\"))\nventas |&gt; select(contains(\"descuento\"))\n\n# Por tipo de dato\nventas |&gt; select(where(is.numeric))\nventas |&gt; select(where(is.character))\n\n\npull(): extrae una única columna, como vector\n\n\nventas |&gt; pull(cantidad) |&gt; mean()\n\n\n\nlibrary(nycflights13)\nselect(flights, -(year:day))    # todas menos \"year, month, day\"\n\n\nnum_range(\"x\", 1:3): para x1, x2 y x3.\nmatches(): nombres que coinciden con una expresión regular\nmatches(\"(.)\\\\1\"): selecciona las variables que coinciden con una expresión regular (en este caso, cualquier variable que contenga caracteres repetidos)."
  },
  {
    "objectID": "docs/Tema02.html#mutate",
    "href": "docs/Tema02.html#mutate",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "3. mutate()",
    "text": "3. mutate()\n\n\n\nCrea o modifica variables mediante una fórmula a partir de otras columnas\n\n\n\n\n\n\n\n\n\nventas2 &lt;- ventas |&gt;\n  mutate(\n    precio_final_unitario = total / cantidad,\n    es_inicio_mes         = day(fecha) &lt;= 7\n  )\n\n\nFunciones para operar con fechas (usando lubridate)\n\n\nventas_tiempo &lt;- ventas |&gt;\n  mutate(\n    fecha_completa = as.Date(fecha),  # tipo de objeto \"fecha\"\n    semana_año = week(fecha),\n    nombre_mes = month(fecha, label = TRUE),\n    dias_desde_venta = Sys.Date() - fecha\n  )\n\n\n\nlubridate es parte de tidyverse"
  },
  {
    "objectID": "docs/Tema02.html#arrange",
    "href": "docs/Tema02.html#arrange",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "4. arrange()",
    "text": "4. arrange()\n\n\n\nre-ordena las filas de un data frame (todas las columnas)\n\nen orden ascendente (por defecto) o descendente con desc()\n\n\n\n\n\n\n\n\n\n\nCaso de Uso: Top 5 ventas más altas\n\n\nventas |&gt; \n  arrange(desc(total)) |&gt; slice(5) |&gt; \n  select(id_venta, fecha, total)  \n\n\nOrdenamientos múltiples: ordena por la primera variable y luego, en caso de empate, por la siguiente, etc.\n\n\nventas |&gt;\n  arrange(id_tienda, desc(total)) |&gt;\n  select(id_tienda, id_venta, total)\n\n\n\nsimilar a Excel\nsort() es para un vector"
  },
  {
    "objectID": "docs/Tema02.html#summarize",
    "href": "docs/Tema02.html#summarize",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "5. summarize()",
    "text": "5. summarize()\n\n\n\nCrea un nuevo conjunto de datos de una sola fila, con variables nuevas de un solo valor que resumen los datos completos\n\n\n\n\n\n\n\n\n\nCaso de Uso: KPIs para el dashboard ejecutivo\n\n\nKPIs &lt;- ventas |&gt;\n  summarize(\n    total_ventas       = n(),           # Volumen (núm. de filas)\n    ingresos_totales   = sum(total),    # Ingresos\n    ingresos_promedio  = mean(total),\n    ingresos_mediano   = median(total),\n    descuento_promedio = mean(descuento_porcentaje), # Descuentos\n    descuento_total    = sum(descuento_aplicado),\n    unidades_vendidas  = sum(cantidad),             # Productos\n    clientes_unicos    = n_distinct(id_cliente)     # Clientes \n                         # (núm. de filas distintas)\n  )"
  },
  {
    "objectID": "docs/Tema02.html#group_by-análisis-por-grupos",
    "href": "docs/Tema02.html#group_by-análisis-por-grupos",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "group_by(): Análisis por Grupos",
    "text": "group_by(): Análisis por Grupos\n\n\nCambia el alcance: cada función actúa dentro de grupos, no sobre toda la tabla\nEjemplo: encontrar la fecha con la mayor venta por tienda\n\n\nventas |&gt; group_by(id_tienda) |&gt;\n  arrange(desc(total)) |&gt;  \n  slice(1) |&gt;                     # Fila 1 (de cada grupo)\n  select(id_tienda, fecha, total)\n\n\n\n\nalternativa slice_max()\n\n\n\n\n\ngroup_by() + summarize() = cambia el nivel de análisis, agregando, p.e., de transacciones a tiendas, productos, etc.\n\nEn Excel: Tablas dinámicas, AGRUPARPOR() (y SUMAR.SI/SUMIF)\n\n\n\nventas                             # tabla a nivel de transacción\nventas |&gt;\n  summarize(ingresos = sum(total)) # resumen global\nventas |&gt;\n  group_by(id_tienda) |&gt;\n  summarize(ingresos = sum(total)) # resumen por tienda\n                                   # tabla a nivel de tienda\n\n\n\n\ngroup_by() similar a facet\nVer ventas |&gt; group_by(id_tienda): tibble muestra que hay dos grupos\ndatos de información/ventas por empleado a información por tienda\nDEBEN INCLUIRSE variables que se quieran mantener\nEjercicio:\n\nPara cada producto, calcular\n\n\nsuma de valor de ventas (variable total)\nmedia de valor de ventas (idem)\nmedia de cantidad vendida (variable cantidad)\n\n\nEn R y Excel\n¿Cuáles son los 5 productos con menor cantidad media vendida?\n\n\n\nventas_prod &lt;- ventas |&gt;\n  group_by(producto) |&gt;\n  summarize(\n    sum_total = sum(total),\n    med_total = mean(total),\n    med_cant  = mean(cantidad)\n  )\n\nexport(ventas, \"ventas.xlsx\")\n# misma secuencia en Tablas Dinamicas de Excel\n\n# igual que antes pero con este nueva tabla de datos a nivel producto\nventas_prod |&gt;\n  arrange(med_cantidad) |&gt; \n  head(5)"
  },
  {
    "objectID": "docs/Tema02.html#group_by-cont.",
    "href": "docs/Tema02.html#group_by-cont.",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "group_by() (cont.)",
    "text": "group_by() (cont.)\n\ngroup_by() + summarize() reduce filas: nueva tabla agregada a nivel de los grupos\n\n\ntabla_sum &lt;- ventas |&gt; group_by(id_tienda) |&gt;\n  summarize(ingresos = sum(total))\n\n\ngroup_by() + mutate() mantiene filas: añade columnas calculadas por grupo a nivel de la tabla original\n\n\ntabla_mut &lt;- ventas |&gt; group_by(id_tienda) |&gt;\n  mutate(ingresos = sum(total))\n\n\n\nEjemplo: Porcentaje de las ventas que representa cada transacción\n\n\nventas |&gt; group_by(id_tienda) |&gt;\n  mutate(\n    ventas_tienda = sum(total),\n    pct_de_ventas = total / ventas_tienda * 100\n  )"
  },
  {
    "objectID": "docs/Tema02.html#ungroup",
    "href": "docs/Tema02.html#ungroup",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "ungroup()",
    "text": "ungroup()\n\n\nIMPORTANTE: No olvidar ungroup() o .groups = \"drop\" después de terminar operaciones agrupadas\nCálculo de Porcentajes Globales: sin desagrupar, el segundo sum(total) suma por tienda → siempre da 100%\n\n\nventas |&gt;\n  group_by(id_tienda) |&gt;\n  mutate(ventas_tienda = sum(total)) |&gt;\n  ungroup() |&gt;\n  mutate(porcentaje = ventas_tienda / sum(total) * 100)\n\nventas |&gt;\n  group_by(id_tienda) |&gt;\n  mutate(ventas_tienda = sum(total),\n         .groups = \"drop\") |&gt;\n  mutate(porcentaje = ventas_tienda / sum(total) * 100)\n\n\n\n\nDespués de group_by() + mutate():\n\nSi tu siguiente operación debe ser GLOBAL → usa ungroup()\nSi debe seguir POR GRUPO → no uses ungroup()\n\nDespués de group_by() + summarize():\n\nsummarize() ya reduce un nivel de agrupación\nSi tenías múltiples grupos, sigue agrupado por los anteriores\nUsa .groups = “drop” o ungroup() para estar seguro\n\n\n\n\nFiltrar Top Global: sin desagrupar, será top 5 de cada tienda\n\n\nventas |&gt;\n  group_by(id_tienda) |&gt;\n  mutate(ventas_tienda = sum(total), \n         .groups = \"drop\" ) |&gt;\n  arrange(desc(ventas_tienda)) |&gt;\n  slice_head(n = 5)\n\n\nMedia Global después de agrupar: sin desagrupar, 1 fila por tienda (media mensual de cada tienda)\n\n\n# Ventas por tienda y mes\nventas_mes_por_tienda &lt;- ventas |&gt;\n  group_by(id_tienda, mes) |&gt;\n  summarize(total_mes = sum(total))\n\nventas_mensuales_medias &lt;- ventas_mes_por_tienda |&gt;\n  ungroup() |&gt;\n  summarize(media = mean(total_mes))\n# Resultado: 1 fila (media de todos los meses de todas las tiendas)\n\n\n\nRanking de Productos\n\n\nventas |&gt;\n  group_by(id_producto) |&gt;\n  summarize(\n    unidades_vendidas = sum(cantidad),\n    ingresos_totales = sum(total)\n  ) |&gt;\n  ungroup() |&gt;                     # posteriores NO por grupos \n  arrange(desc(ingresos_totales))\n# ungroup() innecesario con summarize en este caso\n\nAplicación: Segmentación de Clientes\n\n# Calcular valor del cliente\nvalor_cliente &lt;- ventas |&gt;\n  group_by(id_cliente) |&gt;\n  mutate(\n    num_compras_cliente = n(),\n    gasto_total_cliente = sum(total),\n    ticket_promedio = mean(total),\n    \n    # Clasificación RFM simplificada\n    recencia_dias = as.numeric(max(fecha) - min(fecha)),\n    frecuencia = n(),\n    monetario = sum(total)\n  ) |&gt;\n  ungroup()\n\nProblema: Análisis de ventas navideñas en Madrid\n\n# SIN pipe: difícil de leer, muchas variables intermedias\nventas_madrid &lt;- filter(ventas, id_tienda == 1)\nventas_madrid_navidad &lt;- filter(ventas_madrid, mes == 12)\nventas_resumen &lt;- summarize(ventas_madrid_navidad, \n                            total = sum(total),\n                            n = n())\n\n# CON pipe: flujo natural de lectura\nanalisis_navidad_madrid &lt;- ventas |&gt;\n  filter(id_tienda == 1) |&gt;\n  filter(mes == 12) |&gt;\n  summarize(\n    ingresos_totales = sum(total),\n    num_transacciones = n(),\n    ticket_promedio = mean(total)\n  )\n\nanalisis_navidad_madrid\n\nAnálisis Completo Paso a Paso\nObjetivo: Análisis de campaña de descuentos del Q4 2023\n\nanalisis_campana_q4 &lt;- ventas |&gt;\n  # 1. Filtrar período relevante\n  filter(año == 2023, trimestre == 4) |&gt;\n  \n  # 2. Agregar categoría de descuento\n  mutate(\n    tipo_descuento = case_when(\n      descuento_porcentaje == 0 ~ \"Sin descuento\",\n      descuento_porcentaje &lt;= 10 ~ \"Descuento bajo\",\n      descuento_porcentaje &lt;= 20 ~ \"Descuento medio\",\n      TRUE ~ \"Descuento alto\"\n    )\n  ) |&gt;\n  \n  # 3. Agrupar por tipo de descuento\n  group_by(tipo_descuento) |&gt;\n  \n  # 4. Calcular métricas\n  summarize(\n    num_ventas = n(),\n    ingresos_totales = sum(total),\n    ticket_promedio = mean(total),\n    unidades_vendidas = sum(cantidad),\n    .groups = \"drop\"\n  ) |&gt;\n  \n  # 5. Ordenar por ingresos\n  arrange(desc(ingresos_totales)) |&gt;\n  \n  # 6. Calcular porcentajes\n  mutate(\n    pct_ventas = round(num_ventas / sum(num_ventas) * 100, 1),\n    pct_ingresos = round(ingresos_totales / sum(ingresos_totales) * 100, 1)\n  )\n\nanalisis_campana_q4"
  },
  {
    "objectID": "docs/Tema02.html#funciones-auxiliares-para-filas",
    "href": "docs/Tema02.html#funciones-auxiliares-para-filas",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Funciones auxiliares para filas",
    "text": "Funciones auxiliares para filas\n\nExtraer filas pero NO por condición: por posición (slice(), slice_head()), aleatoriamente (slice_sample()), etc.\n\n\nventas |&gt; slice_max(total, n = 5) # Top 5 ventas\nventas |&gt; slice_sample(n = 100)   # sub-muestra aleatoria\n\n\ndistinct(): extrae sólo las filas únicas (una o varias variables)\n\n\nventas %&gt;% distinct(id_producto)\n\n\ndrop_na() y replace_na(): elimina/reemplaza filas con valores ausentes\n\n\n# Quita filas con NA en cualquier variable\nventas_completas &lt;- ventas %&gt;%\n  drop_na()                    \n\n# solo quita si precio_unitario es NA\nventas_completas_precio &lt;- ventas %&gt;%\n  drop_na(precio_unitario)  \n\n\n\nslice_head(), slice_tail(), slice_min(), slice_max()\n\n\nEliminar NA (valores ausentes), PERO\n\nen alguna variable, con na.rm=TRUE o filter(!is.na(x)) o drop_na(x)\nen todo el conjunto de datos con drop_na()\nen cor(), use = \"complete.obs\"\n\n\n\nReemplazar con un valor, PERO ¿cúal?\n\n\nNA por no presentarse a un examen es cero\nNA por no contestar a pregunta de renta o gasto es ¿cero?\n\n\nna.omit() vs. drop_na: el primero es de base (stats) el otro de tidyr"
  },
  {
    "objectID": "docs/Tema02.html#otras-funciones-auxilidares-de-tidyverse",
    "href": "docs/Tema02.html#otras-funciones-auxilidares-de-tidyverse",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Otras funciones auxilidares de tidyverse",
    "text": "Otras funciones auxilidares de tidyverse\n\n\nMuchas funciones son equivalentes a otras de R base:\n\nparse_number(), parse_factor(), etc. por as.numeric(), as.factor(), etc.\nbind_cols() y bind_rows() por cbind() y rbind()\nif_else() y case_when() para ejecución condicional (ifelse())\n\n\n\nventas |&gt;\n  mutate(\n    tipo_venta = if_else(total &gt; 1000, \"Alta\", \"Baja\"), # condición simple\n    categoria_cliente = case_when(              # múltiples condiciones\n      total &lt; 300  ~ \"Económico\",\n      total &lt; 1000 ~ \"Estándar\",\n      TRUE         ~ \"Premium\"               # OJO: convertir a factor\n    )\n  )\n\n\nDiscretizar variables: cut_interval(), cut_number(), cut_width()\n\n\nFunciones para fechas de lubridate: year(), month(), day(), quarter(), week()"
  },
  {
    "objectID": "docs/Tema02.html#funciones-auxiliares-de-creación-de-variables",
    "href": "docs/Tema02.html#funciones-auxiliares-de-creación-de-variables",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Funciones auxiliares de creación de variables",
    "text": "Funciones auxiliares de creación de variables\n\nrename(): cambiar el nombre de una columna\n\n\nventas_renamed &lt;- ventas |&gt;\n  rename(\n    fecha_venta = fecha,\n    monto_total = total\n  )\n\n\n\n\n\n\n\n\ntransmute(): como mutate() pero solo mantiene las variables creadas\nrelocate(): cambiar orden de columnas\n\n\n\nacross(): aplica la misma transformación a múltiples columnas\n\n\nventas |&gt; mutate(across(c(cantidad, subtotal:total), ~ log(.x)))\nventas |&gt; mutate(across(where(is.character), ~ parse_factor(.x)))\n\n\nOperadores aritméticos (+, -, *, /, ^, %/%, %%) y lógicos (&lt;, &lt;=, &gt;, &gt;=, !=)\nFunciones como log(), lag(), lead(), cumsum(), row_number() etc.\n\n\n\ncombinados con otros: funciones de “agregación” x - mean(x), y - sum(y)\nOrdenamiento: row_number()\nmin_rank(), row_number() y otras de dplyr::ranking\npercent_rank(), cume_dist()\n\n\nAgregados acumulativos y móviles: ver ayuda de cumsum() y cummean()"
  },
  {
    "objectID": "docs/Tema02.html#funciones-auxiliares-de-resumen",
    "href": "docs/Tema02.html#funciones-auxiliares-de-resumen",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Funciones auxiliares de resumen",
    "text": "Funciones auxiliares de resumen\n\ncount(): cuenta los valores únicos de una o más variables\n\n\nventas |&gt; count(id_tienda)\n# ventas |&gt; group_by(id_tienda) |&gt;  summarize(n = n())\nventas |&gt; count(id_tienda, sort = TRUE)\n\n\n\nMedidas de centralidad y de dispersión: mean(x), median(x), sd(x), IQR(x) \nMedidas de rango: min(x), quantile(x, 0.25), max(x)\nMedidas de posición: first(x), nth(x, 2), last(x).\n\n\n\nsimilar a x[1], x[2] y x[length(x)]\n\n\n\nSumas, productos, etc.\nConteos:\n\nn(): observaciones totales (tamaño del grupo)\nn_distinct(x): filas distintas en x\n\n\n\n\nsum(!is.na(x)): observaciones no ausentes\nmás rápido que unique()"
  },
  {
    "objectID": "docs/Tema02.html#operaciones-adicionales-de-limpieza",
    "href": "docs/Tema02.html#operaciones-adicionales-de-limpieza",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Operaciones Adicionales de Limpieza",
    "text": "Operaciones Adicionales de Limpieza\n\nseparate(): dividir una columna por caracter o posición\n\n\nunite(): combinar columnas\n\n\n\nArgumentos: date frame, columna a dividir, nombres de las nuevas variables y carácter (expresión regular) para separar\n\nSi se pasa a sep un vector de enteros, son posiciones en las que dividir\nla longitud de sep debe ser uno menos que la de into\nvalores positivos comienzan (en 1)por la izquierda; negativos (desde -1) por la derecha\n\nCon convert = TRUE intenta convertir el tipo de dato (no mantener carácter)\n\n\ntable3 |&gt; separate(rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\n\nArgumentos: data frame, nombre de la nueva variable a crear, columnas a combinar y carácter entre valores de las columnas originales\n\nEl separador por defecto es subrayado, sep = _\n\n\n\n\n\nPara nombres de columnas con espacios o caracteres especiales, debemos usar acento invertido\n\nMejor: renombrar sin espacios\n\n\n\ndatos_problema |&gt; \n  rename(nombre_producto = `Nombre Producto`,\n         precio_euros    = `Precio (€)`)"
  },
  {
    "objectID": "docs/Tema02.html#mismos-datos-dos-formatos-ancho-o-largo",
    "href": "docs/Tema02.html#mismos-datos-dos-formatos-ancho-o-largo",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Mismos datos, dos formatos: ancho o largo",
    "text": "Mismos datos, dos formatos: ancho o largo\n\n\nSe pueden almacenar datos en uno u otro formato, según nuestro objetivos\n\nP.e., largo en Excel para tablas dinámicas, fórmulas de agregación (SUMAR.SI), algunos gráficos\n\n\n\n\n\n\nFormato ANCHO:\n\n\n\ntienda\nQ1\nQ2\nQ3\nQ4\n\n\n\n\nMadrid\n145\n158\n151\n169\n\n\nBarcelona\n152\n164\n156\n175\n\n\nValencia\n138\n151\n149\n162\n\n\n\n\n\nventas_ancho\n\n(datos del informe enviado por gestores)\n\nFormato LARGO:\n\n\n\ntienda\ntrimestre\nventas\n\n\n\n\nMadrid\nQ1\n145\n\n\nMadrid\nQ2\n158\n\n\nMadrid\nQ3\n151\n\n\nMadrid\nQ4\n169\n\n\nBarcelona\nQ1\n152\n\n\n…\n…\n…\n\n\n\n\n\n\n\nLos trimestres son columnas\nCada tienda = 1 fila\nAnálisis de datos a menudo complicado\n\n\n\nLos trimestres son valores\nCada tienda-trimestre = 1 fila\nNo adecuado para tablas de presentación final"
  },
  {
    "objectID": "docs/Tema02.html#pivot_longer-girar-de-ancho-a-largo",
    "href": "docs/Tema02.html#pivot_longer-girar-de-ancho-a-largo",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "pivot_longer(): girar de ancho a largo",
    "text": "pivot_longer(): girar de ancho a largo\n\n\n\n\nGirar para analizar los datos\n\n\nventas_largo &lt;- ventas_ancho |&gt;\n  pivot_longer(\n    cols = Q1:Q4,              \n    names_to = \"trimestre\",    \n    values_to = \"ventas\"       \n  )\n\n\n\n\n\n\n\n\n\ntabla a cambiar de forma\nnombres o índices (numéricos) de las columnas a girar: representan valores, no variables\nnombre para la nueva variable que tendrá, como valores, esas antiguas columnas a girar\nnombre para la nueva variable que tendrá como valores las antiguas celdas\n\n\n\n\nRecordad que existen formas equivalentes de hacer lo mismo\n\n\ntable4a %&gt;% pivot_longer(cols = `1999`:`2000`, \n                         values_to = \"cases\", names_to = \"year\")\n\n\nNotar que los nombres de columna son caracteres y cuando son números van entre ` (evita confusión con índice de posición)\n\n\nDeberíamos cambiar el tipo de las nuevas variables"
  },
  {
    "objectID": "docs/Tema02.html#pivot_wider-girar-de-largo-a-ancho",
    "href": "docs/Tema02.html#pivot_wider-girar-de-largo-a-ancho",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "pivot_wider(): girar de largo a ancho",
    "text": "pivot_wider(): girar de largo a ancho\n\n\n\nGirar para crear tabla de presentación\n\n\nventas_largo |&gt;             \n  pivot_wider(\n    names_from = trimestre, \n    values_from = ventas    \n  )\n\n\n\n\n\n\n\n\n\ntabla a cambiar de forma\nnombre de la variable cuyos valores dan nombre a las nuevas columnas\nnombre de la variable de cuyas celdas toman los valores las nuevas columnas"
  },
  {
    "objectID": "docs/Tema02.html#comparación-tareas-comunes",
    "href": "docs/Tema02.html#comparación-tareas-comunes",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Comparación: Tareas Comunes",
    "text": "Comparación: Tareas Comunes\n\n\nSegún nuestro objetivos, podemos preferir formato ancho o largo\nProblemas prácticos con formato ancho para analizar datos:\n\n\n\nP.e., largo en Excel para tablas dinámicas, fórmulas de agregación (SUMAR.SI), algunos gráficos\nTotal por trimestre: en formato ancho, posible pero repetitivo\n\n\nFiltrar trimestres específicos\n\n\n# Formato ANCHO: difícil - ¿cómo filtro \"solo Q2 y Q3\"?\nventas_ancho |&gt;\n  select(tienda, Q2, Q3)  # Solo puedo seleccionar columnas, no filtrar\n\n# Formato LARGO: trivial\nventas_largo |&gt;\n  filter(trimestre %in% c(\"Q2\", \"Q3\"))\n\n\n\nAlgunas tareas son imposibles. P.e., ¿qué trimestres superan 160 en ventas?\n\n\nventas_largo |&gt;\n  filter(ventas &gt; 160)\n\n\nCódigo repetitivo y propenso a errores. P.e., Calcular crecimiento\n\n\nventas_ancho |&gt;\n  mutate(\n    crec_Q2 = (Q2 - Q1) / Q1 * 100,\n    crec_Q3 = (Q3 - Q2) / Q2 * 100,\n    crec_Q4 = (Q4 - Q3) / Q3 * 100\n  )\n\nventas_largo |&gt;\n  group_by(tienda) |&gt;\n  mutate(crecimiento = (ventas - lag(ventas)) / lag(ventas) * 100)\n\n\n\nformato ancho: tarea manual difícil con muchas fechas)\nformato ancho: cada columna manualmente, difícil con muchas fechas"
  },
  {
    "objectID": "docs/Tema02.html#comparación-tareas-comunes-cont.",
    "href": "docs/Tema02.html#comparación-tareas-comunes-cont.",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Comparación: Tareas Comunes (cont.)",
    "text": "Comparación: Tareas Comunes (cont.)\n\n\nNo escalable. P.e., gráfico temporal por grupos\n\n\nggplot(ventas_ancho) +\n  geom_line(aes(x = 1:4, y = c(Q1[1], Q2[1], Q3[1], Q4[1])), color = \"red\") +\n  geom_line(aes(x = 1:4, y = c(Q1[2], Q2[2], Q3[2], Q4[2])), color = \"blue\") +\n  geom_line(aes(x = 1:4, y = c(Q1[3], Q2[3], Q3[3], Q4[3])), color = \"green\")\n\nggplot(ventas_largo, aes(x = trimestre, y = ventas, \n                         color = tienda, group = tienda)) +\n  geom_line() + geom_point()\n\n\n\n\n\nFormato ancho solo para tablas de presentación final\n\n\nanalisis &lt;- ventas_largo |&gt;\n  group_by(trimestre) |&gt;\n  summarize(total = sum(ventas))\n\ntabla_presentacion &lt;- ventas_largo |&gt;\n  pivot_wider(names_from = trimestre, values_from = ventas) |&gt;\n  mutate(Total = Q1 + Q2 + Q3 + Q4)"
  },
  {
    "objectID": "docs/Tema02.html#por-qué-múltiples-tablas",
    "href": "docs/Tema02.html#por-qué-múltiples-tablas",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Por Qué Múltiples Tablas",
    "text": "Por Qué Múltiples Tablas\n\nAnalizar datos suele implicar múltiples tablas\n\ndiferentes orígenes: ej., dptos. de empresa (personal, ventas, almacén)\nalmacenamiento más eficiente: elementos “similares” dentro de una tabla y diferentes entre ellas\n\nPara poder combinar información los datos deben ser relacionales: cada par de tablas están relacionadas mediante identificadores comunes llamados claves\n\nPrimaria (o interna): identifican de forma única cada observación en una tabla. Puede ser una sola variable o múltiples\nSecundaria (o externa): señala a la clave primaria de otra tabla\n\n\n\n\nEs conveniente verificar que las claves primarias realmente identifican de manera única cada observación.\n\n\nplanes %&gt;% count(tailnum) %&gt;% filter(n &gt; 1)\n#table(planes$tailnum)\n\n\nLa clave externa asegura la integridad referencial.\nSubrogada = número de fila, si la tabla carece de identificación única\nTabla sin clave de identificación única: se crea con mutate() y row_number().\n\n\nflights %&gt;% \n  count(year, month, day, flight) %&gt;% \n  filter(n &gt; 1)\n\n\n\nUna clave primaria y su externa asociada en otra tabla forman una relación: de uno-a-muchos, de uno-a-uno, de muchos-a-muchos, de muchos-a-uno"
  },
  {
    "objectID": "docs/Tema02.html#diagrama-de-relaciones-del-sistema-retailcorp",
    "href": "docs/Tema02.html#diagrama-de-relaciones-del-sistema-retailcorp",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Diagrama de Relaciones del Sistema RetailCorp",
    "text": "Diagrama de Relaciones del Sistema RetailCorp\n\n\n\ngráfico creado con UML en https://www.plantuml.com\nusando Tema02relat.puml\n\nlibrary(plantuml)\n# Guarda el código en un archivo \"diagrama.puml\"\nplantuml(\"diagrama.puml\")\nOperaciones con dos tablas\n\nUniones de transformación (“Mutating joins”): añade nuevas variables a una tabla desde filas coincidentes en otra.\nUniones de filtro (“Filtering joins”): filtra las observaciones de una tabla basándose en si coinciden o no con una observación de la otra tabla.\nOperaciones de conjunto (“Set operations”): combinan las observaciones en los conjuntos de datos como si fueran elementos de un conjunto.\nEsta discusión asume que tenemos datos ordenados (tidy):\n\nlas filas son observaciones\nlas columnas son variables"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-transformación",
    "href": "docs/Tema02.html#uniones-de-transformación",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Uniones de transformación",
    "text": "Uniones de transformación\n\nAñaden nuevas variables a una tabla desde filas coincidentes en otra.\n\n\n\n\nTenemos estos datos.\n¿Cómo conseguimos unirlos adecuadamente en R y en Excel?\n\n\n\n\n\n\n\n\n\nCon cbind() o bind_columns() o copiando y pegando en Excel: nuevas columnas para filas en el mismo orden\n\n\n\ntabla1 &lt;- import(\"data/DosTablas.xlsx\", sheet = 1)\ntabla2 &lt;- import(\"data/DosTablas.xlsx\", sheet = 2)\nunion  &lt;- inner_join(tabla1, tabla2, by = \"Vendedor\")\n\n\ncomo mutate = mutating joins\nclave = fila Y ademán en el mismo orden\n\nen Excel, las uniones se hacen con VLOOKUP o HLOOKUP o XLOOKUP (BUSQUEDAH, BUSQUEDAV, BUSQUEDAX)"
  },
  {
    "objectID": "docs/Tema02.html#tipos-de-uniones-visión-general",
    "href": "docs/Tema02.html#tipos-de-uniones-visión-general",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Tipos de Uniones: Visión General",
    "text": "Tipos de Uniones: Visión General\n\n\n\n\nUnión interna: inner_join(x, y) sólo incluye observaciones que coincidan en x y y.\n\n\n\n\n\n\n\n\n\n\n\n\nUniones externas: cuando una fila no coincide en una unión externa, las nuevas variables se rellenan como valores ausentes\n\n\n\nleft_join(x, y)\n\n\n\n\n\n\nright_join(x, y)\n\n\n\n\n\n\nfull_join(x, y)\n\n\n\n\n\n\n\nPensar con cuidado el tipo de unión necesaria: qué observaciones quedan (todas, solo de una tabla y cuál) y ser conscientes de la introducción de NAs\n\n\n\nunión interna: Uniendo dos series temporales con periodos diferentes: PIB y consumo\n\n\n\n\n\n\n\nleft_join(df1, df2): mantiene todas las observaciones en x, coincidan o no con la de y\n\n(no se pierden observaciones de la tabla primaria)\n\nright_join(df1, df2): mantiene todas las observaciones en y\nfull_join(df1, df2): incluye todas las observaciones de x e y"
  },
  {
    "objectID": "docs/Tema02.html#análisis-de-ventas-por-región-en-el-tiempo",
    "href": "docs/Tema02.html#análisis-de-ventas-por-región-en-el-tiempo",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Análisis de ventas por región en el tiempo",
    "text": "Análisis de ventas por región en el tiempo\n\n\nPara usar la información de región se deben unir las tablas de ventas y de tiendas\n\n\ntabla_regional &lt;- ventas |&gt;\n  left_join(tiendas, by = \"id_tienda\") |&gt;   \n  group_by(region, año, mes) %&gt;%\n  summarize( valor_ventas = sum(total),\n             ticket_medio = mean(total),\n             cantidad_media = mean(cantidad) ) |&gt; ungroup()\n\n\nAhora podemos realizar más análisis\n\n\n# Evolución de ventas por región\ntabla_regional |&gt; \n  mutate(periodo = ym(paste(año, mes, sep = \"-\"))) |&gt;\n  ggplot() + \n  geom_line(aes(x = periodo, y = valor_ventas, color = region))\n\n# Los dos periodos con más ventas medias de cada región\ntabla_regional |&gt; \n  group_by(region) |&gt;  \n  arrange(desc(ticket_medio)) |&gt; slice(1:2)"
  },
  {
    "objectID": "docs/Tema02.html#sobre-el-argumento-by",
    "href": "docs/Tema02.html#sobre-el-argumento-by",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Sobre el argumento by",
    "text": "Sobre el argumento by\n\nLas claves, es decir, las variables que relacionan ambas tablas, se indican con\n\nby = \"varX\", cuando la clave es una variable\nby = c(\"varX\", \"varY\"), cuando son varias variables\n\nSi los nombre son distintos en cada tabla, se empareja x1 en la primera con y1 en la segunda con by = c(\"x1\" = \"y1\", \"x2\" = \"y2\")\n\n\n\nSi se omite el argumento by, se usan todas las variables en común. Esto no siempre es deseable: ej., año no es lo mismo en flights y planes\nColumnas con el mismo nombre (ej., año) se desambigúan con un sufijo\n\n\n\n\nEj., calcular el bono medio de los Vendedores\n\n\nempleados |&gt; filter(puesto == \"Vendedor\") |&gt;\n  left_join(promociones_empleado, \n            by = c(\"id_empleado\" = \"cod_empleado\", \n                   \"id_tienda\" = \"cod_tienda\") ) |&gt; \n  pull(monto_bono) |&gt; mean(na.rm = T)"
  },
  {
    "objectID": "docs/Tema02.html#claves-duplicadas",
    "href": "docs/Tema02.html#claves-duplicadas",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Claves duplicadas",
    "text": "Claves duplicadas\n\nSi una coincidencia no es única, se generan todas las combinaciones posibles (producto cartesiano) de las observaciones coincidentes\nUn uso habitual de las uniones: los nombres completos de categorías se ponen una tabla aparte y solo se une cuando se necesitan\n\n\n# margen medio por categoría de producto\nproductos |&gt; \n  mutate(margen = precio - costo) |&gt; \n  select(id_categoria, margen) |&gt; \n  right_join(categorias,                 # ¿por qué right?\n             by = c(\"id_categoria\" = \"categoria\")) |&gt;\n    group_by(nombre_categoria) |&gt; \n  summarize(margen_medio = mean(margen))\n\n\n\nEn una tabla: añade información adicional en una relación de uno a muchos.\n\n\n\n\n\n\n\nEn ambas tablas: igualmente, todas las combinaciones posibles\n\n\n\n\n\n\n\nposible error: NO hay clave primaria única (que identifica una observación)\n\n\ndf1dup2 &lt;- tibble(clave = c(1, 2, 2, 3), val_x = c(\"x1\", \"x2\", \"x3\", \"x4\"))\ndf2dup2 &lt;- tibble(clave = c(1, 2, 2, 3), val_y = c(\"y1\", \"y2\", \"y3\", \"y4\"))\ndf1dup2 %&gt;% left_join(df2dup2)\n\n\nbase::merge() realizar los cuatro tipos de unión de transformación (usando las opciones all.x = y all.y =, ver ayuda).\nlos verbos específicos de dplyr es que expresan más claramente la intención del código: la diferencia entre las uniones es realmente importante pero está oculta en los argumentos de merge(). Las uniones de dplyr son considerablemente más rápidas y no alteran el orden de las filas.\n\nmelt et al. http://had.co.nz/reshape/"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-filtrado",
    "href": "docs/Tema02.html#uniones-de-filtrado",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Uniones de Filtrado",
    "text": "Uniones de Filtrado\n\nFiltran las observaciones de la tabla de la izquierda basándose en si coinciden o no con una observación de la otra tabla\nSe tiene un subconjunto de las filas de la tabla de la izquierda\n\n\n\n\nsemi_join(x, y) mantiene las observaciones en x que están en y\n\n\n\n\nanti_join(x, y) elimina las observaciones en x que están en y\n\n\n\n\n\nno afectan a las variables\nClaves duplicadas: en uniones de filtro sólo importa la existencia de una coincidencia, NO qué observación coincida \\(\\Rightarrow\\) NUNCA duplica filas"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-filtrado-cont.",
    "href": "docs/Tema02.html#uniones-de-filtrado-cont.",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Uniones de Filtrado (cont.)",
    "text": "Uniones de Filtrado (cont.)\n\nAplicación: ¿cuántos clientes tenemos y cuántos sí han comprado?\n\n\nclientes |&gt; distinct(id_cliente) |&gt; count()\nclientes |&gt; semi_join(ventas) |&gt; distinct(id_cliente) |&gt; count()\n\n\nAplicación: ¿qué productos NO han sido devueltos?\n\n\n\nÚtiles para diagnosticar desajustes de uniones (qué observaciones serán emparejadas). Importante antes de unir tablas MUY grandes\n\n\n# empleados sin información de ventas\nempleados |&gt; anti_join(ventas, \n                       by = c(\"id_empleado\", \"id_tienda\")) |&gt; \n  count(id_empleado, id_tienda)  \n\n\n\nUtiles porque solo eliminan y nunca duplican observaciones\n\n\n\nPueden ser una alternativa simple a usar filter() con filtrados complejos (que involucran varias variables), creando previamente tablas resumidas\n-Ej., venta promedio de los 10 productos con más cantidad vendida\n\n\nUnión, PERO NO con tabla ya existente\nCreamos una tabla para nuestro objetivo de unión de filtrado\n\nAlgunas uniones de filtrado pueden ser equivalentes a usar filter(), con tablas previamente resumidas, pero permiten filtrados complejos (que involucran varias variables) fácilmente\n\n\nej., los diez días con más vuelos (o con los atrasos promedio más altos, necesita un filtro con varias variables (year, month, day)"
  },
  {
    "objectID": "docs/Tema02.html#operaciones-de-conjunto",
    "href": "docs/Tema02.html#operaciones-de-conjunto",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Operaciones de conjunto",
    "text": "Operaciones de conjunto\n\nTrabajan con filas completas, comparando valores de cada variable.\nEsperan que x e y tengan las mismas variables, y tratan las observaciones (filas) como elementos de un conjunto.\nÚtil cuando se quiere dividir un filtro complejo en piezas más simples.\n\n\n\nCombinan las observaciones en los conjuntos de datos como si fueran elementos de un conjunto.\n\n\n\ndf1 &lt;- tibble(x = 1:2, y = c(1, 1))\ndf2 &lt;- tibble(x = c(1,1), y = 1:2)\n\nintersect(df1, df2)     # solo filas tanto en df1 como en df2\nunion(df1, df2)         # filas únicas en ambas tablas df1 y df2` \nunion_all(df1, df2)     # todas las filas de df1 y df2, manteniendo duplicados \nsetdiff(df1, df2)       # filas en df1, pero no en df2\nsetdiff(df2, df1)   \n\n\nEquivalencia con bases de datos SQL\nhttps://www.cs.utexas.edu/~mitra/csFall2006/cs329/lectures/sql.html\n\nSQL soporta más tipos de unión y puede trabajar con más de dos tablas.\n\nComo sugiere esta sintaxis, más tipos de unión porque se pueden conectar las tablas usando restricciones diferentes a la igualdad (algunas veces llamadas no-equijoins).\nx and y no tienen que ser tablas en la misma base de datos. Si especifica copy = TRUE, dplyr copiará la tabla y en el mismo lugar que x.\nRevisar las reglas de coerción. P. e., los factores se conservan sólo si los niveles coinciden exactamente; si no, se “coaccionan” (se fuerza su conversión) a tipo de carácter."
  },
  {
    "objectID": "docs/Tema02.html#buenas-prácticas",
    "href": "docs/Tema02.html#buenas-prácticas",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Buenas Prácticas",
    "text": "Buenas Prácticas\n\nDatos Ordenados\nCódigo Legible y reproducible\n\nScripts ordenados y comentados\nEncadenar operacion con |&gt; en un paso por línea\nInspeccionar resultados intermedios\nDocumentar decisiones de limpieza\nNombres descriptivos de variables\nGuardar datos procesados\n\nErrores comunes\n\nNo verificar claves duplicadas en uniones\nOrden de operaciones incorrecto: ej., filtar después de summarize() por una variable que ya no existe"
  },
  {
    "objectID": "docs/Tema02.html#buenas-prácticas-cont.",
    "href": "docs/Tema02.html#buenas-prácticas-cont.",
    "title": "Tema 02 - Limpieza y Tratamiento de Datos",
    "section": "Buenas Prácticas (cont.)",
    "text": "Buenas Prácticas (cont.)\nEficiencia:\n\nFiltrar temprano, unir tarde\n\n\nventas_2023 &lt;- ventas |&gt;\n  filter(año == 2023) |&gt;    # reduce tamaño\n  left_join(productos, by = \"id_producto\")\n\nventas_2023_lento &lt;- ventas |&gt;\n  left_join(productos, by = \"id_producto\") |&gt;\n  filter(año == 2023)\n\n\nSeleccionar solo columnas necesarias\n\n\nRecursos Adicionales\n\nDocumentación: ?dplyr, ?tidyr\nCheat Sheets: RStudio &gt; Help &gt; Cheatsheets\nLibros:\n\n“R for Data Science” (Wickham & Grolemund)\n“Advanced R” (Wickham)\n\nComunidad: Stack Overflow, RStudio Community"
  },
  {
    "objectID": "docs/Tema06.html#el-problema-muchas-variables",
    "href": "docs/Tema06.html#el-problema-muchas-variables",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "El problema: muchas variables",
    "text": "El problema: muchas variables\n\nEscenario típico en economía/empresa: predecir una variables (ventas, salarios, abandono de clientes) con múltiples factores explicativos y/o interacciones y polinomios\nDesafíos de MCO para estimar modelos con muchos regresores:\n\n¿Qué variables incluimos?\nCon muchas variables, alta varianza\nModelo complejo, difícil de interpretar\nPosible overfitting\n\n\n\n\n¿Solución? Tres enfoques complementarios:\n\nSelección de variables relevantes y estimar por MCO\nRegularización (penalizar coeficientes grandes) ← Este tema\nReducción de dimensionalidad (usar un número menor de variables combinando las originales)\n\n\n\n\nMCO puede estimar modelos con muchos regresores (ej., polinomios e interacciones para relaciones no lineales), pero ¿qué variables incluimos?\nCuando crece el número de parámetros \\(\\small k\\) relativo al de observaciones \\(\\small n\\):\n\nmenor precisión (+ varianza) \\(\\Rightarrow\\) no solución única de MCO con \\(\\small k&gt;n\\)\nmodelo complejo y menos interpretable\\(\\Rightarrow\\) selección de variables\n\nPrecisión: incluso si la verdadera relación es lineal, mayor varianza cuando crece el número de parámetros/regresores relativo al de observaciones \\(\\Rightarrow\\) no solución única de MCO con \\(\\small k&gt;n\\)\n\ncon \\(\\small k&gt;n\\) no existe una estimación única de mínimos cuadrados\n\nInterpretación: un modelo con variables irrelevantes \n\n\nReducción de la dimensionalidad: usar \\(\\small M&lt;k\\) combinaciones lineales (proyecciones) y estimar por mínimos cuadrados (PCR, PLS)\n\nPartial Least Square / PCR: Principal Components Regression\nMétodos de selección de variables\n\nSelección del mejor subconjunto: estimar \\(\\small 2^k\\) modelos posibles con cada combinación de regresores y elegir aquel con menor error \\(\\Rightarrow\\) prohibitivo!\nAlternativas factibles (consideran un menor número de modelos)\n\nSelección paso a paso hacia adelante: añadir un regresor cada vez, eligiendo aquel con menor error en cada paso o eligiendo según p-valor\nSelección paso a paso hacia atrás (no factible si \\(\\small k&gt;n\\))\nSelección mixta: en cada paso se añaden variables de forma secuencial, pero también se eliminan algunas (p-valor alto)\n\nNo tienen criterio riguroso, no llevan a la misma solución y no garantizan encontrar el mejor subconjunto (ej., elimina pronto un regresor importante)\nSe pueden usar también en regresión logística\n\nSelección del Mejor Subconjunto\n\nDebemos estimar \\(\\small 2^k\\) modelos posibles con cada combinación de regresores (desde un solo regresor hasta todos a la vez)\nUsar SCR en entrenamiento lleva a elegir el modelo con \\(\\small k\\) parámetros\nProcedimiento:\n\nPara cada \\(\\small p=1,\\dots,k\\), estimar todos los modelos con \\(p\\) parámetros y elegir aquel con menor error (ej., SCR): \\(\\small M^*_p\\)\nElegir entre los modelos \\(\\small M^*_1, \\dots, M^*_k\\) usando validación cruzada o similar\n\nNo validamos todos, pero estimarlos es prohibitivo para \\(\\small k\\) moderada\n\nSelección paso a paso hacia adelante\n\nProcedimiento: empezando por modelo sin regresores \\(\\small M_0\\)\n\nPara cada \\(\\small p=0, 1,\\dots,k-1\\), estimar todos los modelos que añadan UN regresor a \\(\\small M^f_p\\)\nElegir como modelo \\(\\small M^f_{p+1}\\) el que tiene menor SCR\nElegir entre \\(\\small M_0, M^f_1, \\dots, M^f_k\\) con validación cruzada o similar\n\nMuchos menos modelos: \\(\\small k-p\\) por iteración, en total \\(\\small 1+\\frac{p(p+1)}{2}\\)\nSolo \\(\\small 1+\\frac{k(k+1)}{2}\\) modelos\nFactible aunque \\(\\small k&gt;n\\) pero para modelo \\(M_0,\\dots,M^f_{n-1}\\)\nNo se garantiza encontrar el mejor subconjunto, por eliminar pronto un regresor importante\n\nej. el mejor \\(\\small M^*_2\\) no usa el regresor de mejor modelo de un regresor \\(\\small M^f_1=M^*_1\\)\n\n\nSelección paso a paso hacia atrás\n\nProcedimiento: empezando por modelo con todos los regresores \\(\\small M_k\\)\n\nPara cada \\(\\small p=k, k-1, \\dots,1\\), estimar todos los modelos que eliminan UN regresor a \\(\\small M^b_p\\)\nElegir como modelo \\(\\small M^b_{p-1}\\) el que tiene menor SCR\nElegir entre \\(\\small M_0, M^b_1, \\dots, M^b_k\\) usando validación cruzada o similar\n\nSolo \\(\\small 1+\\frac{k(k+1)}{2}\\) modelos\nPero no factible si \\(\\small k&gt;n\\) (no se puede ajustar \\(M_{k}\\))\nNADA garantiza acabar con el mejor subconjunto de regresores\n\nOtros procedimientos\n\nSelección mixta de subconjuntos: en cada iteración se añaden variables de forma secuencial, pero también se eliminan las que ya no mejoren el ajuste\n\nsimulan la selección de mejores subconjuntos, con las ventajas computacionales de selección por pasos.\n\nEstimar directamente el error de prueba mediante validación cruzada\nEstimar indirectamente el error de prueba mediante ajustes en el error de entrenamiento para tener en cuenta el sesgo por “overfitting”\nTodos estos métodos (y los anteriores de selección) se pueden usar también en regresión logística"
  },
  {
    "objectID": "docs/Tema06.html#trade-off-sesgo-varianza-de-nuevo",
    "href": "docs/Tema06.html#trade-off-sesgo-varianza-de-nuevo",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "“Trade-off” Sesgo-Varianza (de nuevo)",
    "text": "“Trade-off” Sesgo-Varianza (de nuevo)\n\nEl dilema fundamental del aprendizaje:\n\nModelos simples → alto sesgo\nModelos complejos → alta varianza\n\nObjetivo: controlar este trade-off, calculando métricas de error para elegir el mejor modelo\n\n\n\nValidación cruzada: estima directamente el error de prueba, pero es costoso (computacionalmente, menor tamaño muestral)\n\n\n\n\nMétodos de ajuste: el error de entrenamiento siempre disminuye para modelos más complejos, pero puede ajustarse y estimar indirectamente el error de prueba mediante supuestos (erróneos?)\n\nCriterio de Información de Akaike: \\(\\small AIC = \\frac{1}{n}\\left( SCR^{entrena} + 2 k \\widehat{\\sigma}^2 \\right)\\)\nCriterio de Información Bayesiano: \\(\\small BIC =  \\frac{1}{n}\\left( SCR^{entrena} + log(n) k \\widehat{\\sigma}^2 \\right)\\)\n\\(\\small R^2-ajustado = 1- \\frac{SCR^{entrena}/(n-k-1)}{SCT^{entrena}/(n-1)}\\)\n\n\ndonde \\(\\small \\widehat{\\sigma}^2\\) un estimación de la varianza del error y \\(\\small k\\) es el número de parámetros\n\n\nSea \\(\\small n\\) el número de observaciones, \\(\\small k\\) el número de parámetros y \\(\\small \\widehat{\\sigma}^2\\) un estimación de la varianza del error \\(\\small \\varepsilon\\)\nValidación cruzada NO necesita estimar \\(\\small \\widehat{\\sigma}^2\\) (difícil en algunos modelos)\nLos métodos de ajuste ofrecen una estimación indirecta del error de prueba, en la muestra de entrenamiento mediante supuestos (erróneos?)\n\\(\\small SCR\\) en entrenamiento siempre se reduce si el modelo es más flexible \\(\\Rightarrow\\) añadir una penalización por número de parámetros\n\nCriterio de Información de Akaike: \\(\\small AIC = \\frac{1}{n}\\left( SCR + 2 k \\widehat{\\sigma}^2 \\right)\\)\n\n\\(\\small \\widehat{\\sigma}^2\\) un estimación de la varianza del error\n\nCriterio de Información Bayesiano: \\(\\small BIC =  \\frac{1}{n}\\left( SCR + log(n) k \\widehat{\\sigma}^2 \\right)\\)\n\\(\\small R^2-ajustado = 1- \\frac{SCR/(n-k-1)}{SCT/(n-1)}\\) \n\n\n** Métodos de regularización**\n\nAlternativa a mínimos cuadrados con selección de regresores\nAjustar un modelo que contenga todos los regresores, PERO con una técnica que limite las estimaciones de los coeficientes, o las reduzca a cero.\nA priori, NO es obvio por qué esa restricción debería mejorar el ajuste, pero esto reduce su varianza\nDos enfoques\n\n“Ridge regression”: se reducen los coeficientes\nLASSO (“least absolute shrinkage and selection operator”): selección automática de regresores\n\nRegresión de red elástica, incorpora ambos"
  },
  {
    "objectID": "docs/Tema06.html#qué-es-la-regularización",
    "href": "docs/Tema06.html#qué-es-la-regularización",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "¿Qué es la regularización?",
    "text": "¿Qué es la regularización?\nIdea central: Penalizar coeficientes grandes para reducir la varianza\n\n\nEn MCO minimizamos:\n\n\n\\[\nmin_{\\beta} \\quad SCR(\\beta) = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n\\]\n\n\n\nCon regularización minimizamos:\n\n\n\\[\nmin_{\\beta} \\quad SCR(\\beta) + \\lambda \\cdot \\text{Penalización}(\\beta)\n\\]\n\ndonde \\(\\lambda \\geq 0\\) es el parámetro de regularización (hiperparámetro)\n\n\n\n\nCastiga coeficientes grandes para forzar modelos más simples: mayor sesgo (peor ajuste), pero reduce la varianza (previene overfitting)\n\nNOTA: NO se penaliza la constante (media de \\(\\small Y\\)), solo el impacto de \\(\\small X\\)\n\nLa regularización funciona mejor cuando MCO tiene alta varianza: intercambia un pequeño aumento de sesgo por una gran reducción de la varianza\n\n\nMétodos de regularización\n\nEn MCO: \\(\\small \\min_{\\beta} SCR={\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\nEn Regresión Penalizada o Regularizada, se añade una restricción que limite (reduzca) los coeficientes estimados \\[\\small \\min_{\\beta} SCR \\text { sujeto a }R(\\beta) \\leq t\\]\n\ndonde \\(R(\\cdot)\\) es una medida del tamaño de los coeficientes\nNO se penaliza a la constante (media de \\(\\small Y\\)), solo el impacto de \\(\\small X\\)\n\nLa restricción limita la importancia de las \\(\\small X\\) para explicar \\(\\small Y\\): empeora el ajuste (sesgo), pero reduce la varianza \\(\\Rightarrow\\) previene “overfitting”\nPermite ajustar un modelo que contenga todos los regresores\nReescribiendo el problema (Lagrangiano): \\(\\small \\min_{\\beta} SCR+\\lambda R(\\beta)\\)\n\\(\\lambda \\geq 0\\) es un parámetro de ajuste (“tuning parameter”)\n\\(\\lambda = 0\\): regresión MCO estándar\n\\(\\lambda\\) grande: coeficientes muy pequeños (modelo simple)\nDebemos elegir \\(\\lambda\\) óptimo mediante validación cruzada"
  },
  {
    "objectID": "docs/Tema06.html#tipos-de-regularización",
    "href": "docs/Tema06.html#tipos-de-regularización",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "Tipos de regularización",
    "text": "Tipos de regularización\nDos formas principales de penalización:\n\n\nRidge Regression \\[\n\\min_\\beta \\text{SCR} + \\lambda \\sum_{j=1}^{k}\\beta_j^2\n\\]\n\nPenaliza la suma de los cuadrados de \\(\\beta\\)\nReduce los coeficientes hacia cero\nPero nunca exactamente cero\nTodas las variables se mantienen\n\n\nLASSO \\[\n\\min_\\beta \\text{SCR} + \\lambda \\sum_{j=1}^{k}|\\beta_j|\n\\]\n\nPenaliza la suma de los valores absolutos de \\(\\beta\\)\nReduce coeficientes y fuerza algunos a cero\nRealiza selección de variables\nModelo más interpretable\n\n\n\n¿Cuál usar?\n\nRidge: muchas variables son relevantes\nLASSO (least absolute shrinkage and selection operator): solo pocas variables son importantes\nElastic Net: combina ambos \\(\\small \\alpha \\left(\\sum_{j=1}^{k}|\\beta_j|\\right) + (1-\\alpha)\\left(\\sum_{j=1}^{k}\\beta_j^2\\right)\\)\n\n\n\n\n\n\n\n\n\nMétodo\nPenalización por tamaño = \\(R(\\boldsymbol{\\beta})\\)\nNorma\n\n\n\n\nMCO\n0\n\n\n\nLASSO\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\\(\\ell_1\\): \\(||\\boldsymbol{\\beta}||_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\n\nRidge Regression\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_2^2 =\\sum_{j=1}^{k}\\beta_j^2\\)\n\\(\\ell_2\\): \\(||\\boldsymbol{\\beta}||_2=\\sqrt{\\sum_{j=1}^{k}\\beta_j^2}\\)\n\n\nRed Elásica\n\\(\\alpha\\lVert\\boldsymbol{\\beta}\\rVert_1 + (1-\\alpha)\\lVert\\boldsymbol{\\beta}\\rVert_2^2\\)\n\n\n\n\n\n\\(\\ell_1\\)-norm: \\(||\\boldsymbol{\\beta}||_1=\\sum_{j=1}^{k}|\\beta_j|\\).\n\\(\\ell_2\\)-norm: \\(||\\boldsymbol{\\beta}||_2=\\left(\\sum_{j=1}^{k}|\\beta_j|^2\\right)^{\\frac{1}{2}}\\), i.e., Euclidean norm.\nLASSO = least absolute shrinkage and selection operator\nEn MCO: \\(\\small \\min_{\\beta}=SCR={\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\nAñadir restricciones para prevenir “overfitting” \\(\\small \\sum_{j=1}^{k}\\beta_j^2 \\leq c\\)\nSe obtiene un coeficiente estimado \\(\\small \\widehat{\\beta}^R_{\\lambda}\\) que minimiza [ SCR + _{j=1}^{k}_j^2 = SCR + ||||_2^2 ]\n\n\\(||\\beta||_2 = \\sqrt{\\sum_{j=1}^{k}\\beta_j^2}\\) es la norma L2 (\\(\\ell_2\\)) del vector de coeficientes\n\\(\\lambda \\geq 0\\) es un parámetro de ajuste (“tuning parameter”)\n\n\n\n\nPenalización de contracción\n\n\n\nPara un \\(\\small \\lambda\\) dado:\n\n\\(\\small \\widehat{\\beta}^R_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}\\beta_j^2\\)\n\n\\[\n\\small\n\\widehat{\\beta}^L_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}|\\beta_j|\n\\]\n\n\nTratamos de ajustarnos a los datos minimizando SCR, PERO se recompensa a los coeficientes cercanos a cero\nPara que todos los coeficientes estén en la misma escala (misma “cercanía a cero), debemos estandarizar los regresores: \\(\\small \\widetilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{ \\frac{1}{n}\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2}}\\)\n\nRecordar: en MCO, el coeficiente \\(\\small \\beta_j\\) cambia si cambiamos las unidades de \\(\\small X_j\\)\n\nEn MCO, si multiplicamos \\(\\scriptsize X_j\\) por \\(\\scriptsize c\\), su coeficiente estimado se reescala por \\(\\scriptsize 1/c\\): el valor predicho \\(\\scriptsize \\widehat{\\beta_j}X_j\\) no cambia \\(\\Rightarrow\\) \\(SCR\\) no cambia\n\nEn Regresión Regularizada, la penalización sí cambia al reescalar \\(\\Rightarrow\\) los coeficientes estimados pueden cambiar drásticamente\n\nLos coeficientes estimados por regresión regularizada pueden cambiar drásticamente después de reescalar cualquier variable\n\n“Ridge Regression”: penalización de contracción\n[ ^R_{} = SCR + {j=1}^{k}_j^2 ]\n\nTratamos de ajustarnos a los datos minimizando SCR, PERO se recompensa a los coeficientes cercanos a cero: penalización de contracción\nNO se penaliza a la constante (media de \\(\\small Y\\)), solo el impacto de \\(\\small X\\)\n\\(\\small \\lambda\\)= importancia de la penalización (cuanto se contraen los coeficientes)\n\n\\(\\small \\lambda \\approx 0\\), cercano a MCO\n\\(\\small \\lambda &gt;&gt; 0\\), todos los coeficientes se van a cero\n\nVentaja sobre la selección de regresores: SOLO necesitamos ajustar un modelo para cada valor de \\(\\small \\lambda\\)\n\nAdvertencia: estandarizar los regresores\n\nEn MCO los coeficientes estimados son equivariantes a la escala de los regresores.\n\nSi multiplicamos \\(\\small X_j\\) por una constante, \\(\\small c\\), el coeficiente estimado se reescala por \\(\\small 1/c\\) y el valor predicho \\(\\widehat{\\beta_j}X_j\\) sigue siendo el mismo.\n\\(SCR\\) no cambia cuando se reescala un regresor\n\nEn Regresión Regularizada, NO, porque la penalización sí cambia al reescalar \\(\\Rightarrow\\) los coeficientes pueden cambiar drásticamente\nLos coeficientes estimados por regresión regularizada pueden cambiar drásticamente después de reescalar cualquier variable\nSe recomienda ajustar después de estandarizar los regresores: [ _{ij} = ]\n\nRegularización y “Trade-off” sesgo-varianza\n\n¿Por qué la regularización mejoraría el ajuste sobre MCO?\n\\(\\small \\lambda\\)= importancia de la penalización (cuanto se contraen los coeficientes)\n\n\\(\\small \\lambda\\) pequeño (cercano a MCO): mayor flexibilidad (\\(-\\) sesgo, \\(+\\) varianza)\n\\(\\small \\lambda &gt;&gt; 0\\), todos los coeficientes a cero: menor flexibilidad (\\(+\\) sesgo, \\(-\\) varianza)\n\nRegularización funciona mejor cuando MCO tiene alta varianza: intercambia un poco más de sesgo por una gran reducción de la varianza\n“Ridge Regression” sigue incluyendo todos los regresores (ningún coeficiente exactamente cero): puede complicar la interpretación con muchos\nLASSO (least absolute shrinkage and selection operator): también contrae hacia cero, algunos exactamente cero (selección de variables)\n\nLASSO\n\nIdea similar \\(\\small \\min_{\\beta}=SCR={\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\), sujeto a \\(\\small \\sum_{j=1}^{k}|\\beta_j| \\leq c\\)\nSelección de mejor conjunto impone restricción \\(\\small \\sum_{j=1}^{k} I(\\beta_j \\neq 0) \\leq s\\)\n\nTampoco es factible: requiere considerar todos los modelso que tiene s regresores\nLASSO/ridge más factibles computacionalmente: sustituyen unas restricciones intratablse por alternativas mucho más fáciles de resolver\n[ ^L_{} = SCR + {j=1}^{k}|_j| ]\n\nLASSO utiliza una penalización basada en la norma L1 (\\(\\small \\ell_1\\)): [ ||||1 = {j=1}^{k} |_j| ]\nTambién contrae los coeficientes estimados hacia cero, PERO obliga algunos a ser exactamente iguales a cero cuando \\(\\small \\lambda\\) es grande\nLASSO realiza la selección de variables."
  },
  {
    "objectID": "docs/Tema06.html#ridge-regression-y-lasso",
    "href": "docs/Tema06.html#ridge-regression-y-lasso",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "“Ridge Regression” y LASSO",
    "text": "“Ridge Regression” y LASSO\n\n\n\n\n\n\n\n“Ridge regression” domina con muchos regresores igualmente importantes\nLASSO con pocos regresores importantes y muchos inútiles\nLASSO es una alternativa a los contrastes de significatividad (sin formalización estadística)\n\n\n\n¿Cuál usar?\n\nRidge: cuando muchas variables son relevantes\nLASSO: cuando solo pocas variables son importantes\nElastic Net: combina ambos\n\n\n\\[\n  \\scriptsize \\alpha \\left(\\sum_{j=1}^{k}|\\beta_j|\\right) + (1-\\alpha)\\left(\\sum_{j=1}^{k}\\beta_j^2\\right)\n\\]\n\n\nRecordad que estos métodos están orientado a la predicción: NO usar para afirmaciones de causalidad (los coeficientes están sesgados)\nLASSO (least absolute shrinkage and selection operator) es una alternativa a los contrastes de significatividad\n\nsin formalización estadística\n\nSe puede estimar por MCO la especificación de variables seleccionadas por LASSO\n\nsí podemos usarlo para causalidad\n\n\n\nLASSO vs. “Ridge Regression”\n\nAmbos reducen significativamente la varianza a expensas de un pequeño aumento del sesgo\n“Ridge regression” domina cuando hay muchos regresores igualmente importantes\nLASSO domina cuando hay un pequeño número de regresores importantes y muchos otros que no son útiles\nGeneralización: Regresión de red elástica\n\n[ _{}=SCR+]"
  },
  {
    "objectID": "docs/Tema06.html#importante-estandarización",
    "href": "docs/Tema06.html#importante-estandarización",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "IMPORTANTE: Estandarización",
    "text": "IMPORTANTE: Estandarización\n\nAntes de aplicar regularización, SIEMPRE estandarizar las variables explicativas\n¿Por qué?\n\nMCO es equivariante a escala.\nCon regularización, los coeficientes sí dependen de las unidades\n\nSe recompensa a los coeficientes cercanos a cero\nDeben tener la misma escala (misma “cercanía a cero”)\n\n\nEstandarización:\n\nMedia = 0\nDesviación estándar = 1\nTodos los coeficientes en la misma escala\n\n\n\\[\n\\widetilde{x}_{ij} = \\frac{x_{ij} - \\bar{x}_j}{\\text{sd}(x_j)}\n\\]\n\n\nMCO es equivariante a escala.\n\nSi multiplicamos \\(X_j\\) por \\(c\\), el coeficiente se divide por \\(c\\)\nLas predicciones no cambian → \\(SCR\\) no cambia\n\n\nTratamos de ajustarnos a los datos minimizando SCR, PERO se recompensa a los coeficientes cercanos a cero\nPara que todos los coeficientes estén en la misma escala (misma “cercanía a cero),\nPero con regularización:\nLa penalización cambia con la escala\nCoeficientes en escalas diferentes son penalizados distinto\nResultados dependen de las unidades\nNotas:\n\nNO estandarizar la variable dependiente\nNO estandarizar variables dummy\nNO estandarizar la constante"
  },
  {
    "objectID": "docs/Tema06.html#eligiendo-lambda-el-hiperparámetro",
    "href": "docs/Tema06.html#eligiendo-lambda-el-hiperparámetro",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "Eligiendo \\(\\lambda\\): el hiperparámetro",
    "text": "Eligiendo \\(\\lambda\\): el hiperparámetro\n\n\\(\\lambda\\) controla cuánta penalización aplicamos:\n\n\\(\\lambda = 0\\): MCO estándar\n\\(\\lambda\\) mayor, más regularización (\\(\\lambda \\to \\infty\\), todos los \\(\\beta \\to 0\\))\n\n\n\n\n¿Cómo elegimos \\(\\lambda\\)?\n\nElegir un rango de valores para \\(\\small \\lambda\\)\nPara cada valor de \\(\\small \\lambda\\), calcular el error promedio mediante validación cruzada\nSeleccionar \\(\\lambda^*\\) con menor error promedio (probar varios rangos para encontrar forma de U)\nVolver a ajustar el modelo completo con \\(\\lambda^*\\) en toda la muestra de entrenamiento\n\nRegla de parsimonia: si varios \\(\\lambda\\) tienen errores similares (dentro de 1 error estándar), elegir el \\(\\lambda\\) más grande (modelo más simple)\n\nEvaluar en muestra de prueba (nunca usada antes)\n\n\n\n\nError de entrenamiento siempre disminuye con menos regularización\nError de validación tiene forma de U\nQueremos el mínimo de validación\nRegla 1-SE: da preferencia a modelos más simples cuando hay empate\nVentaja sobre la selección de regresores: SOLO necesitamos ajustar un modelo para cada valor de \\(\\small \\lambda\\)\nRegla de parquedad paramétrica: dado un conjunto de modelos igualmente buenos (dentro de un error estándar del menor error), elegir el más simple\n\nseleccionar el modelo con menos variables que esté dentro de un error estándar del menor error de prueba estimado."
  },
  {
    "objectID": "docs/Tema06.html#en-regresión-lineal",
    "href": "docs/Tema06.html#en-regresión-lineal",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "En regresión lineal",
    "text": "En regresión lineal\n\nCaracterísticas:\n\nImplementación eficiente y rápida\nFunciona con matrices, no con fórmulas\nEstandariza automáticamente por defecto\nFunciona para regresión y clasificación\n\n\n\nlibrary(mosaicData)\nlibrary(glmnet)\n\n\nPreparar datos y ajustar el modelo\n\n\n# 1. Datos como matrices\nx &lt;- model.matrix(data = RailTrail, \n                  volume ~ cloudcover + weekday + precip + poly(hightemp, 6))\n# 2. Modelo\nfit.lmreg &lt;- glmnet(x = x, y = RailTrail$volume, \n                    family=\"gaussian\", \n                    alpha = .5,      # 1=LASSO, 0=Ridge\n                    lambda = 2)      # 0, 2, 10\nfit.lmreg$beta\n\n\nValidación cruzada para elegir lambda\n\n\nset.seed(1)  \ncv_modelo &lt;- cv.glmnet(x, RailTrail$volume, alpha = 1, nfolds = 10)\ncv_modelo \ncv_modelo |&gt; plot()\n\nmejor_lambda &lt;- cv_modelo$lambda.min  # o lambda.1se\n\n\nObservad: Ridge mantiene todas las variables, LASSO elimina algunas"
  },
  {
    "objectID": "docs/Tema06.html#en-regresión-logística",
    "href": "docs/Tema06.html#en-regresión-logística",
    "title": "Tema 06 - Selección y Regularización en Modelos Lineales",
    "section": "En regresión logística",
    "text": "En regresión logística\n\ncenso &lt;- read_csv(\"data/census.csv\") |&gt;\n  mutate(across(where(is.character), ~parse_factor(.x)),\n         income = if_else(income == \"&gt;50K\", 1,  0))\n\n\nPreparar datos y ajustar el modelo\n\n\n# 1. Preparar datos como matrices\nx &lt;- model.matrix(data = censo, \n        income ~ race + poly(age, 3) + log(hours_per_week)*sex + \n          education*race + occupation)\n# 2. Modelo\nfit.glmreg &lt;- glmnet(x = x, y = censo$income, \n                     family = \"binomial\",\n                     lambda=0.001, alpha=1)\nfit.glmreg$beta\n\n\nValidación cruzada para elegir lambda\n\n\nset.seed(1)  \ncv_modelo &lt;- cv.glmnet(x, censo$income, alpha = 1, nfolds = 10)\ncv_modelo \ncv_modelo |&gt; plot()\n\nmejor_lambda &lt;- cv_modelo$lambda.min  # o lambda.1se\n\n\nResumen y Mejores Prácticas\nCuándo usar cada método\n\n\n\n\n\n\n\n\nSituación\nMétodo Recomendado\nRazón\n\n\n\n\n\\(k &lt; n\\), todas variables relevantes\nMCO\nSuficientes datos, no necesita regularización\n\n\n\\(k\\) cercano a \\(n\\)\nRidge o LASSO\nPrevenir sobreajuste\n\n\n\\(k &gt; n\\)\nLASSO\nMCO no tiene solución única\n\n\nPocas variables importantes\nLASSO\nSelección automática\n\n\nMuchas variables igualmente importantes\nRidge\nNo elimina, solo reduce\n\n\nObjetivo: predicción\nLASSO\nMejor balance sesgo-varianza\n\n\nObjetivo: inferencia\nMCO con variables de LASSO\nCoeficientes no sesgados\n\n\n\n\nChecklist: Proceso completo de regularización\n\nPreparación\n\n✓ Limpiar y explorar datos\n✓ Identificar variables numéricas y categóricas\n✓ Crear variables dummy para categóricas\n\nEstandarización\n\n✓ Estandarizar variables numéricas\n✓ NO estandarizar variable dependiente\n✓ NO estandarizar dummies\n\nDivisión de datos\n\n✓ Separar entrenamiento y prueba (80/20 o 70/30)\n✓ Nunca usar datos de prueba para ajustar \\(\\lambda\\)\n\nAjuste del modelo\n\n✓ Usar validación cruzada en entrenamiento\n✓ Probar varios valores de \\(\\lambda\\)\n✓ Aplicar regla 1-SE para modelos más parsimoniosos\n\nEvaluación\n\n✓ Evaluar en datos de prueba\n✓ Comparar con modelo base (MCO)\n✓ Interpretar variables seleccionadas\n\n\n\nErrores comunes a evitar\n⚠️ NO hacer:\n\nOlvidar estandarizar variables numéricas\n\nLos coeficientes dependerán de unidades arbitrarias\n\nUsar datos de prueba para elegir \\(\\lambda\\)\n\nContamina la evaluación final\n\nConfiar ciegamente en LASSO para inferencia causal\n\nLos coeficientes están sesgados\nUsar para predicción o selección\n\nIgnorar la regla 1-SE\n\nModelos más complejos sin beneficio real\n\nNo verificar supuestos básicos\n\nRegularización no soluciona problemas graves de datos\n\n\n\nRecursos y próximos pasos\nEn el próximo tema:\n\nFlujo completo con tidymodels\nAutomatización del proceso\nComparación sistemática de modelos\nCaso práctico completo de clasificación (churn)\n\nPara profundizar:\n\nIntroduction to Statistical Learning - Capítulo 6\nglmnet vignette\nRegularization Paths for Generalized Linear Models via Coordinate Descent - Paper original\n\n\nResumen ejecutivo\nConceptos clave:\n\nLa regularización añade una penalización para reducir la complejidad del modelo\nRidge (L2) reduce coeficientes pero los mantiene todos\nLASSO (L1) fuerza algunos coeficientes exactamente a cero (selección automática)\n\\(\\lambda\\) controla el nivel de regularización\nElegimos \\(\\lambda\\) mediante validación cruzada\n\nAplicaciones:\n\nPredicción cuando \\(k\\) es grande\nSelección automática de variables\nPrevención de sobreajuste\nMejora de la generalización\n\nPróximos pasos:\n\nPráctica con datos reales\nIntegración con tidymodels (Tema 07)\nExtensión a modelos no lineales (temas posteriores)"
  },
  {
    "objectID": "docs/Tema00ej1.html",
    "href": "docs/Tema00ej1.html",
    "title": "Tema 0. Introducción a R. Ejercicio 1",
    "section": "",
    "text": "En este ejercicio vamos a practicar los conceptos básicos de R. Debéis escribir un archivo de código de R con los comandos necesarios para responder a los siguientes ejercicios. Podéis encontrar una plantilla aquí\n\n\nProblema 1\nEl archivo Ventas1.xlsx contiene las ventas de dos tiendas, A y B, de Lunes a Viernes. Calcular las ventas totales (sumando ambas tiendas) para cada día, las ventas totales de ambas tiendas en toda la semana y las ventas medias de la semana de la tienda A.\nNOTA: se recomienda crear un proyecto de RStudio y guardar el archivo Ventas1.xlsx en la carpeta.\n\n\nProblema 2\n\nLos archivos Ventas2a.xlsx y Ventas2b.xlsx contiene el valor de las ventas de tres productos cada uno, a nivel nacional y a nivel internacional (en millones de euros). Combinar ambos conjuntos de datos en uno solo con las información de todos los productos.\n\n\nAñadir una columna con el valor total de las ventas (nacionales más internacionales) de cada producto.\n\n\nCalcular la media del valor de las ventas internacionales (media sobre todos los productos) y la media del valor de las ventas nacionales pero solo para los productos X, Y y R.\n\n\nSe quiere conocer el número de compradores de los productos a partir del valor de las ventas y la información de los precios de los productos disponible en la siguiente tabla:\n\n\n\n\n\nPrecioN\nPrecioI\n\n\n\n\nX\n5.2\n4.2\n\n\nY\n4.7\n4.3\n\n\nZ\n5.7\n4.2\n\n\nR\n6.1\n4.5\n\n\nS\n7.0\n4.9\n\n\nT\n6.7\n4.8\n\n\n\n\n\n\nProblema 3\n\nEl conjunto de datos mtcars está incluido en R por defecto; buscar en la ayuda de RStudio mtcars para conocer las variables que incluye. Comprobar la estructura con str() y visualizar las primeras observaciones con head().\n\nGenerar la variable (escalar) Datsun710_CV con los caballos de potencia del coche modelo Datsun 710.\nGenerar el vector Valiant_vector con toda la información (esto es, variables) disponibles sobre el coche modelo Valiant.\n\n\n\nGenerar el vector cilindros con la información para todos los modelos de coche de la variable sobre el número de cilindros. Generar el vector cambio_vector con la información de la variable de tipo de cambio (manual o automático) de todos los modelos de coche Mazda y Hornet.\n\n\nGenerar media_consumo_autom con el consumo medio de los coches con cambio automático. Generar media_consumo_autom_cyl4 con el consumo medio de los coches con cambio automático y cuatro cilindros.\n\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema00ej1_123456789.R"
  },
  {
    "objectID": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "href": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "title": "Introducción",
    "section": "“Datificación” de la vida diaria",
    "text": "“Datificación” de la vida diaria\n\n\n\n\nIBM: en 2025 más de 175 zettabytes (175 billones de gigas) requerirán de distintos análisis\nForbes: 2,5 trillones de bytes de datos cada día\nThe 4 Vs of big data: Volume, Velocity, Variety, Veracity"
  },
  {
    "objectID": "docs/0Intro.html#importancia-de-los-datos",
    "href": "docs/0Intro.html#importancia-de-los-datos",
    "title": "Introducción",
    "section": "Importancia de los datos",
    "text": "Importancia de los datos\n\nNeelie Kroes (Comisaria Europea para la Agenda Digital): “Data is the oil of the new economy, […], the new oil for the digital era”\n\n\nNuevas oportunidades para las empresas: analítica de negocios para la toma de decisiones.\nMcKinsey: “aquellas organizaciones que adoptan analítica de negocios como cultura tienen 23 veces más probabilidades de adquirir clientes, seis veces más probabilidades de retener a esos clientes y 19 veces más probabilidades de ser rentables” (Bokman et al., 2018).\nMás ejemplos importancia del análisis de datos en economía, aquí y aquí, y en la empresa"
  },
  {
    "objectID": "docs/0Intro.html#objetivos",
    "href": "docs/0Intro.html#objetivos",
    "title": "Introducción",
    "section": "Objetivos",
    "text": "Objetivos\n\nAprender a extraer información de los datos\n\n\n\n\n\nUsando técnicas computacionales y estadísticas"
  },
  {
    "objectID": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "href": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "title": "Introducción",
    "section": "Aprendiendo a analizar datos",
    "text": "Aprendiendo a analizar datos\n\nEs una inversión de futuro en el trabajo aquí y aquí\nDebemos conocer las técnicas y NO esperar magia"
  },
  {
    "objectID": "docs/0Intro.html#análitica-cadena-de-valor",
    "href": "docs/0Intro.html#análitica-cadena-de-valor",
    "title": "Introducción",
    "section": "Análitica: Cadena de Valor",
    "text": "Análitica: Cadena de Valor"
  },
  {
    "objectID": "docs/0Intro.html#tipos-de-análisis",
    "href": "docs/0Intro.html#tipos-de-análisis",
    "title": "Introducción",
    "section": "Tipos de Análisis",
    "text": "Tipos de Análisis"
  },
  {
    "objectID": "docs/0Intro.html#ciclo-de-vida-del-análisis-de-datos",
    "href": "docs/0Intro.html#ciclo-de-vida-del-análisis-de-datos",
    "title": "Introducción",
    "section": "Ciclo de Vida del Análisis de Datos",
    "text": "Ciclo de Vida del Análisis de Datos"
  },
  {
    "objectID": "docs/Tema05ej1.html",
    "href": "docs/Tema05ej1.html",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "",
    "text": "El siguiente conjunto de datos tiene información sobre el volumen de usuarios de un camino ciclista (“via verde”) en EE.UU. Tenéis más información en la ayuda de RStudio.\n\nlibrary(tidyverse)\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nLa comisión gestora, PVPC, quiere entender la relación entre el volumen de usuarios y variables explicativas como incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon\n\\tag{1}\\]\n\nmodelo1 &lt;- lm(data = RailTrail,\n              volume ~ hightemp + cloudcover + weekday + precip)"
  },
  {
    "objectID": "docs/Tema05ej1.html#datos",
    "href": "docs/Tema05ej1.html#datos",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "",
    "text": "El siguiente conjunto de datos tiene información sobre el volumen de usuarios de un camino ciclista (“via verde”) en EE.UU. Tenéis más información en la ayuda de RStudio.\n\nlibrary(tidyverse)\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nLa comisión gestora, PVPC, quiere entender la relación entre el volumen de usuarios y variables explicativas como incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon\n\\tag{1}\\]\n\nmodelo1 &lt;- lm(data = RailTrail,\n              volume ~ hightemp + cloudcover + weekday + precip)"
  },
  {
    "objectID": "docs/Tema05ej1.html#apartado-1",
    "href": "docs/Tema05ej1.html#apartado-1",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Apartado 1",
    "text": "Apartado 1\nPara este apartado, trabajaréis con un coeficiente concreto de la Ecuación 1 estimada anteriormente. El coeficiente dependerá de la última cifra de vuestro DNI o similar:\n\nsi es 1, 4 o 7, con el de hightemp\nsi es 2, 5 o 8, con el de cloudcover\nsi es 3, 6 o 9, con el de weekday\nsi es 0, con el de precip\n\n\nCalcular el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error, bajo el supuesto de que los errores del modelo siguen una distribución normal.\n\n\nNota: bajo normalidad de los errores, \\(\\widehat{\\beta} \\sim N\\left(\\beta, Var(\\widehat{\\beta})\\right)\\) y \\((n-k)*s^2 / Var(\\varepsilon) \\sim \\chi^2_{(n-k)}\\), donde \\(n\\) es el número de observaciones, \\(k\\) es el número de coeficientes (incluida la constante) y \\(s^2\\) es la estimación de la varianza del error.\n\n\nUsar bootstrap para obtener el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error. Debéis fijar como semilla vuestro DNI para realizar un bucle como el visto en clase.\n\n\nComentar BREVEMENTE las diferencias en los intervalos de confianza de ambos apartados.\n\n\nNotas\n\nLos resultados de una estimación están almacenados en el objeto creado aplicando summary() a la función lm().\n\n\nsum.modelo1 &lt;- summary(modelo1)\n\n## Para todos los coeficientes (filas)\n## el valor estimado y su error estándar (dos columnas)\nsum.modelo1$coefficients[,1:2]\n\n## Varianza del error del modelo\nsum.modelo1$sigma^2\n\n## R-cuadrado\nsum.modelo1$r.squared\n\n\nIntervalo de confianza al 95% para el coeficiente estimado: \\(\\widehat{\\beta} \\pm z_{0.975} \\cdot \\sqrt{\\operatorname{Var}(\\widehat{\\beta})}\\), donde \\(z_{0.975}\\) es el valor crítico de la distribución normal estándar .\nIntervalo de confianza al 95% para la varianza del error: \\(\\left( \\frac{(n - k) \\cdot s^2}{\\chi^2_{0.975, (n - k)}}, \\frac{(n - k) \\cdot s^2}{\\chi^2_{0.025, (n - k)}} \\right)\\), donde \\(\\chi^2_{0.975, (n - k)}\\) y \\(\\chi^2_{0.025, (n - k)}\\) son los valores críticos de la distribución \\(\\chi^2\\) con \\(n - k\\) grados de libertad, correspondientes a los percentiles del 97.5% y 2.5%, respectivamente.\nEn R, los valores críticos se obtienen con qnorm() y qchisq() (mirad la ayuda)."
  },
  {
    "objectID": "docs/Tema05ej1.html#apartado-2",
    "href": "docs/Tema05ej1.html#apartado-2",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Apartado 2",
    "text": "Apartado 2\nRealizamos un análsis exploratorio de los datos y encontramos la siguiente forma para la relación no lineal entre el número de visitantes y la temperatura.\n\n\n\n\n\n\n\n\n\nPresentar en una tabla los resultados de estimar la Ecuación 1 y añadir primero la temperatura al cuadrado, después también la temperatura al cubo, la temperatura elevada a la cuarta potencia y finalmente elevada a la quinta potencia. Comentar qué modelo elegirías, es decir, qué grado del polinomio en temperatura captura mejor la relación no lineal descrita anteriormente. ¿Podríamos tener una relación no lineal distinta de la descrita por un polinomio?\n\nNotas sobre tablas de resultados en Quarto\n\nPodemos combinar tidy() (de la biblioteca broom) con las funciones de la biblioteca kableExtra para incluir tablas de estadísticos descriptivos o de resultados de regresión. En el documento de Quarto, se debe incluir la opción results: markup.\n\n\nlibrary(broom)\nlibrary(kableExtra)\nmodelo1 %&gt;% tidy() %&gt;%\n      kbl() %&gt;% kable_classic()\n\n\nNotad que tras usar tidy() tenemos un conjunto de datos. Por tanto, podemos usar comandos conocidos para manipular la tabla, p.e., no mostrar todas las columnas.\n\n\nmodelo1 %&gt;% tidy() %&gt;% select(term:std.error) %&gt;%\n  kbl() %&gt;% kable_paper()\n\n\nCon modelsummary(), podemos mostrar los resultados de uno o varios modelos en la misma tabla. También debemos incluir la opción results: markup.\n\nConsideramos el siguiente modelo: \\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\beta_5 \\cdot spring + \\beta_6 \\cdot summer + \\varepsilon\n\\]\n\nlibrary(modelsummary)\nmodelo2 &lt;- lm(data = RailTrail,\n                volume ~ hightemp + cloudcover + weekday + precip +\n                          spring + summer)\n\nmodelsummary(list(\"Modelo 1\" = modelo1,\n                  \"Modelo 2\" = modelo2),\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\",\n                          \"F\", \"rmse\") ,\n             stars = T)\n\n\n\n    \n\n    \n\n    \n    \n    \n      \n        \n        \n              \n                 \n                Modelo 1\n                Modelo 2\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  76.826\n                  45.483\n                \n                \n                  \n                  (62.710)\n                  (79.724)\n                \n                \n                  hightemp\n                  5.549***\n                  5.696***\n                \n                \n                  \n                  (0.781)\n                  (1.164)\n                \n                \n                  cloudcover\n                  -8.503*\n                  -8.353*\n                \n                \n                  \n                  (3.339)\n                  (3.435)\n                \n                \n                  weekdayTRUE\n                  -35.045\n                  -37.062+\n                \n                \n                  \n                  (21.752)\n                  (22.280)\n                \n                \n                  precip\n                  -106.483*\n                  -98.904*\n                \n                \n                  \n                  (40.720)\n                  (42.137)\n                \n                \n                  spring\n                  \n                  31.239\n                \n                \n                  \n                  \n                  (32.082)\n                \n                \n                  summer\n                  \n                  9.424\n                \n                \n                  \n                  \n                  (47.504)\n                \n                \n                  Num.Obs.\n                  90\n                  90\n                \n                \n                  R2\n                  0.500\n                  0.509\n                \n                \n                  R2 Adj.\n                  0.476\n                  0.473\n                \n                \n                  F\n                  21.208\n                  14.322\n                \n                \n                  RMSE\n                  89.67\n                  88.85"
  },
  {
    "objectID": "docs/Tema05ej1.html#apartado-3",
    "href": "docs/Tema05ej1.html#apartado-3",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Apartado 3",
    "text": "Apartado 3\nRealizamos un nuevo análisis exploratorio para la relación entre el número de visitas y la nubosidad (como porcentaje de cielo cubierto por nubes, en una escala continua de 0 a 10).\n\n\n\n\n\n\n\n\n\nDado lo que observamos en el gráfico, vamos a discretizar cloudcover. Primero, consideramos solo dos grupos: hasta 7.5 y más de 7.5. Luego, consideramos tres rangos: entre 0 y 5, entre 5 y 7.5, y mayor de 7.5. Finalmente, consideramos cuatro categorías: [0,2.5], (2.5,5], (5, 7.5] y (7.5, 10]. Presentar en una tabla el modelo de la Ecuación 1, con la variable cloudclover, y todas las variantes donde la hemos discretizado. Discutir qué especificación preferís y por qué.\n\nNotas\n\nComo hemos visto en las transparencias, se puede discretizar una variable con cut() (o cut_width(), cut_interval(), etc.), generando un factor con categorías dadas por los puntos de corte: ej., cut(cloudcover, breaks=c(0, 7.5, 10), include.lowest = T)\nTambién se podría generar una variable binaria para cada categoria con ifelse() (o if_else())"
  },
  {
    "objectID": "docs/Tema05ej1.html#apartado-4",
    "href": "docs/Tema05ej1.html#apartado-4",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Apartado 4",
    "text": "Apartado 4\nFinalmente, vamos a considerar otra variante de la ecuación Ecuación 1 donde los efectos de la temperatura (hightemp) y de la nubosidad (cloudcover) no son constantes, sino que su efecto es heterogéneo en función de otros factores, en este caso si es un día laborable (weekday). Estimaremos el siguiente modelo\n\\[\n\\begin{aligned}\nvolume &= \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip  \\\\\n&+ \\beta_5 \\cdot hightemp \\cdot weekday + \\beta_4 \\cdot  cloudcover \\cdot weekday + \\varepsilon\n\\end{aligned}\n\\tag{2}\\]\n\nmodelo1.H &lt;- lm(data = RailTrail,\n                volume ~ (hightemp + cloudcover)*weekday + precip)\n\nPresentar en una tabla los resultado de estimar la ecuación Ecuación 1 y de la ecuación Ecuación 2. Discutir si evidencia de que la temperatura y la nubosidad afectan de manera diferente a las visitas en función de otros factores. ¿Qué modelo preferiría?"
  },
  {
    "objectID": "docs/Tema05ej1.html#entrega",
    "href": "docs/Tema05ej1.html#entrega",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Entrega",
    "text": "Entrega\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema05ej1_123456789.qmd\nTema05ej1_123456789.zip"
  },
  {
    "objectID": "docs/Tema04ej2.html",
    "href": "docs/Tema04ej2.html",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "La biblioteca tidyquant integra análisis financiero con el ecosistema tidyverse, facilitando la obtención, transformación y visualización de datos económicos y financieros.\n\n\nFRED (Federal Reserve Economic Data) proporciona miles de series económicas. Ejemplo: PIB de España.\n\n# Obtener datos de PIB español\npib_esp &lt;- tq_get(\"CLVMNACSCAB1GQES\",\n                  get = \"economic.data\",\n                  from = \"2000-01-01\")\n\n# Visualizar evolución\nggplot(pib_esp, aes(x = date, y = price)) +\n  geom_line()\n\nCómo encontrar series FRED:\n\nBusca en fred.stlouisfed.org\nIdentifica el “símbolo” o código de la serie (ej: “UNRATE” para tasa de desempleo USA)\nUsa ese código en tq_get()\n\n\n\n\nPara acciones, identifica el símbolo en Yahoo Finance.\n\n# Obtener datos de dos empresas tecnológicas (Apple y Microsoft)\ntech_stocks &lt;- tq_get(c(\"AAPL\", \"MSFT\"),\n                      get = \"stock.prices\",\n                      from = \"2020-01-01\")\n\n# Gráfico de precios de cierre\ntech_stocks %&gt;%\n  ggplot(aes(x = date, y = close, color = symbol)) +\n  geom_line()\n\n\n\n\ntidyquant incluye gráficos financieros específicos:\n\n\nMuestran apertura, cierre, máximo y mínimo diarios:\n\ntech_stocks %&gt;%\n  filter(symbol == \"AAPL\", year(date) == 2024) %&gt;%\n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high,\n                       low = low, close = close))\n\n\n\n\nSuavizan tendencias de corto y largo plazo:\n\ntech_stocks %&gt;%\n  filter(symbol == \"AAPL\", year(date) &gt;= 2023) %&gt;%\n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high,\n                       low = low, close = close)) +\n  geom_ma(ma_fun = SMA, n = 50, color = \"blue\") +  # Media móvil 50 días\n  geom_ma(ma_fun = SMA, n = 200, color = \"red\")    # Media móvil 200 días"
  },
  {
    "objectID": "docs/Tema04ej2.html#obtener-datos-económicos-de-fred",
    "href": "docs/Tema04ej2.html#obtener-datos-económicos-de-fred",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "FRED (Federal Reserve Economic Data) proporciona miles de series económicas. Ejemplo: PIB de España.\n\n# Obtener datos de PIB español\npib_esp &lt;- tq_get(\"CLVMNACSCAB1GQES\",\n                  get = \"economic.data\",\n                  from = \"2000-01-01\")\n\n# Visualizar evolución\nggplot(pib_esp, aes(x = date, y = price)) +\n  geom_line()\n\nCómo encontrar series FRED:\n\nBusca en fred.stlouisfed.org\nIdentifica el “símbolo” o código de la serie (ej: “UNRATE” para tasa de desempleo USA)\nUsa ese código en tq_get()"
  },
  {
    "objectID": "docs/Tema04ej2.html#obtener-datos-financieros",
    "href": "docs/Tema04ej2.html#obtener-datos-financieros",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "Para acciones, identifica el símbolo en Yahoo Finance.\n\n# Obtener datos de dos empresas tecnológicas (Apple y Microsoft)\ntech_stocks &lt;- tq_get(c(\"AAPL\", \"MSFT\"),\n                      get = \"stock.prices\",\n                      from = \"2020-01-01\")\n\n# Gráfico de precios de cierre\ntech_stocks %&gt;%\n  ggplot(aes(x = date, y = close, color = symbol)) +\n  geom_line()"
  },
  {
    "objectID": "docs/Tema04ej2.html#visualizaciones-especializadas",
    "href": "docs/Tema04ej2.html#visualizaciones-especializadas",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "tidyquant incluye gráficos financieros específicos:\n\n\nMuestran apertura, cierre, máximo y mínimo diarios:\n\ntech_stocks %&gt;%\n  filter(symbol == \"AAPL\", year(date) == 2024) %&gt;%\n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high,\n                       low = low, close = close))\n\n\n\n\nSuavizan tendencias de corto y largo plazo:\n\ntech_stocks %&gt;%\n  filter(symbol == \"AAPL\", year(date) &gt;= 2023) %&gt;%\n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high,\n                       low = low, close = close)) +\n  geom_ma(ma_fun = SMA, n = 50, color = \"blue\") +  # Media móvil 50 días\n  geom_ma(ma_fun = SMA, n = 200, color = \"red\")    # Media móvil 200 días"
  },
  {
    "objectID": "docs/Tema04ej2.html#parte-1-datos-económicos-fred",
    "href": "docs/Tema04ej2.html#parte-1-datos-económicos-fred",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Parte 1: Datos Económicos (FRED)",
    "text": "Parte 1: Datos Económicos (FRED)\n\nTarea 1.1: Obtener series económicas\nDescarga las siguientes series económicas de la zona euro o países específicos:\n\nTasa de desempleo de la zona euro o un país europeo\nÍndice de precios al consumo (IPC) o inflación\nTipo de interés de referencia del BCE o equivalente\n\n\n\nTarea 1.2: Análisis univariante\n\nPara cada serie económica:\n\nVisualiza su evolución temporal completa\nCalcula estadísticos descriptivos básicos en todo el periodo y en los últimos 5 años\n\n\n\nDescribe brevemente qué patrones observas en cada serie: ¿tendencias? ¿estacionalidad? ¿cambios bruscos?"
  },
  {
    "objectID": "docs/Tema04ej2.html#parte-2-datos-financieros",
    "href": "docs/Tema04ej2.html#parte-2-datos-financieros",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Parte 2: Datos Financieros",
    "text": "Parte 2: Datos Financieros\n\nTarea 2.1: Obtener datos de acciones\nSelecciona 3 empresas europeas de sectores diferentes. Puedes elegir de:\n\nBanca: Santander, BBVA, Deutsche Bank\nEnergía: Iberdrola, Repsol, TotalEnergies\nTecnología: SAP, ASML, Infineon\nConsumo: Inditex, LVMH, Unilever\n\n\n\nTarea 2.2: Análisis de precios\n\nPara cada empresa:\n\nCrea un gráfico de velas para los últimos 6 meses\nAñade medias móviles (50 y 200 días) al gráfico completo\nCalcula estadísticos descriptivos del precio de cierre\nIdentifica períodos de alta/baja volatilidad\n\n\n\n\nTarea 2.3: Rendimientos\n\nCalcula los rendimientos diarios (% cambio en precio de cierre) para cada empresa:\n\n\nAnaliza y compara la distribución de rendimientos\nAnaliza y compara la volatilidad"
  },
  {
    "objectID": "docs/Tema04ej2.html#parte-3-integración-de-datos-económicos-y-financieros",
    "href": "docs/Tema04ej2.html#parte-3-integración-de-datos-económicos-y-financieros",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Parte 3: Integración de Datos Económicos y Financieros",
    "text": "Parte 3: Integración de Datos Económicos y Financieros\n\nTarea 3.1: Preparar datos mensuales\nAgrega tanto datos económicos como financieros a frecuencia mensual:\n\n\nTarea 3.2: Combinar datasets\nUne los datos económicos y financieros por fecha (mes/año):\n\n\nTarea 3.3: Análisis de covariación\nAnaliza las relaciones entre variables económicas y precios de acciones:\n\nMatriz de correlación: ¿Cómo se correlacionan las variables?\n\n\nGráficos de dispersión: Relaciones específicas de interés\n\n\nSeries temporales superpuestas:\n\nVisualiza cómo evolucionan juntas una variable económica y un precio (usando dos ejes Y si es necesario):\n\n¿Qué relaciones observas? ¿Son intuitivas o sorprendentes? ¿Alguna relación inversa?"
  },
  {
    "objectID": "docs/Tema04ej2.html#entrega-del-ejercicio",
    "href": "docs/Tema04ej2.html#entrega-del-ejercicio",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Entrega del ejercicio",
    "text": "Entrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema04ej2_123456789.qmd\nTema04ej2_123456789.html\nTema04ej2_123456789.zip"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Datos.html",
    "href": "Datos.html",
    "title": "Datos",
    "section": "",
    "text": "A lo largo de las clases utilizaremos varios conjuntos de datos de ejemplo:\n\nTema 0:\n\nrenta.txt\nsex_data.csv\nbeauty.xls\nnsw.dta\nearn.RData\n\nTema 1:\n\ndatosVisualizacion.RData\n\nTema 2:\n\nretail_data.RData\nVentasTabla\nDosTablas\nEmpleados\nregionEmpleado\n\nTema 4:\n\npymes_europa.csv\ndiccionario_pymes.csv\nstartups_fintech.csv\ndiccionario_startups.csv\n\nTema 5:\n\ndescuento.csv\ncensus.csv\nhealth_insurance.csv"
  },
  {
    "objectID": "Evaluacion.html",
    "href": "Evaluacion.html",
    "title": "Evaluación",
    "section": "",
    "text": "Nota: información adicional sobre segunda convocatoria y posibles contingencias en la ficha de la asignatura\n\n\n\n\nEjercicios teórico-prácticos (35%): prácticas a entregar durante el periodo de clases\nTrabajo empírico final (50%)\nParticipación (15%): preguntas y pequeños ejercicios en clase\nRequisito: asistir al menos a un 80% de las clases.\n\n\n\n\n\nTrabajo empírico final (65%)\nEjercicios teórico-prácticos (35%)"
  },
  {
    "objectID": "Evaluacion.html#evaluación-continua",
    "href": "Evaluacion.html#evaluación-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Ejercicios teórico-prácticos (35%): prácticas a entregar durante el periodo de clases\nTrabajo empírico final (50%)\nParticipación (15%): preguntas y pequeños ejercicios en clase\nRequisito: asistir al menos a un 80% de las clases."
  },
  {
    "objectID": "Evaluacion.html#evaluación-no-continua",
    "href": "Evaluacion.html#evaluación-no-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Trabajo empírico final (65%)\nEjercicios teórico-prácticos (35%)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 12:50h\nMiércoles de 11h a 12:50h\nViernes de 11 a 12:50h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud\n\n\n\n\n\nDespacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es\nTutorias: Miércoles de 11:00 a 13:00\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar la herramienta de tutorías de UACloud"
  },
  {
    "objectID": "index.html#pedro-albarrán",
    "href": "index.html#pedro-albarrán",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 12:50h\nMiércoles de 11h a 12:50h\nViernes de 11 a 12:50h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud"
  },
  {
    "objectID": "index.html#alberto-pérez",
    "href": "index.html#alberto-pérez",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es\nTutorias: Miércoles de 11:00 a 13:00\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar la herramienta de tutorías de UACloud"
  },
  {
    "objectID": "ProyectoFinal.html",
    "href": "ProyectoFinal.html",
    "title": "Proyecto Final",
    "section": "",
    "text": "Para realizar este proyecto final, debéis proponer un tema de estudio usando datos y las técnicas que hemos visto en el curso. Más abajo os indico unas propuestas tanto de temas como de fuentes para obtener datos. También podéis proponerme un tema de estudio, usando datos de que dispongáis por trabajo, contactos, búsqueda propia, etc.\nEl resultado final debe ser un proyecto de análisis de datos que tenga sentido en el ámbito de economía, empresa, negocios, finanzas, etc. (“business analytics”). Se aplicarán los conocimientos adquiridos en el curso, quedando claras todas las etapas del análisis de datos:\n\n\n\nPor tanto, debe explicarse claramente:\n\nObjetivo del análisis: qué cuestión se analiza y su importancia\nDatos: qué datos se utilizan, su origen, por qué son adecuados para el objetivo del análisis\nProcesamiento de los datos (importación, limpieza y transformación): por qué es necesario para el análisis\nAnálisis exploratorio de datos: qué información básica aprendemos de los datos y cómo esto ayuda a especificar los modelos\nProceso de Modelización: cómo se especifican distintos modelos que ayudan a responder al objetivo y cómo se validan para obtener el mejor modelo final\nComunicar de manera efectiva mediante gráficos, resultados de estimación, etc. las implicaciones de los resultados obtenidos en el análisis para el objetivo. En particular, explicar cómo los resultados responden a la cuestión económica, financiera o decisión de empresa que se plantea cómo objetivo."
  },
  {
    "objectID": "ProyectoFinal.html#elección-de-tema",
    "href": "ProyectoFinal.html#elección-de-tema",
    "title": "Proyecto Final",
    "section": "Elección de Tema",
    "text": "Elección de Tema\n\nPor favor, cumplimentad este FORMULARIO con vuestra propuesta de tema para el proyecto.\nDeben queda claro los objetivos/utilidad de hacer del análisis que proponéis; debéis indicar qué datos usaréis y comentar brevemente cómo pensáis hacerlo (si haréis regresión o clasificación, tipo de algoritmos, etc.)\nOs recomiendo hacer esto cuanto antes, preferiblemente tras discutirlo en clase.\nDebéis esperar a mi visto bueno sobre vuestra propuesta, para asegurar que tiene sentido y que los trabajos son diferentes (los datos pueden ser los mismos, pero NO con el mismo objetivo.)\n\n\nEn cualquier momento podéis consultarme dudas relativas al trabajo. Si fuera necesario, en enero podemos tener tanto tutorías presenciales, preferentemente coordinadas entre varios, para poder reservar un aula."
  },
  {
    "objectID": "ProyectoFinal.html#entrega-final",
    "href": "ProyectoFinal.html#entrega-final",
    "title": "Proyecto Final",
    "section": "Entrega Final",
    "text": "Entrega Final\n\nEl trabajo en su formato final deberá entregarse antes del lunes, 3 de febrero de 2025 (hora límite 23:55h de la noche) por medio de este FORMULARIO"
  },
  {
    "objectID": "ProyectoFinal.html#importante-plagio.",
    "href": "ProyectoFinal.html#importante-plagio.",
    "title": "Proyecto Final",
    "section": "IMPORTANTE: PLAGIO.",
    "text": "IMPORTANTE: PLAGIO.\n\nSeguro que podéis encontrar análisis ya realizados sobre vuestra propuesta, en internet o de estudiantes de cursos anteriores. Yo también.\nLa detección de plagio supondrá automáticamente el suspenso en todas las convocatorias de la asignatura en este curso académico y el inicio de la apertura de un expediente."
  },
  {
    "objectID": "Contenidos.html",
    "href": "Contenidos.html",
    "title": "Contenidos",
    "section": "",
    "text": "(10-Nov. a 16-Nov.)\n\nTema 05 - Ejercicio 1\nTema 06 - Selección y Regularización"
  },
  {
    "objectID": "Contenidos.html#semana-10",
    "href": "Contenidos.html#semana-10",
    "title": "Contenidos",
    "section": "",
    "text": "(10-Nov. a 16-Nov.)\n\nTema 05 - Ejercicio 1\nTema 06 - Selección y Regularización"
  },
  {
    "objectID": "Contenidos.html#semana-9",
    "href": "Contenidos.html#semana-9",
    "title": "Contenidos",
    "section": "Semana 9",
    "text": "Semana 9\n(3-Nov. a 9-Nov.)\n\nTema 05 - Modelización y Aprendizaje Estadístico\nTema 04 - Ejercicio 1\n\nFecha límite de entrega: dom., 9-nov., 23:59h\n\nTema 04 - Ejercicio 2\n\nEjercicio voluntario para subir nota.\nFecha límite de entrega: dom., 21-dic., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-8",
    "href": "Contenidos.html#semana-8",
    "title": "Contenidos",
    "section": "Semana 8",
    "text": "Semana 8\n(27-Oct. a 2-Nov.)\n\nTema 04 - Análisis Exploratorio de Datos"
  },
  {
    "objectID": "Contenidos.html#semana-7",
    "href": "Contenidos.html#semana-7",
    "title": "Contenidos",
    "section": "Semana 7",
    "text": "Semana 7\n(20-Oct. a 26-Oct.)\n\nTema 02 - Ejercicio"
  },
  {
    "objectID": "Contenidos.html#semana-6",
    "href": "Contenidos.html#semana-6",
    "title": "Contenidos",
    "section": "Semana 6",
    "text": "Semana 6\n(13-Oct. a 19-Oct.)\n\nTema 03 - Ejercicio\n\nFecha límite de entrega: dom., 19-oct., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-5",
    "href": "Contenidos.html#semana-5",
    "title": "Contenidos",
    "section": "Semana 5",
    "text": "Semana 5\n(06-Oct. a 12-Oct.)\n\nTema 03 - Introducción a Quarto"
  },
  {
    "objectID": "Contenidos.html#semana-4",
    "href": "Contenidos.html#semana-4",
    "title": "Contenidos",
    "section": "Semana 4",
    "text": "Semana 4\n(29-Sept. a 5-Oct.)\n\nTema 02 - Limpieza y Tratamiento de Datos"
  },
  {
    "objectID": "Contenidos.html#semana-3",
    "href": "Contenidos.html#semana-3",
    "title": "Contenidos",
    "section": "Semana 3",
    "text": "Semana 3\n(22-Sept. a 28-Sept.)\n\nTema 01 - Visualización de Datos\nTema 01 - Ejercicio\n\nFecha límite de entrega: dom., 05-oct., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-2",
    "href": "Contenidos.html#semana-2",
    "title": "Contenidos",
    "section": "Semana 2",
    "text": "Semana 2\n(15-Sept. a 21-Sept.)\n\nTema 0 - Ejercicio 1\n\nFecha límite de entrega: dom., 21-sep., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-1",
    "href": "Contenidos.html#semana-1",
    "title": "Contenidos",
    "section": "Semana 1",
    "text": "Semana 1\n(08-Sept. a 14-Sept.)\n\nIntroducción\nTema 0 - Introducción a R y a RStudio"
  },
  {
    "objectID": "docs/Tema01.html#por-qué-visualizar-datos",
    "href": "docs/Tema01.html#por-qué-visualizar-datos",
    "title": "Tema 01 - Visualización de datos",
    "section": "¿Por qué visualizar datos?",
    "text": "¿Por qué visualizar datos?\n\nObjetivos de Aprendizaje\nAl finalizar este tema, serás capaz de:\n\nComprender los principios fundamentales de la visualización de datos\nUsar la gramática de gráficos implementada en ggplot2\nCrear visualizaciones efectivas para análisis exploratorio\nAplicar buenas prácticas en la comunicación visual de datos\n\n\n\nResumir información que no se vería en los datos en bruto (hoja de cálculo)\nIdentificar patrones y relaciones entre variables\nComunicar hallazgos de forma efectiva a diferentes audiencias\n\n\n\nLa visualización es esencial en:\n\nBancos Centrales: dashboard de indicadores macroeconómicos\nConsultoras: presentaciones ejecutivas con insights de datos\nInvestigación: trabajos con gráficos que demuestran hipótesis\nMedios: The Economist, Financial Times - visualización como marca\nEmpresas: dashboards de KPIs, segmentación de clientes\n\nEn un buen gráfico, la audiencia encuentra obvias las ideas a transmitir, sin abrumar con muchos hallazgos"
  },
  {
    "objectID": "docs/Tema01.html#ggplot2-y-la-gramática-de-gráficos",
    "href": "docs/Tema01.html#ggplot2-y-la-gramática-de-gráficos",
    "title": "Tema 01 - Visualización de datos",
    "section": "ggplot2 y la Gramática de Gráficos",
    "text": "ggplot2 y la Gramática de Gráficos\n\nComponentes básicos:\n\nDatos\nEstéticas (aes): asocia variables a propiedades visuales (posición, longitud, área, color)\nGeometrías (geom): objetos para representar datos (líneas, círculos, barras)\nEscalas, Sistemas de coordenadas, Facetas (subgráficos), Contexto (títulos, leyendas), etc.\n\nConstruir gráficos como frases gramaticales\n\nsujeto + verbo + objeto = oración\ndatos + geometría + estética = gráfico de ggplot2\n\n\n\nElementos Básicos de un Gráfico\n\nSeñales Visuales (Aesthetics)\n\n\nPosición: ubicación en ejes x, y\nColor: matiz para distinguir categorías o magnitudes\nTamaño: área/radio para representar magnitudes\nForma: símbolos diferentes para categorías\nTransparencia: nivel alpha para densidad o solapamiento\n\n\nSistema de Coordenadas\n\n\nCartesiano (por defecto)\nPolar: coord_polar()\n\nGeográfico: coord_map()\n\n\nEscala\n\n\nNumérica lineal, logarítmica\nCategórica, temporal\n¿Cómo se traduce la distancia en algo con significado?\n\n\nContexto\n\n\nTítulos, leyendas, puntos/líneas de referencia\n\n\n“Por encima de todo, mostrar los datos”"
  },
  {
    "objectID": "docs/Tema01.html#creando-un-ggplot",
    "href": "docs/Tema01.html#creando-un-ggplot",
    "title": "Tema 01 - Visualización de datos",
    "section": "Creando un “ggplot”",
    "text": "Creando un “ggplot”\n\nlibrary(ggplot2)\nload(\"data/datosVisualizacion.RData\")\n\n\n\nSolo ggplot() crea un gráfico vacío\n\n\nggplot(data = ventas)\n\n\naes() define cómo las variables se asignan a propiedades visuales\n\n\nggplot(data = ventas, aes(x = marketing, y = ventas))\n\n\nAñadir capas con +: objeto geométrico geom_point()\n\n\nggplot(data = ventas, aes(x = marketing, y = ventas)) + \n  geom_point()\n\n\n\n\nNOTAR: datos y estética para todas las capas o solo para una\n\n\nggplot(data = ventas) + \n  geom_point(aes(x = marketing, y = ventas))"
  },
  {
    "objectID": "docs/Tema01.html#objetos-geométricos",
    "href": "docs/Tema01.html#objetos-geométricos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Objetos Geométricos",
    "text": "Objetos Geométricos\nCada geom_*() agrega un tipo diferente de capa:\n\n\n\nTipo\nFunción\nUso Habitual\n\n\n\n\nPuntos\ngeom_point()\nDispersión\n\n\nLíneas\ngeom_line()\nEvolución temporal\n\n\nBarras\ngeom_bar()\nFrecuencias categóricas\n\n\nHistograma\ngeom_histogram()\nDistribución continua\n\n\nCajas\ngeom_boxplot()\nEstadísticos descriptivos\n\n\nSuavizado\ngeom_smooth()\nTendencias\n\n\nTexto\ngeom_text()\nEtiquetas\n\n\n\nPara lista completa: buscar funciones que comienzan con geom_ en Ayuda"
  },
  {
    "objectID": "docs/Tema01.html#asociación-estética-con-aes",
    "href": "docs/Tema01.html#asociación-estética-con-aes",
    "title": "Tema 01 - Visualización de datos",
    "section": "Asociación Estética, con aes()",
    "text": "Asociación Estética, con aes()\n\nElementos estéticos son “algo que se puede ver” (información)\n\n\nCada aes() es una asociación entre una señal visual y una variable:\n\n\n\n\n\n\n\n\nposición: x, y\n|\nforma: shape\n\n\ncolor: color exterior\n|\nrelleno: fill (color interior)\n\n\ntamaño: size\n|\ntipo de línea: linetype\n\n\n\n\n\n\nposición: x, y\n\ncolor: color exterior\nrelleno: fill (color interior)\nforma: shape (de los puntos)\ntipo de línea: linetype\ntamaño: size\n\n\n\nAlgunas estéticas son solo adecuadas para variables cuantitativas o para cualitativas\nCada geom acepta solo un subconjunto de estéticas (ver ayuda)\nRegla de oro: Si quieres que algo varíe con los datos, ponlo en aes()\n\n\nggplot(ventas, aes(x = marketing, y = ventas)) +\n  geom_point(aes(color = region))"
  },
  {
    "objectID": "docs/Tema01.html#asociación-estética-vs.-opción-fija",
    "href": "docs/Tema01.html#asociación-estética-vs.-opción-fija",
    "title": "Tema 01 - Visualización de datos",
    "section": "Asociación Estética vs. Opción Fija",
    "text": "Asociación Estética vs. Opción Fija\n\nCon aes(), se visualiza una variable con una señal visual\n\n\nFuera de aes(), se establece un valor fijo de la señal visual\n\n\nggplot(ventas, aes(x = marketing, y = ventas)) +\n  geom_point(aes(color = \"red\"))\n\n\n\nPrincipio: Añadir señal visual para representar información, NO “embellecer”\n\n\nggplot(macro, aes(y = desempleo, x = pib)) +\n  geom_point(aes(color = norte), shape = \"diamond\")\n\n\nNO saturar el gráfico con estéticas fijas o información innecesaria\n\n\nggplot(macro, aes(y = desempleo, x = pib)) +\n  geom_point(aes(size = inflacion, color = deuda))\n\nggplot(macro, aes(y = desempleo, x = pib)) +\n  geom_point(shape = \"diamond\", color = \"blue\", size = 3)\n\n\nNota: norte (carácter) se convierte automáticamente a factor: → escala categórica\n\n\nesquisse: Interfaz Gráfica\nesquisse implementa visualmente la lógica de ggplot2:\n\nSimilar a Tableau, PowerBI, Gapminder\n“Arrastrar y soltar” variables a estéticas\n\n\n#install.packages(\"esquisse\")\nlibrary(esquisse)\nesquisser()                         \ndata(\"mpg\")\nesquisser(mpg, viewer = \"browser\")   \n\nCaracterísticas: - Elegir tipo de gráfico, estéticas, títulos, apariencia - Genera código R para crear el gráfico\n- Descargar gráfico creado - Ayuda para aprender cómo hacer las cosas"
  },
  {
    "objectID": "docs/Tema01.html#gráficos-como-objetos",
    "href": "docs/Tema01.html#gráficos-como-objetos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Gráficos como Objetos",
    "text": "Gráficos como Objetos\n\nUn gráfico también es un objeto de R\n\n\ngraf_base &lt;- ggplot(macro, aes(y = desempleo, x = pib)) +\n                geom_point()\n\n\nSe pueden agregar capas a este objeto:\n\n\ngraf_base + geom_line()\ngraf_base + geom_point(aes(shape = norte)) \ngraf_base + geom_point(aes(size = inflacion, color = deuda))"
  },
  {
    "objectID": "docs/Tema01.html#datos-y-estéticas-específicas-por-capa",
    "href": "docs/Tema01.html#datos-y-estéticas-específicas-por-capa",
    "title": "Tema 01 - Visualización de datos",
    "section": "Datos (y estéticas) específicas por capa",
    "text": "Datos (y estéticas) específicas por capa\n\n\nRecordad: cada capa puede usar datos o estéticas distintas\n\n\nEjemplo práctico:\n\ngeom_text(): acepta estéticas de etiquetas (variables con texto):\n\n\ngraf_base + geom_text(aes(label = pais), size = 3)\n\nlibrary(ggrepel)  # Evita solapamiento\ngraf_base + geom_text_repel(aes(label = pais), size = 3)\n\n\nAhora con datos específicos por capa si solo queremos señalar algunos puntos\n\n\ngraf_base + \n  geom_text_repel(\n    data = subset(macro, \n                  pais %in% c(\"España\",\"Francia\",\"Alemania\")), \n    aes(label = pais), size = 3)\n\n\nEsta idea se puede generalizar: usar distintos datos o estéticas en cada capa según las necesidades del gráfico"
  },
  {
    "objectID": "docs/Tema01.html#gráficos-que-muestran-datos-transformados",
    "href": "docs/Tema01.html#gráficos-que-muestran-datos-transformados",
    "title": "Tema 01 - Visualización de datos",
    "section": "Gráficos que muestran datos transformados",
    "text": "Gráficos que muestran datos transformados\n\nAlgunos gráficos (ej., dispersión) muestran los datos originales directamente\n\n\nPero otros gráficos representan estadísticas calculadas a partir de los datos\ngeom_boxplot(): datos → cuartiles, mediana\n\n\n\n\nggplot(clientes, \n       aes(y = gasto/1000)) +  \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\ngeom_smooth(): regresión → predicción de línea de tendencia\n\n\ngraf_base + geom_smooth()           # con intervalos de confianza\ngraf_base + geom_smooth(method = lm, se = FALSE)  \n\n\n\nPodríamos agregar la línea de regresión “manualmente”\n\n\nres &lt;- lm(gasto ~ ingreso, data = clientes)\nclientes$ingreso_pred &lt;- res[[\"fitted.values\"]]\n# graf_base +  geom_line(aes(y = ingreso_pred))  # ERROR: pred.SC no estaba en graf_base\n\ngraf_base &lt;- ggplot(clientes, aes(y = gasto, x = ingreso)) + geom_point()\ngraf_base + geom_line(aes(y = ingreso_pred))\n\n\nNO necesitamos repetir la estetica de posición x para geom_line() porque ya está definida en graf_base"
  },
  {
    "objectID": "docs/Tema01.html#gráficos-que-muestran-datos-transformados-cont.",
    "href": "docs/Tema01.html#gráficos-que-muestran-datos-transformados-cont.",
    "title": "Tema 01 - Visualización de datos",
    "section": "Gráficos que muestran datos transformados (cont.)",
    "text": "Gráficos que muestran datos transformados (cont.)\n\ngeom_bar() y geom_histogram(): datos → frecuencias por intervalo\nLa estadística predeterminada en geom_bar() es contar casos (stat_count)\n\nNotad que en Excel un gráfico de barras requiere los datos previamente transformados (datos contados)\n\n\n\nggplot(ventas, aes(x = region)) + geom_bar()\n\n\n\nCon datos ya transformados, usar stat = \"identity\":\n\n\n# Frecuencias automáticas\nggplot(ventas, aes(x = region)) + geom_bar()\n\n# Valores ya calculados - ventas promedio por región\nventas_promedio &lt;- ventas %&gt;% \n  group_by(region) %&gt;% \n  summarise(venta_media_miles = mean(ventas))\n\nggplot(ventas_promedio, aes(x = region, y = venta_media_miles)) + \n  geom_bar(stat = \"identity\")\n\n\n\nEn variables continuas, no hay categorías “naturales” para calcular frecuencias\n\nSe tienen que definir “arbitrariamente” los intervalos\nDistintas elecciones pueden revelar distinta información: p.e., no apreciamos un grupo importante de clientes con muy bajos ingresos en el último gráfico\n\n\n\ngraf &lt;- ggplot(clientes, aes(x = ingresos/1000))\ngraf + geom_histogram(bins = 20)              # Número de grupos\ngraf + geom_histogram(binwidth = 3)           # Ancho de grupos\ngraf + geom_histogram(breaks = seq(10,90,5))  # Rangos"
  },
  {
    "objectID": "docs/Tema01.html#escalas-control-de-asociación-estética",
    "href": "docs/Tema01.html#escalas-control-de-asociación-estética",
    "title": "Tema 01 - Visualización de datos",
    "section": "Escalas: Control de Asociación Estética",
    "text": "Escalas: Control de Asociación Estética\n\naes() establece qué variable asignar, la escala cómo representarla\nFunciones de escala: scale_&lt;estética&gt;_&lt;tipo&gt;. Ejemplos,\n\n\n\n\n\nEscala\nTipos\nEjemplos\n\n\n\n\n\n\n\n\n\nscale_color_\nidentity\nscale_fill_continuous\n\n\nscale_fill_\nmanual\nscale_color_discrete\n\n\nscale_size_\ncontinuous\nscale_color_manual\n\n\n\ndiscrete\nscale_size_discrete\n\n\n\n\n\n\n\nscale_shape_\ndiscrete\nscale_shape_discrete\n\n\nscale_linetype_\nmanual\nscale_shape_manual\n\n\n\nidentity\nscale_linetype_discrete\n\n\n\n\n\n\n\nscale_x_\ncontinuous\nscale_x_continuous\n\n\nscale_y_\ndiscrete\nscale_y_discrete\n\n\n\nreverse\nscale_y_reverse\n\n\n\nlog10\nscale_x_log10\n\n\n\ndate\nscale_x_date\n\n\n\ndatetime\nscale_y_datetime"
  },
  {
    "objectID": "docs/Tema01.html#escalas-cont.",
    "href": "docs/Tema01.html#escalas-cont.",
    "title": "Tema 01 - Visualización de datos",
    "section": "Escalas (cont.)",
    "text": "Escalas (cont.)\n\nAlgunos argumentos son habituales en casi todas las escalas (name, breaks, labels)\nOtros argumentos son específicos según el tipo de variables (continua, discreta) o la escala concreta\n\n\nggplot(macro, aes(y = pais, x = pib)) + \n  geom_point(aes(color = desempleo))  +\n  scale_color_continuous(breaks = c(5, 10, 15),\n                         labels = c(\"Bajo\", \"Medio\", \"Alto\"), \n                         low = \"green\", high = \"red\")\n\nggplot(macro, aes(y = desempleo, x = pib/1000)) + \n  geom_point(aes(color = norte, size = deuda, shape = norte)) + \n  scale_y_continuous(breaks = seq(0, 20, 5), limits = c(-5, 25)) +\n  scale_shape_discrete(labels = c(\"Norte\", \"Sur\"), \n                       name = \"Zona de Europa\")\n\n\n\nArgumentos Habituales\n\nlimits: mínimo y máximo\nbreaks: valores donde aparecen etiquetas\n\nlabels: etiquetas en cada break\nname: título de la escala\n\n\n\n\nNota: este ejemplo tiene elementos redundantes a efectos ilustrativos\n\n\n\nEj., dos estéticas para una variables\nlimits que no concuerdan con breaks"
  },
  {
    "objectID": "docs/Tema01.html#escala-logarítmica",
    "href": "docs/Tema01.html#escala-logarítmica",
    "title": "Tema 01 - Visualización de datos",
    "section": "Escala Logarítmica",
    "text": "Escala Logarítmica\n\nEn muchos contextos, las variables tienen un rango de valores amplio\n\nPIB, población (Lux 0.6M vs ALE 83M), clientes (pyme 500 vs Inditex 200M)\n\nEscala lineal vs logarítmica:\n\nLineal: misma distancia visual = mismo aumento absoluto → los valores pequeños quedan “aplastados” para mostrar los grandes\nLogarítmica: misma distancia visual = mismo incremento relativo (%)\n\n\n\nggplot(macro, aes(y = desempleo, x = poblacion)) + \n  scale_x_log10(breaks = seq(0,100,20)) + geom_point()\n\n\nMejor que x = log(pib) porque los ejes se muestran en unidades originales\n\n\n\nEn escala lineal: misma distancia entre 20 y 40 que entre 40 y 60 -&gt; incremento de 20 millones de personas en ambos casos\nEn escala logarítmica: misma distancia entre 20 y 40 que entre 40 y 80 -&gt; incremento del 100% en ambos casos\nqué es un logaritmo de euros o de personas\n\n\n\nUsar logs cambia la interpretación de diferencias absolutas a porcentuales\n\nMás relevante +10% o +500 clientes (mucho en pyme, nada en Inditex)\nNO para “evitar” valores extremos o distribución asimétrica"
  },
  {
    "objectID": "docs/Tema01.html#facetas-sub-gráficos",
    "href": "docs/Tema01.html#facetas-sub-gráficos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Facetas (sub-gráficos)",
    "text": "Facetas (sub-gráficos)\n\nLos sub-gráficos por variables categóricas son una alternativa a aes() para añadir variables\nFacilitan comparaciones, evitando la saturación visual (ej., demasiadas líneas en un solo gráfico)\n\n\ngraf_tiempo &lt;- ggplot(ventas_tiempo, aes(x = fecha, y = ventas))\ngraf_tiempo + geom_line(aes(color = region))\n\n\nfacet_wrap(): facetas por una variable (usando “fórmula” ~)\n\n\ngraf_tiempo + geom_line() + facet_wrap(~region, ncol = 2)\n\n\nfacet_grid(): facetas en dos dimensiones\n\n\ng3 &lt;- ggplot(data = clientes) + geom_histogram(aes(x = gasto))\ng3 + facet_grid(segmento ~ canal)  # Filas y columnas\ng3 + facet_grid(segmento ~ .)      # Solo por filas \ng3 + facet_grid(. ~ canal)         # Solo por columnas"
  },
  {
    "objectID": "docs/Tema01.html#contexto-con-labs",
    "href": "docs/Tema01.html#contexto-con-labs",
    "title": "Tema 01 - Visualización de datos",
    "section": "Contexto con labs()",
    "text": "Contexto con labs()\n\nUna buena práctica de legibilidad es dar título al gráfico, nombrar los ejes, incluir leyendas\n\nDescripciones claras de variables y sus unidades\n\n\n\nggplot(macro, aes(y = desempleo, x = pib/1000)) + \n  geom_point(aes(color = norte, size = deuda)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Relación entre PIB per cápita y tasa de desempleo\",\n    subtitle = \"Países de la Unión Europea (2023)\",\n    caption = \"Fuente: Eurostat\",\n    x = \"PIB per cápita (miles de €)\",\n    y = \"Tasa de desempleo (%)\",\n    color = \"Norte\",\n    size = \"Deuda pública (% PIB)\") +\n  scale_y_continuous(breaks = seq(0, 20, 5))"
  },
  {
    "objectID": "docs/Tema01.html#otros-elementos-de-contexto",
    "href": "docs/Tema01.html#otros-elementos-de-contexto",
    "title": "Tema 01 - Visualización de datos",
    "section": "Otros Elementos de Contexto",
    "text": "Otros Elementos de Contexto\n\nannotate(): añade objetos geométricos NO asociados a variables:\n\n\nggplot(macro, aes(y = desempleo, x = pib/1000)) +\n  geom_point(aes(color = norte)) + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  annotate(\"text\", x = 60, y = 11, \n           label = \"La doble división Norte-Sur\") +\n  annotate(\"text\", x = 85, y = 6, label = \"R ^ 2 == 0.45\", \n           parse = TRUE)\n\n\nLíneas de Referencia\n\n\nggplot(clientes, aes(x = canal, y = gasto/1000)) +\n  geom_boxplot() +\n  geom_hline(yintercept = 3.0, linetype = \"dashed\", \n             color = \"red\") +\n  annotate(\"text\", x = 3, y = 3.3, \n           label = \"Objetivo mínimo\", color = \"red\")"
  },
  {
    "objectID": "docs/Tema01.html#personalizar-el-aspecto-general",
    "href": "docs/Tema01.html#personalizar-el-aspecto-general",
    "title": "Tema 01 - Visualización de datos",
    "section": "Personalizar el aspecto general",
    "text": "Personalizar el aspecto general\n\n\nSe puede personalizar el aspecto general de la visualización del gráfico de dos formas: color y temas\n\nCOLOR\n\nCambiamos colores manualmente usando nombres o códigos hexadecimales\n\n\ngraf &lt;- ggplot(ventas, aes(x = region, y = ventas, \n                           fill = region)) + \n          geom_boxplot()\n\ngraf + scale_fill_manual(values = c(\"red\", \"green\", \"blue\", \"orange\"))\ngraf + scale_fill_manual(values = c(\"#1f77b4\", \"#ff7f0e\", \n                                    \"#2ca02c\", \"#d62728\"))\n\n\nPrecaución: los elementos decorativos deben ayudar a nuestro objetivo de transmitir información\n\n\n\nSe pueden cambiar manualmente colores (p.e., scale_fill_manual()) o la forma (ej., scale_shape_manual())\nPERO es preferible usar paletas predefinidas con criterios de diseño y visualización de información:\n\n\ngraf &lt;- ggplot(ventas, aes(x = region, y = ventas, fill = region)) + \n          geom_boxplot()\nlibrary(RColorBrewer)\ndisplay.brewer.all()\ngraf + scale_fill_brewer(palette = \"Set2\")\n\n\n\nRColorBrewer o viridis \nTambién se puede cambiar la forma con scale_shape_manual()\n\n\n\n\nTEMAS\n\nSe puede añadir una capa para definir el tema, es decir, estilo general de todos los componentes del gráfico:\n\n\n\nSe puede añadir una capa de tema (estilo general de todos los componentes)\n\n\n\n\ngraf + theme_gray()      \n\n\n\ngraf + theme_minimal()\n\n\n\nTambién existen temas profesionales predefinidos en bibliotecas\n\n\nlibrary(ggthemes)\ngraf + theme_economist() + scale_fill_economist()     \n\n\n\nNota: es posible, pero no recomendable personalizar elementos concretos del tema (o definir un tema nuevo propio)\n\n\ntema_empresa &lt;- theme_minimal() + \n  theme(text = element_text(color = \"darkblue\", family = \"Arial\"))\ngraf + tema_empresa\n\n\n\nMejores Prácticas\n\nPrincipios de Diseño\n\nClaridad sobre ornamentación\nDatos prominentes, diseño sutil\n\nProporciones adecuadas (ratio de aspecto)\nColores accesibles (daltonismo)\n\nElementos Contextuales\n\nTítulos descriptivos e informativos\nEtiquetas de ejes con unidades\nLeyendas claras y bien posicionadas\nFuentes de datos y notas metodológicas\n\nErrores Comunes a Evitar\n\nEjes que no empiezan en cero (cuando corresponde)\nDemasiados colores o patrones\nTexto ilegible por tamaño o contraste\n\nGráficos 3D innecesarios\nSobrecarga de información"
  },
  {
    "objectID": "docs/Tema01.html#ejemplos-aplicados",
    "href": "docs/Tema01.html#ejemplos-aplicados",
    "title": "Tema 01 - Visualización de datos",
    "section": "Ejemplos Aplicados",
    "text": "Ejemplos Aplicados\n\nRelación Gasto Marketing - Ventas\n\n\nggplot(ventas, aes(x = marketing, y = ventas)) +\n  geom_point(aes(color = region)) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"ROI del Gasto en Marketing por Región\",\n       x = \"Inversión en Marketing (miles €)\",\n       y = \"Ventas (miles €)\",\n       color = \"Región\") +\n  theme_minimal()\n\n\nDistribución de Satisfacción del Cliente\n\n\nggplot(ventas, aes(x = satisfaccion)) +\n  geom_bar(fill = \"steelblue\") +\n  facet_wrap(~producto) +\n  labs(title = \"Distribución de Satisfacción del Cliente por Producto\",\n       x = \"Puntuación de Satisfacción (1-5)\",\n       y = \"Número de Clientes\") +\n  theme_light()"
  },
  {
    "objectID": "docs/Tema01.html#ejemplos-aplicados-1",
    "href": "docs/Tema01.html#ejemplos-aplicados-1",
    "title": "Tema 01 - Visualización de datos",
    "section": "Ejemplos Aplicados",
    "text": "Ejemplos Aplicados\n\n\nComparación de Indicadores UE\n\n\nggplot(macro, aes(x = pais, y = pib)) +\n  geom_col(aes(fill = norte)) +\n  labs(title = \"PIB per cápita en países de la UE\",\n       x = \"País\",\n       y = \"PIB per cápita (miles €)\",\n       fill = \"Norte\") +\n  theme_economist() +\n  scale_fill_economist()\n\n\n\nIndicadores Macroeconómicos\n\n\nggplot(macro, aes(x = desempleo, y = inflacion)) +\n  geom_point(aes(size = deuda, color = norte)) +\n  geom_text_repel(aes(label = pais), size = 3) +\n  labs(title = \"Relación Desempleo-Inflación por País\",\n       x = \"Tasa de Desempleo (%)\",\n       y = \"Tasa de Inflación (%)\",\n       size = \"Deuda Pública (% PIB)\",\n       color = \"Norte de Europa\")\n\n\nBuenas prácticas: visualizar no es decorar datos, es comunicar insights\n\nUna idea por gráfico\nClaridad sobre ornamentación: cada elemento visual debe tener propósito\nTítulos y leyendas descriptivos e informativos\nEvitar demasiados colores o patrones y la sobrecarga de información\n\n\n\n\nEl contexto económico importa tanto como la técnica\n\n\n\nMejores Prácticas\n\nPrincipios de Diseño\n\nClaridad sobre ornamentación\nDatos prominentes, diseño sutil\n\nProporciones adecuadas (ratio de aspecto)\nColores accesibles (daltonismo)\n\nElementos Contextuales\n\nTítulos descriptivos e informativos\nEtiquetas de ejes con unidades\nLeyendas claras y bien posicionadas\nFuentes de datos y notas metodológicas\n\nErrores Comunes a Evitar\n\nEjes que no empiezan en cero (cuando corresponde)\nDemasiados colores o patrones\nTexto ilegible por tamaño o contraste\n\nGráficos 3D innecesarios\nSobrecarga de información"
  },
  {
    "objectID": "docs/Tema01.html#comentarios-finales",
    "href": "docs/Tema01.html#comentarios-finales",
    "title": "Tema 01 - Visualización de datos",
    "section": "Comentarios Finales",
    "text": "Comentarios Finales\n\nGuardar gráficos: en la pestaña de Plots &gt; Export o con el comando\n\n\nggsave(\"analisis-ventas.pdf\")\nggsave(\"dashboard-macro.png\", width = 12, height = 8, dpi = 300)\n\n\n\nRecursos de Ayuda\n\nHelp &gt; Cheatsheets &gt; Data Visualization with ggplot2\nChuletas de R y RStudio\nR Graph Gallery\nggplot2 book\n\nOtras bibliotecas de gráficos en R\n\nplotly: gráficos interactivos para dashboards\ngganimate: animaciones para evolución temporal\n\n\n\n\npatchwork: combinación de gráficos para reportes"
  },
  {
    "objectID": "docs/Tema03ej.html",
    "href": "docs/Tema03ej.html",
    "title": "Tema 03. Quarto. Ejercicio.",
    "section": "",
    "text": "Apartado a)\n\nIniciar un nuevo proyecto de Quarto y crear un nuevo documento .qmd. Adapta el encabezado para que tenga, al menos, un título y tu nombre como autor o autora. (Puedes eliminar el resto del contenido para los siguientes apartados, dejando espacio tras la cabecera).\nCrea una primera sección del documento, p.e., con el nombre “Apartado a)”. Para cada apartado posterior debes crear una nueva sección correspondiente al apartado.\nEscribe un breve frase introductoria general, una lista que enumere las dos variables que elegiste para el ejercicio de Visualización de Datos, incluye un enlace a una página web e inserta una imagen.\nNota: Puedes usar, aquí y en cualquier otra parte del documento, negritas o cursivas cuando lo consideres oportuno.\nGuarda el documento con un nombre con el siguiente formato que incluye vuestro número de DNI: Tema03ej_123456789.qmd\nRenderiza tu documento para visualizar el documento html creado.\nComprueba en el mismo directorio donde tienes el archivo .qmd se ha creado un archivo con extensión html; nota que también se ha creado un subdirectorio del mismo nombre que contiene todo lo necesario para visualizar el archivo html.\nCambia a otro formato de salida en el encabezado YAML y genera otro documento de salida.\nComprueba de nuevo que tienes un archivo de salida (.pdf o .docx) en el mismo directorio donde está el archivo .qmd.\nBorra el documento html y el subdirectorio con el mismo nombre generados previamente. Cambia la opción de YAML para que se genere un html autocontenido. Comprueba que puedes visualizar el archivo. Comentar.\n\n\n\nApartado b)\n\nEscribe una línea de texto (NO celda de código) que incluya (entre el texto) código de R para mostrar la media de la variable mpg del conjunto de datos mtcars.\nCrear y dar un nombre a una sub-sección que incluya lo siguiente.\n\nTres celdas, todas con el código summary(mtcars). La primera debe mostrar el código, pero no el resultado; la segunda sólo mostrar el resultado (no el código); la tercera debe mostrar ambos. Antes de cada celda, incluye una frase explicando qué va a pasar.\nCargar las bibliotecas AER y Hmisc en una nueva celda de código. Cambia los valores de warning, error y message y renderiza el documento para observar los cambios. Comentar los cambios brevemente y qué forma de presentación prefieres para tu documento.\n\nCrear y dar nombre a otra sub-sección.\n\nAñadir una celda con el código a &lt;- 2, fijando la opción para que NO se evalúe. Añadir otra celda posterior con código b &lt;- 3 + a y que sí se evalúe. Renderizar el documento y comprobar que da un error.\nCambiar las opciones del segundo fragmento para que se pueda renderizar un documento de salida.\n\n\n\n\nApartado c)\n\nCrear una celda con el código para mostrar un gráfico de puntos con los datos de mtcars para las variables disp (tamaño del motor) y mpg (consumo).\n\nAñadir en la celda de código (no usando ggplot) un título del gráfico (aparece en la parte inferior).\n\nCrear una nueva celda de código que incluya dos gráficos de caja, para disp y para mpg, que se muestren uno al lado del otro.\n\n\n\nApartado d)\n\nCrear una sub-sección. Incluir una nueva celda de código (que sí se evalúe) para mostrar mtcars y summary(mtcars).\nCrear una sub-sección. Incluir un nuevo fragmento de código (que sí se evalúe) y que incluya:\n\ncargar la biblioteca kableExtra para poder usar la función kbl()\nmostrar el resultado de mtcars y summary(mtcars) con la función kbl() con distintas opciones de estilo (una guía completa aquí). Por ejemplo\n\n\n\nmtcars %&gt;% kbl()  %&gt;%\n  kable_styling()\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_styling()\n\nmtcars %&gt;% kbl()  %&gt;%\n  kable_classic(full_width = F)\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_minimal()\n\nComentar las diferencias con el apartado anterior, d.i), y qué forma de presentación prefieres para tu documento.\n\n\nApartado e)\n\nIncluir la opción df-print: paged en la cabecera. Comprobar el efecto antes y después de incluirlo sobre cómo se muestra el conjunto de datos (“data frame”) mtcars en los apartados d.i) y d.ii).\nComentar las diferencias y qué forma de presentación prefieres para tu documento.\nIncluye la opción code-fold: true en la cabecera. Comprobar cómo cambia el documento y comentar brevemente qué forma de presentación prefieres para tu documento.\nElige un tema entre estos y aplícalo al documento.\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema03ej_123456789.qmd\nTema03ej_123456789.zip"
  },
  {
    "objectID": "docs/Tema04ej1.html",
    "href": "docs/Tema04ej1.html",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "Una firma de capital riesgo está evaluando startups fintech europeas para identificar oportunidades de inversión. Los datos contienen información financiera, operativa y de riesgo de 350 startups fundadas entre 2014-2023.\nLos datos están disponibles en el archivo startups_fintech.csv; una descripción detallada de las variables en diccionario_startups.csv\n\nIMPORTANTE:\n\nMuestra tu análisis manual (aunque uses herramientas automatizadas como punto de partida), justificando tus decisiones.\nNo basta con mostrar gráficos o tablas, explica qué significan y por qué son relevantes."
  },
  {
    "objectID": "docs/Tema04ej1.html#contexto-del-ejercicio",
    "href": "docs/Tema04ej1.html#contexto-del-ejercicio",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "",
    "text": "Una firma de capital riesgo está evaluando startups fintech europeas para identificar oportunidades de inversión. Los datos contienen información financiera, operativa y de riesgo de 350 startups fundadas entre 2014-2023.\nLos datos están disponibles en el archivo startups_fintech.csv; una descripción detallada de las variables en diccionario_startups.csv\n\nIMPORTANTE:\n\nMuestra tu análisis manual (aunque uses herramientas automatizadas como punto de partida), justificando tus decisiones.\nNo basta con mostrar gráficos o tablas, explica qué significan y por qué son relevantes."
  },
  {
    "objectID": "docs/Tema04ej1.html#pregunta-1.-cargar-explorar-y-limpiar-los-datos",
    "href": "docs/Tema04ej1.html#pregunta-1.-cargar-explorar-y-limpiar-los-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Pregunta 1. Cargar, Explorar y Limpiar los Datos",
    "text": "Pregunta 1. Cargar, Explorar y Limpiar los Datos\n\nApartado 1.a.\n\nIdentifica problemas de calidad.\n\n\n\nApartado 1.b.\n\nIdentifica qué variables tienen tipos incorrectos y corrígelos. Justifica por qué necesitan ser convertidas\n\n\n\nApartado 1.c. \n\nDetecta y elimina filas duplicadas.\nDetecta y elimina variables redundantes.\n\n\n\nApartado 1.d. \n\n¿Qué variables tienen valores ausentes y cuántos en cada variable?"
  },
  {
    "objectID": "docs/Tema04ej1.html#pregunta-2-análisis-exploratorio-de-datos",
    "href": "docs/Tema04ej1.html#pregunta-2-análisis-exploratorio-de-datos",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Pregunta 2: Análisis Exploratorio de Datos",
    "text": "Pregunta 2: Análisis Exploratorio de Datos\n\nApartado 2.a. Distribución de las variables principales\n\nMuestra tablas y/o gráficos de las variables que consideres más relevantes.\n\nPista: en otras, presta atención a subsector, etapa, pais, financiacion_total, valoracion, ltv_cac_ratio, rating_riesgo, tasa_retencion, probabilidad de éxito y empleados.\n\nComenta brevemente las características principales de las variables que se derivan de dichas tablas y/o gráficos.\nEntre otras cosas,\n\n¿Detectas inconsistencias en las categorías de alguna variable? En caso afirmativo, ¿cómo las corriges?\n¿Consideras que se pueden agrupar ciertas categorías para mejorar la interpretación?\n¿Algunas variables tienen distribuciones sesgadas o asimétricas?\n¿Algunas variables tienen valores extremos o “atípicos”?\n\nDiscute la información útil que se puede extraer de las variables analizadas a través de sus distribuciones o principales estadísticos.\n\n\n\nApartado 2.b. Relación entre variables\n\nEstudia las relaciones que consideres más relevantes usando estadísticos y visualizaciones.\nDiscute brevemente cómo es la relación.\n\nPor ejemplo, si es lineal o no, fuerte o débil, positiva o negativa, etc.\n\nEntre otras, tu análisis debería abordar las siguientes cuestiones:\n\nFinanciación por subsector.\nRelación financiación-valoración.\n¿Qué características están relacionadas con el riesgo de las startups? Pista: considera al menos ltv_cac_ratio, burn_rate, runway_meses y tasa_retencion.\n\n\n\nComparar indicadores clave (financiación, valoración, probabilidad de éxito) entre los principales países (los cinco países con más empresas).\nPatrones de madurez: ¿cómo cambian (o no) las características de las startups con la etapa?"
  },
  {
    "objectID": "docs/Tema04ej1.html#entrega-del-ejercicio",
    "href": "docs/Tema04ej1.html#entrega-del-ejercicio",
    "title": "Tema 04 - Análisis Exploratorio de Datos",
    "section": "Entrega del ejercicio",
    "text": "Entrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema04ej1_123456789.qmd\nTema04ej1_123456789.html\nTema04ej1_123456789.zip"
  },
  {
    "objectID": "docs/Tema00.html#introducción",
    "href": "docs/Tema00.html#introducción",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Introducción",
    "text": "Introducción\n\nDebéis tener instalados los programas gratuitos R y RStudio\nNos familiarizaremos con los conceptos y comandos básicos de programación en R\nR es un lenguaje interpretado: ejecuta las instrucciones directamente en la consola\n\n\nRStudio es un entorno de desarrollo integrado (IDE) que combina varias herramientas para facilitar el uso de R: consola, editor para escribir comandos, ayuda, etc.\n\n\n\nUn editor de texto NO es un procesador de texto (como Word): solo importa el texto sin formato (negrita, etc.)"
  },
  {
    "objectID": "docs/Tema00.html#r-studio",
    "href": "docs/Tema00.html#r-studio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "R Studio",
    "text": "R Studio"
  },
  {
    "objectID": "docs/Tema00.html#empezando-con-r",
    "href": "docs/Tema00.html#empezando-con-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Empezando con R",
    "text": "Empezando con R\n\nEscribimos comandos en la consola y se ejecutan pulsando Enter:\n\nLa tecla de tabulador  ofrece opciones de autocompletado\nEjecutar algo que no es un comando de R devuelve un error\n\n\n\n2 + 2\n3 * (1 - 4)^2\nsqrt(log(5/2))\npi\nhola\n\n\n\nOperadores aritméticos habituales: +,-,*,/, %/%, %%\nFunciones o constantes incorporadas: log, sqrt, abs, exp, round, pi\n\nabs(-5)\n9 %/% 4\n9 %% 4\n\nSi intentamos evaluar algo que NO es un comando de R o no está correctamente escrito, tendremos un ERROR\nEs NORMAL cometer errores\n\n\n\nO en el Editor de RStudio y se envían a la consola la o las líneas seleccionadas para ser evaluadas con el icono  o con el atajo de teclado Ctrl+Enter\nNOTA: en MacOS, usad la tecla Command en lugar de Ctrl"
  },
  {
    "objectID": "docs/Tema00.html#archivos-de-guion-scripts",
    "href": "docs/Tema00.html#archivos-de-guion-scripts",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Archivos de guion (“scripts”)",
    "text": "Archivos de guion (“scripts”)\n\nEs preferible incluir varios comandos en un archivo de texto para ejecutarlos\nSe puede replicar el proceso de cálculos paso a paso (no como Excel) \nCreamos un nuevo archivo con el icono  o en el menú File &gt; New File &gt; R script (atajo Ctrl + Mays + N)\nGuardamos el archivo con  o en File &gt; Save (atajo Ctrl + S), eligiendo un directorio y nombre de extensión “.R” (por defecto) o “.r”\nEn un archivo de guion (guardado), RStudio marca las líneas con error y muestra el mensaje de error al pasar el puntero"
  },
  {
    "objectID": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "href": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Trabajar con ficheros de guion",
    "text": "Trabajar con ficheros de guion\n\nCada comando es “una” línea y se ejecutan secuencialmente\nUn comando se puede extender visualmente más de una línea hasta completarse: p.e., hasta cerrar los paréntesis.\n\nEscribimos log(, en otra línea 9 y ejecutamos: la consola cambia de &gt; a + \nNo hace “nada” esperando que completemos el comando.\n\n\n\n\nNO LO VEREMOS: se pueden incluir más de un comando por línea, separados por “;”, pero el código es menos legible\nPodemos ejecutar todo el archivo:\n\nseleccionando todas las líneas Ctrl + A y luego \n\n\n\nusando  con “echo” o sin “echo” (no muestra resultados en consola)\n\nEn ambos casos, se para la ejecución cuando encuentra error\n\n\n\n\nEl carácter # marca el inicio de un comentario: lo que sigue se “ignora” (no se ejecuta) en R\n\n\n# Pueden ir al principio de la línea \n2 + 2 # o después de una instrucción\n\n\nComentar es un buen hábito: ayuda a entender/recordar qué hacemos\nNotad que RStudio tiene resaltado de sintaxis: distinto color para comentarios, números, funciones, etc."
  },
  {
    "objectID": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "href": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Directorio de Trabajo. Proyectos.",
    "text": "Directorio de Trabajo. Proyectos.\n\nConviene organizar los archivos relacionados con un mismo tema en una estructura de (sub)directorios a partir de un directorio de trabajo principal \n\n\nRStudio permite definir proyectos para gestionarlo fácilmente a través del menú File o desplegando el icono en la parte superior derecha \n\n\n\nPara conocer el directorio de trabajo actual\n\n\ngetwd()\n\n\nInicialmente el directorio de trabajo es el directorio por defecto del usuario del SO (“~”), donde “/” es el separador de directorios\n\nen Windows: C:/Users/nombre/Documents\nen MacOS: /Users/nombre\nen Linux: /home/nombre\n\n\n\nWindows usa la barra invertida “\\” (‘backward slash’ en lugar de ‘forward slash’) como separador de directorio en una ruta\n\n\nPERO “\\” tiene una función “especial” para cadenas de caracteres en programación: denotar caracteres especiales (“escapar”)\n\n\nSi “insistimos” en usarla, será su versión “escapada”: (C:\\\\Usuarios\\\\nombre\\\\Mis Documentos)\nEn el explorador de archivos (de Windows y de MacOS) la ruta “~” está en castellano (p.e., C:\\Usuarios\\nombre\\Documentos), pero internamente en inglés\n\n\n\nDesde el menú File &gt; New Proyect o desde el icono, creamos un nuevo proyecto:\n\nPodemos usar un Nuevo Directorio o elegir una ubicación ya existente\nEl nombre del proyecto será el nombre del directorio\nTambién se crea un archivo con el mismo nombre y extensión “.Rproj”\n\nAl abrir RStudio, tenemos activo el último proyecto abierto: ej., \nTanto desde el menú como desde el icono de gestión de proyectos, podemos\n\ncerrar el proyecto actual, File &gt; Close Projects,\nabrir otros proyectos guardados: File &gt; Open Project o File &gt; Recent Projects"
  },
  {
    "objectID": "docs/Tema00.html#proyectos-cont.",
    "href": "docs/Tema00.html#proyectos-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Proyectos (cont.)",
    "text": "Proyectos (cont.)\n\nPara trabajar con un archivo, usamos la ruta relativa al directorio de trabajo:\n\nsi están en el raíz del directorio: codigo.R, misdatos.Rdata\nsi están en un subdirectorio, indicamos la ruta separando directorios por /: datos/ventas.Rdata, datos/ano2020/ingresos.Rdata\n\nLa pestaña  en el cuadrante inferior-derecho ofrece una forma visual de abrir, crear, copiar, mover o eliminar archivos o directorios, etc.\n\n\nEvitad caracteres “raros” (acentos, espacios, etc.) en directorios y ficheros\nNOTA. El Explorador de Archivos de Windows y Finder de MacOS, no muestran defecto las extensiones de los archivos.\n\nPuede ser confuso para distinguir entre dos archivos con el mismo nombre y diferente extensión: proyecto.R y proyecto.Rproj\nConsultad cómo mostrarlas: p.e., para Windows y MacOS"
  },
  {
    "objectID": "docs/Tema00.html#funciones-en-r",
    "href": "docs/Tema00.html#funciones-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Funciones en R",
    "text": "Funciones en R\n\nLas expresiones que aceptan argumentos se denominan funciones.\n\n\nexp(2)\nceiling(5.2)\n\n\n\n\n\nAlgunos argumentos son obligatorios, otros tienen valores por defecto que se pueden omitir\nLos argumentos se pueden especificar por nombre o por orden.\n\n\nlog(2, base=2)\nlog(2, 10)\nlog(base = 10, x = 2)\n\n\n¿Cómo sabemos la manera de usar una función (ej. argumentos necesarios) o comando de R?\n\n\n\nNO omitir los argumentos tiene ventajas\n\nClaridad\nLos argumentos no tienen que especificarse en orden (sin nombre del argumento debe seguirse el orden establecido)"
  },
  {
    "objectID": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "href": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Ayuda en R y RStudio",
    "text": "Ayuda en R y RStudio\n\nRStudio tiene autocompletado y ayuda flotante para funciones y otros elementos de R\n\nP.e., si empezamos a escribir la función log, se muestra la forma esperada de trabajar con esa función\n\nRStudio también tiene una pestaña para buscar ayuda\n\n\nLas búsquedas online o las IAs (como chatGPT, Gemini o Copilot) pueden ser útiles.\nPERO debemos tener un conocimiento mínimo para aprovechar realmente una solución\n\nhay muchas formas de hacer lo mismo en R: una respuesta correcta puede no ajustarse a lo que ya sabemos\n\nNO uséis copiar-pegar sin entender el código: copiar-pensar-adaptar\n\n\n\nSe puede usar ?? para buscar ayuda en la consola sobre algo de lo que se desconoce el nombre concreto de la función\n\n\nNO siempre estará la solución exacta a nuestro problema\nLas soluciones pueden utilizar enfoques que requieren conocer comandos de extensiones (bibliotecas) de R"
  },
  {
    "objectID": "docs/Tema00.html#el-operador-de-asignación",
    "href": "docs/Tema00.html#el-operador-de-asignación",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El operador de asignación",
    "text": "El operador de asignación\n\nEl operador &lt;- almacena un contenido en un objeto con un nombre,1 que incluye letras, números y algunos carácteres especiales (“.”, “_”)\n\n\n\nalt - = &lt;-\nUn objeto es simplemente algo almacenado en la memoria de R\nImportante: recordar almacenar nuestros cálculos y resultados en objetos para poder reutilizarlos.\n\na menudo no es “recomendado”, es una necesidad\n\n\n\n\nx &lt;- 2*3    # asignación, no muestra resultado\nx           # ejecutamos mostrar la variable   \nprint(x)\n(x &lt;- 2)    # asignación e impresión a la vez\n\n\nR es “case-sensitive”: x y X son dos objetos distintos\nLos objetos asignados pueden usarse posteriormente, p.e., para generar otros a partir de ellos\n\n\ny &lt;- x + 5  # asignamos y a partir del VALOR de x\n(x &lt;- x*3)  # re-asignamos x a partir de ella misma\ny           # NO cambia (en Excel, sí)\n\n\n\nSe prefiere &lt;- para diferenciar asignación de objetos (NO solo asignaremos números) del concepto de igualdad matemática\nY se evita la confusión con = usado para dar valores a un argumento, log(2, base=10), y con la igualdad en comparaciones (==)\nTambién se puede mostrar con print(x) o con show(x)\nUn error habitual: object not found. Porque hemos creado x y luego queremos usar X…\nCuando se asigna a partir del objeto x, en la expresión aparece el contenido x en ese momento (no x propiamente dicho)\nEn Excel, si cambia un valor en una celda, cambian aquellas que la referencian.\n\n\nTambién se puede asignar con ="
  },
  {
    "objectID": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "href": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El Espacio de Trabajo en R ",
    "text": "El Espacio de Trabajo en R \n\nEl espacio de trabajo es el conjunto de objetos activos en memoria, resultado de todos los comandos ejecutados previamente\nEn RStudio, la pestaña  muestra los objetos y su valor\nLas funciones ls() y rm() muestran y eliminan respectivamente objetos del espacio de trabajo\n\n\n\n#| echo: false\nls()        # mostrar objetos\nrm(y)       # eliminar el objeto \"y\"\nrm(a,b,c)   # eliminar varios objetos (separados por comas)\n\n\n\nBorramos todos los objetos con  en el Environment o el comando\n\n\nrm( list=ls() )  # eliminar todos los objetos\nrm(y, x)         # eliminar solo algunos objetos\n\n\nGuardamos el contenido del entorno de trabajo con  (o al cerrar RStudio), pero es innecesario: ejecutando los comandos guardados en un archivo .R recuperamos los objetos\n\n\n\nNotar que el Environment también tiene una pestaña de History con todos los comandos ejecutados durante la sesión.\nVeremos cómo guardar datos en R con más detalle"
  },
  {
    "objectID": "docs/Tema00.html#mensajes-de-error-y-warning",
    "href": "docs/Tema00.html#mensajes-de-error-y-warning",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Mensajes de “Error” y “Warning”",
    "text": "Mensajes de “Error” y “Warning”\n\nEn programación, cometer errores es normal\nEn muchos errores, R se “quejará” mostrando mensajes en rojo\n\nAviso: R ofrece un resultado (y continuará al siguiente comando), PERO indica que puede haber algo “no deseado”\nError: para la ejecución, sin resultado, e “informa” de la razón\n\nAlgunos mensajes son claros, pero otros requieren más investigación\n\n\nPeor que un mensaje de error: escribimos (copiamos) un código que funciona pero no hace lo que queremos…\nEl ordenador NO se equivoca: hace lo que le pedimos según unas reglas bien definidas por R, que debemos conocer\n\nSed cuidadosos, pensad y entended cada paso del código \n\n\n\n\nAlgunos mensajes son intimidantes (en rojo!) … e indescifrables\nAviso: “He hecho lo que he podido para entender lo que pides (log. de un número negativo!), pero a lo mejor no es lo que quieres”\nConocer las “reglas” es saber programar (hablar) en ese lenguaje\nComo toda convención, algunas reglas de R pueden ser “arbitrarias”\n\np.e., log(-1) podría ser error y seq(from = 10, to = 2, by = 1) interpretado como una cuenta atrás\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y =="
  },
  {
    "objectID": "docs/Tema00.html#tipos-de-objetos-en-r",
    "href": "docs/Tema00.html#tipos-de-objetos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Tipos de Objetos en R",
    "text": "Tipos de Objetos en R\n\nTODO en R es un objeto, cada uno con distintas propiedades y, por tanto, distintas formas de trabajar con él\n\n\n\nR es un lenguaje orientado a objetos\n\n\n\nAdemás de las funciones, los principales objetos con los que trabajaremos son:\n\nvectores\nfactores\nconjuntos de datos (“data frames”)\nlistas\n\nEstos objetos pueden contener varios tipos de datos o variables:\n\nentero\nnumérico (números reales) \nlógico (valores verdadero/falso)\ncaracteres"
  },
  {
    "objectID": "docs/Tema00.html#vectores",
    "href": "docs/Tema00.html#vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores",
    "text": "Vectores\n\nUn vector es una secuencia de datos elementales, creados con el operador “c()” (combinar)\n\n\nx &lt;- c(2.5,-4.1,6.4,8.2)           # vector numérico\ny &lt;- c(3,0,-1,2)                   # vector de enteros\nw &lt;- c(\"hola\", 'adios')            # vector de caracteres \nz &lt;- c(FALSE, TRUE, T, F)          # vector lógico\n\n\n\nLos caracteres puede ir entre comillas simples ` o dobles \"\nT y F atajo para TRUE y FALSE\n\n\n\nPodemos crear vectores a partir de otros vectores o usando comandos\n\n\nz &lt;- c(x, y)\nx &lt;- rep(1, times=4)\ny &lt;- seq(from = 10, to = 1, by = -1)\nz &lt;- 1:10       # equivale a z &lt;- seq(1,10,1)\n\n\nUn vector sólo puede contener objetos de un único tipo elemental, que podemos conocer en el Environment o con str()"
  },
  {
    "objectID": "docs/Tema00.html#vectores-cont.",
    "href": "docs/Tema00.html#vectores-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores (cont.)",
    "text": "Vectores (cont.)\n\nSi se mezclan tipos distintos, R busca una clase que “acomode” a todos\n\n\nvcr &lt;- c(\"lunes\", 2) \n\n\nForzamos que un objeto sea tratado con una clase concreta, con as.integer(), as.numeric(), as.character() y as.logical()\n\nSi no se puede convertir a número, devuelve NA (con un “warning”)\n\n\n\n\n“lunes” no puede ser un número pero “2” sí se puede representar como carácter\n\nel carácter “2” NO es lo mismo que el número 2: no se pueden hacer operaciones matemáticas\n\nLas funciones is.numeric(), is.numeric(), is.logical() e is.character() comprueban si un objeto es del tipo indicado, devolviendo un valor lógico.\nDebemos diferenciar entre la clase de un objeto y como se muestra (formatea): ver la función format()\n\n\n\nNO se pueden realizar operaciones incompatibles entre clases\n\nCuidado con las comillas: NO es lo mismo un objeto (su contenido) que el carácter de su nombre\n\n\n\na &lt;- 4\nc &lt;- 'a' + 1\n\n\n\nLa clase de un objeto es única (solo un tipo de elementales) y puede conocerse en el Environment o con str()\n\n\nstr(y)\n\n\ncon class()\nTambién se puede conocer la clase/modo con is() o mode()\n\n\nstr() sirve para cualquier tipo de objeto: p.e., funciones: str(log)\n\n\n\nLos vectores pueden tener nombres (una “etiqueta” única para cada elemento): un vector de caracteres de la misma longitud asignado con names()\n\n\n\nLos nombres de un vector son un vector de caracteres de la misma longitud\n\n\naltura &lt;- c(176, 165, 189, 155, 168)\naltura\nnames(altura) &lt;- c(\"Jose\", \"Maria\", \"Juan\", \"Elena\", \"Rosa\")\nnames(altura)\naltura\n\n\n\n\nObviamente podemos asignar el vector creándolo con c() o a partir de un vector existente\nNotad cómo cambian las propiedades (cómo se ve el vector) tras aplicarle un nombre"
  },
  {
    "objectID": "docs/Tema00.html#aritmética-de-vectores",
    "href": "docs/Tema00.html#aritmética-de-vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Aritmética de vectores",
    "text": "Aritmética de vectores\n\nLa mayoría de los operadores se aplican elemento-a-elemento\n\n\n\n\na &lt;- seq(1,3,1)\nb &lt;- seq(6,8,1)\n\n\n\n\n\na+b\na*b\n\n\n\nCon diferentes longitudes, se repite el vector corto cuanto sea necesario\n\n\n\n\nb &lt;- 6:9\na + b\na + 1  # lo que queremos!\n\n\n\n\n\n\n\nAlgunas funciones relevantes\n\n\n\n\n\nlength(x)   # longitud\nsort(x)     # ordenar\nmax(x)      # máximo\nmin(x)      # mínimos\nsum(x)      # suma \nprod(x)     # producto \n\n\n\n\n\nmean(x)     # media \nvar(x)      # varianza\ntable(x)    # frecuencias\n\nsummary(x)  # estadísticos \n\n\n\n\nEs MUY CONVENIENTE revisar cuidadosamente las dimensiones de los vectores antes de una operación, aunque R va a proceder de una forma bien definida…"
  },
  {
    "objectID": "docs/Tema00.html#vectores-lógicos",
    "href": "docs/Tema00.html#vectores-lógicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores lógicos",
    "text": "Vectores lógicos\n\nObtenemos un objeto lógico enunciando una relación que puede ser cierta o falsa , como comparaciones básicas de igualdad o desigualdad\n\n\n\n\n1 == 1  # TRUE\n1 != 3  # TRUE\n1 &gt; 2   # FALSE\n\n\n\n\n\na &lt;- 3 \na &gt;= 3       # TRUE\na + 1 &lt;= 10  # FALSE\n\n\n\nCombinamos varios enunciados con operadores Y (&), O (|) y NO (!)\n\n\nPara conjuntos, x %in% Y es cierto cuando x es un elemento de Y\n\n\n\nNotad la doble igualdad == para el operador lógico de igualdad\nNuevamente podemos confundir los objetos hola y adios con sus caracteres\n\n\n\naltura &lt;- c(176, 165, 189, 155, 168)\n\naltura &gt;= c(175, 165, 195, 165, 168)  # elemento a elemento\naltura == 155                         # elemento a elemento\naltura &gt; 160 & altura &lt;= 180\naltura &lt; 160 | altura &gt;= 180\nc(165,179) %in% altura\ncondicion &lt;- !(altura &lt;= 170)\n\n\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y ==\naprender lógico para selección: paro de hombre,paro de hombre jovenes\ncondiciones compuesta: venta media de hombres de valencia y alicante en realidad es un enunciado formal con OR\n(recordad que esto también pasaba en gretl y en general aprender lógica)"
  },
  {
    "objectID": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "href": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Acceso a los elementos de un vector",
    "text": "Acceso a los elementos de un vector\n\nSe utiliza el operador [] (paréntesis cuadrado)1 y\n\n\n\nCon [[ ]] se enfatiza acceso a un elemento: esto es importante en otros objetos (listas, datos) pero no en vectores (ambas formas son equivalentes)\n\n\n\nPosiciones de los elementos, usando un vector de enteros\n\n\naltura[3]\naltura[c(1,3,5)]\n\n\nCon enteros negativos, indicamos posiciones que NO queremos\n\n\naltura[-c(2,4)] \n\n\n\nimporta el orden de las posiciones: altura[c(3,1)] frente altura[c(1,3)]\n\n\n\nCondición que satisfacen los elementos, usando un vector lógico\n\n\naltura[altura &gt; 180 | altura &lt; 160]\n\n\n(Si lo tienen) Nombres de los elementos, usando un vector de caracteres\n\n\n\nerror por comillas se puede hablar diferencias de altura[pos] y altura[“pos”] y altura[“Juan”]: confusió de comillas y diferencia entre objeto y caracter de nombre de objeto\nLa función which() también puede ser útil para posiciones lógicas\n\n\n\n\nLos vectores de selección pueden ser un objeto previamente asignado en los tres casos; p.e.,\n\n\npos &lt;- (altura &gt; 180 | altura &lt; 160)\naltura[pos]\n\n\nPodemos seleccionar un subconjunto del vector para trabajar con él\n\n\nalturaExtremo &lt;- altura[pos]\nmean(alturaExtremo)\n\n\nCon la asignación se pueden cambiar elementos específicos de un vector (o añadir nuevos)\n\n\naltura[3] &lt;- 196\n\naltura[c(\"María\", \"Luis\")] &lt;- c(169, 175)\n\n\nTambién con [[ ]]"
  },
  {
    "objectID": "docs/Tema00.html#factores",
    "href": "docs/Tema00.html#factores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Factores",
    "text": "Factores\n\nLa información cualitativa se suele codificar como texto o números, pero NO tiene sentido numérico (ni de “texto”): representan clases o categorías\n\n\nPara destacar la naturaleza distinta de estos datos, existe un tipo de objeto específico en R: los factores\nAdemás de otras ventajas que veremos, permiten separar la representación original de las categorías (niveles) de cómo queremos mostrarlas (etiquetas)\n\n\ngenero   &lt;- c(2, 1, 2, 2, 2)\ngenero_f &lt;- factor(genero, levels = c(1, 2), \n                           labels = c(\"Mujer\", \"Hombre\"))\n\n\nSe asocia nivel 1 con “Mujer”, 2 con “Hombre”, etc.\nLas operaciones con factores se realiza con las etiquetas, no con los niveles\n\n\ngenero_f == 1       # NO existe valor 1\ngenero_f == \"Mujer\"\n\n\n\nNotar que el comando factor() se extiende en el editor en varias lineas (no es “una” línea por comando)\nEn la consola, se indica que sigue siendo el mismo comando en múltiples líneas con + en lugar de &gt;"
  },
  {
    "objectID": "docs/Tema00.html#factores-cont.",
    "href": "docs/Tema00.html#factores-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Factores (cont.)",
    "text": "Factores (cont.)\n\nTambién podemos usar as.factor() para convertir un vector en un factor\nPERO es conveniente especificar los niveles y las categorías porque si no, R los asigna alfabéticamente\n\n\ng &lt;- factor(genero)  # as.factor(genero) hace lo mismo\ng\n\n\nEn este caso la etiqueta del primer nivel encontrado en los datos (el número 2) es “1” y la del siguiente nivel (el número 1) es “2”\nTambién podemos tener factores con orden con la opción order = TRUE y enumerando los niveles en orden\n\n\nsatisf   &lt;- c(\"A\", \"B\", \"A\", \"B\", \"M\")\nsatisf_f &lt;- factor(satisf, order = TRUE, \n                    levels = c(\"B\", \"M\", \"A\"),\n                    labels = c(\"Bajo\", \"Medio\", \"Alto\"))\n\n\n\nSi etiquetas y niveles coinciden, no es necesario especificarlos\n\n\nsatisf   &lt;- c(\"Alto\", \"Bajo\", \"Alto\", \"Bajo\", \"Medio\")\nsatisf_f &lt;- factor(satisf, order = TRUE,\n                        levels = c(\"Bajo\", \"Medio\", \"Alto\"))"
  },
  {
    "objectID": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "href": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Resumiendo” un vector numérico o un factor",
    "text": "“Resumiendo” un vector numérico o un factor\n\nLa función summary() devuelve los principales estadísticos descriptivos de un vector numérico\n\n\nsummary(altura)\n\n\n\nEl “resultado” de summary() también es un objeto de R: se puede asignar y trabajar con él\n\na &lt;- summary(altura)\nstr(a)\na[1:2]\n\n\nPara información cualitativa, la media y otros estadísticos no tienen sentido\n\n\nsummary(genero)\ngenero  &lt;- c(1, 20, 20, 1, 1)  # dos categorías igualmente\nsummary(genero)\n\n\nLa función summary() ofrece resultados diferentes según el tipo de objeto (porque tiene distintas propiedades)\n\n\nsummary(genero_f)\n\n\nMatrices\n\nLas matrices son una extensión de vectores a dos dimensiones.\nSe pueden crear con matrix(), a partir de un vector con todos los valores,  rellenando por columnas (argumentobyrow = FALSE) y conocemos su dimensión condim()`\n\n\nSe pueden crear con matrix() o uniendo vectores filas o vectores []: # nas (de las mismas dimensiones) con cbind() y rbind()\n\n\n\n\nr1 &lt;- 1:4\nr2 &lt;- c(4, 8, 5, 10)\nM1 &lt;- rbind(r1, r2)\n\n\n\n\n\nc1 &lt;- 11:12\nc2 &lt;- 25:26\nc3 &lt;- c(14, 25)\nM2 &lt;- cbind(c1, c2, c3)\n\n\n\nPodemos usarlos para añadir nuevas filas, columnas u otra matriz\n\n\nSi no tienen dimensiones compatibles, R repetirá (como ya vimos en aritmética de vectores)\n\nM1 &lt;- cbind(matrx, c(90,95))\nM2 &lt;- rbind(matrx, c(40, -20, 25))\nA &lt;- cbind(c(40,30), c(70, 75))\ncbind(M1, A)\nB &lt;- cbind(c(40, 2), c(-20, 1), c(25, 1))\nrbind(matrx, B)\n\nPodemos dar nombres a columnas y filas\n\n\ncolnames(M2) &lt;- c(\"ene\", \"feb\", \"mar\")\nrownames(M2) &lt;- c(\"gast\", \"ingr\")\n\nPodemos dar nombres a columnas y filas\n\nNotad que NO podemos usar la función names() vista anteriormente porque solo aplica a vectores\nTambién se puede especificar los nombres al crear con matrix con argumento dimnames\n\nmeses &lt;- c(\"ene\", \"feb\", \"mar\")\nmatrx &lt;- matrix(data = c(100, 60, 55, 75, 110, 85),\nnrow = 2,dimnames=list(c(\"gast\", \"ingr\"), meses))\n\nUsamos los paréntesis cuadrados para acceder a los elementos (o una sub-matriz) por posición, nombre o condición lógica\n\n\n\n\nM2[1,3]                 \nM2[\"ingr\", \"ene\"]      \nM2[c(1:2),c(1,3)]\n\n\n\n\n\nM2[2,]      # fila entera\nM2[,\"feb\"]  # columna entera\n\n\n\nNotad que en matrices tiene más sentido el doble paréntesis cuadrado [[ ]] (debería preferirse para acceder a un elemento por su posición sobre el total)\nTambién se pueden extraer filas o columnas enteras\n\nAritmética de Matrices\n\nLas operaciones habituales son elemento a elemento: la matrices deben tener las mismas []: # siones (o R repetirá elementos)\n\n\n\n\nmatrx + M2\nmatrx * M2\n\n\n\n\n\nmatrx - 3\nmatrx * 10 \n\n\n\nComo en el caso de vectores, si las dimensiones no son iguales, se repiten elementos\nEn las operaciones con escalares , realmente se han “expandido” los escalares a una matriz de []: ensiones equivalentes (una matriz con todos los elementos iguales al escalar)\nSe pueden hacer todo tipo operaciones matriciales con R como multiplicación matricial, %*%, []: # poner, t(M1), invertir, solve(A), etc.\nTambién existen funciones para matrices: diag(), rowSums(), colMeans(), etc.\n\nFunciones para Matrices\n\nPara crear la matriz identidad de dimensiones \\(n\\times n\\)\n\n\n#| echo: false\ndiag(n)     \n\n\nPara crear un matriz con los elementos del vector vec en la diagonal\n\n\n#| echo: false\ndiag(vec)   \n\n\nSe pueden calcular sumas o medias de las filas o columnas de una matriz\n\n\nNotar que mean(matrx) calcula la media de todos los elementos de la matriz (como si fuera un vector)\nTambién, se puede operar con un subconjunto de la matriz (que puede ser otra matriz o un vector)\n\n“Arrays”\n\nUn “Array” es un vector de “n” dimensiones. Se crea con la función array\n\n\nx &lt;- array(c(1:8), dim =c(2,2,2) )\nx\n\n\nSe puede acceder a los elementos con paréntesis cuadrados\n\n\nx[2,1,2]\nx[,,1]\n\n\nLos nombres de todas las dimensiones de un “array” (includas matrices) se manejan con la función dimnames, además de al crearlos.\n\nEs un tipo de objetos nuevos conocidos como listas."
  },
  {
    "objectID": "docs/Tema00.html#data-frames",
    "href": "docs/Tema00.html#data-frames",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Data Frames”",
    "text": "“Data Frames”\n\nEs un tipo de objetos específico para facilitar el análisis de datos: una colección de variables por columnas y observaciones por filas.\n\n\nCada columna es un vector con un nombre y tipos de datos (quizás) diferentes\n\n\naltura &lt;- c(177, 178, 168, 164, 186, 162, 160)\npeso   &lt;- c(75, 85, 70, 60, 80, 65, 54)\ngenero   &lt;- c(2, 1, 2, 2, 2, 1, 1)\ngenero_f &lt;- factor(genero, levels = c(1, 2), \n                           labels = c(\"Mujer\", \"Hombre\"))\ndatos &lt;- data.frame(\"Altura\"=altura, \"Peso\"=peso, \"Genero\"= genero_f)\n\n\n\nLos “data frames” son una colección (técnicamente, una lista) de vectores que corresponde a cada variable.\nPor ser listas, pueden tener columnas de tipos de diferentes, a diferencia de las matrices\n\n\n\nSe visualizan con View(datos) o en “Enviroment” o una parte con head() \n\n\nSeleccionamos columnas por nombre con $ o por nombre o posición con [[ ]]\n\n\nvectAltura &lt;- datos$Altura    # objeto resultante = vector\ndatos[[2]] == datos[[\"Peso\"]]"
  },
  {
    "objectID": "docs/Tema00.html#data-frames-cont.",
    "href": "docs/Tema00.html#data-frames-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Data Frames” (cont.)",
    "text": "“Data Frames” (cont.)\n\n\nnotar\n\naltura_vect[1] == datos$altura[1]\ndatos[[2]][1] == datos[[\"peso\"]][1]\n\n\nTambién podemos usar [] para seleccionar filas y columnas por posición, nombre y/o condición lógica\n\n\ndatos1 &lt;- datos[datos$Genero == \"Hombre\", 1:2]  # Altura y Peso de hombres        \n\n\n\n\n\nSuele ser mejor usar subset() que devuelve siempre un “data frame”\n\n\nD1 &lt;- subset(datos, Altura &gt; 165)   \nD2 &lt;- subset(datos, subset = Altura %in% c(177,178),\n                    select = c(Altura, Peso)) \n\n\nGeneramos nuevas variables con el vector de asignación\n\n\ndatos$Altura_m &lt;- datos$Altura / 100\n\n\n\nTambién se puede usar (pero NO recomendable) attach(): carga un objeto en el “Global Environment” y no es necesario poner su nombre para acceder a las variables con $\n\n\nÚtil con solo un conjunto de datos o si no hay lugar de confusión (no hay el mismo nombre de variable en diferentes conjuntos de datos)\nSe deja de vincular con detach()\n\n\nPara ordenar un conjunto de datos por una variable, order() crea un vector de posiciones de orden\n\n\n\nSe pueden añadir filas y columnas a un data frame con rbind() y cbind(), respectivamente, a partir de vectores u otros data frames"
  },
  {
    "objectID": "docs/Tema00.html#listas",
    "href": "docs/Tema00.html#listas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Listas",
    "text": "Listas\n\nUna lista es una colección de objetos de distinto tipo (a diferencia de un vector)\n\n\n\nVeremos que muchos objetos de R son listas\nTambién vemos las propiedades del objeto en el Environment\n\n\n\nLos elementos de una lista suelen tener nombres\n\n\nmiLista &lt;- list(saludo=\"hola\", vec=x, lista=list(1:4, \"X\"), \n                datos=datos)\n\n\nCon [[ ]] (por posición o por nombre) o con $(solo por nombre) extraemos los elementos en su clase original\n\n\nmiLista$vec\nmiLista[[2]] + 3\n\n\nTambién podemos usar [], pero devuelve una lista\n\n\n\nNota: el uso de [ ] y [[ ]] también se aplica a “data frames”\nEs importante entender el tipo de objeto de obtenemos con una forma de acceso u otra, por las operaciones que podemos realizar y por las transformaciones que se permiten\nP.e., podemos acceder a elementos individuales de la (sub-)lista con [[ ]], pero no con [ ]:\n\nmiLista[[2]][2]\nmiLista[2][2]   # lista de longitud 1\n\n\nunlist() convierte una lista en vector, usando la clase que pueda ajustarse a todos los objetos (elementales)"
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-libraries",
    "href": "docs/Tema00.html#bibliotecas-libraries",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (“libraries”)",
    "text": "Bibliotecas (“libraries”)\n\nUna biblioteca contiene nuevos objetos de R: funciones, datos, etc.\nPara instalar una nueva biblioteca (se hace una vez), en Tools &gt; Install packages o en  o con el comando \n\n\ninstall.packages(\"AER\")\n\n\nMantenemos actualizados los paquetes, en el menú Tools o en \nLa biblioteca solo está disponible si se carga en la sesión actual\n\n\nlibrary(AER)\n\n\nNota: en adelante, la bibliotecas que carguemos se suponen instaladas\nEn  vemos las bibliotecas instaladas y las cargadas aparecen marcadas \n\n\n\nR puede extenderse con capacidades adicionales instalando paquetes con bibliotecas\nSe instala UNA VEZ, se carga en cada sesión que se usa\nPodemos ver las bibliotecas cargadas en \n\nmirarlo antes y después de library(AER)\no por línea de comandos\n\n\n\nLa ayuda contiene información sobre las funciones de una biblioteca, incluyendo ejemplos de uso (“vignettes”) en algunos casos\n\nlibrary(help=utils)\n\nPodemos descargar una biblioteca de memoria con detach()\nLa función require() es “similar” a library()"
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-cont.",
    "href": "docs/Tema00.html#bibliotecas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (cont.)",
    "text": "Bibliotecas (cont.)\n\nEl nombre completo de un objeto es biblioteca::nombre\n\nLa nombre de la biblioteca solo es necesaria si no se ha cargado o dos objetos diferentes tienen el mismo nombre en bibliotecas distintas\n\n\n\n\n\nbase::log(1)\nlog(1)\n\n\n\n\n\nlibrary(Hmisc)\nfind(\"units\")\n\n\n\n\nEn la Ayuda, vemos la biblioteca a la que pertenece una función (entre llaves)\nEl nombre completo es necesario si hay conflicto entre bibliotecas: contienen objetos con el mismo nombre\n\n\nTambién se usa nombre completo si no se ha cargado la biblioteca\n\n\n\nPara mostrar todos los datos de las bibliotecas cargadas\n\n\ndata()\n\n\nLos podemos cargar en el “Environment” y obtener información detallada en la ayuda (ej., nombre de variables)\n\n\ndata(\"Affairs\")\nhelp(\"Affairs\")"
  },
  {
    "objectID": "docs/Tema00.html#datos-nativos-en-r",
    "href": "docs/Tema00.html#datos-nativos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos “nativos” en R",
    "text": "Datos “nativos” en R\n\nGuardamos objetos del espacio de trabajo con save() (en una ruta relativa al directorio de trabajo)\n\n\nx &lt;- 1:20\ny &lt;- 2 * x ^ 2 + 1\nsave(x, file=\"x.RData\")      # un objeto, o varios\nsave(x, y, file=\"data/xy.RData\")  #   separados por comas\n\n\n\nExtensiones .RData, .rda, .rds, …\nO todo el workspace con save.image() (= icono )\n\n\n\nPara cargar datos al espacio de trabajo, con load() (= icono )\n\n\nload(\"data/xy.RData\")\n\n\nEn la pestaña de : doble-clic carga un archivo de datos\nNota: este tipo de archivo puede contener varios objetos, incluidas varios conjuntos de datos\n\n\n\nEs posible cargar directamente desde internet:\n\nload(url(\"https://github.com/albarran/BigDataEcon/raw/main/data/altura.RData\"))\n\nTambién se eliminan archivos con la función unlink()"
  },
  {
    "objectID": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "href": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos en otros formatos externos a R",
    "text": "Datos en otros formatos externos a R\n\nVarias bibliotecas permiten trabajar con distintos formatos de datos, p.e.:\n\nTexto, con delimitadores o de ancho fijo: utils (R base), readr\nHojas de cálculo: readxl, openxlsx \nFormatos de software estadístico: haven, foreign\n\n\n\n\nDos bibliotecas a veces ofrecen comandos distintos que hacen lo mismo\nPero tienen distintas opciones y sus opciones por defecto son diferentes (p.e., cómo tratan los caracteres: ¿se convierten a factores?)\n\n\n\nDescargad estos ejemplos (UA cloud): renta.txt, sex_data.csv, beauty.xls, nsw.dta\nEn  de RStudio, tenemos acceso visual para cargar algunos formatos (con la biblioteca necesaria instalada)\nrio es un meta-paquete (instala otras bibliotecas) para importar y exportar varios formatos de datos de forma sencilla\n\nA partir de la extensión del archivo, detecta el formato y, por tanto, la biblioteca necesaria"
  },
  {
    "objectID": "docs/Tema00.html#importar-y-exportar-con-rio",
    "href": "docs/Tema00.html#importar-y-exportar-con-rio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Importar y exportar con rio",
    "text": "Importar y exportar con rio\n\nrio permite trabajar con el mismo comando para todos los formatos, pero las opciones por defecto pueden no ser adecuadas\n\nEn la Ayuda se incluye una presentación completa del paquete\n\n\nEl comando import() se usa para leer los datos\n\n\nlibrary(rio)\nsex   &lt;- import(\"data/sex_data.csv\")\nrenta &lt;- import(\"data/renta.txt\")\nbeauty &lt;- import(\"data/beauty.xls\")\nnsw    &lt;- import(\"data/nsw.dta\")    # formato Stata\n\n\nPodemos exportar datos a un tipo de formato con export()\n\n\nexport(nsw, \"data/nsw.csv\")\n\n\nO convertir un archivo del disco a otro formato con convert()"
  },
  {
    "objectID": "docs/Tema00.html#otras-fuentes-de-datos",
    "href": "docs/Tema00.html#otras-fuentes-de-datos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Otras fuentes de datos",
    "text": "Otras fuentes de datos\n\nBibliotecas con datos muy utilizados: pwt (“Penn World Tables”)\nBibliotecas con funciones para obtener datos online (con APIs públicas)\n\ndatos de las OECD y eurostat (incluye datos del INE español)\nrdbnomics para los datos gratuitos de https://db.nomics.world/\ndatos económicos y financieros con quantmod y tidyquant\nquandl (de pago)\n\nqualtRics trabaja con software de encuestas qualtrics\nDescarga de páginas web y webscraping con las bibliotecas rvest y httr (función GET())\ngooglesheets4\nDBI accede con Bases de Datos relaciones (SQL)"
  },
  {
    "objectID": "docs/Tema00.html#gráficos-básicos",
    "href": "docs/Tema00.html#gráficos-básicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Gráficos Básicos",
    "text": "Gráficos Básicos\n\nPodemos representar gráficos de dos variables o funciones\n\n\n\n\nx &lt;- c(3, 4, 5, 6, 7, 8)\ny &lt;- c(5, 3, 7, 7, 5, 10)\n\n\n\n\n\nplot(x,y)\n\n\n\nEl resultado aparece en la pestaña Plots de RStudio\n\n\n\n\n\nPodemos cambiar opciones (ver Ayuda de plot.default) como type (puntos, líneas, etc.), símbolo de punto (pch), tipo de línea (lty), ancho de línea (lwd), color (col), título, etiquetas de los ejes, etc.\n\n\nplot(x, y, type=\"b\", pch=3)\nplot(x, y, type=\"l\", lty=2, lwd=2)\nplot(x, y, xlab=\"Eje X\", ylab=\"Eje Y\", main=\"Mi título\")\n\n\nSe pueden cambiar más opciones con par(), combinar gráficos, añadir líneas, texto, etc. y exportar los gráficos"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables discretas",
    "text": "Estadísticos descriptivos: variables discretas\n\nPara variables discretas (factores), table() calcula distribuciones de frecuencias de una variable o conjuntas: el resultado es un objeto\n\n\ndata(\"PSID1982\", package = \"AER\")\n(frec  &lt;- table(PSID1982$occupation) )\n(frec2 &lt;- table(PSID1982$occupation, PSID1982$ethnicity))\n\n\n\nEl objeto es una “tabla” es una variante de vector o matrices con nombres\nSe podría opera con él: table(PSID1982$occupation) / sum(table(PSID1982$occupation)))\n\n\n\nPodemos mostrar frecuencias relativas con prop.table()\n\n\n\n\nprop.table(frec)\nprop.table(frec2)\n\n\n\n\n\nprop.table(frec2, margin = 1)\nprop.table(frec2, margin = 2)\n\n\n\n\nRecordad: conceptos de distribución marginal (probabilidad de un valor en X), distribución conjunta (prob. de un valor de X Y uno de Y ) y distribución condicional (prob. de Y dado un valor de X)\n(In)dependencia y distribuciones conjunta y marginal: p.e., la distribución de trabajos es distinta en general o condicional a ser afroamericano\n\nsabiendo que una persona es afroamericano, es más probable que sea cualificado (mayor renta, etc.)\n\n\n\n\nTambién es informativa su representación con gráficos de barras\n\n\nbarplot(frec, horiz = T)\nbarplot(prop.table(frec2), beside = T)\n\n\n\nbarplot(prop.table(frec2)) en otros casos puede ser más informativo que aquí\nTambién se puede representar con gráficos de tarta: pie(frec)\nLos gráficos admiten (casi) todas las opciones de plot() como títulos, etc. y otras específicas"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas",
    "text": "Estadísticos descriptivos: variables continuas\n\ndata(ceosal1, package='wooldridge')\n\n\nYa hemos visto funciones de estadísticos como mean(), var(), etc.\n\n\nmedian(ceosal1$salary)\nvar(ceosal1$salary)\n\n\nquantile(ceosal1$salary, \n         probs=c(0.25, 0.75) ) # 1er y 3er cuartil\n\nsummary(ceosal1$salary)  # de una variable (vector)\nsummary(ceosal1)         # de todo el conjunto de datos  \n\ncov(ceosal1$salary, ceosal1$roe)  # covarianza\ncor(ceosal1$salary, ceosal1$roe)  # correlación\n\n\n\nRecordad el tratamiento diferente de factores en summary()\nOtras funciones de estadísticos: min(), max(), range(), sum()"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas (cont.)",
    "text": "Estadísticos descriptivos: variables continuas (cont.)\n\nPara variables continuas, las frecuencias de valores en un intervalo se pueden tabular o graficar en un histograma\n\n\n\nEn teoría, cada obervación de una variable continua tiene valores distinto; en la práctica se repiten pero no tanto como en las discretas\n\n\n\nhist(ceosal1$roe)   # intervalos automáticos\nhist(ceosal1$roe, freq=F,       # densidad, no casos\n     breaks=c(0,5,10,20,30,60)) # intervalos explícitos\n\n\nO la densidad (versión suavizada del histograma)\n\n\nplot(density(ceosal1$roe))\n\n\n\nSe pueden combinar histograma y densidad ejecutando hist(x) y luego lines(density(x))\n\n\nLa función de distribución acumulada empírica es otra representación de la distribución de una variable (en especial, continua)\n\nplot(ecdf(ceosal1$roe))\n\nLa definición de valor atípico/extremo es “arbitraria”. Aquí es 1.5 veces el rango intercuartículo por encima/debajo de la caja.\n\n\n\nUn gráfico de caja ofrece información resumida de la distribución: mediana, 1er y 3er cuartil, y valores “extremos”\n\n\nboxplot(ceosal1$roe, horizontal=T)\nboxplot(ceosal1$roe~ceosal1$consprod)\n\n\n\nEl símbolo \\~ en R indica que una variable es función de otras: en este caso, la distribución de roe se reprensenta en función de los valores de otra"
  },
  {
    "objectID": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "href": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Valores ausentes (“missing values”): NA",
    "text": "Valores ausentes (“missing values”): NA\n\nMuchos conjuntos de datos tienen valores ausentes de ciertas observaciones para algunas variables: ej., descargad (UA Cloud) earn.RData\n\n\nSabemos si una observación es NA y la frecuencia total:\n\n\n\n\nload(\"data/earn.RData\")\nx &lt;- earn$earnings\n\n\n\n\n\nis.na(x)\ntable(is.na(x))\n\n\n\n\nRecordemos también any(is.na(x)) (hay algun NAs?) o which(is.na(x)) (qué elementos son NA)\n\n\n\nPor defecto en R, un cálculo con NAs es NA: debemos decir que los elimine explícitamente (y ser conscientes de lo que implica)\n\n\n\n\nmean(x)\n\n\n\n\n\nmean(x, na.rm=TRUE)\n\n\n\n\nsum(), quantile() y otras tienen la opción de na.rm=TRUE\nen cor() la opción es diferente: cor(x, earn$age, use=\"complete.obs\")\n\n\n\nna.omit() elimina observaciones con NAs de una o varias variables\n\n\nearn2 &lt;- na.omit(earn)\n\n\n¿Cómo tratar los NAs? Eliminarlos implica selección muestral y la alternativa de imputar valores implica supuestos sobre éstos\n\n\n\nTambién podemos filtrar y &lt;- x[!is.na(x)] u otras formas\nOtra función útil complete.cases()\n\ns &lt;- complete.cases(x)\nearnComplete &lt;- earn[s,]\n\nPara reemplazar valores (si pensamos que tiene sentido): y &lt;- replace(x, which(is.na(x)), -1)\nLos estadísticos con la muestra sin NA pueden no ser representativos de la población total: solo muestrear en barrio pobre es igual de poco representativo que haya menos respuestas en el barrio rico\nsuponer que podemos imputar renta solo con edad, genero y educación es restrictivo…"
  },
  {
    "objectID": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "href": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Nota sobre programación “avanzada”",
    "text": "Nota sobre programación “avanzada”\n\nComo en todo lenguaje de programación R, tiene funciones para\n\nEjecución condicional if(): una parte del código se ejecuta solo si se cumple una condición\nBucles for(): se repite un mismo bloque de código mientras se itera por los valores de vector\nCrear funciones propias con function()\n\nUna variante de la ejecución condicional, solo para crear variables según una condición\n\n\ndata(\"Affairs\", package = \"AER\")\nAffairs$univers &lt;- ifelse(Affairs$education&gt;15, 1, 0)\n\n\n\nTanto if-else como for pueden escribirse en una sola línea sin \\{ si solo incluye un comando en el bloque entre llaves:\n\nif (p&lt;=0.05) decision &lt;- \"Rechazar H0\" else decision &lt;- \"NO Rechazar H0\"\n\nPueden anidarse if-else, for y ambos\nOtros comandos de bucles: while, repeat, replicate, apply, lapply, y otros (map) en bibliotecas adicionales"
  },
  {
    "objectID": "docs/Tema02ej1.html",
    "href": "docs/Tema02ej1.html",
    "title": "Tema 02 - Transformación de Datos",
    "section": "",
    "text": "NOTA: Este ejercicio se realizará en clase y NO cuenta para los alumnos de evaluación NO continua (aunque es recomendable como práctica).\nPodéis encontrar una plantilla para vuestras respuestas aquí."
  },
  {
    "objectID": "docs/Tema02ej1.html#ejercicio-1",
    "href": "docs/Tema02ej1.html#ejercicio-1",
    "title": "Tema 02 - Transformación de Datos",
    "section": "Ejercicio 1",
    "text": "Ejercicio 1\nDescargad este archivo (comprimido) con datos en texto separados por punto y coma con la siguiente información de los empleados de una empresa: el identificador de empleado (ID), sus dos apellidos y su nombre, su género (hombre o mujer) y el valor de las ventas realizadas por dicho empleado en un periodo concreto, dado por año y mes.\nPara garantizar claridad y accesibilidad, se recomienda dividir las tareas en pasos manejables y utilizar herramientas que permitan una visualización clara de los datos.\n\nApartado 1.a)\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores.\n\n\nApartado 1.b)\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas relativas al total de ventas de la empresa en ese periodo (proporción vendida por ese empleado en un periodo) fueron mayores.\n\n\nApartado 1.c)\nRepetir el apartado a) para cada empleado de la empresa, es decir, encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores.\n\n\nApartado 1.d)\n¿En qué periodo (año y mes) hubo más ventas en total en la empresa y cuántas fueron?\n\n\nApartado 1.e)\n\nRepresentar la evolución temporal de las ventas anuales totales realizadas por los hombres y por las mujeres de la empresa.\nPresentar un gráfico de barras con el número de hombres y de mujeres empleados en la empresa en cada año.\nPresentar una tabla con la media de ventas anuales de hombres y de mujeres en los años 2000, 2005 y 2010."
  },
  {
    "objectID": "docs/Tema02ej1.html#ejercicio-2",
    "href": "docs/Tema02ej1.html#ejercicio-2",
    "title": "Tema 02 - Transformación de Datos",
    "section": "Ejercicio 2",
    "text": "Ejercicio 2\nAdemás del archivo del Ejercicio 1, disponemos de este archivo Excel con dos hojas: regiones, con la clave de las regiones donde la empresa tiene sedes y el nombre completo de cada región, y regionEmpleado, con el identificador de cada individuo y la región a la que pertenece.\n\nApartado 2.a)\nMostrar en una tabla el nombre y apellidos del empleado de cada región con mayores ventas totales en el periodo de tiempo analizado.\n\n\nApartado 2.b)\nMostrar el nombre completo de la región con más ventas cada año.\n\n\nApartado 2.c)\nMostrar los nombres y apellidos de los empleados “misteriosos”: es decir, aquellos que no sabemos a qué región pertenecen."
  },
  {
    "objectID": "docs/Tema02ej1.html#entrega-del-ejercicio",
    "href": "docs/Tema02ej1.html#entrega-del-ejercicio",
    "title": "Tema 02 - Transformación de Datos",
    "section": "Entrega del ejercicio",
    "text": "Entrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema02ej1_123456789.R"
  },
  {
    "objectID": "docs/Tema01ej.html",
    "href": "docs/Tema01ej.html",
    "title": "Tema 01 - Visualización de Datos",
    "section": "",
    "text": "NOTA: todos los comentarios sobre los resultados se incluyen en el propio archivo de guión."
  },
  {
    "objectID": "docs/Tema01ej.html#ejercicio-1",
    "href": "docs/Tema01ej.html#ejercicio-1",
    "title": "Tema 01 - Visualización de Datos",
    "section": "Ejercicio 1",
    "text": "Ejercicio 1\nEl fichero pwt.csv contiene datos de las Penn World Tables (PWT) más una variable de continente. Las descripción de las variables de las PWT se puede encontrar aquí\n\nApartado 1.a)\nUsando otras DOS variables económicas que tengan sentido relacionar, debes reproducir aproximadamente este gráfico de The Economist sobre Corrupción y Desarrollo Humano:\n\n\n\n\nSugerencias de pares de variables:\n\nCapital humano (hc) vs Productividad (rtfpna)\nPIB per cápita (rgdpna) vs Esperanza de vida (pop)\nFormación de capital (csh_i) vs Crecimiento\n\nNota: este es un ejercicio individual. Se recomienda evitar el uso de las mismas variables y/o ofrecer resultados y comentarios demasiado similares.\nRequisitos:\n\nUsa datos de un solo año\nIncluye puntos coloreados por continente\nAñade línea de tendencia\nEtiqueta algunos países seleccionados\nLa reproducción es aproximada (no necesitas puntos vacíos o R²)\n\n\n\n\nApartado 1.b)\nComenta brevemente qué información revela tu gráfico."
  },
  {
    "objectID": "docs/Tema01ej.html#ejercicio-2",
    "href": "docs/Tema01ej.html#ejercicio-2",
    "title": "Tema 01 - Visualización de Datos",
    "section": "Ejercicio 2",
    "text": "Ejercicio 2\nUna consultora de inversiones quiere comparar el perfil de ingresos obtenidos entre startups tecnológicas y grandes corporaciones para una estrategia de inversión.\n\nIngresos y Empleados: Corporaciones vs Startups (2023)\n\n\nempresa\ntipo\ningresos_millones\nempleados\n\n\n\n\nGoogle\nCorporación\n3522.91\n85000\n\n\nMicrosoft\nCorporación\n2831.89\n72000\n\n\nApple\nCorporación\n2413.98\n65000\n\n\nAmazon\nCorporación\n1751.65\n48000\n\n\nMeta\nCorporación\n1187.63\n35000\n\n\nTechStart\nStartup\n81.40\n120\n\n\nInnovateLab\nStartup\n62.83\n85\n\n\nDataFlow\nStartup\n37.21\n45\n\n\nCloudVision\nStartup\n15.80\n28\n\n\nAI-Solutions\nStartup\n8.45\n15\n\n\n\n\nApartado 2.a)\nMostrar dos diagramas de caja de la distribución de ingresos por tipo de empresa, sin usar y usando escala logarítmica.\n\nNota: realizar algunos ajustes (mínimos) a los gráficos como dar color a los diagramas (asociado al tipo de empresa), poner título al gráfico, los ejes, etc.\n\n\n\nApartado 2.b)\n\nComparando ambos gráficos, ¿qué diferencias existen en la posición central y la variabilidad dentro de cada grupo? ¿qué explican esas diferencias?\n¿Qué gráfico es más informativo y por qué?\nSi la variabilidad observada en los gráficos es una aproximación de la variabilidad en la rentabilidad de una inversión, ¿qué concluirías como empleado de la consultora sobre si es más volátil invertir en Corporaciones o en Startups?"
  },
  {
    "objectID": "docs/Tema01ej.html#ejercicio-3",
    "href": "docs/Tema01ej.html#ejercicio-3",
    "title": "Tema 01 - Visualización de Datos",
    "section": "Ejercicio 3",
    "text": "Ejercicio 3\nEl fichero hotels.csv contiene información sobre reservas de hoteles, donde cada fila corresponde con una reserva; la información detallada sobre las variables puede encontrarse aquí.\n\nApartado 3.a)\nLa columna market_segment contiene información de a qué categoría de los segmentos de mercado pertenece la reserva: Aviation (reservas por aerolíneas), Complementary (reservas de cortesía/gratuitas), Corporate (reservas de Empresas), Direct (reservas directas), Groups (Grupos), Offline TA/TO (Agencia de Viajes/Tour Operador ‘offline’), Online TA (Agencia de Viajes de internet), Undefined (Sin definir). \nUna cadena hotelera está interesada en desarrollar promociones basadas en diferentes segmentos de mercado. Pero primero necesita saber cuántas de las transacciones ocurren para cada segmento de mercado y si esto dependía del tipo de hotel. La variable hotel indica el tipo de hotel: City Hotel (hotel urbano) o Resort Hotel (hotel de vacaciones).\nMostrar una visualización que permita a la cadena hotelera tener la información para tomar decisiones sobre sus promociones. Realizar los ajustes necesarios para que la visualización sea clara y fácil de interpretar: títulos, etiquetas, colores, etc.\n\n\nApartado 3.b)\nUn directivo de la empresa afirma que deben centrarse en personas que reservan con antelación, y cree que las personas con hijos tienden a reservar con mayor anticipación. Realice un análisis que permita comprobar si esta afirmación es cierta o no.\nNota: para realizar este análisis, se puede usar la variable lead_time (número de días que transcurren entre la fecha de reserva y la fecha de llegada) y la variable children (número de niños)."
  },
  {
    "objectID": "docs/Tema03.html#el-sistema-de-publicaciones-quarto",
    "href": "docs/Tema03.html#el-sistema-de-publicaciones-quarto",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "El sistema de publicaciones Quarto",
    "text": "El sistema de publicaciones Quarto\n\n\n\nOrientado al análisis de datos reproducible: combina código, resultados y comentarios\nÚtil como cuaderno de trabajo del código y para comunicar resultados en un documento final para tomar decisiones\n\n\n\n\n\n\n\nInstalar Quarto para vuestro sistema operativo desde aquí\nLa guía y referencia completa de Quarto están en su Web\nUn documento de Quarto se renderiza, procesando cada componente (código, resultado de ejecutarlo y texto) para producir documentos en varios formatos: html, PDF, Word, presentaciones, etc.\n\n\n\nEstas y otras chuletas disponibles en http://rstudio.com/resources/cheatsheets."
  },
  {
    "objectID": "docs/Tema03.html#documentos-de-quarto-crear-y-guardar",
    "href": "docs/Tema03.html#documentos-de-quarto-crear-y-guardar",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Documentos de Quarto: Crear y Guardar",
    "text": "Documentos de Quarto: Crear y Guardar\n\nCreamos un proyecto de Quarto en File &gt; New Project &gt; New Directory &gt; Quarto Project o en el icono de proyectos \n\nIgnoramos el documento que se crea por defecto\n\nCreamos un nuevo documento a partir de una plantilla en RStudio con  o File &gt; New File &gt; Quarto Document\n\nPodemos elegir Título, Autor/a y formato de salida (HTML, por defecto)\n\nSe guarda con  o con File &gt; Save, con extensión .qmd\nSe renderiza con  al formato de salida elegido\nEn el botón de engranaje  se pueden cambiar algunas opciones\n\np.e., dónde se visualiza la salida (en ventana aparte o en RStudio)"
  },
  {
    "objectID": "docs/Tema03.html#documentos-de-quarto-formato-de-salida",
    "href": "docs/Tema03.html#documentos-de-quarto-formato-de-salida",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Documentos de Quarto: formato de salida",
    "text": "Documentos de Quarto: formato de salida\n\nEl renderizado crea un archivo en el mismo directorio donde está el archivo de Quarto .qmd\nEn el caso de HTML, se crea tanto un archivo con extensión .html como un subdirectorio del mismo nombre con componentes necesarios (ej., imágenes, css)\n\nsolo podemos visualizar correctamente el archivo .html en cualquier navegador si copiamos a otro lugar tanto el .html como el subdirectorio\n\nPara crear PDFs, se necesita una distribución de LaTeX: instala una escribiendo en la pestaña de “Terminal” (a la derecha de la consola):\n\n\nquarto install tool tinytex"
  },
  {
    "objectID": "docs/Tema03.html#documentos-de-quarto-texto-con-markdown",
    "href": "docs/Tema03.html#documentos-de-quarto-texto-con-markdown",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Documentos de Quarto: Texto con Markdown",
    "text": "Documentos de Quarto: Texto con Markdown\n\nLos componentes de texto están escritos en Markdown: un conjunto ligero de convenciones para archivos de texto sin formato. Por ejemplo,\n\ntodo lo escrito entre dos * como **Hola** se renderiza en negritas\nse utiliza # para indicar encabezados de secciones\n\nEn el menú de ayuda tenemos una descripción completa (Markdown quick reference) y “chuletas” (Cheatsheets)\nTambién son útiles la web de Quarto y este libro online.\n\n\n\nMarkdown está diseñado para ser fácil de leer y fácil de escribir. También es muy fácil de aprender. La siguiente guía muestra cómo usar el Markdown de Pandoc, una versión ligeramente extendida de Markdown que R Markdown entiende.\n\n\n\nFormato de texto\n*cursiva*  o _cursiva_\n**negrita**   __negrita__\n`código`\nsuperíndice^2^ y subíndice~2~\n~~tachado~~\nEncabezamientos\n# Encabezado de 1er. nivel\n## Encabezado de 2º nivel\n### Encabezado de 3er. nivel\n#### Encabezado de 4º nivel\n\nListas\n*   Item (elemento) de la lista (no numeradas)\n*   Item 2\n    - Sub-Item 2a (*, + y - son alternativas)\n        + sub-sub-item\n    - Sub-Item 2b\n\n1.  Item 1 de la lista numerada\n1.  Item 2. Los números se incrementan automáticamente.\n\n1)  Otra forma de crear listas numeradas.\n2)  También, se puede poner explícitamente el número.\n\n\n\nBloques de citas literales\n&gt; Esto es parte de un bloque de cita.\n&gt; Esto es parte del mismo bloque de cita.\n\n&gt;\n&gt; &gt; Esto es otro bloque de cita anidado.\n&gt; &gt; Esto es parte del bloque anidado.\n&gt;\n&gt; Esto es parte del bloque de cita de primer nivel.\nEsto es una línea normal\nNotas a pie de página\nEsto es un texto con nota al pie [^nota1] \ny esta es otra nota [^2]\n\n[^nota1]: Esto es una nota al pie de página.\n[^2]: Esto es la segunda nota al pie.\n\nLíneas de separación\n---\n***\nReferencias\n[Página de R][1]\n[1]: https://cran.r-project.org/\n\n#### Título 1 {#tit1}\n[Enlace a titulo1](#tit1)\n\nImaǵenes y enlaces\n![texto del subtítulo opcional](dirección/hacia/img.png)\n&lt;http://example.com&gt;\n[frase con vínculo](http://example.com)\n[![RUsers](http://rusersgroup.com/img/final5x5.png)](https://cran.r-project.org/ )\n\n\nTablas\nPrimer encabezado  | Segundo encabezado\n------------------ | ------------------\nCelda              | Celda\nCelda              | Celda\n\nCon alineación de columnas\n| Items    | Cantidad | Precio   |\n| :------- | :------: | -------: |\n| Item 1   | 15       | 9,050    |\n| Item 2   | 3250     | 239,99   |\n\n\nSe puede incluir código en HTML (útil para algunos formateos como centrar) y en LaTeX (útil para ecuaciones)\n; también se pueden incluir diagramas UML.\n\necuación en texto entre $ $ o en editor visual , Inline Math\necuación aparte entre $$ $$ -o en editor visual , Displayed Math\n\nLos comentarios se escriben entre\nLa barra \\ delante de un símbolo de formato o enlace: muestra el símbolo, no aplica el formato: ej.,\\* muestra *, no empieza lista (idem para \\[ o \\$ ), enlace o ecuación\nprovoca que no tengan efecto a la hora de convertirse en negritas, cursivas, links, etc.: \\*\n\n\n\nRStudio incorpora un editor visual de documentos de Quarto, similar a un procesador de texto\n\nun ventaja del modo no visual es el número de línea, para errores"
  },
  {
    "objectID": "docs/Tema03.html#editor-visual-de-quarto-en-rstudio",
    "href": "docs/Tema03.html#editor-visual-de-quarto-en-rstudio",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Editor Visual de Quarto en RStudio",
    "text": "Editor Visual de Quarto en RStudio\n\nEn documentos .qmd, se puede elegir entre editar la fuente (source) de Markdown, como texto sencillo, o editar el documento de forma Visual en \nEn el modo visual, en esa misma barra de herramientas se tienen accesos a\n\nformatos de texto (negritas, cursivas, encabezamientos) y listas\ninsertar enlaces, imágenes, notas a pie de página, tablas\nincluir ecuaciones (en LaTeX)\ntambién insertar directamente código HTML, comentarios, etc.\n\nSe puede configurar la corrección ortográfica en Tools &gt; Global Options &gt; Spelling: agregar/seleccionar el diccionario de Español\n\n\n- marcar corrección en tiempo real"
  },
  {
    "objectID": "docs/Tema03.html#formato-en-la-cabecera-el-bloque-yaml",
    "href": "docs/Tema03.html#formato-en-la-cabecera-el-bloque-yaml",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Formato en la cabecera: el bloque YAML",
    "text": "Formato en la cabecera: el bloque YAML\n\nAl principio del documento, entre dos líneas con ---, se pueden especificar varias opciones del documento: título, autor, fecha, formato de salida\n\n\nLos formatos de salida son html, pdf, docx (y otros en Quarto Presentations)\nTambién se especifican opciones globales del documento, algunas específicas de cada tipo de salida (ver la referencia para html y otros formatos)\n  ---\n  title: \"Título\"\n  author: Autor \n  date: 15-octubre-2025\n  format:\n    html:\n      toc: true              # índice\n      number-sections: true  # secciones numeradas\n      embed-resources: true  # archivo html autocontenido\n      theme: united          # más temas: https://bootswatch.com/3/\n  ---"
  },
  {
    "objectID": "docs/Tema03.html#fragmentos-o-celdas-de-código",
    "href": "docs/Tema03.html#fragmentos-o-celdas-de-código",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Fragmentos o celdas de código",
    "text": "Fragmentos o celdas de código\n\n“code chunks”\n\n\nInsertamos código en medio del texto con el icono (visual) \n\nSi pulsamos , escribimos r y luego un código, el documento de salida incluirá el resultado de ejecutar el código\n\n\n\n\nPodemos incluir un fragmento de código (de varias líneas), con , en el desplegable  o Ctrl + Alt + I\n\nSe puede personalizar cómo se muestran varios aspectos del código y de sus resultados\nbien para una celda concreta de código, incluyendo opciones de celda\no para todo el documento en la cabecera: las opciones de html están en la sección de código de su referencia (y similar para otros formatos)"
  },
  {
    "objectID": "docs/Tema03.html#opciones-para-una-celda-de-código",
    "href": "docs/Tema03.html#opciones-para-una-celda-de-código",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Opciones para una celda de código",
    "text": "Opciones para una celda de código\n\n\nLas opciones se incluyen al principio de una celda precedidas por #|\necho: true muestra el código en la salida (o no con echo: false)\neval: true ejecuta el código (o no con eval: false)\n\nSi un fragmento no se evalúa, sus resultados no se muestran y ni están para otras celdas posteriores (p.e., cargar datos o una biblioteca para usar luego)\n\noutput: true incluye los resultados del código\ninclude: false no incluye ni el código ni su resultado, pero se evalúa\nSe muestran (o no) los mensajes, errores y avisos de ejecutar un código con las opciones message, error y warning, respectivamente.\nlabel: etiqueta para identificar la celda\nLa lista completa de opciones aquí y aquí"
  },
  {
    "objectID": "docs/Tema03.html#opciones-para-una-celda-de-código-cont.",
    "href": "docs/Tema03.html#opciones-para-una-celda-de-código-cont.",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Opciones para una celda de código (cont.)",
    "text": "Opciones para una celda de código (cont.)\n\n\ncode-fold: true oculta el código pero da opción a mostrarlo\nCómo mostrar resultados de texto y numéricos:\n\nresults: hide (no mostrar)\nresults: hold (mostrar todo, no el resultado de cada línea)\n\nfig-cap y tbl-cap para los títulos de las figuras y tablas\nCómo mostrar los gráficos: fig-show\n\nhide y hold son como en results\nasis muestra el gráfico como se generó\nanimate concatena varios gráficos en una animación\n\nfig-width y fig-height: dimensiones (reales, en pulgadas) de una figura\nout-width y out-height: ídem en el documento de salida (% de las reales)"
  },
  {
    "objectID": "docs/Tema03.html#opciones-para-una-celda-de-código-y-3",
    "href": "docs/Tema03.html#opciones-para-una-celda-de-código-y-3",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Opciones para una celda de código (y 3)",
    "text": "Opciones para una celda de código (y 3)\n\n\nfig-align: mostrar la figura centrada o alineada a derecha o izquierda\nlayout-ncol: en cuantas columnas se componen los resultados\n\n```{r}\n#| layout-ncol: 2\n#| fig-show: hold\nggplot(data = cars) + geom_histogram(aes(x = speed))  # izquierda\nggplot(data = cars) + geom_histogram(aes(x = dist))   # derecha\n```"
  },
  {
    "objectID": "docs/Tema03.html#opciones-globales-para-todas-las-celdas",
    "href": "docs/Tema03.html#opciones-globales-para-todas-las-celdas",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Opciones globales para todas las celdas",
    "text": "Opciones globales para todas las celdas\n\nEn la cabecera, especificamos opciones por defecto para las celdas de código\n\np.e., de ejecución como echo, eval, etc. en execute (ver aquí y aquí)\n---\nexecute:\n  echo: false\n  warning: false\n---\n\n\n\nTambién enabled: false y freeze\nVer sección de ejecución en https://quarto.org/docs/computations/r.html\n\n\nTambién otras opciones que ya hemos visto (aquí listado completo para html)\n---\nformat:\n  html:\n    code-fold: true\n    cap-location: bottom\n    fig-align: center\n    df-print: paged      # cómo visualizar tablas\n---"
  },
  {
    "objectID": "docs/Tema03.html#ejecución-de-código-en-un-documento-.qmd",
    "href": "docs/Tema03.html#ejecución-de-código-en-un-documento-.qmd",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Ejecución de código en un documento .qmd",
    "text": "Ejecución de código en un documento .qmd\n\nRenderizar un .qmd crea un espacio de trabajo para ejecutar el código distinto del que vemos en RStudio (diferentes objetos, bibliotecas, etc.)\n\nsi no estamos en un proyecto, el directorio de trabajo puede ser diferente\n\nComprobamos los resultados del código del .qmd ejecutándolo sin renderizar: línea a línea, la celda completa con  o todas las anteriores con \n\nasí, el código pasa a la consola y sí forma parte del espacio de la sesión actual\nnos aseguramos de que no hay errores (ej., objetos previos no definidos)\n\nPara garantizar que la sesión actual incluye sólo resultados de las celdas del .qmd, incluimos una celda inicial con include: false con\n\nrm(list = ls()): al ejecutar todas las celdas previas, empezamos con una sesión sin objetos previos\nTodas las bibliotecas (ej., tidyverse) que utilizaremos en varias celdas"
  },
  {
    "objectID": "docs/Tema03.html#mejorar-la-salida-de-tablas",
    "href": "docs/Tema03.html#mejorar-la-salida-de-tablas",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Mejorar la salida de tablas",
    "text": "Mejorar la salida de tablas\n\nComo las salidas de muchas funciones no son visualmente “profesionales”, algunas bibliotecas las mejoran (printr) u ofrecen funciones para hacerlo\nUn enfoque “fácil”: crear data frames con resultados (usando tidyverse) y mostrarlo como una tabla con knitr::kable()\nLa biblioteca kableExtra ofrece más opciones.\nbroom::tidy() convierte muchos objetos de R (como listas con resultados de comandos) en tibbles\nLa biblioteca modelsummary() tiene funciones para\n\nconvertir modelos en tablas (modelsummary()) o gráficos\ncrear tablas de estadísticos descriptivos con datasummary() o datasummary_crosstab()\n\n\n\n\nstargazer https://zief0002.github.io/book-8252/pretty-printing-tables-in-markdown.html\nprintr\npander (avanzado): la función pandoc.table() convierto objetos de R a tablas en código de Markdown, con muchas opciones\n\nrequiere results = 'as.is'\n\nxtable:"
  },
  {
    "objectID": "docs/Tema03.html#comentarios-finales",
    "href": "docs/Tema03.html#comentarios-finales",
    "title": "Tema 03 - Introducción a Quarto",
    "section": "Comentarios finales",
    "text": "Comentarios finales\n\nDashboards (tableros): son presentaciones visuales e interactivas de los resultados claves de un análisis que permiten una comunicación más efectiva\n\nQuarto permite crear dashboards con tablas, gráficos y otros elementos\nEjemplos de sus capacidades usando el paquete shiny, shinydashboards o flexdashboard\n\nJupyter Notebook: son otra forma de combinar texto, código y resultados en un documento. Desarrollados para Python, admiten varios lenguajes de programación (como Quarto)\n\nse crean, visualizan y ejecutan en navegadores web, pero son fácilmente modificables, localmente u online en JupyterLab o con Google Colab\nQuarto renderiza libros de Jupyter, creados en .qmd o en su propio formato\n\nMuchas herramientas están preparadas para Python y R porque se usan a menudo indistintamente o combinados"
  },
  {
    "objectID": "docs/Tema05.html#métodos-estadísticos-1",
    "href": "docs/Tema05.html#métodos-estadísticos-1",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Métodos Estadísticos",
    "text": "Métodos Estadísticos\n\n\n\nLa modelización mediante métodos estadísticos permite\n\nEncontrar patrones \nInterpretar datos \n\n\n\n\n\n\n\n\n\n\n\nLos datos (casos observados) son una muestra de una población mayor (casos potenciales)\n\n\n# Población: ventas diarias ~ Uniforme(0, 20), media = 10\nset.seed(9915)\ntibble(x = runif(n=1e9, min=0, max=20)) |&gt; pull(x) |&gt; mean()\n\n# Muestra de solo 25 días\nset.seed(9915)\ntibble(x = runif(n=25, min=0, max=20)) |&gt; pull(x) |&gt; mean()\n\n\nEl estadístico varía entre muestras.\n¿Cómo de fiable es este estadístico en una muestra?"
  },
  {
    "objectID": "docs/Tema05.html#variabilidad-muestral",
    "href": "docs/Tema05.html#variabilidad-muestral",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Variabilidad muestral",
    "text": "Variabilidad muestral\n\nCon todas las muestras potenciales de tamaño \\(\\small n\\) conoceríamos la distribución muestral de un estadístico (información calculada en una muestra)\n\nAproximación de “todas” las muestras potenciales con 1000 muestras\n\n\n\n\nSimulemos la distribución para la media en muchas muestras de \\(\\small n=25\\)\n\n\n\nset.seed(101)\nnsim &lt;- 1000\nybar &lt;- numeric(nsim)\nfor (j in 1:nsim) {\n  muestra &lt;- runif(n=25, 0, 20)\n  ybar[j] &lt;- mean(muestra)\n}\n\nas_tibble(ybar) |&gt; ggplot(aes(x=value)) + geom_density() +\n  geom_vline(xintercept=10)\n\n\nConcepto fundamental: cualquier estadístico muestral tiene incertidumbre asociada.\n\n\nTenemos una ÚNICA MUESTRA: ¿cómo cuantificar la incertidumbre?\n\n\nSuponiendo que los datos son normales, la media tiene una distribución normal\nTeorema Central del Límite: para datos de cualquier distribución, \\(\\overline{Y} \\overset{a}{\\sim} N(\\mu, \\sigma^2/n)\\) cuando \\(n \\to \\infty\\)\n\n\n\nLey de números grandes: para un tamaño de la muestra \\(n\\) grande, el promedio de la muestra está cerca de la media de la población \nTeorema de Límite Central: para un tamaño de la muestra \\(n\\) grande, la distribución muestral de la media es normal.\nPermite hacer inferencia sin suponer que los datos sean normales, solo necesitamos n suficientemente grande."
  },
  {
    "objectID": "docs/Tema05.html#procedimiento-bootstrap",
    "href": "docs/Tema05.html#procedimiento-bootstrap",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Procedimiento Bootstrap",
    "text": "Procedimiento Bootstrap\n\nIdea: Usar la ÚNICA muestra como si fuera la población → generar variación “similar” a la muestral\n\n\ngenera variación de remuestras a partir de una única muestra\n\n\n\nset.seed(101)\nUNICAmuestra &lt;- tibble(x=runif(n=25, 0, 20))\n\n\nTomar muchas remuestras con reemplazamiento de la muestra original\n\n\n\np.e., para (1,2,3) incluye los casos (1,1,2), (1,1,3), (2,2,1), etc.\nremuestras o muestras de Bootstrap\n\\({n\\choose n}= (n + n - 1)!/(n! (n-1)!)\\) remuestras: la muestra original es una combinación entre muchas\n\n\n\nlibrary(rsample)\nremuestras &lt;- bootstraps(UNICAmuestra, times = 1000)\n\n\nCalcular el estadístico en cada remuestra\n\n\ndistrib &lt;- list()\nfor (r in 1:1000) {\n  remuestra &lt;- remuestras$splits[[r]] |&gt; as_tibble()\n  media  &lt;- remuestra |&gt; pull(x) |&gt; mean()\n  sd    &lt;-  remuestra |&gt; pull(x) |&gt; sd()\n  distrib[[r]] &lt;- list(medias = media, sds =sd )\n}\ndistribDF &lt;- distrib |&gt; bind_rows()\n\n\nIDEA de un bucle: saber como hacerlo en un caso, y luego hacer en general y se guarda en una lista\nremuestra &lt;- remuestras$splits[[1]] |&gt; as_tibble()\n\nhago todo lo que tenga que hacer, con todos los pasos que sean necesarios media &lt;- remuestra |&gt; pull(x) |&gt; mean() sd &lt;- sd(remuestra$x)\nguardo los resultaods\n\n\n\nLa distribución de remuestras es “similar” a la distribución muestral sin supuestos (normalidad, TCL)\n\n\n\nLa distribución muestral bootstrap NO es la distribución muestral, pero aproxima sus aspectos principales (error estándard) sin supuestos (normalidad, TCL)\n\n\n\ndistribDF |&gt; ggplot(aes(x=medias)) + geom_density()               # distribución\nmediaSE &lt;- distribDF |&gt; pull(medias) |&gt; sd()                      # ES de la media\nmediaIC &lt;- distribDF |&gt; pull(medias) |&gt; quantile(c(0.025, 0.975)) # IC de la media"
  },
  {
    "objectID": "docs/Tema05.html#qué-es-el-aprendizaje-estadístico",
    "href": "docs/Tema05.html#qué-es-el-aprendizaje-estadístico",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "¿Qué es el aprendizaje estadístico?",
    "text": "¿Qué es el aprendizaje estadístico?\n\nAprendizaje automático (machine learning, ML) o estadístico (statiscal learning): conjunto de técnicas algorítmicas para extraer información de los datos\nTipos principales\n\n\nAprendizaje supervisado: para cada medida de \\(X\\) hay una respuesta asociada \\(Y\\)\n\nAprendemos la respuesta \\(Y\\) de casos nuevos a partir de casos previos\n\nAprendizaje no supervisado: no hay una respuesta asociada, aprendemos rasgos no medidos\n\nej., observaciones similares organizadas en grupos distintos\n\n\n\n\nAprendizaje supervisado: escenarios en los que para cada observación de las mediciones \\(X_i\\) hay una respuesta asociada \\(Y_i\\) (“supervisa” el aprendizaje)\n\nAprendemos la respuesta \\(Y\\) de casos nuevos a partir de casos previos\n\nAprendizaje no supervisado: no hay una respuesta asociada a las mediciones de \\(X_i\\) para supervisar el análisis que generará un modelo.\n\nAprendemos rasgos no medidos a partir de casos “no etiquetados”: ej. observaciones similares organizadas en grupos distintos (de clientes, países)"
  },
  {
    "objectID": "docs/Tema05.html#aprendizaje-supervisado",
    "href": "docs/Tema05.html#aprendizaje-supervisado",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Aprendizaje supervisado",
    "text": "Aprendizaje supervisado\n\\[\n\\small Y = f(X) + \\varepsilon\n\\]\n\nModelo para la variable dependiente en función de\n\nfactores observados (predictores/características)\nfactores no observados (\\(\\small \\varepsilon\\))\n\\(f\\) representa la relación sistemática que \\(X\\) (género, educación, etc.) ofrece sobre \\(Y\\) (ej. renta)\n\n\n\n\nY= variable objetivo, variable dependiente, de respuesta\nX= independientes (predictores, características, regresores, factores)\nX= inputs, features, covariates\n\\(f\\) representa la información/relación sistemática que \\(X\\) (género, educación, etc.) ofrecen sobre un resultado medido \\(Y\\) (ej. renta)\n\n\n\nObjetivos:\n\nPredecir el valor esperado de \\(\\small Y\\) para casos nuevos\nComprender cómo afectan al resultado esperado de \\(\\small Y\\) cambios en los valores de las características\n\np.e., tiene la experiencia un efecto positivo o nula sobre la renta esperada\n¡cuidado con afirmaciones de causalidad!\n\n\n\n\n\na partir de otros previamente etiquetados (medidos/clasificados)\nevaluar la calidad de nuestras predicciones e inferencias\n\n\n\nEn ambos casos, tenemos que estimar (“aprender”) la \\(f\\) desconocida"
  },
  {
    "objectID": "docs/Tema05.html#aprendizaje-supervisado-cont.",
    "href": "docs/Tema05.html#aprendizaje-supervisado-cont.",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Aprendizaje supervisado (cont.)",
    "text": "Aprendizaje supervisado (cont.)\n\nSegún la naturaleza de \\(Y\\) tenemos:\n\nProblemas de Regresión: \\(Y\\) cuantitativa (salario, ventas, precio)\nProblemas de Clasificación: \\(Y\\) cualitativa (compra/no compra, categoría producto)\n\n\n\n1.- Variable de respuesta cuantitativa (toma valores numéricos)\n2.- variable de respuesta cualitativa (toma valores en una de \\(C\\) categorías o clases)\n\n\n\nDos enfoques para especificar la relación \\(f\\):\n\nModelo Paramétrico: supone un forma de \\(f\\) que depende de parámetros desconocidos, p.e., lineal \\(f(x) =\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\)\n\nMás fácil de estimar e interpretar\nMenos flexible\n\nModelo No paramétrico: Ajustar sin supuestos funcionales\n\nMás flexible, mejor ajuste\nMás difícil de interpretar\n\n\n\nLa capacidad predictiva de un modelo mejora si incluimos más variables explicativas (modelo más flexible)"
  },
  {
    "objectID": "docs/Tema05.html#modelo-de-regresión-lineal",
    "href": "docs/Tema05.html#modelo-de-regresión-lineal",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Modelo de regresión lineal",
    "text": "Modelo de regresión lineal\n\nModelo paramétrico para problemas de regresión que supone una relación lineal:\n\n\\[\\quad \\small \\color{blue}{ventas = \\beta_0 + \\beta_1 renta + \\beta_2 descuento + u}\\]\n\n  + en este caso, la renta es 0 y el individuo no tiene descuento\n\n\nConstante \\(\\small \\color{blue}{\\beta_0= E(ventas|renta=0, descuento=0)}\\)\n\nvalor esperado de \\(\\small Y\\), ventas, cuando todas las variables explicativas son cero\n\nPendiente de una variable continua \\(\\small \\color{blue}{\\beta_1 = \\frac{\\delta E(ventas|renta,descuento)}{\\delta{renta}}}\\)\n\ncambio esperado de \\(\\small Y\\), ventas, cuando la variable explicativa, renta, aumenta en una unidad, manteniendo el resto de variables constantes (en este caso, un valor dado para descuento)\ntambién \\(\\small \\beta_1 = E(ventas|renta=x+1,descuento=d)-E(ventas|renta=x,descuento=d)\\)\n\nPara variables discretas binarias \\(\\small \\color{blue}{\\beta_2 = E(ventas|renta=x,descuento=1)-E(ventas|renta=x,descuento=0)}\\)\n\ndiferencia del valor esperado de \\(\\small Y\\), ventas, para el grupo indicado por la variable (tienen descuento) respecto al grupo de referencia (no tienen descuento), manteniendo el resto de variables (en este caso, renta) constante"
  },
  {
    "objectID": "docs/Tema05.html#regresión-lineal-estimación",
    "href": "docs/Tema05.html#regresión-lineal-estimación",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Lineal: Estimación",
    "text": "Regresión Lineal: Estimación\n\nObjetivo: estimar los coeficientes poblacionales desconocidos a partir de una muestra\nLos coeficientes estimados minimizan la Suma Cuadrática de Residuos, \\(\\small \\hat{e}\\) (errores de estimación): es decir , las distancias entre\n\nlos datos observados: \\(\\small y_i\\)\ny los datos predichos por el modelo estimado \\(\\small \\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1 X_1+ \\dots + \\hat{\\beta}_k X_p\\)\n\n\n\n\n\n\n\n\n\n\n\\[\n\\small SCR=\\sum_{i=1}^{n} \\hat{e}_i^2= \\sum_{i=1}^{n} ( y_i - \\hat{y}_i)^2\n\\]\n\n\nEsto equivale a las condiciones derivadas de suponer \\(\\small E(\\varepsilon|X)=0\\)\n\n\n\n# Usar datos del ejemplo original\ndescuento &lt;- read.csv(\"data/descuento.csv\") |&gt;\n  mutate(zona = parse_factor(zona), mujer = as.factor(mujer))\n\nmodelo &lt;- lm(ventas ~ renta + descuento, data = descuento)\nsummary(modelo)\n\nInterpretación:\n\nCoef. de renta: Cambio en ventas por cada mil euros más de renta\nCoef. de descuento: Diferencia en ventas entre quienes tienen y no tienen descuento"
  },
  {
    "objectID": "docs/Tema05.html#regresión-lineal-estimación-cont.",
    "href": "docs/Tema05.html#regresión-lineal-estimación-cont.",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Lineal: Estimación (cont.)",
    "text": "Regresión Lineal: Estimación (cont.)\n\nLos parámetros del modelo \\(f(.)\\) estimado, los \\(\\small \\beta_j\\), son estadísticos con variabilidad muestral, medida por su error estándar \\(\\small se(\\widehat{\\beta}_j)\\)\n\nUsados para construir intervalos de confianza y para contrastar hipótesis sobre los parámetros poblacionales, p.e., significatividad (\\(\\small \\beta_1=0\\)) y signo.\n\n\n\n\\[\n\\small se(\\widehat{\\beta}_j) =  \\frac{\\sigma^2}{(n-1)S^2_{x_j} (1 - R^2_{j})}\n\\]\n\n\\(\\small \\sigma^2=Var(\\varepsilon)\\), estimada con \\(\\small \\frac{SCR}{n-k-1}\\)\n\\(\\small S^2_{x_j}=\\frac{\\sum (x_{ij}-\\bar{x}_j)^2}{n-1}=\\)varianza muestral de \\(\\small X_j\\)\n\\(\\small R^2_{j}\\) es el \\(\\small R^2\\) de la regresión de \\(\\small X_j\\) sobre el resto de regresores\n\nindividual: \\(\\small H_0: \\beta_1=0\\) con un estadístico \\(\\small t=\\frac{\\widehat{\\beta}_1-0}{se(\\widehat{\\beta}_1)}\\)\nconjunta: \\(\\small H_0: \\beta_1=\\beta_2=\\dots=\\beta_k=0\\) con un estadístico \\(\\small F\\)\n\nMedidas de la precisión del modelo: \\(\\small MSE\\) o \\(\\small R^2=1-\\frac{SCR}{SCT} = \\frac{SCE}{SCT}\\)\n\n\n\nLa función lm() con la notación de fórmula crea un objeto lista con resultados\n\n\ndescuento &lt;- read.csv(\"data/descuento.csv\") |&gt;\n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))\nmodelo &lt;- lm(data = descuento, ventas ~ renta + descuento)\n(sum.modelo &lt;- summary(modelo))\nnobs(modelo)\n\n\nLa predicción \\(\\widehat{y}\\) también está sujeta a incertidumbre por la estimación: se puede calcular su error estándar e intervalos de confianzas\n\n\npred &lt;- predict(modelo, type = \"response\",\n                se.fit = T, interval = \"confidence\")\ncbind(descuento$ventas, pred$fit, pred$se.fit) |&gt; head()\n\n\n“Confounding factor” y Causalidad\n\n“Correlación no implica causalidad”, salvo en ensayos científicos aleatorios cuidadosamente controlados\n\nen otros campos como marketing digital o analítica de web se denominan pruebas A/B (ej. dos versiones de una misma web)\n\nEn general (datos observacionales), nos preocupa que otros factores que puedan ser los verdaderos determinantes de la relación observada\n\nEn los ensayos aleatorios se controla quien recibe una intervención (tratamiento) y quien no (control)\n+ En promedio, todos los demás factores están equilibrados entre los dos grupos: las diferencias pueden atribuirse a la aplicación del tratamiento\n\n+  Pero si los sujetos no cumplen con los tratamientos o se pierden en el seguimiento.."
  },
  {
    "objectID": "docs/Tema05.html#ampliando-el-modelo-de-regresión-lineal",
    "href": "docs/Tema05.html#ampliando-el-modelo-de-regresión-lineal",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Ampliando el Modelo de Regresión Lineal",
    "text": "Ampliando el Modelo de Regresión Lineal\n\nIncorporar información cualitativa: incluimos una variable binaria (dummy) para cada categoría, excepto una (grupo de referencia)\n\nCada coeficiente es el efecto diferencial de ese grupo respecto al grupo de referencia\nLas dummies se crean automáticamente con factores (sin orden)\n\ntambién se pueden usar la biblioteca fastDummies\n\n\n\n\nlm(data = descuento, ventas ~ renta + descuento + zona) |&gt; summary()\n\n\n\nModelizar relaciones no lineales entre la variable dependiente y las explicativas\nEl modelo lineal asume efecto constante \\(\\frac{\\partial Y}{\\partial X_j} = \\beta_j\\), PERO en la realidad observamos\n\nRendimientos decrecientes (productividad, utilidad)\nElasticidades variables\nUmbrales y efectos discretos\nEfectos heterogéneos entre grupos\n\nSolución: Transformar variables para capturar estas no linealidades"
  },
  {
    "objectID": "docs/Tema05.html#superando-la-linealidad",
    "href": "docs/Tema05.html#superando-la-linealidad",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Superando la linealidad",
    "text": "Superando la linealidad\n\nUsando logaritmos, modelizamos elasticiades (cambios porcentuales) y rendimientos decrecientes\n\n\n# Y ~ log(X): semi-elasticidad / rendimientos decrecientes\nlm(data = descuento, ventas ~ log(renta) + descuento)\n# log(Y) ~ log(X): elasticidad constante\nlm(data = descuento, log(ventas) ~ log(renta) + descuento)\n# log(Y) ~ X: semi-elasticidad / crecimiento exponencial\nlm(data = descuento, log(ventas) ~ renta + descuento)\n\n\nInterpretación:\n\n\\(\\log(Y) \\sim \\log(X)\\): \\(\\beta\\) = elasticidad (% cambio en \\(Y\\) por % cambio en \\(X\\))\n\\(Y \\sim \\log(X)\\): Efecto decreciente de \\(X\\) sobre \\(Y\\)\n\\(\\log(Y) \\sim X\\): Cambio porcentual en \\(Y\\) por unidad de \\(X\\)\n\nLos logaritmos son fundamentales en economía: funciones de producción, demanda, ecuación de Mincer, etc.\n\n\n\nUsando polinomios (y otras funciones no lineales), modelizamos efectos que varían con el nivel de la variable\n\n\nlm(data=descuento, ventas ~ edad + I(edad^2) ) |&gt; summary()\nggplot(descuento, aes(x=edad, y=ventas)) + geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x + I(x^2))\n\n\nEl efecto marginal de \\(edad\\) sobre \\(ventas\\), \\(\\small{\\frac{\\partial ventas}{\\partial edad} = \\beta_1 + 2\\beta_2 edad}\\) depende de la \\(edad\\)\n\n\n\nSi \\(\\beta_2 &lt; 0\\): rendimientos decrecientes (forma de U invertida)\nSi \\(\\beta_2 &gt; 0\\): rendimientos crecientes (forma de U)\n\nÚtil para ciclo de vida, curva de Laffer, relación ingreso-felicidad, etc."
  },
  {
    "objectID": "docs/Tema05.html#superando-la-linealidad-cont.",
    "href": "docs/Tema05.html#superando-la-linealidad-cont.",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Superando la linealidad (cont.)",
    "text": "Superando la linealidad (cont.)\n\nDiscretizando variables también capturamos efectos no lineales: permite efectos “escalón” diferentes para distintos valores\n\n\nlm(data=descuento, ventas ~\n     cut(edad, seq(20, 60, 5), include.lowest = TRUE)) |&gt; summary()\nggplot(descuento, aes(x=edad, y=ventas)) + geom_point() +\n  geom_smooth(method = \"lm\",\n              formula = y ~ cut(x, seq(20, 60, 5), include.lowest = T))\n\n\n\nSe incluyen indicadores binarios para cada clase excepto grupo de referencia\n\nla constante recoge el valor medio de \\(\\small Y\\) para ese grupo de referencia\nCada coeficiente: diferencia respecto al grupo base\nPermite modelizar umbrales y cambios bruscos\n\n\nÚtil cuando sospechamos efectos discretos: tramos impositivos, niveles educativos, etc.\n\n\n\nUsando interacciones entre variables, el efecto de un regresor dependerá de otro regresor\n\n\nLa “pendiente” cambia con el valor de la otra variable: \\(\\small{\\frac{\\partial ventas}{\\partial mujer} = \\beta_1 + \\beta_3 mujer}\\)\nDeben incluirse siempre los factores principales (NO sólo edad:renta)\n\n\nlm(data = descuento, ventas ~ edad*renta)  |&gt; summary()\nlm(data = descuento, ventas ~ renta*mujer) |&gt; summary()\n\nggplot(descuento, aes(x=renta, y=ventas, color = mujer)) +\n  geom_point() + geom_smooth(method = \"lm\", formula = y ~ x,\n                               se = FALSE)\n\n\n\nCuando interactuamos un regresor continuo y uno binario, permitimos que la pendiente del primero sea diferente para cada grupo\nLas interacciones son clave para capturar heterogeneidad de efectos: distintos impactos según género, edad, región, etc.\n\n\nlm(data=descuento , ventas ~ (renta + zona)*descuento) |&gt; summary()\n\n\nLa interacción de dos variables binarias tiene una interpretación similar, para el efecto esperado de \\(\\small Y\\)\n\n\n\n¿Cómo elegir entre modelos alternativos?\n\nlibrary(modelsummary)\nmodelos &lt;- list(\n  \"Lineal\" = lm(ventas ~ renta + descuento, data = descuento),\n  \"Logarítmico\" = lm(ventas ~ log(renta) + descuento, data = descuento),\n  \"Cuadrático\" = lm(ventas ~ renta + I(renta^2) + descuento, data = descuento),\n  \"Con interacción\" = lm(ventas ~ renta * mujer + descuento, data = descuento)\n)\n\nmodelsummary(modelos,\n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\", \"rmse\"),\n             stars = TRUE)\n\n\n\\(R^2\\) ajustado: Penaliza complejidad \\[\\bar{R}^2 = 1 - \\frac{(1-R^2)(n-1)}{n-k-1}\\]\nAIC, BIC: Criterios de información que balancean ajuste y parsimonia\nSignificatividad conjunta: Test \\(F\\) para grupos de variables\nValidación cruzada: Error predictivo en datos no vistos (siguiente sección)\n\nAdvertencia: NO usar solo significatividad individual cuando hay múltiples términos de una variable (ej. polinomios)\nLa significatividad individual puede ser engañosa con polinomios o discretización debido a multicolinealidad."
  },
  {
    "objectID": "docs/Tema05.html#regresión-lineal-comentarios-finales",
    "href": "docs/Tema05.html#regresión-lineal-comentarios-finales",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Lineal: comentarios finales",
    "text": "Regresión Lineal: comentarios finales\n\nLos resultados de (todos) estos modelos informan de la relación entre los regresores y la variables dependiente\n“Correlación no implica causalidad”, salvo en ensayos científicos aleatorios controlados, también llamados pruebas A/B\n\n\n\nLa selección de variables es importante: evita sesgos o aumenta la variabilidad\n\n\nlm(data = descuento, ventas ~ descuento) |&gt; summary()\nlm(data = descuento, ventas ~ descuento + renta) |&gt; summary()\nlm(data = descuento, ventas ~ renta) |&gt; summary()\nlm(data = descuento, ventas ~ renta + educ) |&gt; summary()\n\n\n\n\nAlgunos sugieren “pruebas” para los problemas en el modelo lineal; eso es erróneo:\n\nNo linealidad: hemos visto que modeliza relaciones no lineales\nNo normalidad: innecesaria, con TCL o bootstrap.\nColinearidad: simplemente elimina la variable colineal.\nHeterocedasticidad y autocorrelación: solo necesitamos errores estándar robustos\n\n\n\n\nOutliers: pueden manejarse sin afectar la validez del modelo.\nAlgunos mencionan “pruebas” para detectar los supuestos problemas del modelo lineal: no linealidad, heterocedasticidad (y autocorrelación), no normalidad, colinearidad, outliers, …\nEste enfoque es mayormente erróneo como hemos visto: el modelo lineal permite no linealidades, no necesita normalidad (TCL, boostrap), eliminar la variable colineal soluciona el “problema”, solo necesitamos usar errores estándar robustos, etc."
  },
  {
    "objectID": "docs/Tema05.html#regresión-logística",
    "href": "docs/Tema05.html#regresión-logística",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Logística",
    "text": "Regresión Logística\n\n\nLa regresión lineal puede usarse respuestas binarias (no más de dos categorías),\n\n\\[\n\\small\n\\Pr(Y=1|X)=\\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k = z\n\\] aunque genera predicciones fuera del rango \\(\\small [0,1]\\)\n\nSolución: aplicar al índice lineal una transformación \\(\\small F(z)\\in[0,1]\\)\n\n\n\nUn modelo de regresión lineal para respuestas binarias no es adecuado porque genera predicciones fuera del rango \\(\\small [0,1]\\)\n\n\n\n\nSolución: aplicar al índice lineal una transformación, la función logística \\(\\small \\Lambda (z)=\\frac{e^z}{1+e^z}\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe manera que \\(\\small \\Pr(Y=1|X)= f(x)= \\color{blue}{\\Lambda( \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k)} \\in [0,1]\\)\n\n\n\n\nLos coeficientes NO se interpretan como cambios en la probabilidad ante cambios unitarios en un regresor (efecto marginal sobre la probabilidad)\nPERO su signo (y significatividad) son los mismos que los del efecto marginal\n\n\n\nComo el modelo siempre es no lineal, el coeficiente NO coincide con la magnitud del efecto de un cambio en los regresores sobre la probabilidad. PERO sí coinciden en su signo (y significatividad)\n\n\n\nEn esta especificación, la probabilidad relativa (“odd”) es \\[\n\\small\n\\frac{p(x)}{1-p(x)}=exp(\\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k)\n\\]\nPor tanto, su logaritmo (“log odd” o logit) es lineal: los coeficientes son la elasticidad de la probabilidad relativa\n\n\n\nNO se puede minimizar la SCR; el objetivo es maximizar la probabilidad (verosimilitud) de observar los unos y ceros en los datos\n\n\n\\[\n\\small\n\\ell(\\beta_0, \\beta_1, \\dots, \\beta_k)=\\prod_{i:y_i=1}p(x_i) \\prod_{i:y_i=0} \\left(1 - p(x_i)\\right)\n\\]"
  },
  {
    "objectID": "docs/Tema05.html#regresión-logística-cont.",
    "href": "docs/Tema05.html#regresión-logística-cont.",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Logística (cont.)",
    "text": "Regresión Logística (cont.)\n\nLa regresión logística se puede estimar en R con la función glm() (similar a lm()); podemos incluir variables explicativas tanto cuantitativas como cualitativas, interacciones, etc.\n\n\ncenso &lt;- read_csv(\"data/census.csv\") |&gt;\n  mutate(across(where(is.character), ~parse_factor(.x)))\n\nlogit &lt;- glm(data = censo, income ~  race + age + I(age^2) +\n               log(hours_per_week)*sex +  education_1  +\n               capital_gain + capital_loss, family = \"binomial\")\nlogit |&gt;  summary()\n\n\nComo en el modelo lineal, podemos calcular predicciones de la probabilidad tanto en los mismos datos como en unos nuevos\n\n\npredict(logit, type=\"response\")\n\nlogit2 &lt;- logit &lt;- glm(data = censo, income ~  age + education_1,\n         family = \"binomial\")\nsummary(logit2)\npredict(logit2, type=\"response\",\n        newdata = tibble(age=c(20,60), education_1=c(9,16)))\n\n\n\nPodemos incurrir en un sesgo por omisión de variables relevantes: ej., el efecto de student por omitir balances (con la que está correlacionada)\n\n\nglm(data = Default, default ~ student + balance, family = \"binomial\" ) |&gt; summary()"
  },
  {
    "objectID": "docs/Tema05.html#regresión-logística-con-más-de-dos-clases",
    "href": "docs/Tema05.html#regresión-logística-con-más-de-dos-clases",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Regresión Logística con más de dos clases",
    "text": "Regresión Logística con más de dos clases\n\nLa regresión logística se puede generalizar a situaciones con múltiples clases (modelos multinomiales) con un índice lineal para cada clase \\[\n\\small\n\\Pr(Y=c|X)=\\frac{e^{\\beta_{0c}+\\beta_{1c}X_1+\\dots+\\beta_{kc}X_k}}{\\sum_{l=1}^{C}e^{\\beta_{0l}+\\beta_{1l}X_1+\\dots+\\beta_{kl}X_k}}\n\\]\nLa librería glmnet() permite la estimación de estos modelos\n\n\nhealth &lt;- read_csv(\"data/health_insurance.csv\") |&gt;\n  mutate(across(where(is.character), ~parse_factor(.x)))\n\nlibrary(glmnet)\nx &lt;- model.matrix(product ~ age + gender, data = health)\nmod.glmnet &lt;- glmnet(x = x, y = health$product, family = \"multinomial\",\n                     lambda = 0, type.multinomial = \"grouped\")\ncoef(mod.glmnet)\npredict(mod.glmnet, newx=x, type = \"response\")  # probabilidad de cada clase\npredict(mod.glmnet, newx=x, type = \"class\")     # clase"
  },
  {
    "objectID": "docs/Tema05.html#métricas-de-error-de-predicción-cuantitativa",
    "href": "docs/Tema05.html#métricas-de-error-de-predicción-cuantitativa",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Métricas de Error de Predicción (cuantitativa)",
    "text": "Métricas de Error de Predicción (cuantitativa)\n\n\nUn modelo es mejor cuanto mejor se ajusten sus predicciones a las observaciones\nEl error de predicción es \\(y - \\widehat{y} = f(X) - \\widehat{f}(X)  + \\varepsilon\\)\n\n\\(f - \\widehat{f}\\) = error reducible (eligiendo modelo)\n\\(\\varepsilon\\) = error irreducible (variables no observadas)\n\n\n\n\n\n\n\n\n\nUna función de pérdida (o coste) evalúa cómo valoramos las desviaciones\n\nMean Square Error (Error Cuadrático Medio): \\(\\small \\color{blue}{MSE(y,\\widehat{y})={\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}}\\)\n\npenaliza grandes desviaciones\n\\(\\small \\color{blue}{R^2}\\) y \\(\\small \\color{blue}{R^2-ajustado}\\): variantes solo para comparar modelos con la misma variable dependiente.\n\nRoot Mean Square Error: \\(\\small  \\color{blue}{RMSE(y,\\widehat{y})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}}\\)\n\nmismas unidades que \\(\\small y\\)\n\nMean Absolute Error: \\(\\small  \\color{blue}{MAE(y,\\widehat{y})=\\frac{1}{n}\\sum_{i=1}^{n}\\left|y-\\widehat{y}\\right|}\\)\n\n\nOtras medidas basadas en distintas funciones de pérdida: verosimilitud del modelo, \\(\\small \\color{blue}{AIC}\\), \\(\\small \\color{blue}{BIC}\\), etc\n\n\n\n\n\\(R^2\\)-ajustado penaliza por número de variables\ntambién median ABs. error\nCorrelación lineal o de rangos entre \\(\\small y\\) y \\(\\small \\widehat{y}\\)\n  + lineal ($y$ y $\\widehat{y}$ pueden no tener las mismas unidades y escala como con RMSE y MAE)\n  + de rangos ($y$ y $\\widehat{y}$ solo tiene que tener el mismo orden relativo, no minimizar distancia entre ellas)\nCoeficiente de determinación\nAIC, BIC ajustan por el número de parámetros\n\nhttps://yardstick.tidymodels.org/reference/rmse.html"
  },
  {
    "objectID": "docs/Tema05.html#seleccionar-el-mejor-modelo.-overfitting",
    "href": "docs/Tema05.html#seleccionar-el-mejor-modelo.-overfitting",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Seleccionar el mejor modelo. “Overfitting”",
    "text": "Seleccionar el mejor modelo. “Overfitting”\n\n\n¿Cuál es el mejor modelo para predecir el número de visitantes en función de la temperatura?\n\n\nlibrary(mosaicData)\nRailTrail |&gt; ggplot(aes(x = hightemp, y = volume)) +\n  geom_point() +  geom_smooth()\n\n\\[\n\\scriptsize\n\\begin{align*}\nvolume &= \\beta_0 + \\beta_1 \\, \\mathrm{hightemp} + \\varepsilon \\\\\nvolume &= \\beta_0 + \\beta_1 \\, \\mathrm{hightemp} + \\beta_2 \\, \\mathrm{hightemp}^2 + \\varepsilon \\\\\n&\\vdots \\\\\nvolume &= \\beta_0 + \\beta_1 \\, \\mathrm{hightemp} + \\dots + \\beta_{22} \\, \\mathrm{hightemp}^{22} + \\varepsilon\n\\end{align*}\n\\]\n\nEl objetivo de un modelo es predecir casos nuevos (no reproducir los datos vistos)\nLas métricas (\\(\\small MSE\\), \\(R^2\\)) calculadas en los mismos datos usados para estimar NO informan de esto: miden in-sample prediction, no out-sample prediction\n\n\n\nLas métricas de error (\\(\\small MSE\\), \\(R^2\\)) calculadas para predicciones de los mismos datos usados para estimar el modelo NO informan de esto\n\n\n\nUn modelo demasiado flexible puede aprender el ruido (características de la muestra concreta) → sobreajuste (overfitting): error casi nulo en los datos que estimamos, pero grande con casos nuevos\n\n\nRailTrail |&gt; ggplot(aes(x = hightemp, y = volume)) +\n  geom_point() + geom_smooth(method = 'lm', formula = y ~ poly(x,22) ) +\n  coord_cartesian(ylim = c(100,750))"
  },
  {
    "objectID": "docs/Tema05.html#muestras-de-entrenamiento-y-de-prueba",
    "href": "docs/Tema05.html#muestras-de-entrenamiento-y-de-prueba",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Muestras de entrenamiento y de prueba",
    "text": "Muestras de entrenamiento y de prueba\n\n\nDividimos la muestra para usar datos diferentes para estimar y para calcular las métricas\n\nMuestra de entrenamiento (train) donde se ajusta el modelo\nMuestra de prueba (test) donde se calculan métricas con observaciones NO vistas antes por el modelo → evaluamos el mejor modelo para predecir casos nuevos\n\n\n\n\n\n\n\n\n\n\n\n\n\nUn buen modelo tiene equilibrio entre capacidad predictiva y complejidad: ni ajuste insuficiente (underfitting) ni overfitting\n\n\n\n\nSiempre que aumenta la flexibilidad, el MSE\n\ndisminuye en la muestra de entrenamiento\ntiene forma de U en la muestra de prueba\n\nNota: el MSE en entrenamiento es siempre menor que en prueba\n\n\n\n\n\n\n\n\n\n\nEvitar modelos con sobre-ajuste: un modelo menos flexible podría tener menor error de predicción con casos nuevos\n\n\n\n\nsobre-ajuste: parecen que su error es casi nulo en los datos que estimamos, pero cometen un gran error en observaciones nuevas\nMostrar ejemplos gráficos de ajuste insuficiente, correcto y sobreajuste.\n\n\n\n\n\n\n\n\n\n\n\n\nLos grados de libertad (número de valores en el modelo que son libres de variar) resume la flexibilidad de una curva."
  },
  {
    "objectID": "docs/Tema05.html#trade-off-varianzasesgo",
    "href": "docs/Tema05.html#trade-off-varianzasesgo",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "“Trade-off” Varianza–Sesgo",
    "text": "“Trade-off” Varianza–Sesgo\n\nMSE en la muestra de prueba\n\\[\n\\small\nE\\left[\\left(y-\\widehat{f}(x)\\right)^2\\right] =\nE\\left[\\left(f(x)-\\widehat{f}(x) + \\varepsilon\n+ E\\left[\\widehat{f}(x)\\right]-E\\left[\\widehat{f}(x)\\right] \\right)^2\\right] =\n\\]\n\\[\n\\small\n=\\underbrace{\\left[E\\left(\\widehat{f}(x)\\right)-f(x)\\right]^2}_{(1)} + \\underbrace{E\\left(\\left[\\widehat{f}(x)-E\\left(\\widehat{f}(x)\\right)\\right]^2\\right)}_{(2)}+Var(\\varepsilon)\n\\]\n\n\\(\\small (1)=\\left[Sesgo\\left(\\widehat{f}(x)\\right)\\right]^2\\): error por supuestos erróneos en \\(f\\)\n\najuste insuficiente (underfit) al perder relaciones relevantes entre \\(X\\) e \\(Y\\)\n\n\\(\\small (2)=Var\\left(\\widehat{f}(x)\\right)\\): sensibilidad a fluctuaciones en el entrenamiento\n\nsi el algoritmo modela puro ruido en entrenamiento, ajustará bien allí, pero predecirá mal casos nuevos (overfit)\n\n\n\n\n\n\n\\(\\small MSE\\) en la muestra de prueba es la suma de sesgo y varianza de la estimación:\n\n\n\\[\n\\small\n\\text{Error Total}  =  \\text{Sesgo}^2 + \\text{Varianza} + \\text{Error Irreducible}\n\\]\n\n\n\n\n\n\n\n\n\nSesgo: diferencia entre predicción promedio y valor real por especificar mal \\(f\\)\n\nmodelos simples (underfit) que pierden relaciones relevantes (omitir variables, forma funcional incorrecta)\n\nVarianza: cuánto cambian las predicciones con diferentes datos\n\nmodelos complejos, sobreajustados a características de cada muestra de entrenamiento\n\nAl aumentar la complejidad ↓ sesgo pero ↑ varianza ⇒ encontrar una flexibilidad intermedia \nNo pueden minimizarse simultáneamente ambas fuentes de error: memorización (en entrenamiento) vs. generalización de resultados\n\n\n\n\n\nRecuerdo de Econometría I:\n\n\nsesgo por omisión de variables relevantes\naumento de varianza por inclusión de variable irrelevante\n\n\nA medida que se añaden más y más parámetros a un modelo, la complejidad del modelo aumenta y la varianza se convierte en nuestra principal preocupación, mientras que el sesgo disminuye constantemente. Por ejemplo, a medida que se añaden más términos polinómicos a una regresión lineal, mayor será la complejidad del modelo resultante.\n\n\n\n\n\n\n\nEs fácil construir un modelo con bajo sesgo, pero tendrá alta varianza. Y al revés.\nEl desafío es encontrar un método (ej., flexibilidad del modelo) para el cual tanto la varianza como el sesgo cuadrado sean bajos"
  },
  {
    "objectID": "docs/Tema05.html#métricas-de-error-en-la-clasificación",
    "href": "docs/Tema05.html#métricas-de-error-en-la-clasificación",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Métricas de Error en la Clasificación",
    "text": "Métricas de Error en la Clasificación\n\n\nLos modelos de clasificación NO predicen directamente la categoría, sino la probabilidad de que una observación pertenezca a cada categoría\nTípicamente se asigna la clase predicha como aquella con mayor probabilidad.\nEn el caso binario, equivale a fijar un umbral de 0.5, pero se deberían probar varios valores del umbral\nComo no tiene sentido diferencia de clases (variables categóricas), NO se pueden calcular medidas como el MSE y otros relacionados\nExisten pseudo-\\(\\small R^2\\) como la correlación al cuadrado entre\n\n\n\nEl modelo predice la probabilidad de que una observación pertenezca a cada categoría ⇒ se asigna como clase predicha aquella con mayor probabilidad\n\nen el caso binario, implica superar el umbral de 0.5 (pero deben probarse varios valores)\n\n\n\ncenso &lt;- read_csv(\"data/census.csv\") |&gt; \n  mutate(income = parse_factor(income))\nlogit &lt;- glm(data = censo, income ~ capital_gain, \n             family = \"binomial\")\nprob_predict &lt;- predict(logit, type = \"response\")\n\numbral &lt;- 0.5\ncat_predict  &lt;- if_else(prob_predict &gt; umbral, 1, 0)\ncbind(censo$income, cat_predict, prob_predict) |&gt; head(10)\n\n\nNO tiene sentido diferencia de clases ⇒ no se puede calcular MSE y similares\nMatriz de Confusión: tabular categorías observadas frente a las categorías predichas\n\n\ntable(cat_predict, censo$income)\n\n\n\n\n\n\n\n\n\n\n\nCLASE OBSERVADA\n\n\n\n\n\nCLASE PREDICHA ↓\nPOSITIVO (1)\nNEGATIVO (0)\n\n\nPOSITIVO (1)\nVerdadero Positivo [VP]\nFalso Positivo [FP] (Error Tipo I)\n\n\nNEGATIVO (0)\nFalso Negativo [FN] (Error Tipo II)\nVerdadero Negativo [VN]"
  },
  {
    "objectID": "docs/Tema05.html#métricas-basadas-en-la-matriz-de-confusión",
    "href": "docs/Tema05.html#métricas-basadas-en-la-matriz-de-confusión",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Métricas basadas en la matriz de confusión",
    "text": "Métricas basadas en la matriz de confusión\n\nExisten varias medidas derivadas de la matriz de confusión\n\n\n\n\n\n\n\n\n\n\n\nCLASE OBSERVADA\n\n\n\nCLASE PREDICHA ↓\nPOSITIVO (1)\nNEGATIVO (0)\n\n\n\n\nPOSITIVO (1)\nVerdadero Positivo [VP]\nFalso Positivo [FP]\n(Error Tipo I)\n\n\nNEGATIVO (0)\nFalso Negativo [FN]\n(Error Tipo II)\nVerdadero Negativo [VN]\n\n\n\n\nTasa de observaciones correctamente clasificadas (exactitud o accuracy)\n\n\\[\n\\scriptsize \\color{blue}{ACCUR=\\frac{VP+VN}{VP+FP+VN+FN}}\n\\]\n\nNo es informativo con clases infrecuentes (datos desequilibrados): con solo 1% de fraude, predecir que nunca hay fraude implica \\(\\scriptsize ACCUR=99\\%\\), PERO NO detecta fraude\n\n\n\nACCUR = 1 - TCE\nSu complemento es la tasa de clasificación errónea o de error en la clasificación: \\(\\small TCE=\\frac{FP+FN}{VP+FP+VN+FN} = \\frac{1}{n}\\sum_{i=1}^{n}I\\left[y_i \\neq \\widehat{y}_i\\right]\\)\n(datos desequilibrados o imbalanced )\nUna medida global para datos imbalanced es la exactitud equilibrada: \\(\\small \\frac{TVP+TVN}{2}\\)\n\nhttps://en.wikipedia.org/wiki/Cohen’s_kappa\n\n\nEl estadístico Kappa (\\(\\small \\kappa\\)) es una medida similar, pero ajusta por el desequilibrio entre clases\n\n\nque ajusta por lo se esperaría solo por azar (corrigiendo en parte el desequilibrio entre clases)."
  },
  {
    "objectID": "docs/Tema05.html#métricas-basadas-en-la-matriz-de-confusión-cont.",
    "href": "docs/Tema05.html#métricas-basadas-en-la-matriz-de-confusión-cont.",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Métricas basadas en la matriz de confusión (cont.)",
    "text": "Métricas basadas en la matriz de confusión (cont.)\n\nTasa de verdaderos positivos o sensibilidad (recall) \\[\n\\scriptsize \\color{blue}{TVP=SENSIT=\\frac{VP}{VP+FN}}\n\\]\nTasa de verdaderos negativos o especificidad \\[\n\\scriptsize \\color{blue}{TVN=ESPECIF=\\frac{VN}{VN+FP}}\n\\]\n\nTasa de falsos positivos: \\(\\scriptsize \\color{blue}{TFP = 1 - TVN = 1 - ESPECIF}\\)\n\n\n\n-TVP: es el porcentaje de verdaderos positivos sobre el total de positivos observados ej., tasa de fraude/enfermos existentes que se detectan correctamente\n\nTVN: es el porcentaje de verdaderos negativos sobre el total de negativos observados\n\nej: ., tasa de “otras” opciones que se clasifican correctamente\n\nEjemplo: prueba diagnóstica, sensibilidad cuantos enfermos es capaz de detectar\nespecificifciad, cuantos no enfermos es capaz de detectar corre\n\n\n\nExactitud equilibrada: (Balanced Accuracy) media de la sensibilidad y de la especificidad\nPrecisión: \\(\\scriptsize PREC=\\frac{VP}{VP+FP}\\)\nLa familia de medidas \\(\\small F_{\\beta}\\): ratio de la importancia ponderada de la sensibilidad y de la precisión\n\n\n\n(Balanced Accuracy) es una media (aritmética o geométrica) de la sensibilidad y de la especificidad\n\nG-mean = sqrt(sensit * especif )\n\nLa precisión o valor de predicción positivo es la cantidad de verdaderos positivos sobre el total de positivos predichos\n\n\\[\n\\scriptsize PREC=\\frac{VP}{VP+FP}\n\\]\n+ Tasa de falso descubrimiento: $\\small 1-PREC$\n\nLa familia de medidas \\(\\small F_{\\beta}\\) es una ratio de la importancia ponderada de la sensibilidad y de la precisión: \\(\\scriptsize F_{\\beta}=\\frac{(1+\\beta)^2 \\times SENSIT \\times PREC}{\\beta^2 \\times SENSIT + PREC}\\)\n\nPara \\(\\scriptsize \\beta&lt;1\\), se da menos importancia a la sensibilidad: los falsos positivos se consideran más costosos\nPara \\(\\scriptsize \\beta&gt;1\\), los falsos negativos son más costosos y para \\(\\scriptsize \\beta=1\\) son igualmente costosos"
  },
  {
    "objectID": "docs/Tema05.html#curva-roc-receiver-operating-characteristic",
    "href": "docs/Tema05.html#curva-roc-receiver-operating-characteristic",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Curva ROC (“Receiver Operating Characteristic”)",
    "text": "Curva ROC (“Receiver Operating Characteristic”)\n\nhttps://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n\n(es una curva de probabilidad)\nReducir el umbral clasifica más elementos como positivos, por lo que aumentan tanto los falsos positivos como los verdaderos positivos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclasificador aleatorio: por debajo de 45º el clasificador es pesimo predice más positivos entre los negativos que entre los positivos\nCon datos imbalanced puede ser más informativo graficar TFP frente a precisión\n\n \nhttps://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\nhttps://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n\n\nRepresenta TVP (eje y) frente a TFP (eje x) en diferentes umbrales : reducir el umbral clasifica más elementos como positivos (verdaderos y falsos)\n\n\n\n\n\n\n\nLa curva ROC informa del grado de separabilidad: dado un nivel de TFP, el clasificador es mejor cuanto mayor sea TVP"
  },
  {
    "objectID": "docs/Tema05.html#auc-area-under-the-curve",
    "href": "docs/Tema05.html#auc-area-under-the-curve",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "AUC (“area under the curve”)",
    "text": "AUC (“area under the curve”)\n\n\nAUC informa del grado de separabilidad: mayor AUC implica que el modelo es capaz de distinguir entre clases (predecir 0s y 1s correctamente)\nAUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n\n\n\nLa AUC es el área bajo la curva ROC: ofrece una medida agregada de rendimiento entre 0 (todas las clasificaciones incorrectas) y 1 (todas correctas)\nResume la curva ROC y permite comparar curvas que se cruzan"
  },
  {
    "objectID": "docs/Tema05.html#extensiones.-métricas-adicionales",
    "href": "docs/Tema05.html#extensiones.-métricas-adicionales",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Extensiones. Métricas adicionales",
    "text": "Extensiones. Métricas adicionales\n\nCon más de dos clases, se realiza un análisis AUC-ROC para cada categoría (frente a las demás) y se promedian (ej., ponderando por casos en cada clase)\n\n\n\nCon más de dos clases, se realiza un análisis AUC-ROC para cada categoría (frente a las demás): se define una variable binaria para la categoría frente a todas las demás y se promedian la ROC y la AUC (ej., ponderando por casos en cada clase) o no\n\nhttps://yardstick.tidymodels.org/reference/roc_aunp.html\nhttps://yardstick.tidymodels.org/reference/roc_aunu.html\n\nCuando la variable de respuesta tiene más de dos clases,\n\nSe realiza un análisis AUC-ROC para cada categoría: se define una variable binaria para la categoría frente a todas las demás\nSe obtiene el promedio de tanto de la ROC como de la AUC, bien dando igual peso a cada categoría o bien ponderando el número de casos de cada una\n\n\nhttps://yardstick.tidymodels.org/reference/pr_auc.html\nhttps://yardstick.tidymodels.org/reference/average_precision.html\n\ngain curve: https://yardstick.tidymodels.org/reference/gain_curve.html\nmn_log_loss: https://yardstick.tidymodels.org/reference/mn_log_loss.html\n\n\n\nCon clases desequilibradas, se puede preferir en lugar de la ROC un gráfico de precisión frente sensibilidad (precision-recall) y su correspondiente AUC (PR-AUC)\nExisten múltiples funciones de pérdida (o coste de clasificación) posibles.\n\nLas relacionadas con la curva de ganancia consideran el coste de alcanzar un cierto nivel de sensibilidad\nOtras se basan en la función de verosimilud o la entropía como medidas de pérdida (ej. mean log loss)"
  },
  {
    "objectID": "docs/Tema05.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "href": "docs/Tema05.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Evaluación de Modelos: entrenamiento y prueba",
    "text": "Evaluación de Modelos: entrenamiento y prueba\n\nPara minimizar problemas de underfit y, sobre todo, de overfit, DEBEMOS dividir aleatoriamente el conjunto de datos en dos partes:\n\n\n\n\n\n\n\n\n\n\n\nEntrenamiento (80-90%): datos sobre los que se construye/estima el modelo\nPrueba(20-10%): se usa el modelo construido para predecir y se evalúa con datos no vistos antes\n\n\n\n\n¿Por qué renunciar a parte de los datos si sabemos que un tamaño muestral grande es importante? Evaluar correctamente un modelo lo es mucho más\nLa estimación del error en prueba puede ser volátil dependiendo de las observaciones incluidas en cada grupo"
  },
  {
    "objectID": "docs/Tema05.html#evaluación-de-modelos-validación-cruzada",
    "href": "docs/Tema05.html#evaluación-de-modelos-validación-cruzada",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Evaluación de Modelos: Validación cruzada",
    "text": "Evaluación de Modelos: Validación cruzada\n\n\nLos resultados de evaluación puede verse afectados por la partición concreta obtenida (ej. incluir observaciones atípicas en la muestra de prueba)\nSe repite varias veces y de forma ordenada el proceso de remuestreo para la partición en grupos de entrenamiento y prueba (similar a bootstrap)\n\nhttps://en.wikipedia.org/wiki/Cross-validation_(statistics)\n\n\n\n\n\n\n\nLa validación cruzada (cross-validation o rotation estimation) repite varias veces y de forma ordenada el proceso de partición en grupos de entrenamiento y prueba (similar a bootstrap)\nEste método de evaluación de modelos:\n\nEvita que los resultados sean sensibles a una partición concreta de los datos\nPermite utilizar todas las observaciones de la muestra, tanto para estimar como para evaluar el modelo (aunque no a la vez)\n\n\n\n\nAlgunas variantes de Validación Cruzada (VC) son:\n\nVC de K iteraciones (K-fold cross-validation o K-fold CV) (el más habitual)\nVC aleatoria (Random cross-validation, RCV)\nVC dejando uno fuera (Leave-one-out cross-validation, LOOCV)\nVC dejando p fuera (Leave-p-out cross-validation, LpOCV)"
  },
  {
    "objectID": "docs/Tema05.html#validación-cruzada-de-k-bloques",
    "href": "docs/Tema05.html#validación-cruzada-de-k-bloques",
    "title": "Tema 05 - Modelización y Aprendizaje Estadístico",
    "section": "Validación cruzada de K bloques",
    "text": "Validación cruzada de K bloques\n\nSe divide, aleatoriamente y ex-ante, la muestra en K subconjuntos (normalmente, 5 o 10)\n\n\n\n\n\n\n\n\n\n\nUn subconjunto se usa como prueba y el K-1 restantes como entrenamiento\nSe repite el proceso durante k iteraciones, con cada posible subconjunto de datos de prueba.\n\n\n\nSe obtiene una métrica de error en cada iteración\nSe promedian para obtener un único resultado de evaluación\n\n\n\nEvita la sensibilidad a una partición concreta de los datos y permite usar todas las observaciones tanto para estimar como para evaluar el modelo\nDe Joan.domenech91 - Trabajo propio, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=17616792\n\nValidación cruzada aleatoria (RCV) y LOOCV\n\n\n\n\n\n\n\n\n\nRCV: en cada iteración se realiza la particion aleatoria (con reemplazamiento) entre entrenamiento y prueba\nLas observaciones pueden “repetir” como prueba\n\n\n\n\n\n\n\n\n\n\n\nLOOCV (leave one out CV): solo una observación se usa como prueba en cada iteración y el resto como entrenamiento\nSe realizan \\(n\\) iteraciones; se calcula una media sobre \\(n\\) resultados"
  }
]