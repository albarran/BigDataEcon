[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas para ‘Big Data’ en Economía",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 13h\nLunes de 15:30h a 17h\nViernes de 11 a 13h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud\n\n\n\n\n\nDespacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es"
  },
  {
    "objectID": "index.html#pedro-albarrán",
    "href": "index.html#pedro-albarrán",
    "title": "Técnicas para ‘Big Data’ en Economía",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 13h\nLunes de 15:30h a 17h\nViernes de 11 a 13h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud"
  },
  {
    "objectID": "index.html#alberto-pérez",
    "href": "index.html#alberto-pérez",
    "title": "Técnicas para ‘Big Data’ en Economía",
    "section": "",
    "text": "Despacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "ProyectoFinal.html",
    "href": "ProyectoFinal.html",
    "title": "Proyecto Final",
    "section": "",
    "text": "Para realizar este proyecto final, debéis proponer un tema de estudio usando datos y las técnicas que hemos visto en el curso. Más abajo os indico unas propuestas tanto de temas como de fuentes para obtener datos. También podéis proponerme un tema de estudio, usando datos de que dispongáis por trabajo, contactos, búsqueda propia, etc.\nEn cualquier caso, el resultado final debe ser un proyecto de análisis de datos que tenga sentido en el ámbito de economía, empresa, negocios, finanzas, etc. Se aplicarán los conocimientos adquiridos en el curso, quedando claras todas las etapas del análisis según el conocido flujo\n\n\n\nPor tanto, debe explicarse claramente:\n\nObjetivo del análisis: qué cuestión se analiza y su importancia\nDatos: qué datos se utilizan, su origen, por qué son adecuados para el objetivo del análisis\nProcesamiento de los datos (importación, limpieza y transformación): por qué es necesario para el análisis\nAnálisis exploratorio de datos: qué información básica aprendemos de los datos y cómo esto ayuda a especificar los modelos\nProceso de Modelización: cómo se especifican distintos modelos que ayudan a responder al objetivo y cómo se validan para obtener el mejor modelo final\nComunicar de manera efectiva mediante gráficos, resultados de estimación, etc. las implicaciones de los resultados obtenidos en el análisis para el objetivo. En particular, explicar cómo los resultados responden a la cuestión económica, financiera o decisión de empresa que se plantea cómo objetivo.\n\nLA INFORMACIÓN SOBRE EL PROYECTO FINAL SE IRÁ ACTUALIZANDO A LO LARGO DEL CURSO"
  },
  {
    "objectID": "ProyectoFinal.html#elección-de-tema",
    "href": "ProyectoFinal.html#elección-de-tema",
    "title": "Proyecto Final",
    "section": "Elección de Tema",
    "text": "Elección de Tema\n\nPor favor, cumplimentad este FORMULARIO con vuestra propuesta de tema para el proyecto.\nDeben queda claro los objetivos/utilidad de hacer del análisis que proponéis; debéis indicar qué datos usaréis y comentar brevemente cómo pensáis hacerlo (si haréis regresión o clasificación, tipo de algoritmos, etc.)\nAunque no pondré plazo formal, os recomiendo hacer esto cuanto antes y, como fecha orientativa, del jueves, 28 de diciembre de 2023.\n\nCuanto antes lo hagáis, antes podéis empezar a organizaros y trabajar\nPERO debéis esperar a que os dé mi visto bueno sobre vuestra propuesta para asegurarme de que vuestra propuesta tiene sentido y, por ejemplo, que dos estudiantes diferentes NO hacen el mismo trabajo (los datos pueden ser los mismos, pero NO con el mismo objetivo.)\n\n\n\nEn cualquier momento podéis consultarme dudas relativas al trabajo. Si fuera necesario, en enero podemos tener tanto tutorías presenciales, preferentemente coordinadas entre varios, para poder reservar un aula."
  },
  {
    "objectID": "ProyectoFinal.html#entrega-final",
    "href": "ProyectoFinal.html#entrega-final",
    "title": "Proyecto Final",
    "section": "Entrega Final",
    "text": "Entrega Final\n\nEl trabajo en su formato final deberá entregarse antes del jueves, 1 de febrero de 2024 (hora límite 23:55h de la noche) por medio de este FORMULARIO"
  },
  {
    "objectID": "ProyectoFinal.html#importante-plagio.",
    "href": "ProyectoFinal.html#importante-plagio.",
    "title": "Proyecto Final",
    "section": "IMPORTANTE: PLAGIO.",
    "text": "IMPORTANTE: PLAGIO.\n\nSeguro que podéis encontrar análisis ya realizados sobre vuestra propuesta, en internet o de estudiantes de cursos anteriores. Yo también.\nLa detección de plagio supondrá automáticamente el suspenso en todas las convocatorias de la asignatura en este curso académico y el inicio de la apertura de un expediente.\n\nNo es la primera vez que estos datos u otros que me propongáis vosotros se han utilizado. Seguro que podéis encontrar análisis ya realizados sobre vuestra propuesta, en internet o de estudiantes de cursos anteriores. Yo también."
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html",
    "href": "docs/Tema05ejWebScrap.html",
    "title": "Tema 5. Ejercicio.",
    "section": "",
    "text": "Internet es un gran lugar para obtener datos. Podemos usar rvest para extraer (en inglés, scrap significa literalmente raspar o rascar una superficie) los datos en tablas HTML de la web, pero a menudo requerirá una limpieza extensa antes de que se puedan usar adecuadamente.\nConsiderar la siguiente lista de los fines de semana de apertura de taquillas más grandes:\n(http://www.boxofficemojo.com/alltime/weekends/)\nUsando rvest podemos traer esta tabla a R.\n\nlibrary(rvest)\nurl &lt;- \"http://www.boxofficemojo.com/alltime/weekends/\"\n\nPrimero, necesitaremos leer el contenido de la página en HTML. La función read_html() proporcionada por rvest procesa el HTML:\n\nhtml_bom &lt;- read_html(url)\nclass(html_bom)\nhtml_bom\n\nDesafortunadamente, esto no es muy legible. Lo que queremos es extraer los datos que están incrustados en las tablas HTML. Empecemos por tomar esas tablas que están dentro de los elementos del html llamados “table”. Para ello podemos utilizar html_nodes():\n\ntables &lt;- html_bom %&gt;%\n  html_nodes(\"table\")\ntables\n\nEn este caso, solo hay 1 elementos de tabla en esa página .\n\ntables[[1]]\n\nLa función html_table() extraerá los datos de esta tabla y los convertirá en un data frame. La opción header = TRUE indica a R que queremos usar la primera fila como nuestros nombres de variable.\n\nmovies &lt;- tables[[1]] %&gt;%\n  html_table(header = TRUE)\nglimpse(movies)\n\nEn algunas ocasiones, existen más de una table en una página web. Si son pocas se puede determinar cuál nos interesa mediante prueba y error. En particular, en esta caso sabemos que los datos tienen 200 observaciones y 9 columnas; si lo que leemos tiene una dimensiones (obtenidas con glimpse() o str()) muy diferentes no debe ser la tabla que buscamos. En cualquier caso, con muchas tablas en la página web, necesitaremos nuevas herramientas de programación que veremos en breve."
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html#scraping-con-rvest",
    "href": "docs/Tema05ejWebScrap.html#scraping-con-rvest",
    "title": "Tema 5. Ejercicio.",
    "section": "",
    "text": "Internet es un gran lugar para obtener datos. Podemos usar rvest para extraer (en inglés, scrap significa literalmente raspar o rascar una superficie) los datos en tablas HTML de la web, pero a menudo requerirá una limpieza extensa antes de que se puedan usar adecuadamente.\nConsiderar la siguiente lista de los fines de semana de apertura de taquillas más grandes:\n(http://www.boxofficemojo.com/alltime/weekends/)\nUsando rvest podemos traer esta tabla a R.\n\nlibrary(rvest)\nurl &lt;- \"http://www.boxofficemojo.com/alltime/weekends/\"\n\nPrimero, necesitaremos leer el contenido de la página en HTML. La función read_html() proporcionada por rvest procesa el HTML:\n\nhtml_bom &lt;- read_html(url)\nclass(html_bom)\nhtml_bom\n\nDesafortunadamente, esto no es muy legible. Lo que queremos es extraer los datos que están incrustados en las tablas HTML. Empecemos por tomar esas tablas que están dentro de los elementos del html llamados “table”. Para ello podemos utilizar html_nodes():\n\ntables &lt;- html_bom %&gt;%\n  html_nodes(\"table\")\ntables\n\nEn este caso, solo hay 1 elementos de tabla en esa página .\n\ntables[[1]]\n\nLa función html_table() extraerá los datos de esta tabla y los convertirá en un data frame. La opción header = TRUE indica a R que queremos usar la primera fila como nuestros nombres de variable.\n\nmovies &lt;- tables[[1]] %&gt;%\n  html_table(header = TRUE)\nglimpse(movies)\n\nEn algunas ocasiones, existen más de una table en una página web. Si son pocas se puede determinar cuál nos interesa mediante prueba y error. En particular, en esta caso sabemos que los datos tienen 200 observaciones y 9 columnas; si lo que leemos tiene una dimensiones (obtenidas con glimpse() o str()) muy diferentes no debe ser la tabla que buscamos. En cualquier caso, con muchas tablas en la página web, necesitaremos nuevas herramientas de programación que veremos en breve."
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html#limpieza-de-datos",
    "href": "docs/Tema05ejWebScrap.html#limpieza-de-datos",
    "title": "Tema 5. Ejercicio.",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nSi bien ahora tenemos los datos, podemos ver que son muy confusos:\n\nlos nombres de las variables contienen caracteres especiales, como asteriscos, paréntesis y espacios. Esto puede causar problemas, así que queremos cambiarlos.\nla mayoría de las columnas se almacenan como vectores de caracteres, aunque contienen información cuantitativa. En particular, hay columnas para dólares, porcentajes y fechas que están en el formato equivocado.\n\nDebido a este desajuste, si intentamos dibujar los datos, esto no funcionará como se esperaba.\n\nggplot(\n  data = movies, \n  aes(x = Date, y = Opening)\n) + \n  geom_point(aes(size = `% of Total`))\n\nUsaremos parse_number() junto con el verbo mutate() para renombrar las columnas al mismo tiempo.\n\nmovies &lt;- movies %&gt;%\n  mutate(opening = parse_number(Opening),\n         percent_total = parse_number(`% of Total`)/100)\nglimpse(movies)\n\nAhora, cuando dibujamos los datos cuantitativos, obtenemos algo que tiene más sentido.\n\nggplot(data = movies, aes(x = Date, y = opening)) + \n  geom_point(aes(size = percent_total))"
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html#fechas-con-lubridate",
    "href": "docs/Tema05ejWebScrap.html#fechas-con-lubridate",
    "title": "Tema 5. Ejercicio.",
    "section": "Fechas con lubridate",
    "text": "Fechas con lubridate\nDesafortunadamente, las fechas siguen siendo un problema. Echemos un vistazo a esas fechas:\n\nmovies %&gt;%\n  select(Date) %&gt;%\n  glimpse()\n\nVemos que las fechas están en formato mes/día/año. Ya hemos visto anterioreme el paquete lubridate que proporciona funcionalidad para trabajar con fechas. Podemos utilizar la función mdy() para convertir el vector de caracteres en una clase de fecha.\n\nlibrary(lubridate)\nmovies &lt;- movies %&gt;%\n  mutate(release_date = mdy(Date))\nglimpse(movies)\n\n\nggplot(data = movies, aes(x = release_date, y = opening/1e6)) + \n  geom_point(aes(color = percent_total), size = 4) +\n  scale_y_continuous(name = \"Recaudación en el Día de Apertura (en millones de $)\") +\n  scale_x_date(\"Fecha de estreno\")"
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html#vuestro-ejercicio",
    "href": "docs/Tema05ejWebScrap.html#vuestro-ejercicio",
    "title": "Tema 5. Ejercicio.",
    "section": "Vuestro Ejercicio",
    "text": "Vuestro Ejercicio\n\nRepetir el ejercicio con la siguiente fuente de información: http://www.the-numbers.com/movie/records/Biggest-Opening-Weekend-at-the-Box-Office. Es decir, debéis extraer los datos relevantes de la web, limpiarlos y dejarlos preparados para trabajar,\n\n\nPartiendo de la tabla de datos obtenida en el apartado 1, realizar un BREVE análisis exploratorio de los datos. Crear dos variables adicionales: año y mes de estreno. Notad que el mes debe ser tratada como factor; el año puede ser numérica o categórica.\nDescribid la variación de algunas variables (no necesariamente todas) y algunas pocas relaciones que consideréis relevantes."
  },
  {
    "objectID": "docs/Tema05ejWebScrap.html#entrega-del-ejercicio",
    "href": "docs/Tema05ejWebScrap.html#entrega-del-ejercicio",
    "title": "Tema 5. Ejercicio.",
    "section": "Entrega del ejercicio",
    "text": "Entrega del ejercicio\nRellenad este FORMULARIO con vuestros datos usando vuestra cuenta institucional de Google Cloud (@gcloud.ua.es) y subid\n\nvuestro archivo de .qmd\nel resultado de compilarlo: bien un archivo .html autocontenido o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema05ej_123456789.qmd\nTema05ej_123456789.zip"
  },
  {
    "objectID": "docs/Tema01ej1.html",
    "href": "docs/Tema01ej1.html",
    "title": "Tema 1. Ejercicio 1",
    "section": "",
    "text": "Entrega del ejercicio\nEste ejercicio se realizará en clase y NO cuenta para los alumnos de evaluación NO continua (aunque es recomendable como práctica).\n\n\nPregunta 1\nDescargad este archivo (comprimido) con datos en texto separados por punto y coma con la siguiente información de los empleados de una empresa: el identificador de empleado (ID), sus dos apellidos y su nombre, su género (hombre o mujer) y el valor de las ventas realizadas por dicho empleado en un periodo concreto, dado por año y mes.\n\nlibrary(rio)\nempleados &lt;- import(\"data/empleados.csv.zip\")\n# empleados &lt;- import(\"https://github.com/albarran/BigDataEcon2021/raw/main/data/empleados.csv.zip\")\n# empleados &lt;- read_csv2(\"~/Dropbox/MAD/00.TEC/data/empleados.csv\")\nempleados %&gt;% drop_na() %&gt;% distinct(ID) %&gt;% count()\n\nEn clase haremos estos apartados tanto usando un programa de hoja de cálculo (como Excel, LibreOffice Calc o Google Sheets) como usando R.\n\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores.\n\n\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas relativas al total de ventas de la empresa en ese periodo (proporción vendida por ese empleado en un periodo) fueron mayores.\n\n\nRepetir los apartados anteriores para cada empleado de la empresa. Es decir, , encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores y en el que sus ventas relativas al total de ventas de la empresa en ese periodo (proporción vendida por ese empleado en un periodo) fueron mayores.\n\n\n¿En qué periodo hubo más ventas en total en la empresa y cuántas fueron?\n\n\nEncontrar los nombres y apellidos de los diez empleados con más ventas (mayor número total de ventas) entre julio de 2002 (incluido) y junio de 2006 (incluido).\n\n\n\nPregunta 2\nCargar los datos de vuelos flights de la biblioteca nycflights13.\nCalcular para cada compañía (carrier) el número total de vuelos, el retraso medio en la salida, el número de destinos únicos a los que vuela, y el número de aviones únicos utilizados. Mostrar el histograma del número de destinos únicos."
  },
  {
    "objectID": "docs/Tema03.html#qué-son-datos-ordenados-tidy-data",
    "href": "docs/Tema03.html#qué-son-datos-ordenados-tidy-data",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "¿Qué son datos ordenados (‘tidy data’)?",
    "text": "¿Qué son datos ordenados (‘tidy data’)?\n\nLos conjuntos rectangulares de datos son tablas con datos ordenados:\n\n1.- Cada columna es una variable: mide el mismo atributo entre unidades\n2.- Cada fila es una observación (caso): misma unidad a través de atributos\n3.- Cada celda es un valor\n\n\n\n\nTendremos información similar y no redundante en una misma tabla\nY se completa la información con uniones a tablas adicionales (ej., para variables codificadas)"
  },
  {
    "objectID": "docs/Tema03.html#datos-no-ordenados",
    "href": "docs/Tema03.html#datos-no-ordenados",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Datos no ordenados",
    "text": "Datos no ordenados\n\n\n\n\n\n\n\n\nOtras estructuras pueden tener sentido para mostrar información (o por convenciones)\nUn ejemplo del portal de datos abiertos del Gobierno de España\nLa visualización es atractiva, PERO sobran filas para analizar los datos"
  },
  {
    "objectID": "docs/Tema03.html#cuatro-representaciones-de-los-mismos-datos",
    "href": "docs/Tema03.html#cuatro-representaciones-de-los-mismos-datos",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Cuatro representaciones de los mismos datos",
    "text": "Cuatro representaciones de los mismos datos\n\nlibrary(tidyverse)\ntable1     # datos ordenados\ntable2     # no tiene un valor por celda"
  },
  {
    "objectID": "docs/Tema03.html#cuatro-representaciones-cont.",
    "href": "docs/Tema03.html#cuatro-representaciones-cont.",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Cuatro representaciones (cont.)",
    "text": "Cuatro representaciones (cont.)\n\ntable3     # mezcla más de una variable en una columna\ntable4a \ntable4b\n\n\ntable4a y table4b ofrecen información útil para presentación, pero\n\nvariables tanto en filas como columnas\nlas cabeceras de columna son valores, no nombres de variables."
  },
  {
    "objectID": "docs/Tema03.html#ventajas-de-datos-ordenados",
    "href": "docs/Tema03.html#ventajas-de-datos-ordenados",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Ventajas de datos ordenados",
    "text": "Ventajas de datos ordenados\n\nLa mayoría de las funciones R (y otros lenguajes) trabajan con vectores: los datos ordenados son una forma natural (variable = vector columna)\n\n\ntable1$cases                   # table1 %&gt;% select(cases)\ntable2$count[c(1,3,5,7,9,11)]  # table2 %&gt;% filter(type == \"cases\") %&gt;%\n                               #            select(count)\nc(table4a$`1999`, table4a$`2000`)\n# crear variables es fácil\ntable1 %&gt;% mutate(rate = cases / population * 10000)  \n\n\ntidyverse es eficiente con datos ordenados: ej., gráfico temporal\n\n\nggplot(table1, aes(x = year, y = cases)) +  \n  geom_line(aes(colour = country))"
  },
  {
    "objectID": "docs/Tema03.html#mismos-datos-dos-formatos-ancho-o-largo",
    "href": "docs/Tema03.html#mismos-datos-dos-formatos-ancho-o-largo",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Mismos datos, dos formatos: ancho o largo",
    "text": "Mismos datos, dos formatos: ancho o largo\n\n\n\nLa utilidad de almacenar los datos en un rectángulo ancho (“wide”) o en uno largo (“long”“) depende de qué queramos hacer\nEl cambio de forma entre formatos es una tarea habitual del analista de datos.\nCambiar entre representación larga y ancha se conoce como pivotar (o girar)\n\n\n\n\n\n\n\ntable4a        # formato ancho\ntable1         # formato largo"
  },
  {
    "objectID": "docs/Tema03.html#pivot_longer-de-ancho-a-largo",
    "href": "docs/Tema03.html#pivot_longer-de-ancho-a-largo",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "pivot_longer(): de ancho a largo",
    "text": "pivot_longer(): de ancho a largo\n\nPivotar las variables no ordenadas en dos nuevas columnas (deben crearse)\n\n\n\n\npivot_longer(table4a, \n             cols=2:3, \n             names_to = \"year\", \n             values_to = \"cases\") \n\n\n\n\n\n\n\ndata frame a cambiar de forma\nnombres o índices de las columnas que representan valores, no variables\nlos nombres de esas antiguas variables van como valores a nueva variable\nlos valores de las antiguas celdas van a otra nueva variable\n\n\n\n\nPara recuperar table1, se debería pivotar también table4b y unir ambas"
  },
  {
    "objectID": "docs/Tema03.html#pivot_longer-de-ancho-a-largo-cont.",
    "href": "docs/Tema03.html#pivot_longer-de-ancho-a-largo-cont.",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "pivot_longer(): de ancho a largo (cont.)",
    "text": "pivot_longer(): de ancho a largo (cont.)\n\nRecordatorio: formas equivalentes de hacer lo mismo\n\n\npivot_longer(table4a, 2:3, names_to = \"year\", values_to = \"cases\")       \ntable4a %&gt;% pivot_longer(c(`1999`, `2000`), values_to = \"cases\", names_to = \"year\")\ntable4a %&gt;% pivot_longer(names_to = \"year\", values_to = \"cases\", -country)\ntable4a %&gt;% pivot_longer(names_to = \"year\", values_to = \"cases\", `1999`:`2000`)\n\n\nNotar que los nombres de columna son caracteres y cuando son números van entre ` (evita confusión con índice de posición)\n\n\nDeberíamos cambiar el tipo de las nuevas variables\n\n\npivot_longer(table4a, 2:3, names_to = \"year\", values_to = \"cases\") %&gt;%\n  mutate(year= parse_number(year))"
  },
  {
    "objectID": "docs/Tema03.html#pivot_wider-de-largo-a-ancho",
    "href": "docs/Tema03.html#pivot_wider-de-largo-a-ancho",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "pivot_wider(): de largo a ancho",
    "text": "pivot_wider(): de largo a ancho\n\n\n\ntable2 %&gt;%\n    pivot_wider(names_from = type,  \n                values_from = count)\n\n\n\n\n\n\n\nel data frame a cambiar de forma\nnombre de la variable de cuyos valores vienen los nuevos nombres de columnas\nnombre de la variable de la que tomar los valores para las nuevas columnas\n\n\nAplicado a table2 sirve para limpiar datos con observaciones que se dispersan en varias filas\n\n\n\n\ntable1 %&gt;% select(-population) %&gt;%            # Tabla de presentación para casos\n    pivot_wider(names_from = year, values_from = cases)"
  },
  {
    "objectID": "docs/Tema03.html#dos-funciones-útiles",
    "href": "docs/Tema03.html#dos-funciones-útiles",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Dos funciones útiles",
    "text": "Dos funciones útiles\n\nseparate(): dividir una columna en múltiples variables indicando un separador o vector de posiciones en las que dividir\n\n\ntable3 %&gt;% separate(rate, into = c(\"cases\", \"population\"), sep = \"/\")\ntable5 &lt;- table3 %&gt;% separate(year, into = c(\"century\", \"year\"), sep = 2)\n\n\nCon el argumento convert = TRUE intenta convertir el tipo de datos (no mantener carácter)\n\n\ntable3 %&gt;% separate(rate, into = c(\"cases\", \"population\"), convert = TRUE)\n\n\nunite(): combinar múltiples columnas en una\n\n\ntable5 %&gt;% \n  unite(new, century, year, sep = \"-\")"
  },
  {
    "objectID": "docs/Tema03.html#comentario-sobre-valores-ausentes",
    "href": "docs/Tema03.html#comentario-sobre-valores-ausentes",
    "title": "Tema 03 - Datos ordenados con tidyr",
    "section": "Comentario sobre valores ausentes",
    "text": "Comentario sobre valores ausentes\n\naccion &lt;- tibble( anio  = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),\n                  trim  = c(   1,    2,    3,    4,    2,    3,    4),\n                  rent  = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66))\n\n\nDos tipos de valores ausentes: en 2015.Q4 explícitos y en 2016.Q1 implícitos\nEsto cambia con la forma de representación\n\n\nancho &lt;- accion %&gt;% \n            pivot_wider(names_from = anio, values_from = rent)     \nancho             # NA explícitos al convertir a formato ancho\n\nancho %&gt;%  pivot_longer(cols = c(\"2015\",\"2016\"), \n                        names_to = \"anio\", values_to = \"rent\")\n\naccion %&gt;% complete(anio, trim)  # todos NA explícitos \n                                 # (rellena buscando todas combinacines)"
  },
  {
    "objectID": "docs/Tema08.html#aprendizaje-estadístico-o-automático",
    "href": "docs/Tema08.html#aprendizaje-estadístico-o-automático",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Aprendizaje Estadístico o Automático",
    "text": "Aprendizaje Estadístico o Automático\n\nAprendizaje automático (machine learning, ML) o estadístico (statiscal learning): conjunto de técnicas algorítmicas para extraer información de los datos\n\n\nTipos principales\n\n\nAprendizaje supervisado: escenarios en los que para cada observación de las mediciones \\(X_i\\) hay una respuesta asociada \\(Y_i\\) (“supervisa” el aprendizaje)\n\nAprendemos la respuesta de casos nuevos a partir de casos previos\n\nAprendizaje no supervisado: no hay una respuesta asociada a las mediciones de \\(X_i\\) para supervisar el análisis que generará un modelo.\n\nAprendemos rasgos no medidos a partir de casos “no etiquetados”: ej. observaciones similares organizadas en grupos distintos"
  },
  {
    "objectID": "docs/Tema08.html#aprendizaje-supervisado",
    "href": "docs/Tema08.html#aprendizaje-supervisado",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Aprendizaje supervisado",
    "text": "Aprendizaje supervisado\n\n\\(\\small Y = f(X) + \\varepsilon\\): modelo para la variable dependiente (de respuesta) en función de factores observados (predictores/características) y no observados (\\(\\small \\varepsilon\\))\n \n\n\\(f\\) representa la información/relación sistemática que \\(X\\) (género, educación, etc.) ofrecen sobre un resultado medido \\(Y\\) (ej. renta)\n\nObjetivos: predecir casos nuevos y comprender qué factores afectan al resultado y cómo (¡cuidado con afirmaciones de causalidad!)\n\n\nModelo paramétrico: supone un forma de \\(f\\) que depende de parámetros desconocidos, p.e., lineal \\(f(x) =\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\)\nModelo no paramétrico: ajustar \\(f\\) a los datos sin supuestos funcionales\n\nmás flexibilidad y mejor ajuste, pero más difícil de estimar e interpretar"
  },
  {
    "objectID": "docs/Tema08.html#problemas-de-regresión-y-de-clasificación",
    "href": "docs/Tema08.html#problemas-de-regresión-y-de-clasificación",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Problemas de “regresión” y de clasificación",
    "text": "Problemas de “regresión” y de clasificación\n1.- Regresión: variable de respuesta cuantitativa (toma valores numéricos)\n\nlibrary(mosaicData)\nmod &lt;- lm(volume ~ poly(hightemp,3), data = RailTrail)\ncbind(RailTrail$volume, mod$fitted, RailTrail$hightemp) %&gt;% head()\n\n2.- Clasificación: variable de respuesta cualitativa (toma valores en una de \\(C\\) categorías o clases)\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;%\n  mutate(income = as.integer(factor(income))-1)\nlogit &lt;- glm(income ~ capital_gain, data = censo, family = \"binomial\")\ncbind(censo$income, predict(logit, type = \"response\")) %&gt;% head()\n\n\nLa predicción mejora si incluimos más variables explicativas (modelo más flexible)"
  },
  {
    "objectID": "docs/Tema08.html#error-de-predicción",
    "href": "docs/Tema08.html#error-de-predicción",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Error de predicción",
    "text": "Error de predicción\n\nUn modelo es mejor si sus predicciones se ajusten mejor a las observaciones\nEl error de predicción es \\(y - \\widehat{y} = f(X) - \\widehat{f}(X) + \\varepsilon\\)\n\n\\(f - \\widehat{f}\\) = error reducible (eligiendo modelo)\n\\(\\varepsilon\\) = error irreducible (variables no observadas)\n\nLa función de pérdida (o coste) evalúa cómo valoramos las desviaciones"
  },
  {
    "objectID": "docs/Tema08.html#métricas-de-error-de-predicción-cuantitativa",
    "href": "docs/Tema08.html#métricas-de-error-de-predicción-cuantitativa",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Métricas de error de predicción (cuantitativa)",
    "text": "Métricas de error de predicción (cuantitativa)\n\nMean Square Error (Error Cuadrático Medio): \\(\\small MSE(y,\\widehat{y})={\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\n\npenaliza grandes desviaciones\n\\(\\small R^2\\) y \\(\\small R^2\\)-ajustado son variantes del MSE, y solo sirven para comparar modelos con la misma variable dependiente.\n\nRoot Mean Square Error: \\(\\small RMSE(y,\\widehat{y})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\n\nmismas unidades que \\(\\small y\\)\n\nMean Absolute Error: \\(\\small MAE(y,\\widehat{y})=\\frac{1}{n}\\sum_{i=1}^{n}\\left|y-\\widehat{y}\\right|\\)\n\n\n\nOtras medidas basadas en distintas funciones de pérdida, la verosimilitud del modelo (\\(\\small AIC\\), \\(\\small BIC\\)), etc"
  },
  {
    "objectID": "docs/Tema08.html#muestras-de-entrenamiento-y-de-prueba",
    "href": "docs/Tema08.html#muestras-de-entrenamiento-y-de-prueba",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Muestras de entrenamiento y de prueba",
    "text": "Muestras de entrenamiento y de prueba\n\nLas métricas de error (ej., \\(\\small MSE\\)) suelen calcularse para predicciones de los mismos datos usados para ajustar/estimar el modelo (in-sample prediction)\n\nEsta muestra se denomina muestra de entrenamiento (training sample)\n\nPERO queremos saber qué tal se predicen casos nuevos (out-sample prediction)\nUsar las métricas en muestras de entrenamiento implica problemas de “overfitting”: sobreajuste a las características de la muestra concreta\n\nUn modelo menos flexible podría tener menor error de predicción con casos nuevos\n\n\n\nDebemos calcular las métricas de error con observaciones que el modelo NO ha usado antes: muestra de prueba (test sample)"
  },
  {
    "objectID": "docs/Tema08.html#overfitting",
    "href": "docs/Tema08.html#overfitting",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "“Overfitting”",
    "text": "“Overfitting”\n\n\n\n\nRailTrail %&gt;% ggplot(aes(x = hightemp, y = volume)) + \n  geom_point() + geom_smooth(method = 'lm', formula = y ~ poly(x,22) ) +\n  coord_cartesian(ylim = c(100,750))"
  },
  {
    "objectID": "docs/Tema08.html#overfitting-cont.",
    "href": "docs/Tema08.html#overfitting-cont.",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "“Overfitting” (cont.)",
    "text": "“Overfitting” (cont.)\n\n\n\n\n\n  \n\n\n\n\n\n\nSiempre que aumenta la flexibilidad, el MSE\n\ndisminuye en la muestra de entrenamiento\ntiene forma de U en la muestra de prueba\n\nNota: el MSE en entrenamiento es siempre menor que en prueba"
  },
  {
    "objectID": "docs/Tema08.html#mse-en-la-muestra-de-prueba",
    "href": "docs/Tema08.html#mse-en-la-muestra-de-prueba",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "MSE en la muestra de prueba",
    "text": "MSE en la muestra de prueba\n\\[\n\\small\nE\\left[\\left(y-\\widehat{f}(x)\\right)^2\\right] =\nE\\left[\\left(f(x)-\\widehat{f}(x) + \\varepsilon\n+ E\\left[\\widehat{f}(x)\\right]-E\\left[\\widehat{f}(x)\\right] \\right)^2\\right] =\n\\]\n\\[\n\\small\n=\\underbrace{\\left[E\\left(\\widehat{f}(x)\\right)-f(x)\\right]^2}_{(1)} + \\underbrace{E\\left(\\left[\\widehat{f}(x)-E\\left(\\widehat{f}(x)\\right)\\right]^2\\right)}_{(2)}+Var(\\varepsilon)\n\\]\n\n\\(\\small (1)=\\left[Sesgo\\left(\\widehat{f}(x)\\right)\\right]^2\\): error por supuestos erróneos en \\(f\\)\n\najuste insuficiente (underfit) al perder relaciones relevantes entre \\(X\\) e \\(Y\\)\n\n\\(\\small (2)=Var\\left(\\widehat{f}(x)\\right)\\): sensibilidad a fluctuaciones en el entrenamiento\n\nsi el algoritmo modela puro ruido en entrenamiento, ajustará bien allí, pero predecirá mal casos nuevos (overfit)"
  },
  {
    "objectID": "docs/Tema08.html#trade-off-varianzasesgo",
    "href": "docs/Tema08.html#trade-off-varianzasesgo",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "“Trade-off” Varianza–Sesgo",
    "text": "“Trade-off” Varianza–Sesgo\n\nEl sesgo se reduce y la varianza aumenta con la complejidad del modelo \\(\\Rightarrow\\) encontrar un método (ej., flexibilidad) para el que ambos sean bajos\n\n\n\n\n\nNO es posible minimizar simultáneamente ambas fuentes de error: memorización (en entrenamiento) vs. generalización de resultados"
  },
  {
    "objectID": "docs/Tema08.html#medir-el-error-en-la-clasificación",
    "href": "docs/Tema08.html#medir-el-error-en-la-clasificación",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Medir el Error en la Clasificación",
    "text": "Medir el Error en la Clasificación\n\nLos modelos de clasificación NO predicen directamente la categoría, sino la probabilidad de que una observación pertenezca a cada categoría\nTípicamente se asigna la clase predicha como aquella con mayor probabilidad.\nEn el caso binario, equivale a fijar un umbral de 0.5, pero se deberían probar varios valores del umbral\n\n\nlogit &lt;- glm(income ~ capital_gain, data = censo, family = \"binomial\")\nprob.predict &lt;- predict(logit, type = \"response\")\n\numbral &lt;- 0.5\ncat.predict  &lt;- if_else(prob.predict &gt; umbral, 1, 0) \ncbind(censo$income, cat.predict, prob.predict) %&gt;% head(10)\n\n\nComo no tiene sentido diferencia de clases (variables categóricas), NO se pueden calcular medidas como el MSE y otros relacionados"
  },
  {
    "objectID": "docs/Tema08.html#matriz-de-confusión",
    "href": "docs/Tema08.html#matriz-de-confusión",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Matriz de Confusión",
    "text": "Matriz de Confusión\n\nTabular categorías observadas frente a las categorías predichas\n\n\n\n\n\n\n\n\n\n\n\n\nCLASE OBSERVADA\n\n\n\n.\nPOSITIVO (1)\nNEGATIVO (0)\n\n\n\n\nCLASE PREDICHA\n\n\nPOSITIVO (1)\nVerdadero Positivo [VP]\nFalso Positivo [FP]\n\n\n\n\n(Error Tipo I)\n\n\nNEGATIVO (0)\nFalso Negativo [FN]\nVerdadero Negativo [VN]\n\n\n\n(Error Tipo II)\n\n\n\n\n\n\n\n\ntable(cat.predict, censo$income)\n\n\nExisten varias medidas derivadas de la matriz de confusión"
  },
  {
    "objectID": "docs/Tema08.html#métricas-con-la-matriz-de-confusión",
    "href": "docs/Tema08.html#métricas-con-la-matriz-de-confusión",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Métricas con la matriz de confusión",
    "text": "Métricas con la matriz de confusión\n\nTasa de observaciones correctamente clasificadas (exactitud o accuracy)\n\n\\[\n\\scriptsize ACCUR=\\frac{VP+VN}{VP+FP+VN+FN}\n\\]\n\nNo es informativo cuando algunas clases son infrecuentes (datos desequilibrados)\n\nsi hay poco fraude/enfermos (ej., 5%), predecir que nunca hay fraude implica \\(\\scriptsize ACCUR=95\\%\\), PERO NO detecta fraude/enfermedad\n\n\n\nEl estadístico Kappa (\\(\\small \\kappa\\)) es una medida similar, pero que ajusta por lo se esperaría solo por azar (corrigiendo en parte el desequilibrio entre clases)."
  },
  {
    "objectID": "docs/Tema08.html#métricas-con-la-matriz-de-confusión-cont.",
    "href": "docs/Tema08.html#métricas-con-la-matriz-de-confusión-cont.",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Métricas con la matriz de confusión (cont.)",
    "text": "Métricas con la matriz de confusión (cont.)\n\nLa tasa de verdaderos positivos o sensibilidad (recall) es el porcentaje de verdaderos positivos sobre el total de positivos observados \\[\n\\scriptsize TVP=SENSIT=\\frac{VP}{VP+FN}\n\\]\n\nej., tasa de fraude/enfermos existentes que se detectan correctamente\n\n\n\nLa tasa de verdaderos negativos o especificidad es el porcentaje de verdaderos negativos sobre el total de negativos observados \\[\n\\scriptsize TVN=ESPECIF=\\frac{VN}{VN+FP}\n\\]\n\nej., tasa de “otras” opciones que se clasifican correctamente\nTasa de falsos positivos: \\(\\scriptsize TFP = 1 - TVN = 1 - ESPECIF\\)"
  },
  {
    "objectID": "docs/Tema08.html#métricas-con-la-matriz-de-confusión-y-3",
    "href": "docs/Tema08.html#métricas-con-la-matriz-de-confusión-y-3",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Métricas con la matriz de confusión (y 3)",
    "text": "Métricas con la matriz de confusión (y 3)\n\nLa exactitud equilibrada (Balanced Accuracy) es una media de la sensibilidad y de la especificidad\n\n\nLa precisión o valor de predicción positivo es la cantidad de verdaderos positivos sobre el total de positivos predichos\n\n\\[\n\\scriptsize PREC=\\frac{VP}{VP+FP}\n\\]\n\nLa familia de medidas \\(\\small F_{\\beta}\\) es una ratio de la importancia ponderada de la sensibilidad y de la precisión: \\(\\scriptsize F_{\\beta}=\\frac{(1+\\beta)^2 \\times SENSIT \\times PREC}{\\beta^2 \\times SENSIT + PREC}\\)\n\nPara \\(\\scriptsize \\beta&lt;1\\), se da menos importancia a la sensibilidad: los falsos positivos se consideran más costosos\nPara \\(\\scriptsize \\beta&gt;1\\), los falsos negativos son más costosos y para \\(\\scriptsize \\beta=1\\) son igualmente costosos"
  },
  {
    "objectID": "docs/Tema08.html#curva-roc-receiver-operating-characteristic",
    "href": "docs/Tema08.html#curva-roc-receiver-operating-characteristic",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Curva ROC (“Receiver Operating Characteristic”)",
    "text": "Curva ROC (“Receiver Operating Characteristic”)\n\nRepresenta TVP (eje y) frente a TFP (eje x) en diferentes umbrales : reducir el umbral clasifica más elementos como positivos (verdaderos y falsos)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa curva ROC informa del grado de separabilidad: dado un nivel de TFP, el clasificador es mejor cuanto mayor sea TVP"
  },
  {
    "objectID": "docs/Tema08.html#auc-area-under-the-curve",
    "href": "docs/Tema08.html#auc-area-under-the-curve",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "AUC (“area under the curve”)",
    "text": "AUC (“area under the curve”)\n\nLa AUC es el área bajo la curva ROC: ofrece una medida agregada de rendimiento entre 0 (todas las clasificaciones incorrectas) y 1 (todas correctas)\n\n\nResume la curva ROC y permite comparar curvas que se cruzan"
  },
  {
    "objectID": "docs/Tema08.html#extensiones.-métricas-adicionales",
    "href": "docs/Tema08.html#extensiones.-métricas-adicionales",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Extensiones. Métricas adicionales",
    "text": "Extensiones. Métricas adicionales\n\nCon más de dos clases, se realiza un análisis AUC-ROC para cada categoría (frente a las demás) y se promedian (ej., ponderando por casos en cada clase) \n\n\nCon clases desequilibradas, se puede preferir en lugar de la ROC un gráfico de precisión frente sensibilidad (precision-recall) y su correspondiente AUC (PR-AUC)\n\n\nExisten múltiples funciones de pérdida (o coste de clasificación) posibles.\n\nLas relacionadas con la curva de ganancia consideran el coste de alcanzar un cierto nivel de sensibilidad\nOtras se basan en la función de verosimilud o la entropía como medidas de pérdida (ej. mean log loss)"
  },
  {
    "objectID": "docs/Tema08.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "href": "docs/Tema08.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Evaluación de Modelos: entrenamiento y prueba",
    "text": "Evaluación de Modelos: entrenamiento y prueba\n\nPara minimizar problemas de underfit y, sobre todo, de overfit, DEBEMOS dividir aleatoriamente el conjunto de datos en dos partes:\n\n\n\n\n\n\n\n\n\nEntrenamiento (80-90%): datos sobre los que se construye/estima el modelo\nPrueba(20-10%): se usa el modelo construido para predecir y se evalúa con datos no vistos antes\n\n\n\n\n¿Por qué renunciar a parte de los datos si sabemos que un tamaño muestral grande es importante? Evaluar correctamente un modelo lo es mucho más\nLa estimación del error en prueba puede ser volátil dependiendo de las observaciones incluidas en cada grupo"
  },
  {
    "objectID": "docs/Tema08.html#evaluación-de-modelos-validación-cruzada",
    "href": "docs/Tema08.html#evaluación-de-modelos-validación-cruzada",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Evaluación de Modelos: Validación cruzada",
    "text": "Evaluación de Modelos: Validación cruzada\n\nPara evitar que los datos sean sensibles a una partición concreta, se usa validación cruzada (cross-validation o rotation estimation)\nSe repite varias veces y de forma ordenada el proceso de remuestreo para la partición en grupos de entrenamiento y prueba (similar a bootstrap)\nPermite utilizar todas las observaciones de la muestra, tanto para estimar como para evaluar el modelo (aunque no a la vez)"
  },
  {
    "objectID": "docs/Tema08.html#validación-cruzada-de-k-bloques",
    "href": "docs/Tema08.html#validación-cruzada-de-k-bloques",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Validación cruzada de K bloques",
    "text": "Validación cruzada de K bloques\n\nSe divide, aleatoriamente y ex-ante, la muestra en K subconjuntos (normalmente, 5 o 10)\n\n\n\n\n\n\n\n\nUn subconjunto se usa como prueba y el K-1 restantes como entrenamiento\nSe repite el proceso durante k iteraciones, con cada posible subconjunto de datos de prueba.\n\n\n\n\nSe obtiene una métrica de error en cada iteración; se promedian para obtener un único resultado de evaluación\nEs el tipo más habitual de validación cruzada"
  },
  {
    "objectID": "docs/Tema08.html#validación-cruzada-aleatoria-rcv-y-loocv",
    "href": "docs/Tema08.html#validación-cruzada-aleatoria-rcv-y-loocv",
    "title": "Tema 08 - Aprendizaje Estadístico",
    "section": "Validación cruzada aleatoria (RCV) y LOOCV",
    "text": "Validación cruzada aleatoria (RCV) y LOOCV\n\n\n\n\n\n\n\nRCV: en cada iteración se realiza la particion aleatoria (con reemplazamiento) entre entrenamiento y prueba\nLas observaciones pueden “repetir” como prueba\n\n\n\n\n\n\n\n\n\n\nLOOCV (leave one out CV): solo una observación se usa como prueba en cada iteración y el resto como entrenamiento\nSe realizan \\(n\\) iteraciones; se calcula una media sobre \\(n\\) resultados"
  },
  {
    "objectID": "docs/Tema11.html#k-nn-k-nearest-neighbors",
    "href": "docs/Tema11.html#k-nn-k-nearest-neighbors",
    "title": "Tema 11 - kNN",
    "section": "k-NN (‘k-nearest neighbors’)",
    "text": "k-NN (‘k-nearest neighbors’)\n\nMétodos paramétricos = supuesto funcional para la esperanza condicional\n\nvariable numérica \\(\\small E[y|\\mathbf{X}=x_0]=f(x_0)=\\beta_0+\\beta_1 x_0\\)\nvariable categórica: \\(\\small \\Pr(y=j|\\mathbf{X}=x_0) =f_j(x_0)=\\Lambda(\\beta_{0j}+\\beta_{1j} x_0)\\)\n\n\n\nk-NN estima la esperanza condicional de forma no parámetrica \nIdea: el valor esperado de \\(\\small y\\) para una observación debe ser “similar” al de otras observaciones “cercanas” (por su valor en \\(\\small \\mathbf{X}\\))\n\nmismo valor de \\(\\small x_0\\), mismo valor esperado de \\(\\small y\\)\n\\(\\small f(\\mathbf{X})\\) no se supone conocida y fija"
  },
  {
    "objectID": "docs/Tema11.html#algoritmo-k-nn",
    "href": "docs/Tema11.html#algoritmo-k-nn",
    "title": "Tema 11 - kNN",
    "section": "Algoritmo k-NN",
    "text": "Algoritmo k-NN\n\n\n\nDada una muestra de entrenamiento y una nueva observación \\(\\small \\mathbf{x^*}\\)\n\n\nIdentificar \\(\\small k&gt;0\\) observaciones cercanas según una norma, ej., \\(\\small ||x^*-x_i||_2\\)\nSe asigna a \\(\\small y^*\\) la media o la clase mayoritaria de las observaciones cercanas\n\n\n\n\n\n\n\n\n\nEl valor “óptimo” de \\(k\\) se elige mediante validación cruzada.\n\n\\(\\small k\\) bajo (= algoritmo demasiado flexible): alta varianza y sesgo bajo\nAl aumentar \\(\\small k\\) (menos flexible), menor varianza, pero mayor sesgo"
  },
  {
    "objectID": "docs/Tema11.html#algoritmo-k-nn-comentarios",
    "href": "docs/Tema11.html#algoritmo-k-nn-comentarios",
    "title": "Tema 11 - kNN",
    "section": "Algoritmo k-NN: comentarios",
    "text": "Algoritmo k-NN: comentarios\n\nSu utilidad depende de la geometría de los datos\n\nconviene centrar y reescalar los datos\nprobar varias medidas de distancia: valor absoluto \\(\\small |x^*-x_i|\\) , norma \n\n\n\nLa distancia solo se puede calcular para variables continuas: convertir factores en dummies (una para cada categoría) \nNO es necesario incluir transformaciones no lineales de los regresores (ej., polinomios, interacción, etc.) en la receta\n\n\nLASSO (modelo lineal) puede no ser informativo sobre la elección de variables para este algoritmo\n\n\nImplementación en R con bibliotecas class y kknn"
  },
  {
    "objectID": "docs/0Intro.html#objetivos",
    "href": "docs/0Intro.html#objetivos",
    "title": "Introducción",
    "section": "Objetivos",
    "text": "Objetivos\n\nAprender a extraer información de los datos\n\n\n\n\n\nUsando técnicas computacionales y estadísticas"
  },
  {
    "objectID": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "href": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "title": "Introducción",
    "section": "“Datificación” de la vida diaria",
    "text": "“Datificación” de la vida diaria"
  },
  {
    "objectID": "docs/0Intro.html#the-4-vs-of-big-data",
    "href": "docs/0Intro.html#the-4-vs-of-big-data",
    "title": "Introducción",
    "section": "The 4 Vs of big data:",
    "text": "The 4 Vs of big data:\n\nVolume - Scale of data.\n\nVelocity - Analysis of streaming data.\n\nVariety - Different forms of data.\n\nVeracity - Uncertainty of data."
  },
  {
    "objectID": "docs/0Intro.html#importancia-de-los-datos",
    "href": "docs/0Intro.html#importancia-de-los-datos",
    "title": "Introducción",
    "section": "Importancia de los datos",
    "text": "Importancia de los datos\n\nNeelie Kroes (Comisaria Europea para la Agenda Digital):\n\n\n\n“Data is the oil of the new economy, […], the new oil for the digital era”\n\n\n\nMúltiples ejemplos de la importancia del análisis de datos en economía, aquí y aquí, y en la empresa\nSi caben en tu ordenador, NO es “Big Data”"
  },
  {
    "objectID": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "href": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "title": "Introducción",
    "section": "Aprendiendo a analizar datos",
    "text": "Aprendiendo a analizar datos\n\nAprender técnicas de análisis de datos es una inversión de futuro en el trabajo aquí o en El País, 08 de agosto de 2023\nPero esto NO es magia"
  },
  {
    "objectID": "docs/0Intro.html#aprendiendo-a-analizar-datos-y-2",
    "href": "docs/0Intro.html#aprendiendo-a-analizar-datos-y-2",
    "title": "Introducción",
    "section": "Aprendiendo a analizar datos (y 2)",
    "text": "Aprendiendo a analizar datos (y 2)\n\nY requiere saber lo que sé hace \nDan Ariely sobre Big Data: aquí"
  },
  {
    "objectID": "docs/0Intro.html#proceso-de-análisis-de-datos",
    "href": "docs/0Intro.html#proceso-de-análisis-de-datos",
    "title": "Introducción",
    "section": "Proceso de Análisis de Datos",
    "text": "Proceso de Análisis de Datos"
  },
  {
    "objectID": "docs/Tema07.html#métodos-estadísticos",
    "href": "docs/Tema07.html#métodos-estadísticos",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Métodos Estadísticos",
    "text": "Métodos Estadísticos\n\n\n\nLos métodos estadísticos (modelización) permiten\n\nEncontrar patrones \nInterpretar datos \n\n\n\n\n\n\n\n\n\n\nLos datos (casos observados) son una muestra de una población mayor (casos potenciales)"
  },
  {
    "objectID": "docs/Tema07.html#muestreo-de-la-población.-variabilidad-muestral",
    "href": "docs/Tema07.html#muestreo-de-la-población.-variabilidad-muestral",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Muestreo de la población. Variabilidad muestral",
    "text": "Muestreo de la población. Variabilidad muestral\n\nSabiendo el número de ventas en un día o visitas por hora a nuestra web podemos planificar la gestión de una tienda, carga de la web, etc.\nLas ventas salen de una población teórica \\(\\chi^2_{(10)}\\), con media poblacional 10:\n\n\ndata &lt;- tibble(x = rchisq(n=1e6, df=10))\nggplot(data, aes(x)) + geom_vline(xintercept = 10, color = \"red\") +\n  geom_density() \n\n\n¿Cómo de fiable es un estadístico (ej., la media) calculado en una muestra? Simulemos la distribución de la media en muchas muestras de \\(n=25\\)\n\n\n\n\nset.seed(101)\nnsim &lt;- 100\nN &lt;- 25\nybar &lt;- numeric(nsim)\n\n\n\n\n\n\n\nfor (j in 1:nsim) { \n  muestra &lt;- round(rchisq(n=N, df=10)) \n  ybar[j] &lt;- mean(muestra) \n}\nsummary(ybar)"
  },
  {
    "objectID": "docs/Tema07.html#distribuciones-muestrales",
    "href": "docs/Tema07.html#distribuciones-muestrales",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Distribuciones muestrales",
    "text": "Distribuciones muestrales\n\nDistribución muestral es la distribución del estadístico en todas las muestras potenciales de tamaño muestral \\(n\\)\n\nnos interesan su forma, error estándar (variabilidad), etc.\n\n\n\nas_tibble(ybar) %&gt;% ggplot(aes(x=value)) + geom_density()   # aquí solo 100 muestras\n\n\n¿Es posible cuantificar la incertidumbre con UNA MUESTRA?\n\n\nSuponiendo que los datos son normales, la media tiene una distribución normal\nTeorema Central del Límite: para datos de cualquier distribución, \\(\\bar{Y} \\overset{a}{\\sim} N(\\mu, \\sigma^2/n)\\) cuando \\(n \\to \\infty\\)\n\nHemos visto ejemplos aquí"
  },
  {
    "objectID": "docs/Tema07.html#procedimiento-bootstrap",
    "href": "docs/Tema07.html#procedimiento-bootstrap",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Procedimiento Bootstrap",
    "text": "Procedimiento Bootstrap\n\nIdea: pensar en la ÚNICA muestra como si fuera la población\n\n\nTomar muchas remuestras (muestras de Bootstrap) con reemplazamiento\n\np.e., para (1,2,3) incluye los casos (1,1,2), (1,1,3), (2,2,1), etc. \n\nEn cada remuestra, se puede calcular cualquier estadístico\n\n\nEste procedimiento permite generar variación (de remuestras) a partir de una única muestra\nLa distribución muestral bootstrap NO es la distribución muestral, pero aproxima sus aspectos principales sin supuestos (normalidad, TCL)\n\n\nPuede aplicarse a cualquier estadístico (media, varianzas, regresión, etc.)"
  },
  {
    "objectID": "docs/Tema07.html#procedimiento-bootstrap-cont.",
    "href": "docs/Tema07.html#procedimiento-bootstrap-cont.",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Procedimiento Bootstrap (cont.)",
    "text": "Procedimiento Bootstrap (cont.)\n\nset.seed(101)\nmuestra &lt;- rchisq(n=25, df=10)\nnboot &lt;- 1000\nboot_muestras &lt;- list()\n\nfor (i in 1:nboot) {\n  data1 &lt;- muestra %&gt;% \n              as_tibble() %&gt;% \n              slice_sample(n=25, replace = TRUE) \n  m &lt;- mean(data1$value)\n  s &lt;- sd(data1$value)\n  boot_muestras[[i]] &lt;-  list(media = m, sd = s)\n}\nboot_datos &lt;- boot_muestras %&gt;% bind_rows()\n\n\nboot_datos %&gt;% ggplot(aes(x = media)) + \n  geom_density()                        # densidad bootstrap de la media\nsd(boot_datos$media)                    # estimación del E.S. de la media\n# I.C. al 95% de la media y de la DT\nc(sort(boot_datos$media)[25], sort(boot_datos$media)[975]) \nc(sort(boot_datos$sd)[25], sort(boot_datos$sd)[975])"
  },
  {
    "objectID": "docs/Tema07.html#modelización-condicional.-causalidad",
    "href": "docs/Tema07.html#modelización-condicional.-causalidad",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Modelización Condicional. Causalidad",
    "text": "Modelización Condicional. Causalidad\n\nLa población NO suele ser homogenea: más visitas ciertos días, horas, etc.\n\n\nUn modelo de regresión permite incluir todas las variables explicativas de la variación de la variable dependiente\n\n\n“Correlación no implica causalidad”, salvo en ensayos científicos aleatorios cuidadosamente controlados\n\nen otros campos como marketing digital o analítica de web se denominan pruebas A/B (ej. dos versiones de una misma web)\n\nEn general (datos observacionales), nos preocupa que otros factores que puedan ser los verdaderos determinantes de la relación observada"
  },
  {
    "objectID": "docs/Tema07.html#confounding-factor-descuentos-y-ventas",
    "href": "docs/Tema07.html#confounding-factor-descuentos-y-ventas",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "“Confounding factor”: Descuentos y ventas",
    "text": "“Confounding factor”: Descuentos y ventas\n\ndatos &lt;- read_csv(\"data/discount.csv\")\n\n\nEl porcentaje medio de descuentos afecta negativamente a las ventas\n\n\ndatos %&gt;% ggplot(aes(x=discount, y=sales)) + geom_point() + geom_smooth(method = \"lm\")\nlm(data = datos, sales ~ discount) %&gt;% summary()\n\n\nPero si tenemos en cuenta la renta…\n\n\ndatos %&gt;% mutate(renta_baja = income &lt; 7500) %&gt;%  \n  ggplot(aes(x=discount, y=sales)) + geom_point() + geom_smooth(method = \"lm\") +\n  facet_wrap(~renta_baja)\nlm(data = datos, sales ~ discount + income) %&gt;% summary()"
  },
  {
    "objectID": "docs/Tema07.html#regresión-lineal",
    "href": "docs/Tema07.html#regresión-lineal",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Lineal",
    "text": "Regresión Lineal\n\nLa regresión lineal predice una respuesta cuantitativa \\(\\small Y\\) como a partir de \\(k\\) regresores \\(X=\\) \\(\\small X_1,X_2,\\dots,X_k\\)\nSupuesto: relación lineal entre \\(\\small X\\) e \\(\\small Y\\) \\[\n\\small\nY=\\beta_0+\\beta_1 X_1+ \\dots + \\beta_k X_k + \\varepsilon\n\\]\nLos coeficientes o parámetros del modelo representan\n\n\\(\\small \\beta_0\\) (constante): valor esperado de \\(\\small Y\\) cuando \\(\\small X_1=X_2=\\dots=X_k=0\\)\n\\(\\small \\beta_j\\) (pendiente de la línea): cambio medio en \\(\\small Y\\) por un incremento de una unidad en \\(\\small X_j\\) (para \\(j=1,...,k\\)), ceteris paribus\n\nObjetivo: estimar los coeficientes desconocidos a partir de una muestra"
  },
  {
    "objectID": "docs/Tema07.html#regresión-lineal-estimación",
    "href": "docs/Tema07.html#regresión-lineal-estimación",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Lineal: Estimación",
    "text": "Regresión Lineal: Estimación\n\nEl error de estimación o residuo es \\(\\small \\hat{e}_i = y_i - \\hat{y}_i\\), donde la predicción a partir del modelo estimado es \\(\\small \\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1 X_1+ \\dots + \\hat{\\beta}_k X_p\\)\nLos coeficientes estimados son los que minimizan la Suma Cuadrática de Residuos: la suma total de distancias entre los datos observados y predichos\n\n\n\n\n\n\n\n\n\\[\n\\small SCR=\\sum_{i=1}^{n} \\hat{e}_i^2= \\sum_{i=1}^{n} ( y_i - \\hat{y}_i)^2\n\\]\n\nPor tanto, también minimiza \\(\\small ECM = \\frac{SCR}{n} = MSE\\)\n\n\n\n\nEsto equivale a las condiciones derivadas de suponer \\(\\small E(\\varepsilon|X)=0\\)"
  },
  {
    "objectID": "docs/Tema07.html#regresión-lineal-precisión-de-las-estimaciones",
    "href": "docs/Tema07.html#regresión-lineal-precisión-de-las-estimaciones",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Lineal: Precisión de las estimaciones",
    "text": "Regresión Lineal: Precisión de las estimaciones\n\nEl error estándar \\(\\small se(\\widehat{\\beta}_j)\\) mmide la precisión del coeficiente estimado\n\n\nSe usan para construir intervalos de confianza y estadísticos para contrastar hipótesis sobre los parámetros, p.e., significatividad\n\nindividual: \\(\\small H_0: \\beta_1=0\\) con un estadístico \\(\\small t=\\frac{\\widehat{\\beta}_1-0}{se(\\widehat{\\beta}_1)}\\)\nconjunta: \\(\\small H_0: \\beta_1=\\beta_2=\\dots=\\beta_k=0\\) con un estadístico \\(\\small F\\)\n\nMedidas de la precisión del modelo: \\(\\small MSE\\) o \\(\\small R^2=1-\\frac{SCR}{SCT} = \\frac{SCE}{SCT}\\)\nLa predicción \\(\\widehat{y}\\) también está sujeta a incertidumbre por la estimación: se puede calcular su error estándar e intervalos de confianzas\n\n\nres &lt;- lm(data = datos, sales ~ discount + income)\ncbind(datos$sales, res$fitted.values) %&gt;% head()"
  },
  {
    "objectID": "docs/Tema07.html#regresión-lineal-superando-la-linealidad",
    "href": "docs/Tema07.html#regresión-lineal-superando-la-linealidad",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Lineal: superando la linealidad",
    "text": "Regresión Lineal: superando la linealidad\n\nSe pueden incluir transformaciones no lineales de las variables del modelo\n\n\nLa interpretación del cambio de un regresor sobre \\(\\small Y\\) es diferente\n\n\nlibrary(ISLR)\ndata(Carseats)\nlm(data=Carseats %&gt;% filter(Sales != 0), log(Sales) ~ poly(Advertising,2))\n\n\nOtra forma de permitir no linealidades es discretizando variables continuas: permite efectos “escalón” diferentes para distintos valores\n\n\nlm(data=Carseats , Sales ~ cut_width(Advertising, 10)) %&gt;% summary()\n\n\nSe incluyen indicadores binarios para cada clase excepto uno\n\nla constante recoge el valor medio de \\(\\small Y\\) para ese grupo de referencia\ncada coeficiente recoge el efecto adicional de su grupo sobre \\(\\small Y\\)"
  },
  {
    "objectID": "docs/Tema07.html#regresión-lineal-superando-la-linealidad-cont.",
    "href": "docs/Tema07.html#regresión-lineal-superando-la-linealidad-cont.",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Lineal: superando la linealidad (cont.)",
    "text": "Regresión Lineal: superando la linealidad (cont.)\n\nTambién podemos incluir interacciones entre variables: el efecto de un regresor dependerá de otro regresor\n\n\nlm(data=Carseats , Sales ~ Advertising*Income)\n\n\nPrincipio jerárquico: al incluir una interacción siempre deben incluirse los factores principales (NO sólo Advertising:Income)\nCuando interactuamos un regresor continuo y uno binario, permitimos que la pendiente del primero sea diferente para cada grupo\n\n\nlm(data=Carseats , Sales ~ (Income + Advertising)*Urban)\n\n\nLa interacción de dos variables binarias tiene una interpretación similar \n\n\nlm(data=Carseats , Sales ~ ShelveLoc*Urban)"
  },
  {
    "objectID": "docs/Tema07.html#problemas-del-modelo-de-regresión-lineal",
    "href": "docs/Tema07.html#problemas-del-modelo-de-regresión-lineal",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "“Problemas” del Modelo de Regresión Lineal",
    "text": "“Problemas” del Modelo de Regresión Lineal\n\nNo linealidad: incluir transformaciones no lineales \nCorrelación de los errores: afecta a los errores estándar, no la estimación\n\nusar errores estándar robustos o modelizar la dinámica\n\nHeterocedasticidad: ídem, usar errores estándar robustos \n\nlos gráficos de los residuos frente a un regresor o valores predichos: ¿heterocedasticidad o no linealidad? \n\nOutliers en la variable de respuesta o en los regresores \nColinearidad: indica que no es posible separar el efecto de cada regresor: eliminar alguno o recombinarlos\nNo normalidad: TCL, Bootstrap,…\nEl único supuesto realmente importante es \\(\\small E[\\varepsilon|X]=0\\)"
  },
  {
    "objectID": "docs/Tema07.html#regresión-logística",
    "href": "docs/Tema07.html#regresión-logística",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Logística",
    "text": "Regresión Logística\n\nLa regresión lineal puede usarse respuestas binarias (no más de dos categorías), aunque genera predicciones fuera del rango \\(\\small [0,1]\\)\n\n\nSolución: aplicar al índice lineal una transformación \\(\\small F(z)\\in[0,1]\\)\n\n\n\n\nLa función logística: \\(\\small \\Lambda (z)=\\frac{e^z}{1+e^z}\\)\n\n\n\n\n\n\n\nDe manera que \\(\\small \\Pr(Y=1|X)= p(x)= \\Lambda( \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k)\\)"
  },
  {
    "objectID": "docs/Tema07.html#regresión-logística-cont.",
    "href": "docs/Tema07.html#regresión-logística-cont.",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Logística (cont.)",
    "text": "Regresión Logística (cont.)\n\nLos coeficientes NO se interpretan como cambios en la probabilidad ante cambios unitarios en un regresor (efecto marginal sobre la probabilidad)\nPERO su signo (y significatividad) son los mismos que los del efecto marginal\n\n\nComo NO tiene sentido minimizar la SCR, el objetivo es maximizar la probabilidad (verosimilitud) de observar los unos y ceros en los datos\n\n\nLa regresión logística pertenece a la familia de modelos lineales generalizados (GLM, en inglés)\n\n\nSe pueden incluir como variables explicativas tanto variables cuantitativas como cualitativas, e incurrir en sesgo por omisión de variables\n\n\nglm(data = Default, default ~ student, family = \"binomial\" ) %&gt;% summary()\nglm(data = Default, default ~ student + balance, family = \"binomial\" ) %&gt;% summary()"
  },
  {
    "objectID": "docs/Tema07.html#regresión-logística-predicciones",
    "href": "docs/Tema07.html#regresión-logística-predicciones",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión Logística: Predicciones",
    "text": "Regresión Logística: Predicciones\n\nEl objeto de R de glm() contiene valores predichos, que son probabilidades de \\(\\small Y=1\\)\n\n\nlogit &lt;- glm(data = Default, default ~ balance*student, family = \"binomial\" ) \ncbind(Default$default, logit$fitted)\n\n\nTambién se puede predecir usando una muestra distinta de la usada para estimar o con valores concretos de los regresores\n\n\nlogit &lt;- glm(data = Default, default ~ balance, family = \"binomial\" )\npredict(logit, newdata = tibble(balance=c(0,100)), type=\"response\")"
  },
  {
    "objectID": "docs/Tema07.html#regresión-logística-con-más-de-dos-clases",
    "href": "docs/Tema07.html#regresión-logística-con-más-de-dos-clases",
    "title": "Tema 07 - Fundamentos Estadísticos",
    "section": "Regresión logística con más de dos clases",
    "text": "Regresión logística con más de dos clases\n\nLa regresión logística se puede generalizar a situaciones con múltiples clases (modelos multinomiales) con un índice lineal para cada clase \\[\n\\small\n\\Pr(Y=c|X)=\\frac{e^{\\beta_{0c}+\\beta_{1c}X_1+\\dots+\\beta_{kc}X_k}}{\\sum_{l=1}^{C}e^{\\beta_{0l}+\\beta_{1l}X_1+\\dots+\\beta_{kl}X_k}}\n\\]\nLa librería glmnet() permite la estimación de estos modelos\n\n\nlibrary(glmnet)\nx &lt;- model.matrix(Species ~ Sepal.Length + Sepal.Width, data = iris)\nmod.glmnet &lt;- glmnet(x = x, y = iris$Species, family = \"multinomial\", \n                     lambda = 0, type.multinomial = \"grouped\")\ncoef(mod.glmnet) \npredict(mod.glmnet, newx=x, type = \"response\")  # probabilidad de cada clase\npredict(mod.glmnet, newx=x, type = \"class\")     # clase"
  },
  {
    "objectID": "docs/Tema07ej.html",
    "href": "docs/Tema07ej.html",
    "title": "Tema 7. Ejercicio.",
    "section": "",
    "text": "La Comisión de Planificación del Valle del Pionero (PVPC) recolectó datos en Florencia, Massachusetts por un período de noventa días. Los recolectores de datos configuraron un sensor láser que registra cuando un usuario del camino ciclista (“via verde”) pasa por la estación de recogida de datos.\n\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nEl PVPC quiere entender la relación entre el número de ciclistas diarios (es decir, el número de ciclistas y caminantes que usan el carril bici en un día dado) y una colección de variables explicativas, incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon\n\\]\n\nmodelo1 &lt;- lm(volume ~ hightemp + cloudcover + weekday + precip, \n             data = RailTrail)"
  },
  {
    "objectID": "docs/Tema07ej.html#datos",
    "href": "docs/Tema07ej.html#datos",
    "title": "Tema 7. Ejercicio.",
    "section": "",
    "text": "La Comisión de Planificación del Valle del Pionero (PVPC) recolectó datos en Florencia, Massachusetts por un período de noventa días. Los recolectores de datos configuraron un sensor láser que registra cuando un usuario del camino ciclista (“via verde”) pasa por la estación de recogida de datos.\n\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nEl PVPC quiere entender la relación entre el número de ciclistas diarios (es decir, el número de ciclistas y caminantes que usan el carril bici en un día dado) y una colección de variables explicativas, incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon\n\\]\n\nmodelo1 &lt;- lm(volume ~ hightemp + cloudcover + weekday + precip, \n             data = RailTrail)"
  },
  {
    "objectID": "docs/Tema07ej.html#tablas-de-resultados-en-quarto",
    "href": "docs/Tema07ej.html#tablas-de-resultados-en-quarto",
    "title": "Tema 7. Ejercicio.",
    "section": "Tablas de resultados en Quarto",
    "text": "Tablas de resultados en Quarto\nPara mostrar en Quarto tablas con estadísticos descriptivos, resultados de una estimación de estimación, etc. podemos utilizar dos bibliotecas:\n\nbroom ofrece, entre otras, la función tidy() que convierte los resultados en un data frame\nkableExtra ofrece varias funciones que extienden la función kable() permitiendo más formatos de tablas (ver ayuda, en particular aquí)\n\nEn el documento de Quarto, se debe incluir la opción results='markup' para que la tabla aparezca en el documento de salida.\n\nlibrary(broom)\nlibrary(kableExtra)\nmodelo1 %&gt;% tidy() %&gt;% kbl() %&gt;% kable_classic()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n76.826254\n62.7097351\n1.225109\n0.2239183\n\n\nhightemp\n5.548811\n0.7805141\n7.109174\n0.0000000\n\n\ncloudcover\n-8.502548\n3.3389634\n-2.546463\n0.0126844\n\n\nweekdayTRUE\n-35.045330\n21.7524650\n-1.611097\n0.1108660\n\n\nprecip\n-106.483028\n40.7199040\n-2.615012\n0.0105546\n\n\n\n\n\n\n\nNotad que tras usar tidy() tenemos un conjunto de datos. Por tanto, podemos usar comandos conocidos para manipular la tabla, p.e., no mostrar todas las columnas.\n\nmodelo1 %&gt;% tidy() %&gt;% select(term:std.error) %&gt;% kbl() %&gt;% kable_paper()\n\nTambién podemos mostrar resultados usando el comando modelsummary() de la biblioteca del mismo nombre. Además nos permite mostrar los resultados de varios modelos en la misma tabla. Igual que con kableExtra, la celda de código debe tener la opción results: markup.\nConsideramos el siguiente modelo: \\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\beta_5 \\cdot spring + \\beta_6 \\cdot summer + \\varepsilon\n\\]\n\nlibrary(modelsummary)\nmodelo2 &lt;- lm(volume ~ hightemp + cloudcover + weekday + precip\n              + spring + summer, data = RailTrail)\n\nmodelsummary(list(\"Modelo 1\" = modelo1, \"Modelo 2\" = modelo2), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\", \"F\", \"rmse\") )\n\n\n\n\n\nModelo 1\n Modelo 2\n\n\n\n\n(Intercept)\n76.826\n45.483\n\n\n\n(62.710)\n(79.724)\n\n\nhightemp\n5.549\n5.696\n\n\n\n(0.781)\n(1.164)\n\n\ncloudcover\n-8.503\n-8.353\n\n\n\n(3.339)\n(3.435)\n\n\nweekdayTRUE\n-35.045\n-37.062\n\n\n\n(21.752)\n(22.280)\n\n\nprecip\n-106.483\n-98.904\n\n\n\n(40.720)\n(42.137)\n\n\nspring\n\n31.239\n\n\n\n\n(32.082)\n\n\nsummer\n\n9.424\n\n\n\n\n(47.504)\n\n\nNum.Obs.\n90\n90\n\n\nR2\n0.500\n0.509\n\n\nR2 Adj.\n0.476\n0.473\n\n\nF\n21.208\n14.322\n\n\nRMSE\n89.67\n88.85"
  },
  {
    "objectID": "docs/Tema07ej.html#acceso-a-coeficientes-de-una-estimación",
    "href": "docs/Tema07ej.html#acceso-a-coeficientes-de-una-estimación",
    "title": "Tema 7. Ejercicio.",
    "section": "Acceso a coeficientes de una estimación",
    "text": "Acceso a coeficientes de una estimación\nSe puede acceder a los coeficientes de estimados por lm() con la función coef(), a la matriz de varianza-covarianza de los coeficientes con vcov. Los coeficientes y errores estándar también se pueden obtener a partir de summary() en el elemento coefficients.\nSe puede acceder a la varianza del error con summary(modelo)$sigma**2.\n\ncoef(modelo1) \nvcov(modelo1)   \n\nsum.modelo1 &lt;- summary(modelo1)\n\nsum.modelo1$coefficients[,1:2]\nsum.modelo1$sigma**2 \n\n## Un coeficiente concreto y su Error Estándar\ncoef(modelo1)[1]\nsummary(modelo1)$coefficients[1,1]\n\nsqrt(vcov(modelo1)[1,1])\nsummary(modelo1)$coefficients[1,2]"
  },
  {
    "objectID": "docs/Tema07ej.html#vuestro-ejercicio",
    "href": "docs/Tema07ej.html#vuestro-ejercicio",
    "title": "Tema 7. Ejercicio.",
    "section": "Vuestro Ejercicio",
    "text": "Vuestro Ejercicio\n\nApartado 1\nPara este apartado, trabajaréis con un coeficiente concreto del primer modelo (Modelo 1) estimado anteriormente. El coeficiente dependerá de la última cifra de vuestro DNI o similar:\n\nsi es 1, 4 o 7, con el de hightemp\nsi es 2, 5 o 8, con el de cloudcover\nsi es 3, 6 o 9, con el de weekday\nsi es 0, con el de precip\n\n\nSuponemos que los errores del modelo siguen una distribución normal. Por tanto, \\(\\widehat{\\beta} \\sim N\\left(\\beta, Var(\\widehat{\\beta})\\right)\\) y \\((n-k)*s^2 / Var(\\varepsilon) \\sim \\chi^2_{(n-k)}\\), donde \\(n\\) es el número de observaciones, \\(k\\) es el número de coeficientes (incluida la constante) y \\(s^2\\) es la estimación de la varianza del error. Calcular el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error.\nRecordad que en R, los valores críticos se obtienen con qnorm() y qchisq()\n\n\nUtilizar bootstrap para obtener el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error. Debéis fijar como semilla vuestro DNI para realizar un bucle como el visto en clase.\n\n\nComentar BREVEMENTE las diferencias en los intervalos de confianza de ambos apartados. \n\n\n\nApartado 2\nRealizamos un análsis exploratorio de los datos y encontramos la siguiente forma para la relación no lineal entre el número de visitantes y la temperatura.\n\nRailTrail %&gt;% ggplot(aes(x=hightemp, y=volume)) + geom_point() + geom_smooth()\n\nPresentar en una tabla los resultados de estimar el Modelo 2 anterior y añadir primero la temperatura al cuadrado, después también la temperatura al cubo y finalmente además la temperatura elevada a la cuarta potencia. Comentar qué modelo elegirías, es decir, qué grado del polinomio en temperatura captura mejor la relación no lineal descrita anteriormente. ¿Podríamos tener una relación no lineal distinta de la descrita por un polinomio?\n\n\nApartado 3\nRealizamos un nuevo análisis exploratorio para la relación entre el número de visitas y la nubosidad (como porcentaje de cielo cubierto por nubes, en una escala continua de 0 a 10).\n\nRailTrail %&gt;% ggplot(aes(y=volume, x=cloudcover))+geom_point()+geom_smooth()\n\nNuevamente, vamos a presentar en una tabla el modelo 2 y varios variantes sobre ese modelo. Como el gráfico sugiere que no existe relación hasta una nubosidad de 7.5, no vamos incluir cloudcover sino que la vamos a discretizar. En la primera variante, vamos a incluir solo un dummy para cloudcover&gt;7.5. En la segunda variante, vamos a dividir a su vez el rango entre 0 y 7.5 (grupo de referencia omitido en la variante anterior); además de la dummy anterior, vamos incluir otra dummy para valores de cloudcover mayores que 5 y menores o iguales que 7.5. Finalmente, vamos a volver a dividir el rango omitido en el paso anterior (0-5), y vamos a incluir una tercer dummy para valores de cloudcover mayores que 2.5 y menores o iguales que 7.5.\nEstas dummies se puede crear de varias formas, entre ellas:\n\nUsando el comando ifelse() (o if_else()) para crear las dummies en el conjunto de datos antes de estimar.\nUsando los comandos cut() (o cut_width(), cut_interval(), etc.) para discretizar una variable continua generando un factor con categorías dadas por los puntos de corte: ej., cut(cloudcover, breaks=c(-1, 7.5,10))\nAlternativamente, escribiendo directamente la condición que cumple la dummy al especificar la fórmula: ej. volume ~  hightemp  + (cloudcover&gt;7.5) + weekday\n\nDiscutir si es preferible la especificación con cloudcover como variable continua o alguna de las que usa categorías discretas de esa variable (cuál de ellas) y por qué.\n\n\nApartado 4\nFinalmente, vamos a considerar otra variante del Modelo 2 donde los efectos de la temperatura (hightemp) y de la nubosidad (cloudcover) no son constantes, sino que su efecto es heterogéneo en función de otros factores. En particular, estimaremos el siguiente modelo\n\\[\n\\begin{aligned}\nvolume &= \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot summer + \\beta_3 \\cdot spring + \\beta_4 \\cdot weekday \\\\\n       &+ \\beta_5 \\cdot cloudcover + \\beta_6 \\cdot precip + \\beta_7 \\cdot hightemp \\cdot summer + \\beta_8 \\cdot hightemp \\cdot spring \\\\\n       &+ \\beta_9 \\cdot hightemp \\cdot weekday + \\beta_{10} \\cdot cloudcover \\cdot weekday + \\varepsilon\n\\end{aligned}\n\\]\n\nmodelo5.1 &lt;- lm(volume ~  hightemp*(summer + spring + weekday) + cloudcover*weekday + precip, \n             data = RailTrail)\n\nPresentar en una tabla los resultado de estimar el modelo 2 y este modelo, para explicar cuál de los dos preferiría. Discutir si pensáis que existe evidencia de que la temperatura y la nubosidad afectan de manera diferente a las visitas en función de otros factores.\n\n\nApartado 5\nComentar brevemente si tiene sentido considerar efectos no lineales y heterogéneos en el Modelo 2. Sin realizar ninguna estimación nueva, discutir brevemente si consideraría un modelo que incluye a la vez más de una de las variantes consideradas a la vez (ej., no linealidad y efectos heterogéneos en hightemp). ¿Cuántas combinaciones consideraría? ¿Cómo decidiría sobre las combinaciones a probar y sobre el mejor modelo?\n\n\nEntrega\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema07ej_123456789.qmd\nTema07ej_123456789.zip"
  },
  {
    "objectID": "docs/Tema01.html#limpieza-y-doma-de-datos",
    "href": "docs/Tema01.html#limpieza-y-doma-de-datos",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Limpieza y “doma” de datos ",
    "text": "Limpieza y “doma” de datos \n\n\n\n\nUn análisis de datos adecuado requiere (mucho) tiempo de trabajo “sucio” \ntidyverse incluye una colección de bibliotecas con herramientes eficientes para el proceso de “tratamiento de datos” (“data wrangling”)\n\n\nLa mayoría de operaciones pueden realizarse combinando 5 “verbos” \nTodos tienen como primer argumento un data frame, los siguientes describen qué hacer (con columnas o filas) y devuelven otro data frame"
  },
  {
    "objectID": "docs/Tema01.html#seleccionar-variables-y-filtrar-filas",
    "href": "docs/Tema01.html#seleccionar-variables-y-filtrar-filas",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Seleccionar variables y filtrar filas",
    "text": "Seleccionar variables y filtrar filas\n\n\n1.- select(): selecciona variables por nombres o posiciones de columnas, separados por comas\n\n\n\n\nselect(presidential, name, party)\nselect(presidential, 1:2, 4)\n\n\n\n\\(\\hspace{1cm}\\)\n\n\n2.- filter(): conserva filas en las que la condición lógica es verdadera\n\n\n\n\nfilter(presidential, party == \"Republican\")\n\n\n\n\nSe pueden combinar (anidar) porque ambas toman y devuelve un data frame, pero así son difíciles de leer\n\n\nselect(filter(presidential, start &gt; 1973 & party == \"Democratic\"), name)"
  },
  {
    "objectID": "docs/Tema01.html#el-operador-de-tubería",
    "href": "docs/Tema01.html#el-operador-de-tubería",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "El operador de tubería %>%",
    "text": "El operador de tubería %&gt;%\n\ndatos %&gt;% filter(condition) equivale a filter(datos, condition)\nEl anidamiento es fácil:  - Tomar presidential y pasarlo a filtrar (produce un nuevo data frame);   - Tomar este resultado y pasarlo a seleccionar.\n\n\npresidential %&gt;% \n  filter(start &gt; 1973 & party == \"Democratic\") %&gt;% \n  select(name)\n\n\nAtajo de teclado: Cmd / Ctrl + Mays + M\nSe puede aplicar a cualquier función \n\n\n10 %&gt;% log()               # = log(10)\npresidential %&gt;% head(2)   # = head(presidential, 2)\nlm(data = mtcars, mpg ~ hp) %&gt;%  summary()"
  },
  {
    "objectID": "docs/Tema01.html#crear-nuevas-variables",
    "href": "docs/Tema01.html#crear-nuevas-variables",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Crear nuevas variables",
    "text": "Crear nuevas variables\n\n\n3.-mutate(): añade nuevas columnas, creando variables según una fórmula a partir de otras\n\n\n\n\n\n\ntambién rename(): cambiar el nombre de una columna \n\n\n\n\n\n\nmypresidents &lt;- presidential %&gt;%                 # evitar \"machacar\" una fuente original\n                  mutate(duracion = end - start) \n\npresidential %&gt;% mutate(sigloXXI = start &gt; 2000,\n                        duracion = end - start,\n                        duracio2 = duracion*2   )  # crear varias separadas por comas\n\npresidential %&gt;% rename(nombre = name)"
  },
  {
    "objectID": "docs/Tema01.html#ordenar-filas",
    "href": "docs/Tema01.html#ordenar-filas",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Ordenar filas",
    "text": "Ordenar filas\n\n\n4.- arrange(): re-ordena las filas todas las columnas de un data frame\n\nen orden ascendente (por defecto) o descendente con desc()\n\n\n\n\n\n\n\n\n\nmypresidents %&gt;% arrange(desc(duracion))           \nmypresidents %&gt;% arrange(desc(duracion), party) # primero ordena por duración \n                                                # en casos de empate, por party"
  },
  {
    "objectID": "docs/Tema01.html#resumir-todo-el-conjunto-de-datos",
    "href": "docs/Tema01.html#resumir-todo-el-conjunto-de-datos",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Resumir todo el conjunto de datos",
    "text": "Resumir todo el conjunto de datos\n5.- summarize(): colapsa valores de un data frame en una sola fila resumen\n\n\n\n\nEspecificando cómo se reducirá una columna entera de datos en un solo valor.\n\n\nlibrary(lubridate)\nmypresidents %&gt;%\n  summarize(media_duracion = mean(duracion),\n            N = n(),                         # n() cuenta número total de filas\n            first_year = min(year(start)),   # year() extrae el año de una fecha\n            num_dems = sum(party == \"Democratic\") )\n\n\nsummarize() suele usarse en conjunción con group_by()"
  },
  {
    "objectID": "docs/Tema01.html#group_by",
    "href": "docs/Tema01.html#group_by",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "group_by()",
    "text": "group_by()\n\ngroup_by(): cambia el alcance de cada función para que no actúe sobre todo el data frame sino en grupos individuales \n¿Cuál es la duración media de los demócratas y de los republicanos? Hacerlo por separado no es eficiente: especificamos que las filas deben ser agrupadas \n\n\nmypresidents %&gt;% group_by(party) %&gt;%          # \"marca\" dos grupos en los datos \n  summarize(N = n(),                          # incluye estas variables \n            media_duracion = mean(duracion))  # mas las de group_by()\n\n\nNuevo data frame con distinto nivel de observación (fila): una fila para cada valor de la variable por la que se agrupa (ej., de presidentes a partidos)\n\n\nungroup() elimina la agrupación: volvemos a operar en datos desagrupados\n\n\nmypresidents %&gt;% group_by(party) %&gt;% mutate(media_duracion = mean(duracion)) %&gt;% \n  ungroup() %&gt;% arrange(duracion) %&gt;%  slice(1)"
  },
  {
    "objectID": "docs/Tema01.html#seleccionar-muchas-variables",
    "href": "docs/Tema01.html#seleccionar-muchas-variables",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Seleccionar muchas variables",
    "text": "Seleccionar muchas variables\n\nlibrary(nycflights13)           # incluye flights:  19 variables\nselect(flights, year:arr_time)    # desde variable \"year\" hasta \"arr_time\"\nselect(flights, -(year:day))      # todas menos \"year, month, day\"\n\n\nFunciones a utilizar dentro de select():\n\nstarts_with(\"abc\"): nombres que comienzan con “abc”.\nends_with(\"xyz\"): nombres que acaban con “xyz”.\ncontains(\"ijk\"): nombres que contienen “ijk”.\nnum_range(\"x\", 1:3): para x1, x2 y x3.\nmatches(): nombres que coinciden con una expresión regular"
  },
  {
    "objectID": "docs/Tema01.html#cómo-tratar-los-contagiosos-na",
    "href": "docs/Tema01.html#cómo-tratar-los-contagiosos-na",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "¿Cómo tratar los (“contagiosos”) NA?",
    "text": "¿Cómo tratar los (“contagiosos”) NA?\n\nEliminar observaciones con valores ausentes, PERO\n\nen alguna variable, con na.rm=TRUE o filter(!is.na(x)) o drop_na(x)\nen todo el conjunto de datos con drop_na()\n\n\n\ndata &lt;- tibble(x1 = c(1:4, NA, 6.0, 7, NA), x2 = c(NA, 12:14, NA, 16.0, 17:18) )\n\ndata %&gt;% summarize(num = n(), meanNA = mean(x1), mean = mean(x1, na.rm = TRUE))\n\ndata %&gt;% drop_na(x1) %&gt;% summarize(num = n(), mean = mean(x1))   # drop_na(x2)?\ndata %&gt;% drop_na()   %&gt;% summarize(num = n(), mean = mean(x1))\n\n\nReemplazar con un valor, PERO ¿cúal?\n\n\ndata %&gt;% mutate(x1 = if_else(is.na(x1), 0, x1)) %&gt;% summarize(num = n(), mean = mean(x1))\ndata %&gt;% mutate(x1 = replace_na(x1,0))          %&gt;% summarize(num = n(), mean = mean(x1))"
  },
  {
    "objectID": "docs/Tema01.html#algunos-verbos-adicionales",
    "href": "docs/Tema01.html#algunos-verbos-adicionales",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Algunos verbos adicionales",
    "text": "Algunos verbos adicionales\n\nslice(), slice_sample(): extrae filas por posición o aleatoriamente\n\n\nmypresidents %&gt;% slice(1, 4)\n\n\ndistinct(): extrae sólo las filas únicas (una o varias variables)\n\n\nmypresidents %&gt;% distinct(party)\n\n\ncount(): cuenta los valores únicos de una o más variables\n\n\nmypresidents %&gt;% count(party)    # mypresidents %&gt;% group_by(party) %&gt;% summarize(n=n())\nmypresidents %&gt;% count(party, sort = TRUE)\n\n\nacross(): aplica la misma transformación a múltiples columnas\n\n\nflights %&gt;% mutate(across(air_time:distance, ~ log(.x)+1))\nflights %&gt;% mutate(across(is.character, ~ parse_factor(.x)))"
  },
  {
    "objectID": "docs/Tema01.html#funciones-para-crear-variables",
    "href": "docs/Tema01.html#funciones-para-crear-variables",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Funciones para crear variables",
    "text": "Funciones para crear variables\n\nOperadores aritméticos: +, -, *, /, ^, %/% (división entera), %% (resto)\n\ncombinados con otros: x - mean(x), y - sum(y)\n\nLogartimos, log(), retardos, lag(), adelantos, lead(), etc.\n\n\nAgregados acumulativos y móviles: ver ayuda de cumsum() y cummean()\n\n\nComparaciones lógicas: &lt;, &lt;=, &gt;, &gt;=, !=\nOrdenamiento: min_rank(), row_number() y otras de dplyr::ranking\n\n\ny &lt;- c (10, 2, 2, NA, 30, 4)\nmin_rank(y)               \nmin_rank(desc(y))\nrow_number(y)"
  },
  {
    "objectID": "docs/Tema01.html#funciones-para-crear-variables-cont.",
    "href": "docs/Tema01.html#funciones-para-crear-variables-cont.",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Funciones para crear variables (cont.)",
    "text": "Funciones para crear variables (cont.)\n\nif_else(): ejecución condicional (también case_when())\n\n\nflights %&gt;% mutate(retraso = if_else(dep_delay &gt; 0, \"tarde\", \"bien\")) %&gt;% select(6,20)  \n\nflights %&gt;% mutate(retraso = if_else(dep_delay &gt; 0, \"tarde\",             # encadenados\n                                        if_else(dep_delay &lt;0, \"bien\", \"normal\")))\n\n\nNota: retraso debería convertirse a factor\n\n\nDiscretizar variables: cut_interval(), cut_number(), cut_width()\n\n\nNota: dplyr tiene muchas funciones equivalentes a otras de R base:\n\nparse_number(), parse_factor(), etc. por as.number(), as.factor(), etc.\nbind_cols() y bind_rows() por cbind() y rbind()"
  },
  {
    "objectID": "docs/Tema01.html#funciones-de-resumen-útiles",
    "href": "docs/Tema01.html#funciones-de-resumen-útiles",
    "title": "Tema 01 - Tratamiento de datos (una tabla)",
    "section": "Funciones de resumen útiles",
    "text": "Funciones de resumen útiles\n\nMedidas de centralidad y de dispersión: mean(x), median(x), sd(x), IQR(x), mad(x)\nMedidas de rango: min(x), quantile(x, 0.25), max(x)\nMedidas de posición: first(x), nth(x, 2), last(x).\n\nsimilar a x[1], x[2] y x[length(x)]\n\nConteos:\n\nn(): observaciones totales (tamaño del grupo)\nsum(!is.na(x)): observaciones no ausentes\nn_distinct(x): filas distintas en x"
  },
  {
    "objectID": "docs/Tema02ej.html",
    "href": "docs/Tema02ej.html",
    "title": "Tema 2. Ejercicio.",
    "section": "",
    "text": "Entrega del ejercicio\nEste ejercicio se realizará en clase y NO cuenta para los alumnos de evaluación NO continua (aunque es recomendable como práctica).\n\n\nPreguntas\n\nUtilizar los datos relacionales de la biblioteca nycflights13. Mostrar cuál es el avión más utilizado y su fabricante y modelo.\n\n\nUtilizar los datos relacionales de la biblioteca nycflights13. Mostrar cuáles son los aeropuertos “misteriosos” (es decir, aeropuertos que aparecen como destinos en la tabla de vuelos pero que no aparecen en la tabla de aeropuertos)."
  },
  {
    "objectID": "docs/Tema02.html#múltiples-tablas-de-datos",
    "href": "docs/Tema02.html#múltiples-tablas-de-datos",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Múltiples tablas de datos",
    "text": "Múltiples tablas de datos\n\nAnalizar datos suele implicar múltiples tablas\n\ndiferentes orígenes: ej., dptos. de empresa (personal, ventas, almacén)\nalmacenamiento más eficiente: elementos “similares” dentro de una tabla y diferentes entre ellas\n\nPara poder combinar la información los datos deben ser relacionales: cada par de tablas están relacionadas mediante identificadores llamados claves\n\n\nP.e., la biblioteca nycflights13 contiene varias tablas: el nombre de la compañía está “codificado” en flights y se puede encontrar en airlines\n\n\nflights %&gt;% select(dep_time,arr_time,carrier:dest) \nairlines\n\n\nAmbas tablas contienen un identificador común clave (“key”): carrier"
  },
  {
    "objectID": "docs/Tema02.html#relaciones-entre-tablas",
    "href": "docs/Tema02.html#relaciones-entre-tablas",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Relaciones entre tablas",
    "text": "Relaciones entre tablas"
  },
  {
    "objectID": "docs/Tema02.html#datos-relacionales",
    "href": "docs/Tema02.html#datos-relacionales",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Datos relacionales",
    "text": "Datos relacionales\n\nTipos de claves:\n\nPrimaria (o interna): identifican de forma única cada observación en una tabla. Puede ser una sola variable (en planes) o múltiples (en weather)\n\nSubrogada = número de fila, si la tabla carece de identificación única\n\nSecundaria (o externa): señala a la clave primaria de otra tabla \n\n\n\nUna clave primaria y una externa (asociada) en otra tabla forman una relación:\n\nde uno-a-muchos (ej., vuelos y aviones), de uno-a-uno, de muchos-a-muchos (ej., aerolíneas y aeropuertos), de muchos-a-uno\n\nOperaciones que se pueden realizar con dos tablas: uniones de transformación, uniones de filtro y operaciones de conjunto"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-transformación",
    "href": "docs/Tema02.html#uniones-de-transformación",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Uniones de transformación",
    "text": "Uniones de transformación\n\nAñaden nuevas variables a una tabla desde filas coincidentes en otra.\n\n\n\n\n\ncbind() o bind_columns(): nuevas columnas para filas en el mismo orden\n\n\nDos argumentos obligatorios: las tablas que se unen\n\n\nflights2 &lt;- flights %&gt;% select(year:day, hour, origin, dest, carrier, tailnum)\nleft_join(flights2, airlines)     # añade el nombre de las compañías en la tabla de vuelos\nflights2 %&gt;% left_join(airlines)"
  },
  {
    "objectID": "docs/Tema02.html#argumento-by-cómo-se-emparejan-las-tablas",
    "href": "docs/Tema02.html#argumento-by-cómo-se-emparejan-las-tablas",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Argumento by: ¿Cómo se emparejan las tablas?",
    "text": "Argumento by: ¿Cómo se emparejan las tablas?\n\nPor defecto se usan todas las variables que aparezcan en ambas tablas\n\n\nflights2 %&gt;% left_join(weather)    # coinciden en año, mes, día, hora y origen        \n\n\nNo siempre deseable o posible: ej., año no es lo mismo en flights y planes\n\n\nby = c(\"varX\", \"varY\"): para usar sólo algunas variables comunes\n\n\nflights2 %&gt;% left_join(planes, by = c(\"tailnum\"))   # también: by = \"tailnum\"  \nflights2 %&gt;% left_join(weather, by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\"))\n\n\nLas columnas con el mismo nombre (ej., año) se desambigúan con un sufijo\nby = c(\"x1\" = \"y1\", \"x2\" = \"y2\") para emparejar la variable x1 en la primera tabla con la variable y1 en la segunda, y la variable x2 con y2\n\n\nflights2 %&gt;% left_join(airports, by = c(\"dest\" = \"faa\"))    # aeropuerto de destino"
  },
  {
    "objectID": "docs/Tema02.html#unión-interna",
    "href": "docs/Tema02.html#unión-interna",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Unión interna",
    "text": "Unión interna\n\ndf1 &lt;- tibble(clave = c(1:3), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(clave = c(1:2, 4), val_y = c(\"y1\",\"y2\",\"y4\"))\n\n\ninner_join(x, y) sólo incluye observaciones que coincidan en x y y.\n\n\ndf1 %&gt;% inner_join(df2)"
  },
  {
    "objectID": "docs/Tema02.html#uniones-externas",
    "href": "docs/Tema02.html#uniones-externas",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Uniones externas",
    "text": "Uniones externas\n\n\n\nCuando una fila no coincide en una unión externa, las nuevas variables se rellenan como valores ausentes \nleft_join(x, y): mantiene todas las observaciones en x, coincidan o no con la de y\n\n(no se pierden observaciones de la tabla primaria)\n\nright_join(x, y): mantiene todas las observaciones en y\nfull_join(x, y): incluye todas las observaciones de x e y"
  },
  {
    "objectID": "docs/Tema02.html#uniones-externas-cont.",
    "href": "docs/Tema02.html#uniones-externas-cont.",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Uniones externas (cont.)",
    "text": "Uniones externas (cont.)\n\n\n\ndf1 %&gt;% left_join(df2)\n\n\n\n\n\n\n\\(\\hspace{0.5cm}\\)\n\n\n\ndf1 %&gt;% right_join(df2)    \n\n\n\n\n\n\n\\(\\hspace{0.5cm}\\)\n\n\n\ndf1 %&gt;% full_join(df2)   \n\n\n\n\n\n\n\nNotar que df1 %&gt;% right_join(df2) es igual que df2 %&gt;% left_join(df1), pero con diferente orden columnas"
  },
  {
    "objectID": "docs/Tema02.html#claves-duplicadas",
    "href": "docs/Tema02.html#claves-duplicadas",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Claves duplicadas",
    "text": "Claves duplicadas\n\nSi una coincidencia no es única, se generan todas las combinaciones posibles (producto cartesiano) de las observaciones coincidentes\n\n\n\n\nEn una tabla: añade información en una relación de uno a muchos.\n\n\n\n\n\n\n\nEn ambas tablas: igualmente, todas las combinaciones posibles\n\n\n\n\nposible error: NO hay clave primaria única"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-filtro",
    "href": "docs/Tema02.html#uniones-de-filtro",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Uniones de filtro",
    "text": "Uniones de filtro\n\nFiltra las observaciones de la tabla de la izquierda basándose en si coinciden o no con una observación de la otra tabla\nSe tiene un subconjunto de las filas de la tabla de la izquierda\n\n\n\n\nsemi_join(x, y) mantiene todas las observaciones en x que coinciden en y\n\n\n\ndf1 %&gt;% semi_join(df2)\n\n\n\n\nanti_join(x, y) elimina todas las observaciones en x que coinciden en y\n\n\n\ndf1 %&gt;% anti_join(df2)"
  },
  {
    "objectID": "docs/Tema02.html#uniones-de-filtro-cont.",
    "href": "docs/Tema02.html#uniones-de-filtro-cont.",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Uniones de filtro (cont.)",
    "text": "Uniones de filtro (cont.)\n\nClaves duplicadas: en uniones de filtro sólo importa la existencia de una coincidencia, NO qué observación coincida \\(\\Rightarrow\\) NUNCA duplica filas"
  },
  {
    "objectID": "docs/Tema02.html#aplicaciones-de-anti_join-y-semi_join",
    "href": "docs/Tema02.html#aplicaciones-de-anti_join-y-semi_join",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Aplicaciones de anti_join() y semi_join()",
    "text": "Aplicaciones de anti_join() y semi_join()\n\nSon útiles para diagnosticar desajustes de uniones (qué observaciones serán emparejadas), porque solo eliminan y nunca duplican observaciones\n\n\nflights %&gt;% anti_join(planes, by = \"tailnum\") %&gt;%   # vuelos sin información del avión\n              count(tailnum, sort = TRUE)\n\n\nPueden ser equivalentes a usar filter(), con tablas previamente resumidas\n\n\ntop_dest &lt;- flights %&gt;% count(dest, sort = TRUE) %&gt;% head(10)   # destinos populares\nflights %&gt;% filter(dest %in% top_dest$dest)\nflights %&gt;% semi_join(top_dest)\n\n\nPero permiten filtrados complejos fácilmente: ej., los diez días con más vuelos necesita un filtro con varias variables (year, month, day)"
  },
  {
    "objectID": "docs/Tema02.html#operaciones-de-conjunto",
    "href": "docs/Tema02.html#operaciones-de-conjunto",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Operaciones de conjunto",
    "text": "Operaciones de conjunto\n\nTrabajan con filas completas, comparando valores de cada variable.\nEsperan que x e y tengan las mismas variables, y tratan las observaciones (filas) como elementos de un conjunto.\nÚtil cuando se quiere dividir un filtro complejo en piezas más simples.\n\n\ndf1 &lt;- tibble(x = 1:2, y = c(1, 1))\ndf2 &lt;- tibble(x = c(1,1), y = 1:2)\n\nintersect(df1, df2)     # solo filas tanto en df1 como en df2\nunion(df1, df2)         # filas únicas en ambas tablas df1 y df2` \nunion_all(df1, df2)     # todas las filas de df1 y df2, manteniendo duplicados \nsetdiff(df1, df2)       # filas en df1, pero no en df2\nsetdiff(df2, df1)"
  },
  {
    "objectID": "docs/Tema02.html#equivalencia-con-bases-de-datos-sql",
    "href": "docs/Tema02.html#equivalencia-con-bases-de-datos-sql",
    "title": "Tema 02 - Manipulación de datos relacionales",
    "section": "Equivalencia con bases de datos SQL",
    "text": "Equivalencia con bases de datos SQL\n\nSQL soporta más tipos de unión y puede trabajar con más de dos tablas."
  },
  {
    "objectID": "docs/Tema12.html#estratificación-para-asociaciones-no-lineales",
    "href": "docs/Tema12.html#estratificación-para-asociaciones-no-lineales",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Estratificación para asociaciones no lineales",
    "text": "Estratificación para asociaciones no lineales\n\n\n\nEjemplo: relación no lineal en los datos de viviendas de Boston\n\n\nBoston &lt;- read_csv(\"https://raw.githubusercontent.com/albarran/00datos/main/BostonHousing.csv\")\n\n\nCuantos más particiones, mejor ajuste.\nPERO ¿dónde dividimos?, ¿cuántas particiones?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsta cuestión también aplica a las interacciones entre variables para capturar heterogeneidad del efecto de una variable: ¿cuántas interacciones? ¿con cuántos intervalos?"
  },
  {
    "objectID": "docs/Tema12.html#árboles-de-decisión",
    "href": "docs/Tema12.html#árboles-de-decisión",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\n\nUn árbol de decisión es un diagrama de flujo con reglas para segmentar el espacio de regresores en regiones más simples y clasificar observaciones"
  },
  {
    "objectID": "docs/Tema12.html#árboles-de-regresión",
    "href": "docs/Tema12.html#árboles-de-regresión",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Árboles de Regresión",
    "text": "Árboles de Regresión\n\n¿Cómo construimos estos árboles para una variable cuantitativa?\n\nDividir el espacio de predicción, \\(\\small x_1, x_2, \\dots, x_p\\) en regiones \\(\\small J\\) distintas y no superpuestas, \\(\\small R_1, R_2, \\dots, R_J\\)\n\ncada vez más homogéneas o “puras”: como todos los modelos (ej., kNN), mismas características, mismo valor esperado de \\(y\\)\n\nCada observación que caiga en la región \\(\\small R_j\\) tiene el mismo valor predicho: la media de \\(\\small y\\) para las observaciones de entrenamiento en \\(\\small R_j\\), \\(\\small \\widehat{y}_{i\\in R_j}= \\bar{y}_{R_j}\\)\n\nEs INVIABLE considerar todas las particiones en \\(\\small J\\) regiones \nAlternativas heurísticas: un algoritmo “voraz” elige una opción localmente óptima en cada paso con la esperanza de llegar a una solución general óptima\n\n(en lugar de elegir la mejor partición para un paso futuro)"
  },
  {
    "objectID": "docs/Tema12.html#partición-binaria-recursiva",
    "href": "docs/Tema12.html#partición-binaria-recursiva",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Partición binaria recursiva",
    "text": "Partición binaria recursiva\n\nEn la parte alta, todas las observaciones pertenecen a una sola región\nSe divide sucesivamente cada región en dos ramas: \\(\\small R_1(j,s) = \\{X|X_j &lt; s\\}\\) y \\(\\small R_2(j,s) = \\{X|X_j \\geq s\\}\\)\n\nEn cada nodo, se consideran todos los regresores \\(\\small X_j\\) y todos los umbrales \\(s\\)\nSe calcula el error de predicción por particionar de esa manera \\(\\small SCR_{j,s} = \\sum_{i\\in R_1(j,s)}(y_i-\\widehat{y}_{R_1})^2 + \\sum_{i\\in R_2(j,s)}(y_i-\\widehat{y}_{R_2})^2\\)\nSOLO una partición en cada iteración: se elige \\(\\small j\\) y \\(\\small s\\) con menor \\(\\small SCR_{j,s}\\) \n\nRepetimos el proceso particionando cada región de la iteración anterior \nSe continua hasta que se cumpla un criterio de parada; p.e., ninguna región contiene más de \\(5\\) observaciones"
  },
  {
    "objectID": "docs/Tema12.html#podar-un-árbol-pruning",
    "href": "docs/Tema12.html#podar-un-árbol-pruning",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Podar un árbol (pruning)",
    "text": "Podar un árbol (pruning)\n\nEvitar árboles demasiados complejos (“overfitting”)\nHacer crecer un árbol “grande” con \\(\\small T_0\\) nodos terminales y podarlo para quedarnos con un sub-árbol con \\(\\small T\\) nodos terminales \\[\n\\small\nmin \\sum_{m=1}^T \\sum_{i \\in R_m} (y_i-\\widehat{y}_{R_m})^2 + \\alpha |T|\n\\] donde \\(\\small R_m\\) es la región de \\(\\small m\\)-nodo terminal\n\\(\\small \\alpha\\) es el hiperparámetro de coste de complejidad de la poda, elegido por validación cruzada"
  },
  {
    "objectID": "docs/Tema12.html#árboles-de-clasificación",
    "href": "docs/Tema12.html#árboles-de-clasificación",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Árboles de clasificación",
    "text": "Árboles de clasificación\n\nPara un árbol de clasificación, se predice que cada observación pertenece a la clase más común en la región a la que pertenece en entrenamiento\nTambién se pueden obtener la proporción de una clase \\(\\small k\\) dentro de una región particular \\(\\small m\\) de nodos terminales: \\(\\small \\widehat{p}_{mk}\\)\nLa métrica usada para hacer crecer los árboles NO puede ser SCR\n\n\nÍndice de Gini: medida de la varianza entre clases \\(\\small G=\\sum_{k=1}^{K}\\widehat{p}_{mk}(1-\\widehat{p}_{mk})\\)\nEntropía (cruzada) \\(\\small D=\\sum_{k=1}^{K}\\widehat{p}_{mk}log(\\widehat{p}_{mk})\\)\n\n\nAmbos son medidas de “pureza” del nodo: un valor pequeño indica que la región contiene en su mayoría observaciones de una sola clase."
  },
  {
    "objectID": "docs/Tema12.html#algoritmos-para-árboles-e-hiperparámetros",
    "href": "docs/Tema12.html#algoritmos-para-árboles-e-hiperparámetros",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Algoritmos para árboles e hiperparámetros",
    "text": "Algoritmos para árboles e hiperparámetros\n\nMotores para árboles: rpart (defecto), spark y C5.0 (solo clasificación)\nDepende de varios hiperparámetros elegidos por tuning\n\nmin_n: mínimo número de observaciones en un nodo parar dividirse más\ntree_depth: máx. número de niveles de profundidad del árbol (no C5.0)\ncost_complexity: coste de complejidad (sólo rpart)\n\n\n\ncenso_modelo_arbol  &lt;- set_engine(\"rpart\") %&gt;% decision_tree(mode = \"classification\", \n                                     cost_complexity = .01)\n\n\nPodemos visualizar un modelo árbol estimado con la biblioteca rpart.plot\n\n\narbol &lt;- censo_flujo_arbol_est %&gt;% extract_fit_parsnip() \nrpart.plot(arbol$fit)"
  },
  {
    "objectID": "docs/Tema12.html#comentarios",
    "href": "docs/Tema12.html#comentarios",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Comentarios",
    "text": "Comentarios\n\nPredicción: media o clase mayoritaria de las observaciones de entrenamiento en el nodo que corresponde a una observación nueva\nImportancia de las variables: reducción total de la SCR o Gini debida a las particiones de una variable\n\nvariables usadas en nodos iniciales o más veces son más importantes\n\nVentajas:\n\najusta (no paramétricamente) relaciones no lineales/complejeas\nfáciles de explicar (más que la regresión lineal) y visualizar\nno requieren dummies (ni transformaciones no lineales de variables continuas)\n\n\n\nDesventajas: overfit (no robustos a cambios en los datos) y bajo poder de predicción"
  },
  {
    "objectID": "docs/Tema12.html#bagging",
    "href": "docs/Tema12.html#bagging",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Bagging",
    "text": "Bagging\n\nAgregación de Bootstrap (bagging): procedimiento general para reducir la varianza, promediando \\(\\small \\{x_i\\}_{i=1}^n iid \\sim (\\mu, \\sigma^2) \\Rightarrow \\bar{x} \\sim (\\mu, \\sigma^2/n)\\)\nPodemos tomar \\(B\\) re-muestras del único conjunto de entrenamiento\n\n\nEn lugar de un único árbol complejo, se combinan muchos árboles diversos que pueden reflejar patrones sutiles\nLa variación muestral en las condiciones de “entrenamiento” se genera mediante “bootstrap”"
  },
  {
    "objectID": "docs/Tema12.html#random-forest",
    "href": "docs/Tema12.html#random-forest",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "“Random forest”",
    "text": "“Random forest”\n\nEs un algoritmo específico de agregación de árboles que introduce aleatorización para eliminar correlación entre los árboles.\n\nSe construyen varios árboles en muestras de entrenamiento de bootstrap\nEn cada partición de un árbol, se seleccionan aleatoriamente \\(\\small m \\approx \\sqrt{k}\\) regresores del total\nSe mitiga la influencia de regresores fuertes, permitiendo una mayor diversidad en los árboles agregados\n\n\n\nMejor predicción a expensas de la interpretación \\(\\Rightarrow\\) medidas de importancia variable: reducción promedio en SCR / Gini para un regresor en los \\(\\small B\\) árboles\n\n\nLa importancia tiene un papel análogo al de los p-valores (sin una inferencia estadística formal), para ayudar a generar hipótesis."
  },
  {
    "objectID": "docs/Tema12.html#algoritmos-para-rf-e-hiperparámetros",
    "href": "docs/Tema12.html#algoritmos-para-rf-e-hiperparámetros",
    "title": "Tema 12 - Métodos basados en árboles",
    "section": "Algoritmos para RF e hiperparámetros",
    "text": "Algoritmos para RF e hiperparámetros\n\nMotores principales para RF en R: ranger, randomForest y spark\n\n\nDepende de trees, números de árboles, a considerar en la agregación (no genera “overfitting”) y de dos hiperparámetros\n\nmtry: número de variables a considerar en cada partición\nmin_n: igual que en árboles\n\n\n\nRailTrail_modelo_RF  &lt;- rand_forest(mode = \"regression\",          # classification\n                                       mtry = 3, trees = 100) %&gt;% \n                          set_engine(\"ranger\", importance = \"impurity\")\n\nRailTrail_flujo_RF_est_fit &lt;- extract_fit_parsnip(RailTrail_flujo_RF_est)$fit\nRailTrail_flujo_RF_est_fit$variable.importance\n\nlibrary(vip)\nextract_fit_parsnip(RailTrail_flujo_RF_est) %&gt;% vip()"
  },
  {
    "objectID": "docs/Tema00ej1.html",
    "href": "docs/Tema00ej1.html",
    "title": "Tema 0. Ejercicio 1",
    "section": "",
    "text": "En este ejercicio vamos a practicar los conceptos básicos de R. Debéis escribir un archivo de código de R con los comandos necesarios para responder a los siguientes ejercicios. Podéis encontrar una plantilla aquí\n\n\nApartado 1\n\nTenemos la siguiente información sobre las ventas de dos tiendas, A y B, a lo largo de una semana. Generar dos vectores llamados, Ventas_A y Ventas_B, que contenga esta información; cada elemento del vector debe tener su correspondiente nombre (día de la semana).\n\n\nGenerar el vector que contenga las ventas totales (sumando ambas tiendas) para cada día, Ventas_totales_diarias, la variable (escalar) con las ventas totales de ambas tiendas en toda la semana, Ventas_totales_semana, y la variable (escalar) con las ventas medias de la semana de la tienda A, Ventas_media_A.\n\n\nGenerar los siguientes objetos\n\nel vector Ventas_A_entre_semana con las ventas de cada día de la tienda A exceptando los lunes y viernes.\nel vector Ventas_seleccion con las ventas totales de cada día para ambas tiendas en los días en los que la tienda B vende más que la tienda A.\nel vector dias_Ventas_seleccion con los nombres de los días en los que la tienda B vende más que la tienda A.\n\n\n\n\nApartado 2\n\nLa siguiente tabla muestras las ventas de tres productos (X, Y y Z) a nivel nacional y a nivel internacional (en millones de euros). Generar una matriz, matriz_ventas, que contenga esta información; sus filas y columnas deben tener los nombres apropiados.\n\n\nConsiderar las ventas de otros tres productos según la siguiente tabla. Generar una nueva matriz, matriz_ventas2, con esta información y combinarla con la matriz del apartado anterior para obtener una nueva matriz, matriz_ventas_combinada, con información para todos los productos.\n\n\nGenerar un vector, ventas_total, con las ventas totales (nacionales más internacionales) de cada producto. Generar una matriz, matriz_ventas_combinada_total, que añada una columna con las ventas totales a matriz_ventas_combinada.\n\n\nGenerar una variable (escalar), internac_media, con la media de las ventas internacionales (media sobre todos los productos) y otro vector, nacional_seleccion_media, con la media de las ventas nacionales sobre los productos X, Y y R.\n\n\nSe quiere conocer el número de compradores de los productos a partir de la matriz de ventas, matriz_ventas_combinada.\n\nGenerar una matriz, compradores_estimados, de compradores estimados para cada producto y destino (nacional e internacional) suponiendo que el precio de todos los productos es 5.\nGenerar la matriz compradores con un cálculo más exacto a partir de la siguiente información de precios.\n\n\n\n\nApartado 3\n\nSe ha preguntado a cinco clientes sobre su satisfacción con los servicios de una empresa. Su contestación ha sido: “poco”, “nada”, “nada”, “poco”, “mucho”. Generar un vector, factor_satisf_vector, adecuado para esta información.\n\n\nGenerar un vector, sum_factor, con las estadísticas descriptivas de la información del apartado anterior y muestra el resultado (“imprime” ese vector).\n\n\nCrear el vector comparar_clientes que informe sobre si el cliente 2 está más satisfecho que el cliente 5.\n\n\n\nApartado 4\n\nEl conjunto de datos mtcars está incluido en R por defecto; buscar en la ayuda de RStudio mtcars para conocer las variables que incluye. Comprobar la estructura con str() y visualizar las primeras observaciones con head().\n\nGenerar la variable (escalar) Datsun710_CV con los caballos de potencia del coche modelo Datsun 710.\nGenerar el vector Valiant_vector con toda la información (esto es, variables) disponibles sobre el coche modelo Valiant.\n\n\n\nGenerar el vector cilindros con la información para todos los modelos de coche de la variable sobre el número de cilindros. Generar el vector cambio_vector con la información de la variable de tipo de cambio (manual o automático) de todos los modelos de coche Mazda y Hornet.\n\n\nGenerar media_consumo_autom con el consumo medio de los coches con cambio automático. Generar media_consumo_autom_cyl4 con el consumo medio de los coches con cambio automático y cuatro cilindros.\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema00ej1_123456787.R"
  },
  {
    "objectID": "docs/Tema06.html#el-sistema-de-publicaciones-quarto",
    "href": "docs/Tema06.html#el-sistema-de-publicaciones-quarto",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "El sistema de publicaciones Quarto",
    "text": "El sistema de publicaciones Quarto\n\n\n\nOrientado al análisis de datos reproducible: combina código, resultados y comentarios\nÚtil como cuaderno de trabajo del código y para comunicar resultados en un documento final para tomar decisiones\n\n\n\n\n\n\n\n\n\nInstalar Quarto para vuestro sistema operativo desde aquí\nLa guía y referencia completa de Quarto están en su Web\nUn documento de Quarto se renderiza, procesando cada componente (código, resultado de ejecutarlo y texto) para producir documentos en varios formatos: html, PDF, Word, presentaciones, etc."
  },
  {
    "objectID": "docs/Tema06.html#documentos-de-quarto-crear-y-guardar",
    "href": "docs/Tema06.html#documentos-de-quarto-crear-y-guardar",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Documentos de Quarto: Crear y Guardar",
    "text": "Documentos de Quarto: Crear y Guardar\n\nUn documento de Quarto se crea a partir de una plantilla en RStudio con  o File &gt; New File &gt; Quarto Document\n\nPodemos elegir Título, Autor/a y formato de salida (HTML, por defecto)\n\n\n\nSe guarda con  o con File &gt; Save, con extensión .qmd\nSe renderiza con  al formato de salida elegido \nEn el botón de engranaje  se pueden cambiar algunas opciones\n\np.e., dónde se visualiza la salida (en ventana aparte o en RStudio)"
  },
  {
    "objectID": "docs/Tema06.html#documentos-de-quarto-formato-de-salida",
    "href": "docs/Tema06.html#documentos-de-quarto-formato-de-salida",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Documentos de Quarto: formato de salida",
    "text": "Documentos de Quarto: formato de salida\n\nEl renderizado crea un archivo en el mismo directorio donde está el archivo de Quarto .qmd\nEn el caso de HTML, se crea tanto un archivo con extensión .html como un subdirectorio del mismo nombre con componentes necesarios (ej., imágenes, css)\n\nsolo podemos visualizar correctamente el archivo .html en cualquier navegador si copiamos a otro lugar tanto el .html como el subdirectorio\n\nPara crear PDFs, se necesita una distribución de LaTeX: instala una escribiendo en la pestaña de “Terminal” (a la derecha de la consola):\n\n\nquarto install tool tinytex"
  },
  {
    "objectID": "docs/Tema06.html#documentos-de-quarto-texto-con-markdown",
    "href": "docs/Tema06.html#documentos-de-quarto-texto-con-markdown",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Documentos de Quarto: Texto con Markdown",
    "text": "Documentos de Quarto: Texto con Markdown\n\nLos componentes de texto están escritos en Markdown: un conjunto ligero de convenciones para archivos de texto sin formato. Por ejemplo,\n\ntodo lo escrito entre dos * como **Hola** se renderiza en negritas\nse utiliza # para indicar encabezados de secciones\n\nEn el menú de ayuda tenemos una descripción completa (Markdown quick reference) y “chuletas” (Cheatsheets)\nTambién son útiles la web de Quarto y este libro online.\n\n\nRStudio incorpora un editor visual de documentos de Quarto, similar a un procesador de texto"
  },
  {
    "objectID": "docs/Tema06.html#editor-visual-de-quarto-en-rstudio",
    "href": "docs/Tema06.html#editor-visual-de-quarto-en-rstudio",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Editor Visual de Quarto en RStudio",
    "text": "Editor Visual de Quarto en RStudio\n\nEn documentos .qmd, se puede elegir entre editar la fuente (source) de Markdown, como texto sencillo, o editar el documento de forma Visual en \nEn el modo visual, en esa misma barra de herramientas se tienen accesos a\n\nformatos de texto (negritas, cursivas, encabezamientos) y listas\ninsertar enlaces, imágenes, notas a pie de página, tablas\nincluir ecuaciones (en LaTeX)\ntambién insertar directamente código HTML, comentarios, etc.\n\nSe puede configurar la corrección ortográfica en Tools &gt; Global Options &gt; Spelling: agregar/seleccionar el diccionario de Español"
  },
  {
    "objectID": "docs/Tema06.html#formato-en-la-cabecera-el-bloque-yaml",
    "href": "docs/Tema06.html#formato-en-la-cabecera-el-bloque-yaml",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Formato en la cabecera: el bloque YAML",
    "text": "Formato en la cabecera: el bloque YAML\n\nAl principio del documento, entre dos líneas con ---, se pueden especificar varias opciones del documento: título, autor, fecha, formato de salida\n\n\nLos formatos de salida son html, pdf, docx (y otros en Quarto Presentations)\nTambién se especifican opciones globales del documento, algunas específicas de cada tipo de salida (ver la referencia para html y otros formatos)\n  ---\n  title: \"Título\"\n  author: Autor \n  date: 15-octubre-2023\n  format:\n    html:\n      toc: true              # índice\n      number-sections: true  # secciones numeradas\n      embed-resources: true  # archivo html autocontenido\n      theme: united          # más temas: https://bootswatch.com/3/\n  ---"
  },
  {
    "objectID": "docs/Tema06.html#fragmentos-o-celdas-de-código",
    "href": "docs/Tema06.html#fragmentos-o-celdas-de-código",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Fragmentos o celdas de código ",
    "text": "Fragmentos o celdas de código \n\nInsertamos código en medio del texto con el icono (visual) \nSi pulsamos , escribimos r y luego un código, el documento de salida incluirá el resultado de ejecutar el código\n\n\n\nPodemos incluir un fragmento de código (de varias líneas), con , en el desplegable  o Ctrl + Alt + I \nSe puede personalizar cómo se muestran varios aspectos del código y de sus resultados\n\nbien para una celda concreta de código, incluyendo opciones de celda\no para todo el documento en la cabecera: las opciones de html están en la sección de código de su referencia (y similar para otros formatos)"
  },
  {
    "objectID": "docs/Tema06.html#opciones-para-una-celda-de-código",
    "href": "docs/Tema06.html#opciones-para-una-celda-de-código",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Opciones para una celda de código",
    "text": "Opciones para una celda de código\n\nLas opciones se incluyen al principio de una celda precedidas por #|\nSe muestra el código en la salida con la opción echo: true (o no con echo: false)\nCon la opción eval: false, el código se ejecuta: los resultados de ejecutarlo están disponibles y pueden mostrarse (o no con eval: false)\n\nSi un fragmento no se evalua, sus resultados no están para otras celdas posteriores (p.e., cargamos datos o una biblioteca para usar luego)\n\n\nIncluimos los resultados del código con output: true\n\n\nTambién se pueden mostrar (o no) los mensajes, errores y avisos de ejecutar un código con las opciones message, error y warning, respectivamente.\nLa lista completa de opciones aquí"
  },
  {
    "objectID": "docs/Tema06.html#opciones-para-una-celda-de-código-cont.",
    "href": "docs/Tema06.html#opciones-para-una-celda-de-código-cont.",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Opciones para una celda de código (cont.)",
    "text": "Opciones para una celda de código (cont.)\n\nCómo mostrar resultado\n\nresults: hide (no mostrar)\nresults: hold (mostrar todo, no el resultado de cada línea)\n\n\ninclude: false no incluye ni el código ni su resultado, pero se evalúa\nlabel: etiqueta para identificar la celda\ncode-fold: true oculta el código pero da opción a mostrarlo\n\n\nfig-cap y tbl-cap para los títulos\nCómo mostrar los gráficos: fig-show\n\nlas opciones hide y hold son como en results\nanimate concatena varios gráficos en una animación"
  },
  {
    "objectID": "docs/Tema06.html#opciones-para-una-celda-de-código-y-3",
    "href": "docs/Tema06.html#opciones-para-una-celda-de-código-y-3",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Opciones para una celda de código (y 3)",
    "text": "Opciones para una celda de código (y 3)\n\nfig-width y fig-height: dimensiones (reales, en pulgadas) de una figura\nout-width y out-height: ídem en el documento de salida (% de las reales)\nfig-align: mostrar la figura centrada o alineada a derecha o izquierda\nlayout-ncol: en cuantas columnas se componen los resultados\n\n\nggplot(data = cars) + geom_histogram(aes(x = speed))  # en la izquierda\nggplot(data = cars) + geom_histogram(aes(x = dist))   # en la derecha"
  },
  {
    "objectID": "docs/Tema06.html#opciones-globales-para-todas-las-celdas",
    "href": "docs/Tema06.html#opciones-globales-para-todas-las-celdas",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Opciones globales para todas las celdas",
    "text": "Opciones globales para todas las celdas\n\nSi no se da un valor a las opciones en una celda, se usa el valor por defecto de Quarto o el definido globalmente en la cabecera.\nEn la cabecera, se pueden especificar las opciones de ejecución de código echo, eval, include, output, error, etc. en execute (ver aquí y aquí)\n  ---\n  execute:\n    echo: false\n    warning: false\n  ---\n\n\nTambién se pueden fijar en la cabecera muchas otras opciones, incluidas algunas que ya hemos visto (un listado completo aquí para html)"
  },
  {
    "objectID": "docs/Tema06.html#opciones-por-defecto-para-todas-las-celdas-cont.",
    "href": "docs/Tema06.html#opciones-por-defecto-para-todas-las-celdas-cont.",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Opciones por defecto para todas las celdas (cont.)",
    "text": "Opciones por defecto para todas las celdas (cont.)\n    ---\n    format:\n      html:\n        code-fold: true\n        cap-location: bottom\n        fig-align: center\n        df-print: paged\n    ---\n\nLa opción df-print especifica el método para visualizar tablas\n\n\nTambién se pueden especificar algunas de estas opciones a través del renderizador de R knitr (descripción completa aquí)."
  },
  {
    "objectID": "docs/Tema06.html#ejecución-de-código-en-un-documento-.qmd",
    "href": "docs/Tema06.html#ejecución-de-código-en-un-documento-.qmd",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Ejecución de código en un documento .qmd",
    "text": "Ejecución de código en un documento .qmd\n\nAl renderizar un documento .qmd, se crea un nuevo espacio de trabajo y se ejecuta el código allí.\n\nese espacio de trabajo es distinto del que vemos en RStudio: diferentes objetos, incluyendo bibliotecas\nel directorio de trabajo también es diferente: es el directorio donde se encuentra el .qmd\n\nEs importante conocer si el código del documento .qmd ofrece los resultados deseado antes de renderizar.\nCuando tenemos varias celdas de código, algunas pueden depender de cálculos y objetos previos (datos, bibliotecas, resultados)\n\n\nSe puede probar ejecutando el código del documento .qmd (sin renderizar): línea a línea, la celda completa con  o todas las anteriores con"
  },
  {
    "objectID": "docs/Tema06.html#ejecución-de-código-en-un-.qmd-cont.",
    "href": "docs/Tema06.html#ejecución-de-código-en-un-.qmd-cont.",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Ejecución de código en un .qmd (cont.)",
    "text": "Ejecución de código en un .qmd (cont.)\n\nCuando ejecutamos el código sin renderizar, éste pasa pasa a la consola y sí forma parte del espacio de trabajo de la sesión actual de R.\nDebemos asegurarnos de que la sesión actual incluye sólo resultados del código de celdas del documento para que nuestra prueba sea equivalente a lo que obtendríamos renderizando\nResulta útil incluir una celda código al principio del documento (que se evalúe pero no muestre código ni resultados) que incluya\n\nrm(list = ls()): al ejecutar todas las celdas previas, empezamos con una sesión sin objetos y podemos probar el código de la celda actual\nTodas las bibliotecas (ej., tidyverse) que utilizaremos en varias celdas\nFijar el directorio de trabajo para acceder a archivos (p.e., imágenes, datos). Esto es innecesario si hemos sido cuidadosos y creado el archivo .qmd como parte de un proyecto."
  },
  {
    "objectID": "docs/Tema06.html#mejorar-la-salida-de-tablas",
    "href": "docs/Tema06.html#mejorar-la-salida-de-tablas",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Mejorar la salida de tablas",
    "text": "Mejorar la salida de tablas\n\nLos resultados de muchas funciones de R no son visualmente “profesionales” en el documento de salida de .qmd\nVarias bibliotecas cambian algunas salidas por defecto (printr) u ofrecen funciones para mejorarlas (pander::pandoc.table(), xtable::xtable())\n\n\nPor ahora, veremos la función kable() de la biblioteca knitr\nMás adelante veremos la biblioteca kableExtra, con más opciones.\n\nkableExtra muestra “data frame”/“tibbles” como tablas\nbroom::tidy() (de tidyverse) convierte mucho objetos de R (como listas con resultados de comandos) en tibbles\n\n\n\nOtras bibliotecas similares: modelsummary, stargazer"
  },
  {
    "objectID": "docs/Tema06.html#comentarios-finales-dashboards-tableros",
    "href": "docs/Tema06.html#comentarios-finales-dashboards-tableros",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Comentarios finales: Dashboards (Tableros)",
    "text": "Comentarios finales: Dashboards (Tableros)\n\nLos dashboards son un tipo de interfaz gráfica para los usuarios finales que ofrecen visualizaciones rápidas de indicadores o resultados clave\nEstas presentaciones visuales e interactivas de los resultados de un análisis de datos puede ayudar a una comunicación más efectiva\nCon Quarto se pueden crear varios tipos de dashboards interactivos, aunque no vamos a profundizar en ellos\nEn particular, Quarto trabaja con el paquete de R llamado Shiny que permite crear fácilmente aplicaciones web interactivas\nPodéis encontrar ejemplos de las capacidades de Shiny en esta galería de aplicaciones"
  },
  {
    "objectID": "docs/Tema06.html#comentarios-finales-libros-de-notas-jupyter",
    "href": "docs/Tema06.html#comentarios-finales-libros-de-notas-jupyter",
    "title": "Tema 06 - Introducción a Quarto",
    "section": "Comentarios finales: libros de notas Jupyter",
    "text": "Comentarios finales: libros de notas Jupyter\n\nSon otra forma de combinar texto, código y resultados en un documento\nDesarrollados para Python, admiten varios lenguajes de programación\n\nQuarto puede incluir celdas de código en otros lenguajes, incluido Python\n\nSe crean, visualizan y ejecutan solo en navegadores web, aunque son fácilmente modificables, en su entorno de trabajo\n\ncon una instalación local (usando Python) u online en JupyterLab (y también incluye un tipo de dashboard propio: Voilà)\no con Google Colab, también para R\n\nQuarto renderiza libros de Jupyter, creados en .qmd o en su propio formato\nMuchas herramientas están preparadas para Python y R porque se usan a menudo indistintamente o combinados"
  },
  {
    "objectID": "docs/Proyect01.html",
    "href": "docs/Proyect01.html",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "Este documento debe entenderse como un ejemplo, no la guía o la receta única de hacer las cosas.\n\nPor un lado, aquí muestro algunas cosas que en vuestros trabajos probablemente NO queréis mostrar. Por ejemplo, he incluido la opción de que se muestre o se oculte el código de todo lo que he hecho, pero vosotros debéis pensar qué y cuándo queréis mostrar algo. También muestro algunos resultados que, como se ha discutido en clase, probablemente tampoco queráis mostrar (o no de la misma manera).\nPor otro lado, he omitido muchos detalles de algunas fases del trabajo que ya se han ido comentando y trabajando en clase (características de los datos, procedimientos, tablas con encabezados adecuados, gráficos con ejes correctamente nombrados, comentario de resultados, etc.)\nFinalmente, cada conjunto de datos es diferente y cada análisis es diferente. Se requiere un tratamiento distinto de los datos (eliminar o imputar valores ausentes, transformar variables, agrupar categorías, discretizar, etc.), diferentes algoritmos y especificaciones (combinaciones de variables a incluir y sus transformaciones).1\n\nEn resumen, este ejemplo tiene probablemente muchos más gráficos y tablas de los que vosotros debéis reportar y se han mostrado muchas pruebas que vosotros no incluiréis como ejemplo de los que debéis; aunque también deberéis probar otras que aquí no he probado. Pero también se espera discusiones algo más detalladas (sin ser excesivas).\n\n\n\nEn este trabajo, se analizará un conjunto de datos con información sobre precios y otros atributos de una muestra de viviendas en Boston. Por un lado, el objetivo es examinar la influencia de varios atributos del vecindario en los precios de la vivienda, en un intento por descubrir las variables explicativas más adecuadas. Por otro lado, la construcción de un modelo de predicción permitirá determinar el valor por el que se puede poner en el mercado una vivienda o detectar si alguna está infravalorada o sobrevalorada dadas sus características.\nPara realizar este análisis utilizaremos lo que hemos aprendido del lenguaje de programación R. En particular usaremos las herramientas de las bibliotecas tidyverse y tidymodels, además de otras puntualmente."
  },
  {
    "objectID": "docs/Proyect01.html#comentario-general",
    "href": "docs/Proyect01.html#comentario-general",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "Este documento debe entenderse como un ejemplo, no la guía o la receta única de hacer las cosas.\n\nPor un lado, aquí muestro algunas cosas que en vuestros trabajos probablemente NO queréis mostrar. Por ejemplo, he incluido la opción de que se muestre o se oculte el código de todo lo que he hecho, pero vosotros debéis pensar qué y cuándo queréis mostrar algo. También muestro algunos resultados que, como se ha discutido en clase, probablemente tampoco queráis mostrar (o no de la misma manera).\nPor otro lado, he omitido muchos detalles de algunas fases del trabajo que ya se han ido comentando y trabajando en clase (características de los datos, procedimientos, tablas con encabezados adecuados, gráficos con ejes correctamente nombrados, comentario de resultados, etc.)\nFinalmente, cada conjunto de datos es diferente y cada análisis es diferente. Se requiere un tratamiento distinto de los datos (eliminar o imputar valores ausentes, transformar variables, agrupar categorías, discretizar, etc.), diferentes algoritmos y especificaciones (combinaciones de variables a incluir y sus transformaciones).1\n\nEn resumen, este ejemplo tiene probablemente muchos más gráficos y tablas de los que vosotros debéis reportar y se han mostrado muchas pruebas que vosotros no incluiréis como ejemplo de los que debéis; aunque también deberéis probar otras que aquí no he probado. Pero también se espera discusiones algo más detalladas (sin ser excesivas)."
  },
  {
    "objectID": "docs/Proyect01.html#introducción-y-objetivos",
    "href": "docs/Proyect01.html#introducción-y-objetivos",
    "title": "Predicción de precios de las casas en Boston",
    "section": "",
    "text": "En este trabajo, se analizará un conjunto de datos con información sobre precios y otros atributos de una muestra de viviendas en Boston. Por un lado, el objetivo es examinar la influencia de varios atributos del vecindario en los precios de la vivienda, en un intento por descubrir las variables explicativas más adecuadas. Por otro lado, la construcción de un modelo de predicción permitirá determinar el valor por el que se puede poner en el mercado una vivienda o detectar si alguna está infravalorada o sobrevalorada dadas sus características.\nPara realizar este análisis utilizaremos lo que hemos aprendido del lenguaje de programación R. En particular usaremos las herramientas de las bibliotecas tidyverse y tidymodels, además de otras puntualmente."
  },
  {
    "objectID": "docs/Proyect01.html#análisis-de-variación",
    "href": "docs/Proyect01.html#análisis-de-variación",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Análisis de variación",
    "text": "Análisis de variación\nComo primer elemento a destacar, estos datos no contiene valores ausentes en ninguna de las variables. En caso contrario, deberíamos identificar cuántas observaciones y qué variables están afectadas. Sabemos que podemos posponer la imputación de valores a una fase posterior (como un paso del pre-procesado antes de estimar un modelo), pero es conveniente tener una visión general y pensar si algunas observaciones probablemente serán descartadas (si tienen muchos valores ausentes y sobre todo afectan a la variable dependiente).\nPodemos centrarnos en describir con más detalles algunas distribuciones. Esto nuevamente es un EJEMPLO dependiendo de las variables que tengamos y de qué observemos. En general, caracterizar la variable dependiente suele ser una buena idea. Visualizamos la distribución y densidad del precio mediano de las viviendas. La curva negra representa la densidad. Vemos que el valor medio del precio de la vivienda está sesgado a la derecha. Es decir, observamos precios muy altos con una frecuencia mayor de la esperada en una distribución simétrica donde existiría la misma proporción por encima y debajo de la media.\n\nBoston %&gt;%  ggplot(aes(x=medv)) + geom_histogram(aes(y=..density..))+ geom_density() + ggtitle(\"Distribución del Precio\") + xlab(\"Precio de las casas\") + ylab(\"Densidad\")\n\n\n\n\nFigura 1. Distribución del precio de la vivienda\n\n\n\n\nDada esta asimetría, quizás debamos considerar modelizar posteriormente esta variable transformada en logaritmos. La razón: se aprecia un comportamiento que puede modelizarse mejor de forma no lineal. También se puede nota una acumulación de valores en 50 mil dólares. Se puede observar en los resultados de describe() que ese valor exacto se repite varias veces, NO es producto de la discretización del gráfico en la que se acumulan varios valores diferentes en un intervalo en torno a 50; también debemos probar distintos anchos de intervalo como se ha discutido en clase.\nTambién podemos representar gráficamente o en un tabla la única variable categórica que tenemos. La conclusión no es particularmente interesante: solo unas pocas zonas de la ciudad están cerca del río.\n\nBoston %&gt;%  count(chas) %&gt;% \n  mutate(freq=n/sum(n)) %&gt;% \n  kbl(col.names=c(\"Casa cercana al río\",\"Número de casos\", \"Frecuencia\"),\n                  caption = \"Tabla 1. Distribución de Casas según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 1. Distribución de Casas según cercanía al río\n\n\nCasa cercana al río\nNúmero de casos\nFrecuencia\n\n\n\n\nNo\n471\n0.93083\n\n\nYes\n35\n0.06917\n\n\n\n\n\n\n\nEn el caso de variables binarias las podemos representar de varias maneras: como una distribución o con una sola barra (NOTA: los gráficos siguientes son redundantes en esta caso, con uno de ellos sería más que suficiente en caso de considerar relevante esta información.)\n\nBoston %&gt;%  ggplot() + geom_bar(aes(x=chas)) +  xlab(\"Zona cercana al río\") +ylab(\"Número de casos\")\n\nBoston %&gt;%  ggplot() + geom_bar(aes(x=\"\",fill=chas)) + labs(fill=\"Zona cercana al río\") +ylab(\"Número de casos\")\n\n\n\n\nFigura 2. Distribución de la cercanía al río\n\n\n\n\n\n\n\nFigura 2. Distribución de la cercanía al río\n\n\n\n\nTambién podemos mostrar algunas otras características interesantes mediante gráficos y/o tablas de estadísticos descriptivos. Algunas variables como el número de habitaciones tienen distribuciones bastante simétricas. Mientras que otras, como la edad o el porcentaje de población desfavorecida muestran claras asimetrías: hay una alta concentración de casas “viejas” y de zonas no desfavorecidas. NOTA: Recordad que habría que probar varios anchos de intervalos (binwidth) para asegurarnos de entender la forma de la distribución. También debéis poner nombres suficientemente descriptivos e informativos a los gráficos, los ejes, la leyenda, etc. (Quizás no es el caso en algunos de los que presento aquí).\n\nBoston %&gt;%  ggplot(aes(x=age)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Edad\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=lstat)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Porcentaje de población desfavorecida\") + ylab(\"Densidad\")\n\n\n\n\nFigura 3. Distribuciones\n\n\n\n\n\n\n\nFigura 3. Distribuciones\n\n\n\n\nNotad que en la variable edad nuevamente hay una concentración de valores en 100; en la salida describe() mostrada anteriormente, se aprecia mejor que ese valor exacto está en los datos originales, no resulta de que se agrupen valores en el gráfico.\nEl caso de la distancia a los centros de empleo es similar a las dos anteriores: una gran concentración en zonas bien conectadas, aunque una cola de zonas alejadas. Se podría omitir: no hay que mostrar gráficos o tablas de cada variable ni comentar necesariamente las características de la distribución de todas, solo de aquellas con rasgos interesante o relevantes.\nOtra variable en principio relacionada, el índice de accesibilidad, muestra una distribución “poco continua”: además de un cúmulo de valores en la cola derecha, hay muchos huecos vacíos. Si probáis un transformación logarítmica, veréis que no cambia en esencia. Las variables con este forma en su distribución suelen ser candidatas a ser discretizadas.\n\nBoston %&gt;%  ggplot(aes(x=dis)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Distancia a centro de trabajo\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=rad)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Índice de accesibilidad\") + ylab(\"Densidad\")\n\n\n\n\nFigura 4. Distribuciones\n\n\n\n\n\n\n\nFigura 4. Distribuciones\n\n\n\n\nAlgunas variables tienen distribuciones con características poco reseñables: unas con valores distribuidos de forma relativamente homogénea, otras dispersas, con concentraciones en valores aislados en medio o en los extremos de la distribución, pero no aportan mucho información (se podrían omitir). En este caso, quizás se podría notar una concentración de zonas con altos impuestos, muy diferenciadas del resto.\n\nBoston %&gt;%  ggplot(aes(x=nox)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Concentración de óxidos nítricos\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=ptratio)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Ratio de alumnos por profesor\") + ylab(\"Densidad\")\n\nBoston %&gt;%  ggplot(aes(x=tax)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Impuesto de la propiedad\") + ylab(\"Densidad\")\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\n\n\n\nFigura 5. Distribuciones\n\n\n\n\nAlgo más interesantes son algunas variables que muestran polaridad en sus valores o una excesiva acumulación en algunos. Por ejemplo, la criminalidad y el porcentaje de población de color tienen distribuciones muy asimétricas y, en el segundo caso, persiste incluso tras transformar en logaritmos.\n\nBoston %&gt;%  ggplot(aes(x=crim)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Criminalidad\") + ylab(\"Densidad\")\nBoston %&gt;%  ggplot(aes(x=crim)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Criminalidad\") + ylab(\"Densidad\") + scale_x_log10()\n\n\n\n\nFigura 6a. Distribuciones\n\n\n\n\n\n\n\nFigura 6a. Distribuciones\n\n\n\n\n\nBoston %&gt;%  ggplot(aes(x=b)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Población de color\") + ylab(\"Densidad\") \nBoston %&gt;%  ggplot(aes(x=b)) + geom_histogram(aes(y=..density..))+ geom_density() + xlab(\"Población de color\") + ylab(\"Densidad\") + scale_x_log10()\n\n\n\n\nFigura 6b. Distribuciones\n\n\n\n\n\n\n\nFigura 6b. Distribuciones\n\n\n\n\nEstas variables y algunas otras anteriores son candidatas a ser discretizadas. La criminalidad, por ejemplo, no solo muestra una concentración en unos pocos valores, sino que una vez transformada en logaritmos se aprecian dos grupos diferenciados, como también pasaba con los impuestos. En el caso de la ratio de profesor/alumno también unos valores con gran concentración de frecuencia y muy pocos por encima de este por lo que podrían agruparse juntos. En el caso de la población de color, vemos que a partir del percentil 75, los valores son prácticamente iguales y antes del percentil 10 son mucho menores que en el resto de la distribución. En estos casos de variables con valores concentrados o infrecuentes y con saltos o huecos, no podemos decir que la variable que observamos en nuestra muestra tenga una apariencia de variable continua, aunque en principio lo sea. Por tanto, agrupar y discretizar es una buena opción. En particular, es más fácil identificar el efecto medio sobre el precio de la vivienda de un rango de valores (ej., zonas de baja criminalidad frente a alta) que el efecto de incrementar en un punto la variable (cuando en los datos no observamos valores con ese punto más). En otras palabras, vamos a modelizar efectos flexibles no lineales."
  },
  {
    "objectID": "docs/Proyect01.html#análisis-de-covariación",
    "href": "docs/Proyect01.html#análisis-de-covariación",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Análisis de covariación",
    "text": "Análisis de covariación\nEmpezamos analizando la relación entre nuestra variable de interés y la única variable categórica que tenemos inicialmente, para lo que podríamos presentar alguna (NO todas) de las siguientes figuras\n\nBoston %&gt;% ggplot(aes(y = medv, x = chas)) +  geom_boxplot() + ylab(\"Densidad\") + xlab(\"Cerca del río\") + ylab(\"Precio\") \nBoston %&gt;% ggplot(aes(x = medv)) + geom_density(mapping = aes(colour = chas)) + xlab(\"Precio\") + ylab(\"Densidad\")  + labs(color = \"Cerca del río\")\n\n\n\n\nFigura 7a. Distribución del precio por cercanía al rio\n\n\n\n\n\n\n\nFigura 7a. Distribución del precio por cercanía al rio\n\n\n\n\n\nBoston %&gt;% ggplot(aes(x = medv)) + geom_density() + facet_wrap(~chas) + ylab(\"Densidad\")  + xlab(\"Precio\")\n\n\n\n\nFigura 7b. Distribución del precio, según cercanía al rio\n\n\n\n\nParece que las casa cercanas al río tienen un precio superior, aunque la diferencia no parece grande. Ambas distribuciones son asimétricas, aunque en el caso de casas cercanas al río la cola derecha no es tan larga. Mediante una regresión simple o calculando las medias podemos comprobar si existen diferencias en media y si son significativas:\nlm(data = Boston, medv ~ chas) %&gt;% broom::tidy() %&gt;%  kbl(digits = 2, caption = \"Table 2a. Precio según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\n\nTable 2a. Precio según cercanía al río\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n22.09\n0.42\n52.9\n0\n\n\nchasYes\n6.35\n1.59\n4.0\n0\n\n\n\n\n\n\nBoston %&gt;% group_by(chas) %&gt;% describe(medv) %&gt;% select(described_variables:n, mean, se_mean) %&gt;%  kbl(digits = 2, caption = \"Tabla 2b. Precio según cercanía al río\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 2b. Precio según cercanía al río\n\n\ndescribed_variables\nchas\nn\nmean\nse_mean\n\n\n\n\nmedv\nNo\n471\n22.09\n0.41\n\n\nmedv\nYes\n35\n28.44\n2.00\n\n\n\n\n\n\nTambién podríamos analizar si la variable binaria de cercanía al río está relacionada. (NOTA: esto nuevamente es un código de ejemplo para hacer de forma fácil este proceso. NO es necesario que vosotros lo hagáis así.)\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\ntabla &lt;-list()\nfor (var in vars) {\n  formula &lt;- paste0(var,\" ~ chas\")\n  tabla[[var]] &lt;- lm(data = Boston, formula) %&gt;% tidy() %&gt;% filter(term==\"chasYes\") %&gt;% select(estimate, p.value)\n}\n\ntabla %&gt;% bind_rows(.id=\"Variable\")  %&gt;%  kbl(digits = 2, caption = \"Tabla 2c. Diferencias en variable por cercanía al río\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 2c. Diferencias en variable por cercanía al río\n\n\nVariable\nestimate\np.value\n\n\n\n\ncrim\n-1.89\n0.21\n\n\nzn\n-3.92\n0.34\n\n\nindus\n1.70\n0.16\n\n\nnox\n0.04\n0.04\n\n\nrm\n0.25\n0.04\n\n\nage\n9.59\n0.05\n\n\ndis\n-0.82\n0.03\n\n\nrad\n-0.25\n0.87\n\n\ntax\n-23.61\n0.42\n\n\nptratio\n-1.04\n0.01\n\n\nb\n17.54\n0.27\n\n\nlstat\n-1.52\n0.23\n\n\n\n\n\n\nVemos que las casas cercanas al rio son más antiguas, con más habitaciones, más cercanas al centro de trabajo, con más contaminación y mejores condiciones escolares.\nA continuación podemos analizar rápidamente si las variables continuas están relacionadas con nuestra variable de interés, precio de la vivienda, y entre ellas. Lo podemos hacer mediante distintos análisis de correlación, en una tabla (excesivamente larga) o visualmente.\n\nBoston %&gt;% correlate() %&gt;% \n  filter(as.integer(var1) &gt; as.integer(var2)) %&gt;% \n  kbl(digits = 2, caption = \"Tabla 3. Correlaciones\") %&gt;% kable_paper(\"hover\")\n\n\nBoston %&gt;% correlate() %&gt;% plot() \n\nBoston %&gt;% mutate(logmedv=log(medv)) %&gt;% select(-medv) %&gt;% correlate() %&gt;% plot()\n\n\n\n\nFigura 8. Correlaciones entre variables continuas\n\n\n\n\n\n\n\nFigura 8. Correlaciones entre variables continuas\n\n\n\n\nHemos considerado la correlación tanto con el precio como con su logaritmo, dado lo discutido anteriormente. Sin embargo, apenas se aprecian diferencias.\nVemos que existe una fuerte correlación (positiva o negativa) entre el precio y varias variables que intuitivamente consideraríamos como importantes. El número de habitaciones tiene la correlación positiva más fuerte con el valor medio del precio de la vivienda, mientras que el porcentaje de la población desfavorecida y el número de alumnos por docente tienen una correlación negativa fuerte. También es evidente que las zonas más industriales y la contaminación están fuertemente correlacionados positivamente entre sí, puesto que los niveles de óxido nítrico tienden a aumentar con el aumento de las industrias. También vemos que las zonas con más población desfavorecida son las más industriales y contaminadas, con casas más antiguas y de menos habitaciones y con escuelas con un mayor ratio de alumnos por profesor. Debemos recordar esto de cara a la especificación de los modelos de regresión lineal.\nSin embargo, esto no considera posibles relaciones no lineales. Para ello vamos a representar varios gráficos de dispersión y un ajuste no lineal. Nuevamente, en vuestro trabajo no mostraréis necesariamente todos estos gráficos sino una selección después de haberlos vistos.\n\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\nfor (v in vars){\n  graf &lt;- Boston %&gt;% \n            ggplot(aes_string(x = v, y = \"medv\")) +\n            geom_point() +  geom_smooth() +\n            labs(x = v, y = \"Precio de las casas ($1000s)\")\n  print(graf)\n}\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\n\n\nFigura 9a. Gráficos de dispersión\n\n\n\n\n\nvars &lt;- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\")\n\nfor (v in vars) {\n  migraf &lt;-  Boston %&gt;% \n              ggplot(aes_string(x = v, y = \"medv\")) +\n              geom_point() +  geom_smooth() +\n              labs(x = v, y = \"Precio de las casas ($1000s)\")  +\n              scale_y_log10() \n  print(migraf)\n}\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\n\n\n\nFigura 9b. Gráficos de dispersión (en escala logaritmica)\n\n\n\n\nEn primer lugar, no se aprecian grandes diferencias entre el modelo con el precio sin transformar o en logaritmos. En segundo lugar, sí se aprecia cierta no linealidad en la relación con las variables de edad, número de habitaciones y porcentaje de población desfavorecida. En el resto de relaciones, no están tan claras por la acumulación de valores.\nTambién se podrían haber probado si este análisis de covariación es distinto según distintos valores de una varible categórica. Por ejemplo, visualizar la relación entre precio y tasa de pobreza cuando la zona está cerca del rio y cuando no está cerca.\nPodemos probar discretizando algunas de las variables comentadas anteriormente. Por ejemplo, hacemos dos grupos de criminalidad; los umbrales para discretizar no tienen una justificación muy formal: se basan en lo que aproximadamente hemos visto.\n\n  Boston %&gt;% \n      mutate(crim.alta = cut(crim, breaks = c(0,1,Inf), labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n      ggplot(aes(y = medv, x = crim.alta)) +  geom_boxplot() + ylab(\"Densidad\") + xlab(\"Criminalidad alta\") + ylab(\"Precio\") \n\n\n\n\nFigura 10. Gráficos Criminalidad Discreta\n\n\n\n\n  Boston %&gt;% \n      mutate(crim.alta = cut(crim, breaks = c(0,1,Inf), labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ crim.alta) %&gt;% tidy() %&gt;%  kbl(digits = 2, caption = \"Table 4. Precio según criminalidad\") %&gt;% kable_paper(\"hover\")\n\n\nTable 4. Precio según criminalidad\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n25.11\n0.47\n53.91\n0\n\n\ncrim.altaAlta\n-7.50\n0.79\n-9.44\n0\n\n\n\n\n\n\nTanto el gráfico como la regresión apuntan a un efecto significativo de la criminalidad sobre los precios. En principio deberíamos probar con otros puntos de corte para discretizar, pero por simplicidad utilizaremos este obtenido a partir del análisis exploratorio.\nPodemos proceder de manera similar con otras variables. Nuevamente, tanto el número de grupos como los valores de corte no se derivan de forma super rigurosa, sino en base al análisis exploratorio. Debería probarse con otras variantes.\nBoston %&gt;% \n  mutate(dis.alta = cut(dis, breaks = c(0,3,Inf), labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ dis.alta) %&gt;% tidy() %&gt;%\n  kbl(digits = 2, caption = \"Table 5. Precio según distancia\") %&gt;% kable_paper(\"hover\")\n\n\nTable 5. Precio según distancia\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.73\n0.57\n34.69\n0\n\n\ndis.altaAlta\n5.32\n0.78\n6.79\n0\n\n\n\n\n\n\nBoston %&gt;% \n  mutate(rad.alta = cut(dis, breaks = c(0,10,Inf), labels = c(\"Baja\",\"Alta\") ) ) %&gt;% \n  lm(data = ., medv ~ rad.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Table 6. Precio según accesibilidad\") %&gt;% kable_paper(\"hover\")\n\n\nTable 6. Precio según accesibilidad\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n22.53\n0.41\n54.79\n0.00\n\n\nrad.altaAlta\n-0.21\n4.14\n-0.05\n0.96\n\n\n\n\n\n\nBoston %&gt;% \n  mutate(tax.alta = cut(tax, breaks = c(0,350,500,Inf), labels = c(\"Baja\",\"Media\",\"Alta\")) ) %&gt;%\n  lm(data = ., medv ~ tax.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Table 7. Precio según impuestos\") %&gt;% kable_paper(\"hover\")\n\n\nTable 7. Precio según impuestos\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n25.88\n0.51\n51.16\n0\n\n\ntax.altaMedia\n-3.68\n0.96\n-3.83\n0\n\n\ntax.altaAlta\n-9.60\n0.87\n-11.06\n0\n\n\n\n\n\n\nBoston %&gt;% \n  mutate(black.cat = cut(b, breaks = c(0,100, 395,Inf), labels = c(\"Baja\",\"Media\",\"Alta\")) ) %&gt;%\n  lm(data = ., medv ~ black.cat) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Table 8. Precio según población de color\") %&gt;% kable_paper(\"hover\")\n\n\nTable 8. Precio según población de color\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n12.33\n1.58\n7.82\n0\n\n\nblack.catMedia\n11.63\n1.65\n7.03\n0\n\n\nblack.catAlta\n9.48\n1.72\n5.52\n0\n\n\n\n\n\n\nBoston %&gt;% \n  mutate(black.alta = cut(b, breaks = c(0, 100,Inf), labels = c(\"Baja\",\"Alta\")) ) %&gt;% \n  lm(data = ., medv ~ black.alta) %&gt;% tidy() %&gt;%  \n  kbl(digits = 2, caption = \"Table 8b. Precio según población de color\") %&gt;% kable_paper(\"hover\")\n\n\nTable 8b. Precio según población de color\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n12.33\n1.59\n7.77\n0\n\n\nblack.altaAlta\n10.87\n1.64\n6.64\n0\n\n\n\n\n\n\n(NOTA: estas tablas se podrían haber hecho con un bucle. También notad que NO he mantenido la variable discretizada en los datos, aunque podría haberlo hecho.)"
  },
  {
    "objectID": "docs/Proyect01.html#importante",
    "href": "docs/Proyect01.html#importante",
    "title": "Predicción de precios de las casas en Boston",
    "section": "IMPORTANTE",
    "text": "IMPORTANTE\nLa fase de análisis exploratorio puede tener resultados interesantes por sí mismos. Es importante comentarlos y discutirlos adecuadamente, en relación con el objetivo del trabajo.\nPero sobre todo esta fase tiene como objetivo aprender de los datos de cara a la siguiente: modelización. Por tanto, es mucho más importante comentar, aquí o en la fase de modelización cuestiones cómo\n\nqué variables incluir en los modelos: aunque esto no es crucial para algunos algoritmos que seleccionan.\n\nb.cómo las vamos a incorporar: en función de los resultados previos podemos queremos incluir transformaciones no lineales, discretizaciones, agrupando categorías, etc."
  },
  {
    "objectID": "docs/Proyect01.html#muestras-de-entrenamiento-y-prueba",
    "href": "docs/Proyect01.html#muestras-de-entrenamiento-y-prueba",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Muestras de entrenamiento y prueba",
    "text": "Muestras de entrenamiento y prueba\nAntes de empezar, generamos una nueva variables igual al logaritmo de la variable dependiente por si queremos usarla transformada dada lo que hemos visto en el análisis exploratorio. Hemos visto que otras variables (explicativas) también podrían ser transformadas tomando logaritmos o polinomios, discretizando, etc. Todo esas transformaciones se pueden hacer en el pre-procesado de tidymodels. El caso de la variable dependiente es diferente y, por eso, es la única que transformamos antes y la incluimos transformada en el conjunto de datos.\n\nBoston &lt;- Boston %&gt;% mutate(logmedv = log(medv))\n\nA continuación, hacemos la partición de los datos reservando una proporción del 80% como conjuntos de datos de entrenamiento y el 20% restante como prueba.\n\nset.seed(1)\nBoston_part &lt;- Boston %&gt;% initial_split(prop = .8)"
  },
  {
    "objectID": "docs/Proyect01.html#modelos-de-regresión-lineal",
    "href": "docs/Proyect01.html#modelos-de-regresión-lineal",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Modelos de regresión lineal",
    "text": "Modelos de regresión lineal\nPrimero, probemos el modelo de regresión lineal para el precio como variable dependiente y todas las variables restantes como variables independientes. Entrenamos el modelo con el conjunto de datos de entrenamiento. A continuación se muestran todos los coeficientes. Finalmente, utilizamos el modelo entrenado para predecir en el conjunto de datos de la prueba y calcular sus métricas.\nlm1_receta &lt;- training(Boston_part) %&gt;%            \n  recipe(medv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) \n\nlm1_modelo &lt;- linear_reg(mode= \"regression\", penalty = 0) %&gt;%\n                    set_engine(\"lm\")\n\nlm1_flujo &lt;- workflow() %&gt;%\n  add_recipe(lm1_receta) %&gt;%\n  add_model(lm1_modelo)\n\nlm1_flujo_est &lt;- lm1_flujo %&gt;% fit(data = training(Boston_part)) \n\nlm1_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy() %&gt;% \n   kbl(digits = 2, caption = \"Table 9. Modelo de Regresión\") %&gt;% kable_paper(\"hover\")\n\n\nTable 9. Modelo de Regresión\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.41\n6.06\n5.35\n0.00\n\n\nchasYes\n3.15\n0.97\n3.24\n0.00\n\n\ncrim\n-0.09\n0.04\n-2.25\n0.02\n\n\nzn\n0.04\n0.02\n2.58\n0.01\n\n\nindus\n0.03\n0.07\n0.43\n0.67\n\n\nnox\n-14.95\n4.42\n-3.38\n0.00\n\n\nrm\n4.07\n0.49\n8.35\n0.00\n\n\nage\n0.00\n0.02\n-0.33\n0.74\n\n\ndis\n-1.44\n0.23\n-6.14\n0.00\n\n\nrad\n0.32\n0.07\n4.37\n0.00\n\n\ntax\n-0.01\n0.00\n-3.18\n0.00\n\n\nptratio\n-0.88\n0.15\n-5.72\n0.00\n\n\nb\n0.01\n0.00\n3.45\n0.00\n\n\nlstat\n-0.55\n0.06\n-9.64\n0.00\n\n\n\n\n\n\n(NOTA: los nombres de las columnas y de las filas/variables son “mejorables”: si el documento está en castellano las columnas no deberían tener nombres en inglés y sería preferible que apareciera un nombre más descriptivo de las variables. Pero no voy a exigir esto en el plazo que tenemos. Eso sí, al menos que en algún sitio aparezca la descripción completa del nombre abreviado de las variables, como hago aquí con el Apéndice A.)\nLos resultados del modelo con todas las variables son similares a los anteriores con solo una variable cada vez, aunque la edad NO es significativa (ceteris paribus). \nFinalmente, calculamos las métricas de error de este modelo.\nlm_metricas &lt;- list()\nlm_metricas[[1]] &lt;- lm1_flujo_est %&gt;% \n                  predict(testing(Boston_part)) %&gt;% \n                  bind_cols(testing(Boston_part)) %&gt;%  \n                  metrics(truth=medv, estimate= .pred) \nVamos a considerar algunas otras especificaciones (diferentes combinaciones de variables) dentro del modelo lineal. Por simplicidad, solo considero unas pocas; vosotros podéis considerar más, aunque quizás no tengáis que reportar todas. Lo importante es justificar por qué se ha decidido probar esas variantes (en particular, en función del análsis exploratorio) y por qué se han elegido las que consideréis.\nEn primer lugar, consideramos algunas transformaciones no lineales según hemos visto en el análisis exploratorio: el precio en logaritmos y polinomios para edad y porcentaje de población desfavorecida. Luego, incluimos también algunas de las discretizaciones vistas antes e interacciones.\nNotad que voy a seguir usando el mismo modelo de antes, solo cambio actualizando la receta y cambiando el flujo.\nlm2_receta &lt;- training(Boston_part) %&gt;%            \n                recipe(logmedv ~ chas + crim + zn + indus + nox + rm + \n                    age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n                step_poly(age, lstat, degree = 4) \n\nlm2_flujo &lt;- workflow() %&gt;%\n  add_recipe(lm2_receta) %&gt;%\n  add_model(lm1_modelo)\n\nlm2_flujo_est &lt;- lm2_flujo %&gt;% fit(data = training(Boston_part)) \n\nlm2_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy() %&gt;% \n   kbl(digits = 3, caption = \"Table 10. Modelo de Regresión (en logaritmos)\") %&gt;% kable_paper(\"hover\")\n\n\nTable 10. Modelo de Regresión (en logaritmos)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3.710\n0.227\n16.348\n0.000\n\n\nchasYes\n0.097\n0.035\n2.724\n0.007\n\n\ncrim\n-0.014\n0.002\n-8.604\n0.000\n\n\nzn\n0.000\n0.001\n0.478\n0.633\n\n\nindus\n0.003\n0.003\n1.030\n0.304\n\n\nnox\n-0.629\n0.163\n-3.872\n0.000\n\n\nrm\n0.068\n0.019\n3.482\n0.001\n\n\ndis\n-0.041\n0.009\n-4.715\n0.000\n\n\nrad\n0.016\n0.003\n6.008\n0.000\n\n\ntax\n-0.001\n0.000\n-4.458\n0.000\n\n\nptratio\n-0.032\n0.006\n-5.577\n0.000\n\n\nb\n0.000\n0.000\n3.113\n0.002\n\n\nage_poly_1\n0.316\n0.333\n0.950\n0.343\n\n\nage_poly_2\n-0.004\n0.211\n-0.019\n0.985\n\n\nage_poly_3\n0.087\n0.198\n0.440\n0.660\n\n\nage_poly_4\n-0.038\n0.189\n-0.202\n0.840\n\n\nlstat_poly_1\n-4.698\n0.315\n-14.906\n0.000\n\n\nlstat_poly_2\n1.461\n0.210\n6.964\n0.000\n\n\nlstat_poly_3\n0.309\n0.204\n1.518\n0.130\n\n\nlstat_poly_4\n0.603\n0.187\n3.230\n0.001\n\n\n\n\n\n\nlm_metricas[[2]] &lt;- lm2_flujo_est %&gt;% \n                  predict(testing(Boston_part)) %&gt;% \n                  bind_cols(testing(Boston_part)) %&gt;%  \n                  metrics(truth=logmedv, estimate= .pred) \nNotad que la edad sigue sin ser significativa.\nAhora vamos a incluir versiones discretas de algunas variables, bien nuevas o bien reemplazando otras transformaciones no lineales previas de las mismas.\nlm3_receta &lt;- training(Boston_part) %&gt;%            \n                recipe(logmedv ~ chas + crim + zn + indus + nox + rm + \n                    age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n                step_poly(lstat, degree = 4) %&gt;% \n                step_cut(dis, breaks = c(0,3,Inf)) %&gt;% \n                step_cut(b, breaks = c(0,100, 395,Inf)) %&gt;% \n                step_cut(age, breaks = c(0,25,75,Inf)) %&gt;% \n                step_dummy(dis, b, age) %&gt;% \n                step_interact(terms = ~ rm:nox + starts_with(\"lstat\"):nox + crim:starts_with(\"b_\") )\n\nlm3_flujo &lt;- workflow() %&gt;%\n  add_recipe(lm3_receta) %&gt;%\n  add_model(lm1_modelo)\n\nlm3_flujo_est &lt;- lm3_flujo %&gt;% fit(data = training(Boston_part)) \n\nlm3_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy() %&gt;% \n   kbl(digits = 2, caption = \"Table 11. Modelo de Regresión (var. discretas e interacciones)\") %&gt;% kable_paper(\"hover\")\n\n\nTable 11. Modelo de Regresión (var. discretas e interacciones)\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.31\n0.56\n-0.54\n0.59\n\n\nchasYes\n0.08\n0.03\n2.63\n0.01\n\n\ncrim\n-0.01\n0.00\n-4.00\n0.00\n\n\nzn\n0.00\n0.00\n0.08\n0.94\n\n\nindus\n0.00\n0.00\n1.06\n0.29\n\n\nnox\n5.37\n0.89\n6.04\n0.00\n\n\nrm\n0.65\n0.09\n7.55\n0.00\n\n\nrad\n0.02\n0.00\n8.56\n0.00\n\n\ntax\n0.00\n0.00\n-5.73\n0.00\n\n\nptratio\n-0.03\n0.00\n-5.47\n0.00\n\n\nlstat_poly_1\n9.32\n1.60\n5.83\n0.00\n\n\nlstat_poly_2\n2.43\n1.73\n1.40\n0.16\n\n\nlstat_poly_3\n5.52\n1.84\n3.00\n0.00\n\n\nlstat_poly_4\n4.78\n1.30\n3.69\n0.00\n\n\ndis_X.3.Inf.\n-0.14\n0.03\n-5.07\n0.00\n\n\nb_X.100.395.\n0.31\n0.05\n6.75\n0.00\n\n\nb_X.395.Inf.\n0.31\n0.05\n6.53\n0.00\n\n\nage_X.25.75.\n-0.03\n0.03\n-1.07\n0.28\n\n\nage_X.75.Inf.\n-0.08\n0.04\n-1.99\n0.05\n\n\nrm_x_nox\n-0.92\n0.14\n-6.54\n0.00\n\n\nnox_x_lstat_poly_1\n-22.38\n2.63\n-8.52\n0.00\n\n\nnox_x_lstat_poly_2\n-0.13\n2.73\n-0.05\n0.96\n\n\nnox_x_lstat_poly_3\n-8.09\n2.84\n-2.85\n0.00\n\n\nnox_x_lstat_poly_4\n-6.63\n2.04\n-3.25\n0.00\n\n\ncrim_x_b_X.100.395.\n-0.01\n0.00\n-2.58\n0.01\n\n\ncrim_x_b_X.395.Inf.\n-0.02\n0.00\n-6.79\n0.00\n\n\n\n\n\n\nlm_metricas[[3]] &lt;- lm3_flujo_est %&gt;% \n                  predict(testing(Boston_part)) %&gt;% \n                  bind_cols(testing(Boston_part)) %&gt;%  \n                  metrics(truth=logmedv, estimate= .pred) \nUn cambio importate: la categoría de mayor edad sí que tiene un efecto significativo sobre el precio. Esto muestra que, a veces, NO debemos descartar una variable por no ser significativa: simplemente refleja que el modelo no es lo suficientemente flexible (no lineal) para capturar la relación.\nSi comparamos las métricas de los tres modelos, vemos que el mejor modelo es el segundo, a pesar de que el tercero es más flexible. NOTA: no podemos usar el \\(R^2\\) para comparar el modelo 1 y los demás porque la variable dependiente no es la misma.\nlm_metricas %&gt;% bind_rows(.id = \"modelo\") %&gt;% \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Table 12. Métricas de los Modelos de Regresión Lineal\") %&gt;% kable_paper(\"hover\")\n\n\nTable 12. Métricas de los Modelos de Regresión Lineal\n\n\nmodelo\nrmse\nrsq\nmae\n\n\n\n\n1\n4.1637\n0.7391\n3.2312\n\n\n2\n0.1942\n0.7560\n0.1452\n\n\n3\n0.2677\n0.6384\n0.1510\n\n\n\n\n\n\nTambién podemos ver la importancia que cada variable tiene en los distintos modelos.\n\nlm1_flujo_est %&gt;% extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\n\nFigura 11. Imporancia en los tres modelos de regresión lineal\n\n\n\nlm2_flujo_est %&gt;% extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\n\nFigura 11. Imporancia en los tres modelos de regresión lineal\n\n\n\nlm3_flujo_est %&gt;% extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\n\nFigura 11. Imporancia en los tres modelos de regresión lineal"
  },
  {
    "objectID": "docs/Proyect01.html#lasso",
    "href": "docs/Proyect01.html#lasso",
    "title": "Predicción de precios de las casas en Boston",
    "section": "LASSO",
    "text": "LASSO\nPara reducir la complejidad de la elección de variables en el modelo lineal podemos considerar modelos de red elástica y/o LASSO. Nuevamente, existen muchas combinaciones iniciales de variables y aquí solo estudiaremos un par de ellas: las del primer y segundo modelos anteriores. Para ajustar \\(\\lambda\\) puede ser necesario varios rangos. Recordad que este algoritmo requiere, como otros, un preprocesado de las variables: no se pueden pasar factores a LASSO, por lo que debemos convertirlos en dummies con step_dummy, y las variables continuas se deben estandarizar.\nset.seed(9753)\nBoston_cv &lt;- training(Boston_part) %&gt;% vfold_cv(v=10)\n\nlasso1_receta &lt;- training(Boston_part) %&gt;%            \n  recipe(medv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n  step_dummy(chas) %&gt;% \n  step_center(all_predictors(), -all_nominal()) %&gt;% \n  step_scale(all_predictors(), -all_nominal()) \n\nlasso1_modelo &lt;- linear_reg(mode= \"regression\", penalty = tune()) %&gt;%\n                    set_engine(\"glmnet\")\n\nlasso1_flujo &lt;- workflow() %&gt;%\n  add_recipe(lasso1_receta) %&gt;%\n  add_model(lasso1_modelo)\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 1), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso1_flujo_tuned &lt;- lasso1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso1_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=penalty, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n##### \nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.2), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso1_flujo_tuned &lt;- lasso1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso1_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=penalty, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\nlasso1_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 13. Mejores lambdas en el Modelo 1 de LASSO\") %&gt;% kable_paper(\"hover\")\n\n\nTable 13. Mejores lambdas en el Modelo 1 de LASSO\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.036\nrmse\nstandard\n4.9563\n10\n0.2895\nPreprocessor1_Model10\n\n\n0.032\nrmse\nstandard\n4.9564\n10\n0.2891\nPreprocessor1_Model09\n\n\n0.040\nrmse\nstandard\n4.9566\n10\n0.2898\nPreprocessor1_Model11\n\n\n0.028\nrmse\nstandard\n4.9566\n10\n0.2888\nPreprocessor1_Model08\n\n\n0.024\nrmse\nstandard\n4.9570\n10\n0.2884\nPreprocessor1_Model07\n\n\n\n\n\n\nlambda1 &lt;- 0 #lasso1_flujo_tuned %&gt;% select_best(\"rmse\")\nEn el proceso de ajuste, encontramos que \\(\\lambda=0\\) (no regularizar) es una opción indistinguible del óptimo. Por tanto, sería el modelo de regresión con todas las variables. Notad que muestro dos búsquedas de valores, refinnando en la segunda la zona que aparecía como más probable en la primera. En general, se deberían probar varios rangos para el hiper-parámetro buscando una forma de U para el valor con mínimo error; se puede empezar con rangos amplios y luego buscar valores en un rango más fino, entorno al valor donde se ve el mínimo. NO está claro que queráis mostrarlos todos o incluso que queráis mostrar más de uno.\nlasso2_receta &lt;- training(Boston_part) %&gt;%            \n                recipe(logmedv ~ chas + crim + zn + indus + nox + rm + \n                    age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n                step_poly(age, lstat, degree = 4) %&gt;% \n                step_dummy(chas) %&gt;% \n                step_center(all_predictors(), -all_nominal()) %&gt;% \n                step_scale(all_predictors(), -all_nominal()) \n\nlasso2_flujo &lt;- workflow() %&gt;%\n  add_recipe(lasso2_receta) %&gt;%\n  add_model(lasso1_modelo)\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.2), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso2_flujo_tuned &lt;- lasso2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso2_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=penalty, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\nFigura 13. Ajuste de lamdba, modelo 2\n\n\n####\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.02), trans = NULL),   \n                          levels = 51)                     \n\nset.seed(1)\nlasso2_flujo_tuned &lt;- lasso2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = LASSO_grid                          \n                          ) \n\nlasso2_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=penalty, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\nFigura 13. Ajuste de lamdba, modelo 2\n\n\nlasso2_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 14. Mejores lambdas en el Modelo 2 de LASSO\") %&gt;% kable_paper(\"hover\")\n\n\nTable 14. Mejores lambdas en el Modelo 2 de LASSO\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0028\nrmse\nstandard\n0.1790\n10\n0.0124\nPreprocessor1_Model08\n\n\n0.0024\nrmse\nstandard\n0.1790\n10\n0.0123\nPreprocessor1_Model07\n\n\n0.0032\nrmse\nstandard\n0.1790\n10\n0.0124\nPreprocessor1_Model09\n\n\n0.0020\nrmse\nstandard\n0.1791\n10\n0.0123\nPreprocessor1_Model06\n\n\n0.0036\nrmse\nstandard\n0.1792\n10\n0.0124\nPreprocessor1_Model10\n\n\n\n\n\n\nlambda2 &lt;- 0 #lasso2_flujo_tuned %&gt;% select_best(\"rmse\")\nTambién encontramos que el valor óptimo de \\(\\lambda=0\\). Dado que obtenemos que los mejores modelos son los dos anteriores, no necesitamos finalizar los modelos ni ver qué variables se han seleccionado. NOTA: deberían haberse probado más modelo con LASSO que incluyan polinomios, interacciones entre variables, etc."
  },
  {
    "objectID": "docs/Proyect01.html#knn",
    "href": "docs/Proyect01.html#knn",
    "title": "Predicción de precios de las casas en Boston",
    "section": "kNN",
    "text": "kNN\nConsideremos modelos de k vecinos. Este método es suficientemente flexible para considerar posibles no linealidades en todas las variables. Vamos a ajustar el número de vecinos por validación cruzada con el precio y su logaritmo como variables dependientes.\n\nknn1_receta &lt;- lasso1_receta \n  \nknn1_modelo &lt;- nearest_neighbor(mode = \"regression\",\n                  neighbors = tune(), dist_power = 2) %&gt;% \n                set_engine(\"kknn\")\n\nknn1_flujo &lt;- workflow() %&gt;%\n  add_recipe(knn1_receta) %&gt;%\n  add_model(knn1_modelo)\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 21), trans = NULL),   \n                          levels = 11)                     \n\nset.seed(1)\nknn1_flujo_tuned &lt;- knn1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn1_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=neighbors, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\n\nFigura 14. Ajuste de k vecinos, modelo 1\n\n\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 11), trans = NULL),   \n                          levels = 11)                     \n###########\nset.seed(1)\nknn1_flujo_tuned &lt;- knn1_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn1_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=neighbors, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\n\nFigura 14. Ajuste de k vecinos, modelo 1\n\n\n\n\nknn1_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 15. k-vecinos óptimo en el Modelo 1\") %&gt;% kable_paper(\"hover\")\n\n\nTable 15. k-vecinos óptimo en el Modelo 1\n\n\nneighbors\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n4\nrmse\nstandard\n4.0733\n10\n0.3965\nPreprocessor1_Model04\n\n\n3\nrmse\nstandard\n4.0959\n10\n0.4083\nPreprocessor1_Model03\n\n\n5\nrmse\nstandard\n4.1115\n10\n0.3893\nPreprocessor1_Model05\n\n\n6\nrmse\nstandard\n4.1555\n10\n0.3876\nPreprocessor1_Model06\n\n\n7\nrmse\nstandard\n4.1946\n10\n0.3897\nPreprocessor1_Model07\n\n\n\n\n\n\nk1 &lt;- knn1_flujo_tuned %&gt;% select_best(\"rmse\")\nknn2_receta &lt;- training(Boston_part) %&gt;%            \n  recipe(logmedv ~ chas + crim + zn + indus + nox + rm + \n          age + dis + rad + tax + ptratio + b + lstat) %&gt;% \n  step_dummy(chas) %&gt;% \n  step_center(all_predictors(), -all_nominal()) %&gt;% \n  step_scale(all_predictors(), -all_nominal())  \n\nknn2_flujo &lt;- workflow() %&gt;%\n  add_recipe(knn2_receta) %&gt;%\n  add_model(knn1_modelo)\n\nknn_grid &lt;- grid_regular(neighbors(range = c(1, 11), trans = NULL),   \n                          levels = 11)  \n\nset.seed(1)\nknn2_flujo_tuned &lt;- knn2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = knn_grid                          \n                          ) \n\nknn2_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=neighbors, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\nFigura 15. Ajuste de k vecinos, modelo 2\n\n\nknn2_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 16. k-vecinos óptimo en el Modelo 2\") %&gt;% kable_paper(\"hover\")\n\n\nTable 16. k-vecinos óptimo en el Modelo 2\n\n\nneighbors\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n5\nrmse\nstandard\n0.1722\n10\n0.0099\nPreprocessor1_Model05\n\n\n6\nrmse\nstandard\n0.1726\n10\n0.0104\nPreprocessor1_Model06\n\n\n4\nrmse\nstandard\n0.1726\n10\n0.0096\nPreprocessor1_Model04\n\n\n7\nrmse\nstandard\n0.1733\n10\n0.0107\nPreprocessor1_Model07\n\n\n8\nrmse\nstandard\n0.1745\n10\n0.0110\nPreprocessor1_Model08\n\n\n\n\n\n\nk2 &lt;- knn2_flujo_tuned %&gt;% select_best(\"rmse\")\nEl número óptimo de vecinos es\n\n\n\n\n\nneighbors\n\n\n.config\n\n\n\n\n\n\n4\n\n\nPreprocessor1_Model04\n\n\n\n\n\npara el primer modelo y\n\n\n\n\n\nneighbors\n\n\n.config\n\n\n\n\n\n\n5\n\n\nPreprocessor1_Model05\n\n\n\n\n\nen el segundo. Vamos a finalizar los modelos y ver sus métricas en la muestra de prueba.\nknn_final &lt;- list() \nknn_final[[1]] &lt;- knn1_flujo %&gt;% \n                    finalize_workflow(k1) %&gt;% \n                    last_fit(Boston_part)  %&gt;% \n                    collect_metrics(\"rmse\")\n\nknn_final[[2]] &lt;- knn2_flujo %&gt;% \n                    finalize_workflow(k2) %&gt;% \n                    last_fit(Boston_part)  %&gt;% \n                    collect_metrics(\"rmse\")\n\nknn_final %&gt;% bind_rows(.id = \"modelo\") %&gt;% \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 17. Métricas de kNN\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 17. Métricas de kNN\n\n\nmodelo\n.config\nrmse\nrsq\n\n\n\n\n1\nPreprocessor1_Model1\n4.2681\n0.7289\n\n\n2\nPreprocessor1_Model1\n0.2031\n0.7350\n\n\n\n\n\n\nComparando estos resultados con los de la Tabla 12, queda claro que kNN tiene una mejor capacidad predictiva, tanto para la variable de precio como usando el logaritmo del precio. Sin embargo, estos modelos no nos dicen mucho sobre qué factores afectan a esa predicción (no tenemos ni modelo paramétrico y contrastes, ni representación gráficas o medidas de importancia)."
  },
  {
    "objectID": "docs/Proyect01.html#árboles-de-regresión",
    "href": "docs/Proyect01.html#árboles-de-regresión",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Árboles de regresión",
    "text": "Árboles de regresión\nPasamos a considerar modelos de árboles de decisión. Notad que para ajustar el coste de complejidad puede ser necesario varios rangos. Dado que hemos visto que sistemáticamente el modelo con el logaritmo del precio predice mejor, nos centramos en ese modelo (aunque esto es obviamene una elección y quizás deberían probarse más).\narbol2_receta &lt;- training(Boston_part) %&gt;%            \n  recipe(logmedv ~ chas + crim + zn + indus + nox + rm + \n           age + dis + rad + tax + ptratio + b + lstat)\n\narbol2_modelo &lt;-  decision_tree(mode = \"regression\", \n                                     cost_complexity = tune()) %&gt;% \n                          set_engine(\"rpart\") \n\narbol2_flujo &lt;- workflow() %&gt;%\n  add_recipe(arbol2_receta) %&gt;%\n  add_model(arbol2_modelo)\n\narbol_grid &lt;- grid_regular(cost_complexity(range = c(0, 0.01), trans = NULL),   \n                          levels = 11)                     \nset.seed(1)\narbol2_flujo_tuned &lt;- arbol2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = arbol_grid                          \n                          ) \n\narbol2_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=cost_complexity, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\nFigura 16. Ajuste de árboles, modelo 2\n\n\narbol2_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 18. Coste de complejidad  en el Modelo 1\") %&gt;% kable_paper(\"hover\")\n\n\nTable 18. Coste de complejidad en el Modelo 1\n\n\ncost_complexity\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.002\nrmse\nstandard\n0.1898\n10\n0.0119\nPreprocessor1_Model03\n\n\n0.001\nrmse\nstandard\n0.1898\n10\n0.0122\nPreprocessor1_Model02\n\n\n0.000\nrmse\nstandard\n0.1899\n10\n0.0123\nPreprocessor1_Model01\n\n\n0.003\nrmse\nstandard\n0.1935\n10\n0.0123\nPreprocessor1_Model04\n\n\n0.004\nrmse\nstandard\n0.1971\n10\n0.0117\nPreprocessor1_Model05\n\n\n\n\n\n\ncost2 &lt;- arbol2_flujo_tuned %&gt;% select_best(\"rmse\")\narbol_final &lt;- arbol2_flujo %&gt;% \n                    finalize_workflow(cost2) %&gt;% \n                    last_fit(Boston_part)  \n\narbol_final %&gt;%  collect_metrics(\"rmse\") %&gt;%  \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 19. Métricas del árbol\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 19. Métricas del árbol\n\n\n.config\nrmse\nrsq\n\n\n\n\nPreprocessor1_Model1\n0.2064\n0.7394\n\n\n\n\n\n\nVemos que el mejor árbol de regresión no es mejor, a pesar de su flexibilidad, que el modelo de regresión lineal. Aun así podemos ver el flujo del árbol para hacernos una idea de qué factores están afectando a la predicción\narb &lt;- arbol_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() \n\nrpart.plot(arb$fit)\n\n\n\nFigura 17a. Mejor árbol de regresión, modelo 2\n\n\nTambién podemos recurrir a medidas de importancia de las variables.\narbol_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\nFigura 17b. Importancia en el mejor árbol de regresión, modelo 2\n\n\nEstos resultado son interesantes, más allá de su capacidad predictiva, porque son informativos son las interacciones entre distintas características. Como sabemos y podemos ver, los árboles trabajan discretizando las variables continuas discretizadas. Pero además implican distintas interacciones entre rangos de las variables para el resultado final. Por ejemplo, vemos que en los niveles superiores del árbol tenemos distintos niveles de población desfavorecida en el barrio, lstat; de hecho, vemos también (como era esperable) que es la variable con mayor valor de la importancia. Pero según los distintos valores de lstat importan diferentes características: cuando lstat es bajo (\\(&lt;10\\)) el precio viene determinado por el número de habitaciones de la vivienda, mientras que cuando es alto por la cantidad de contaminación o la proporición de gente de color en el vecindario."
  },
  {
    "objectID": "docs/Proyect01.html#random-forests",
    "href": "docs/Proyect01.html#random-forests",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Random Forests",
    "text": "Random Forests\nIntentamos ver si un modelo de “random forests” puede mejorar al árbol de regresión u otros modelos.\nrf2_receta &lt;- arbol2_receta \n\nrf2_modelo &lt;-  rand_forest(mode = \"regression\",\n                                       mtry = tune(), trees = 100) %&gt;% \n                          set_engine(\"ranger\", importance = \"impurity\")\n\nrf2_flujo &lt;- workflow() %&gt;%\n  add_recipe(rf2_receta) %&gt;%\n  add_model(rf2_modelo)\n\nrf_grid &lt;- grid_regular(mtry(range = c(1, 12), trans = NULL),   \n                          levels = 12)                     \n\nrf2_flujo_tuned &lt;- rf2_flujo %&gt;% \n                        tune_grid(\n                          resamples = Boston_cv,\n                          metrics   = metric_set(rmse),\n                          grid      = rf_grid                          \n                          ) \n\nrf2_flujo_tuned %&gt;% collect_metrics() %&gt;% \n  ggplot(aes(x=mtry, y=mean)) + \n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\") \n\n\n\nFigura 18. Ajuste de RF, modelo 2\n\n\nrf2_flujo_tuned  %&gt;% show_best(\"rmse\") %&gt;% \n  kbl(digits = 4, caption = \"Table 20. Ajuste de Random Forest  en el Modelo 2\") %&gt;% kable_paper(\"hover\")\n\n\nTable 20. Ajuste de Random Forest en el Modelo 2\n\n\nmtry\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n7\nrmse\nstandard\n0.1363\n10\n0.0086\nPreprocessor1_Model07\n\n\n9\nrmse\nstandard\n0.1368\n10\n0.0085\nPreprocessor1_Model09\n\n\n6\nrmse\nstandard\n0.1378\n10\n0.0085\nPreprocessor1_Model06\n\n\n8\nrmse\nstandard\n0.1383\n10\n0.0095\nPreprocessor1_Model08\n\n\n12\nrmse\nstandard\n0.1391\n10\n0.0091\nPreprocessor1_Model12\n\n\n\n\n\n\nmtry2 &lt;- rf2_flujo_tuned %&gt;% select_best(\"rmse\")\nEl número óptimo de variables a usar (aleatoriamente) en cada nodo son\n\n\n\n\n\nmtry\n\n\n.config\n\n\n\n\n\n\n7\n\n\nPreprocessor1_Model07\n\n\n\n\n\n, aunque podría ser alguna menos o algunas más, dado que los valores de la métrica de error no son significativamente diferentes.\nPor último finalizamos el modelo\nrf_final &lt;- rf2_flujo %&gt;% \n                    finalize_workflow(mtry2) %&gt;% \n                    last_fit(Boston_part)  \n\nrf_final %&gt;%  collect_metrics(\"rmse\") %&gt;%  \n  pivot_wider(names_from = .metric, values_from=.estimate) %&gt;% \n  select(-.estimator) %&gt;% \n  kbl(digits = 4, caption = \"Tabla 21. Métricas de RF\") %&gt;% kable_paper(\"hover\")\n\n\nTabla 21. Métricas de RF\n\n\n.config\nrmse\nrsq\n\n\n\n\nPreprocessor1_Model1\n0.1619\n0.824\n\n\n\n\n\n\nEl modelo de “Random Forest” incluso mejora claramente a “kNN”. En este caso, podemos ver qué variables han resultados mejores predictores del precio.\nrf_final$.workflow[[1]] %&gt;%   \n  extract_fit_parsnip() %&gt;% \n  vip(num_features = 14)\n\n\n\nFigura 19. Importancia en el mejor RF, modelo 2\n\n\nEste gráfico nos indica que la variable más importante (con diferencia) es la relacionada con la “pobreza” de la zona en la que se encuentra la casa. Después nos encontramos una característica de la casa en sí (número de habitaciones, aunque realmente es la media de la zona) y la criminalidad de la zona. No existe un criterio formal para decidir en que punto parar determinar qué variables son importantes. Quizás en este caso se puede “argumentar” que hay una caída mayor de la importancia después de la contaminación de la zona, la calidad de las escuelas y la distancia al centro."
  },
  {
    "objectID": "docs/Proyect01.html#footnotes",
    "href": "docs/Proyect01.html#footnotes",
    "title": "Predicción de precios de las casas en Boston",
    "section": "Notas",
    "text": "Notas\n\n\nPor eso existen competiciones (“hackatones”) para ver quién predice mejor con los mismos datos: si existiera una receta, ganaría un ordenador.↩︎"
  },
  {
    "objectID": "docs/Tema05.html#de-los-datos-en-bruto-a-la-información",
    "href": "docs/Tema05.html#de-los-datos-en-bruto-a-la-información",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "De los datos en bruto a la información",
    "text": "De los datos en bruto a la información\n\n\n\nAED es una fase inicial importante\n\nconocer nuestros datos (qué variables, tipo de información, calidad)\nencontrar escenarios de análisis\n\n\n\n\n\n\n\n\n\n\nNO hay una “receta”: el proceso es diferente con distintos datos o con los mismos datos para diferentes objetivos\nEs un proceso iterativo y creativo para descubrir información\n\nDada una pregunta, exploramos para aprender información útil, por sí misma o para posteriormente modelizar\nPERO lo aprendido también refinar las preguntas y/o generar nuevas"
  },
  {
    "objectID": "docs/Tema05.html#primera-aproximación-a-los-datos",
    "href": "docs/Tema05.html#primera-aproximación-a-los-datos",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Primera aproximación a los datos",
    "text": "Primera aproximación a los datos\n\nContexto: conocimiento previo de nuestros datos, aquí o aquí\n\nfuente (de dónde han salido), cómo están almacenados (.csv, .xlsx, …)\n“diccionario”: información de cada variable (descripción, unidades, etc.)\n\n\n\nCargar los datos\n\n\nBank &lt;- read_csv2(\"data/BankMarketing.csv\")\nBoston &lt;- read_csv(\"data/BostonHousing.csv\")\n\n\nReconocimiento inicial de las características de los datos: número de observaciones y de variables, tipo de cada variable, etc.\n\n\n\n\nglimpse(Bank)  # str(Bank)\n\n\n\n\nView(Bank)     # head(Bank)\n\n\n\n\nNO TODO lo que hagamos se incluirá en un documento para comunicar"
  },
  {
    "objectID": "docs/Tema05.html#primera-aproximación-a-los-datos-cont.",
    "href": "docs/Tema05.html#primera-aproximación-a-los-datos-cont.",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Primera aproximación a los datos (cont.)",
    "text": "Primera aproximación a los datos (cont.)\n\nLimpiar y procesar los datos:\n\nDebemos asegurarnos de que los datos son ordenados\n¿Tienen las variables la información y el tipo adecuado? Convertimos datos a factores, numéricas, etc.\nTransformamos variables (logaritmos, discretizar variables continuas), creamos nuevas o renombramos para mayor claridad\n¿Mantenemos solo algunas variables u observaciones?\n\nUn caso destacado: ¿cuántos NA? ¿qué hacer con ellos?\n\n\n\n\nBank %&gt;%  is.na() %&gt;% summary()\n#\n\n\n\n\nload(\"data/earn.RData\")\nearn %&gt;% is.na() %&gt;% summary()\n\n\n\n\nNO ES UNA RECETA: más adelante puede que volvamos hacia atrás o rehagamos parte de esto y decidiremos sobre NAs al modelizar"
  },
  {
    "objectID": "docs/Tema05.html#variación-análisis-univariante",
    "href": "docs/Tema05.html#variación-análisis-univariante",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Variación (“análisis univariante”)",
    "text": "Variación (“análisis univariante”)\n\nVariación: tendencia de los valores de una variable a cambiar entre medidas \n\np.e., nivel educativo de dos personas (cualitativa) o ventas de dos empresas (continua)\n\nCada variable tiene su propio patrón de variación: esta información relevante se obtiene analizando su distribución de valores, númerica o gráficamente\n\nsummary() para calcular estadísticos básicos, y complementer con otros (varianza, percentiles, asimetría y kurtosis, etc.)\ncount() o table() (para frecuencias) y summarize() (con funciones para estadísticos)\n\n\n\nsummary(Bank)\n\n\nNotar que el análisis es diferente para variables categóricas y numéricas: es conveniente describirlas por separado en un documento final"
  },
  {
    "objectID": "docs/Tema05.html#visualizando-distribuciones",
    "href": "docs/Tema05.html#visualizando-distribuciones",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Visualizando distribuciones",
    "text": "Visualizando distribuciones\n\nPara Variables Categóricas, usamos histogramas (gráficos de barras):\n\n\ng0 &lt;- ggplot(data = Bank) \ng0 + geom_bar(aes(x = job)) + theme(axis.text.x = element_text(angle = 90))\ng0 + geom_bar( aes(x = \"\", fill = education))\n\n\nPara variables continuas, usar un histograma o densidad (o ambos)\n\n\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 5)\ng0 + geom_density(mapping = aes(x = balance)) + scale_x_log10()\nBoston %&gt;%  ggplot(aes(x=medv)) + \n  geom_histogram(aes(y=..density..)) + geom_density() \n\n\nConsideramos varios anchos del intervalo: pueden revelar diferentes patrones\n\n\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 1)\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 10)"
  },
  {
    "objectID": "docs/Tema05.html#visualizando-distribuciones-cont.",
    "href": "docs/Tema05.html#visualizando-distribuciones-cont.",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Visualizando distribuciones (cont.)",
    "text": "Visualizando distribuciones (cont.)\n\nLos gráficos de caja también aportan información para distribuciones continuas\n\n\nggplot(Boston) + geom_boxplot(mapping = aes(y = medv))"
  },
  {
    "objectID": "docs/Tema05.html#aspectos-a-prestar-atención",
    "href": "docs/Tema05.html#aspectos-a-prestar-atención",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Aspectos a prestar atención",
    "text": "Aspectos a prestar atención\n\nValores frecuentes, concentración en valores concretos (p.e., ceros, números “redondos”, etc.): ¿por qué se producen? ¿son “esperables”?\n\n\n¿Tienen sentido las categorías de las variables cualitativas?\n\nagrupar valores con pocas observaciones\ncrear categorías más “finas”o más agregadas (ej. de países a continentes)\n\n\n\n¿Sería preferible discretizar alguna variable continua?\nVariables con alta dispersión o distribución asimétrica (logs?)\n\n\nVariables con información redundante, homogeneizar valores, normalidad(?)\n\n\nValores inusuales (“atípicos” o “outliers”): no encajan en el patrón general\n\n¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?"
  },
  {
    "objectID": "docs/Tema05.html#otras-herramientas-para-aed",
    "href": "docs/Tema05.html#otras-herramientas-para-aed",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Otras herramientas para AED",
    "text": "Otras herramientas para AED\n\nBiblioteca skimr\n\n\nlibrary(skimr)\nskim(Bank)   # ¿para incluir en un informe?\n\n\nBiblioteca DataExplorer\n\n\nlibrary(DataExplorer)\nplot_bar(Bank)        # para TODAS las variables categóricas\nplot_histogram(Bank)  # para TODAS las variables numéricas\n\n\nÚtiles para una primera aproximación automática (qué patrones existen, qué cambiar), pero probablemente NO para incluir en un informe final"
  },
  {
    "objectID": "docs/Tema05.html#otras-herramientas-dlookr",
    "href": "docs/Tema05.html#otras-herramientas-dlookr",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Otras herramientas: dlookr",
    "text": "Otras herramientas: dlookr\n\ndescribe(): estadísticos como un data frame, para usar con kable()\n\n\nlibrary(dlookr)            # en MacOS, puede pedir instalar XQuartz\ndescribe(Bank, campaign:y)\n\nBank %&gt;% describe() %&gt;%\n  select(described_variables, skewness, mean, p25, p50, p75) %&gt;% \n  filter(!is.na(skewness)) %&gt;% arrange(desc(abs(skewness)))\n\nBank %&gt;%\n  group_by(education) %&gt;% \n  describe(age, balance, campaign, pdays) \n\n\nearn %&gt;% eda_web_report()"
  },
  {
    "objectID": "docs/Tema05.html#covariación-análisis-multivariante",
    "href": "docs/Tema05.html#covariación-análisis-multivariante",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Covariación: análisis multivariante",
    "text": "Covariación: análisis multivariante\n\nLa variación describe el comportamiento dentro de una variable\nLa covariación describe relaciones entre variables: tendencia a que sus valores cambien juntos\nÚtil para formular modelos, que explican patrones complejos de los datos\n\n¿qué explica la relación sugerida por el patrón de covariación?\n¿cómo de fuerte es la relación?\n¿otras variables pueden afectar a la relación? ¿varían por subgrupos?\n\nCovariación implica que los valores de una variable se pueden predecir a partir de otra\n\n¿es la covariación una relación causal?"
  },
  {
    "objectID": "docs/Tema05.html#una-variable-continua-y-una-categórica",
    "href": "docs/Tema05.html#una-variable-continua-y-una-categórica",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Una variable continua y una categórica",
    "text": "Una variable continua y una categórica\n\n¿Es diferente la distribución de Y (continua) por categorías de X? Si \\(\\small{\\Pr(Y|X=x_1) = \\Pr(Y|X=x_0) = \\Pr(Y)} \\Rightarrow\\) Y NO depende de X\n\n1.- mediante el histograma o densidad (en el mismo gráfico o diferentes)\n\n\nggplot(Bank) + geom_density(aes(x = balance, color = default))  + scale_x_log10()\nggplot(Bank) + geom_density(aes(x = balance)) + facet_wrap(~default)  + scale_x_log10()\nggplot(Boston) + geom_density(aes(x=lstat, color=as.factor(chas))) \n\n\n2.- mediante gráficos de caja: menos información pero más fácil de comparar\n\nggplot(Boston) + geom_boxplot(aes(x=medv, y=as.factor(chas)))\nggplot(Bank) + geom_boxplot(aes(x=duration, y=as.factor(y)))\n\n\nSi un grupo es mucho más pequeño, es difícil ver las diferencias\nSe pueden necesitar reordenar las categorías de un factor, rotar los ejes, etc."
  },
  {
    "objectID": "docs/Tema05.html#correlación-entre-una-variable-continua-y-una-categórica",
    "href": "docs/Tema05.html#correlación-entre-una-variable-continua-y-una-categórica",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "“Correlación” entre una variable continua y una categórica",
    "text": "“Correlación” entre una variable continua y una categórica\n\nLa regresión simple también describe una relación: equivale a calcular la media de la variable continua por grupos definidos por la categórica\n\n\\[\nE[Y|X]=\\beta_0+\\beta_1 X \\Rightarrow\n\\begin{cases}\nE[Y|X=0] &=\\beta_0 \\\\\nE[Y|X=1]&=\\beta_0+\\beta_1\n\\end{cases}\n\\]\n\nsummary(lm(data = Bank, balance ~ default))\nBank %&gt;% group_by(default) %&gt;% summarise(media = mean(balance))\n\nBank %&gt;% group_by(y) %&gt;% summarise(media = mean(duration))\n\n\n¿Mediante la correlación? NO tiene sentido cuando una variable es categórica\n\n\nPara variables dependientes categóricas veremos una variante de regresión lineal: regresión logística"
  },
  {
    "objectID": "docs/Tema05.html#dos-variables-categóricas",
    "href": "docs/Tema05.html#dos-variables-categóricas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables categóricas",
    "text": "Dos variables categóricas\n\n\nTabular/visualizar el número de observaciones para cada combinación\n\n\nBank %&gt;% count(job, education) %&gt;% pivot_wider(names_from = education, values_from = n)\nggplot(Bank, aes(y=job, x=education)) + geom_count() \nggplot(Bank, aes(y=job, x=education)) + geom_count(aes(size=after_stat(prop), group=1)) \n\n\nTambién se pueden visualizar sus histogramas\n\n\nBank %&gt;%  ggplot(aes(x=y)) + geom_bar(aes(fill=education)) \nBank %&gt;%  ggplot(aes(x=y)) + geom_bar(aes(fill=education), position=\"dodge2\")\nBank %&gt;%  ggplot(aes(x=y)) + geom_bar()+ facet_wrap(~education)\n\n\nO los histogramas de proporciones generados manualmente\n\n\nBank %&gt;% group_by(education, y) %&gt;% summarise(n=n()) %&gt;%  \n   group_by(education) %&gt;% mutate(prop=n/sum(n)) %&gt;% \n   ggplot() + geom_bar(aes(x=education, y = prop), stat =\"identity\") + facet_wrap(~y)"
  },
  {
    "objectID": "docs/Tema05.html#dos-variables-continuas",
    "href": "docs/Tema05.html#dos-variables-continuas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables continuas",
    "text": "Dos variables continuas\n\nLa forma obvia de visualizar relaciones entre variables continuas es un gráfico de dispersión; añadir smoothers ayuda a apreciar un patrón en los puntos\n\n\nggplot(Boston, aes(y=medv, x=lstat)) + geom_point() + geom_smooth()\nggplot(Boston, aes(y=medv, x=lstat)) + geom_point() + geom_smooth() +\n  scale_y_log10()\n\n\nlibrary(GGally)\nBoston %&gt;% ggpairs()\n\n\nOtra opción categorizar una variable continua y usar las técnicas anteriores\n\n\nggplot(Bank) + geom_boxplot(aes(x= balance, y=cut_width(age, 10)))  +\n  scale_x_log10()\nBank %&gt;% mutate(agegroup=cut(age, breaks=seq(20, 70, by=10))) %&gt;% \n  ggplot()  + geom_boxplot(aes(x= balance, y =agegroup))"
  },
  {
    "objectID": "docs/Tema05.html#correlación-entre-variables-continuas",
    "href": "docs/Tema05.html#correlación-entre-variables-continuas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Correlación entre variables continuas",
    "text": "Correlación entre variables continuas\n\nObviamente podemos calcular modelos de regresión con dos variables continuas\n\n\nsummary(lm(data = Boston, medv ~ lstat) )\n\n\nY también correlaciones (dos variables, múltiples, visualizándolas)\n\n\ncor(Boston$medv, Boston$lstat, use = \"complete.obs\")\nBoston %&gt;% select(medv, lstat) %&gt;%  dlookr::correlate()\n\nBoston %&gt;%  dlookr::correlate()\nBoston %&gt;%  group_by(chas) %&gt;%  dlookr::correlate() %&gt;% plot()\n\nlibrary(corrplot)\ncorrplot(cor(Boston))\ncorrplot.mixed(cor(Boston))"
  },
  {
    "objectID": "docs/Tema05.html#más-herramientas-de-aed-automático",
    "href": "docs/Tema05.html#más-herramientas-de-aed-automático",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Más herramientas de AED “automático”",
    "text": "Más herramientas de AED “automático”\n\nMuchas partes del AED son parcialmente “automatizables”: muchos paquetes tratan de facilitar esas partes\nRadiant, que puede probarse online\nGwalkR, explore\n\n\nlibrary(GWalkR)\ndata(iris)\ngwalkr(iris)\n\n\nDataMaid, smartEDA\n\n\nlibrary(dataMaid)\nmakeDataReport(Bank, output = \"pdf\", replace = TRUE)\n\n\nOtras partes y sobre la interpretación del AED es muy específica de los datos y del objetivo del estudio"
  },
  {
    "objectID": "docs/Tema10ej.html",
    "href": "docs/Tema10ej.html",
    "title": "Tema 10. Ejercicio.",
    "section": "",
    "text": "Usamos los datos del Censo de EE.UU.:\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;% \n  mutate(income=factor(income))\n\nTenemos información de 15 variables relevantes:\n\n\n\nage\nedad\n\n\nworkclass\ntipo de trabajo del individuo\n\n\nfnlwgt\npeso en el censo (no relevante)\n\n\neducation\nnivel educativo\n\n\neducation_1\naños de educación\n\n\nmarital_status\nestado civil\n\n\noccupation\nprofesión de la persona\n\n\nrelationship\nrelación con el principal miembro del hogar\n\n\nrace\norigen racial de la persona\n\n\nsex\ngénero\n\n\ncapital_gain\nganancias de capital\n\n\ncapital_loss\npérdidas de capital\n\n\nhours_per_week\nhoras trabajadas a la semana\n\n\nnative_country\npaís de origen\n\n\nIncome\nrenta mayor o menor de 50 mil dólares\n\n\n\n\n\n\nEn este ejercicio NO vamos a desarrollar explícitamente el análisis exploratorio de datos. Pero siempre debemos conocer las características de nuestros datos, incluidas la distribución de valores de las variables y las relaciones entre ellas. Además, deberíamos haber realizado un proceso de limpieza y transformación de los datos, en parte sugerido por este análisis exploratorio.\n\n\n\n\nset.seed(9753)\ncenso_part &lt;- censo %&gt;% initial_split(prop = .8)\n\n\n\n\nEn este ejercicio, usaremos la misma especificación inicial: la categoría de renta va a depender edad, educación (education_1), ganancias de capital, horas trabajadas, género y raza.\nEn general, debería justificarse las variables incluidas (p.e., por los resultados del análisis exploratorio) y considerar variantes."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-a",
    "href": "docs/Tema10ej.html#apartado-a",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado a)",
    "text": "Apartado a)\n\nPreparar los datos según las necesidades para estimar el modelo kNN.\n\nNOTA: podemos usar step_dummy() con la opción one_hot = TRUE para que NO se omita un grupo por defecto en los factores"
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-b",
    "href": "docs/Tema10ej.html#apartado-b",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado b)",
    "text": "Apartado b)\n\nObtener mediante validación cruzada el ajuste óptimo del número de vecinos. Nota: usaremos como distancia la norma L2 (dist_power = 2) y como motor la biblioteca kknn.\n\n\nmodelo_knn_tuned &lt;- nearest_neighbor(mode= \"classification\", \n                                     neighbors = tune(), dist_power = 2) %&gt;% \n                set_engine(\"kknn\")\n\n\nProbad primero con un rango de valores para los vecinos entre 60 y 100 en incrementos de 10 y mostrar el resultado.\nAjustar vuestro rango de búsqueda del valor óptimo, teniendo siempre en cuenta que kNN es muy muy lento.\n\nNOTA: puede ser resultar conveniente hacer pruebas sin renderizar el documento .Qmd."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-c",
    "href": "docs/Tema10ej.html#apartado-c",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado c)",
    "text": "Apartado c)\n\nEstimar el modelo con el hiperparámetro elegido y mostrar las métricas de error en la muestra de prueba. ¿Qué interpretación podemos extraer sobre los resultados? ¿Qué ventajas y desventajas tiene este método respecto al anterior?"
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-a-1",
    "href": "docs/Tema10ej.html#apartado-a-1",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado a)",
    "text": "Apartado a)\n\nPreparar los datos según las necesidades para estimar este modelo."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-b-1",
    "href": "docs/Tema10ej.html#apartado-b-1",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado b)",
    "text": "Apartado b)\n\nObtener mediante validación cruzada el ajuste óptimo del coste de complejidad.\n\n\nmodelo_arbol &lt;- decision_tree(mode= \"classification\", cost_complexity = tune()) %&gt;% \n  set_engine(\"rpart\")\n\n\nNuevamente elegid cuidadosamente el rango de valores para el hiperparámetro y mostrar un gráfico final donde se aprecie con claridad que tenemos un óptimo."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-c-1",
    "href": "docs/Tema10ej.html#apartado-c-1",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado c)",
    "text": "Apartado c)\n\nEstimar el modelo con el hiperparámetro elegido.\nRepresentar gráficamente el árbol obtenido y la importancia de cada variables.\nInterpretar los resultados y discutir las diferencias, ventajas y desventajas respecto a los resultados de los métodos anteriores."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-d",
    "href": "docs/Tema10ej.html#apartado-d",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado d)",
    "text": "Apartado d)\n\nMostrar las métricas de error en la muestra de prueba."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-a-2",
    "href": "docs/Tema10ej.html#apartado-a-2",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado a)",
    "text": "Apartado a)\n\nPreparar los datos según las necesidades para estimar este modelo."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-b-2",
    "href": "docs/Tema10ej.html#apartado-b-2",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado b)",
    "text": "Apartado b)\n\nObtener mediante validación cruzada el ajuste óptimo del número de variables seleccionadas aleatoriamente para hacer la partición en cada nodo. Usamos cien árboles para este método (esto es, se toman cien re-muestras de boostrap) y usamos la biblioteca ranger.\n\n\nmodelo_RF &lt;- rand_forest(mode= \"classification\", mtry = tune(), trees = 100) %&gt;% \n  set_engine(\"ranger\", importance = \"impurity\")\n\n\nNuevamente elegid cuidadosamente el rango de valores para el hiperparámetro y mostrar un gráfico final donde se aprecie con claridad que tenemos un óptimo."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-c-2",
    "href": "docs/Tema10ej.html#apartado-c-2",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado c)",
    "text": "Apartado c)\n\nEstimar el modelo con el hiperparámetro elegido.\nRepresentar la importancia de cada variables.\nInterpretar los resultados y discutir las diferencias, ventajas y desventajas respecto a los resultados de los métodos anteriores."
  },
  {
    "objectID": "docs/Tema10ej.html#apartado-d-1",
    "href": "docs/Tema10ej.html#apartado-d-1",
    "title": "Tema 10. Ejercicio.",
    "section": "Apartado d)",
    "text": "Apartado d)\n\nMostrar las métricas de error en la muestra de prueba."
  },
  {
    "objectID": "docs/Tema04.html#introducción",
    "href": "docs/Tema04.html#introducción",
    "title": "Tema 04 - Visualización de datos",
    "section": "Introducción",
    "text": "Introducción\n\nLa visualización es una forma de obtener información que no se vería en los datos en bruto (en una hoja de cálculo)\n\nposición central, dispersión, valores extremos\nidentificar patrones\n\nEn un buen gráfico, la audiencia encuentra obvias las ideas a transmitir, sin abrumar con muchos hallazgos\n\n\nUsaremos la biblioteca ggplot2, basada en la Gramática de Gráficos (Wilkinson, 2005)\n\nalgunos gráficos simples requieren más opciones que en R base\nPERO ofrece facilidades para gráficos complejos y profesionales\n\n\n\nOtras bibliotecas: rgl (gráfics 3D), ggvis (interactivos), plotly"
  },
  {
    "objectID": "docs/Tema04.html#elementos-básicos-de-un-gráfico-de-datos",
    "href": "docs/Tema04.html#elementos-básicos-de-un-gráfico-de-datos",
    "title": "Tema 04 - Visualización de datos",
    "section": "Elementos básicos de un gráfico de datos",
    "text": "Elementos básicos de un gráfico de datos\n\nSeñales visuales: posición, longitud, área, etc.\nSistema de coordenadas: ¿cómo se organizan los puntos de datos?\n\ncartesiano, polar, geográfico\n\nEscala: ¿cómo se traduce la distancia en algo con significado?\n\nnumérica lineal, numérica logarítmica, categórica, de tiempo\n\nContexto: ¿en relación con qué?\n\ntítulos, leyendas, etiquetas de ejes, puntos/líneas de referencia\n\nOtros: facetas/pequeños múltiplos, capas, animaciones, etc.\n\n\n“Por encima de todo, mostrar los datos”"
  },
  {
    "objectID": "docs/Tema04.html#señales-visuales",
    "href": "docs/Tema04.html#señales-visuales",
    "title": "Tema 04 - Visualización de datos",
    "section": "Señales Visuales",
    "text": "Señales Visuales"
  },
  {
    "objectID": "docs/Tema04.html#la-gramática-de-gráficos",
    "href": "docs/Tema04.html#la-gramática-de-gráficos",
    "title": "Tema 04 - Visualización de datos",
    "section": "La “Gramática de Gráficos”",
    "text": "La “Gramática de Gráficos”\n\nEspecificar bloques independientes y combinarlos para crear cualquier visualización gráfica, como las frases a partir de nombres, verbos, objetos, etc.\nBloques de construcción de un gráfico\n\nDatos: data\nObjeto geométrico (qué dibujamos: líneas, puntos, barras, etc.): geom_*()\nAtributos estéticos (del objeto geométrico, como posición, color, forma, tamaño) que transmiten información de una variable: aes()\nEscalas (rango of valores, colores, etc.): scale_*()\nSistema de Coordenadas\nFacetas (pequeños múltiplos): facet_wrap(), facet_grid()"
  },
  {
    "objectID": "docs/Tema04.html#creando-un-ggplot",
    "href": "docs/Tema04.html#creando-un-ggplot",
    "title": "Tema 04 - Visualización de datos",
    "section": "Creando un “ggplot”",
    "text": "Creando un “ggplot”\n\nggplot(data = mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\nggplot(data = mpg) = gráfico vacío (coordenadas cartesianas, por defecto)\nAñadir capas con +: ej., objeto geométrico del tipo puntos = geom_point()\nEl argumento mapping, asociado a aes(), define cómo las variables son asignadas a propiedades visuales\n\nx e y especifican qué variables asignar a cada eje\n\n\n\nNOTA: el primer código define datos y estética para todas las capas que siguen; el segundo solo para el objeto geométrico de puntos."
  },
  {
    "objectID": "docs/Tema04.html#objetos-geométricos",
    "href": "docs/Tema04.html#objetos-geométricos",
    "title": "Tema 04 - Visualización de datos",
    "section": "Objetos geométricos",
    "text": "Objetos geométricos\n\nCada geom_*() agrega un tipo diferente de capa/marcas en el gráfico \n\npuntos (geom_point, para diagramas de dispersión, de puntos, etc.)\nlíneas (geom_line, para series de tiempo, líneas de tendencia, etc.)\ndiagrama de caja (geom_boxplot)\netc.\n\n\n\nPara una lista de objetos geométricos disponibles, buscar las funciones que comienzan con geom_ en la Ayuda"
  },
  {
    "objectID": "docs/Tema04.html#elementos-estéticos-con-aes",
    "href": "docs/Tema04.html#elementos-estéticos-con-aes",
    "title": "Tema 04 - Visualización de datos",
    "section": "Elementos Estéticos con aes()",
    "text": "Elementos Estéticos con aes()\n\nElementos estéticos son “algo que se puede ver” (información)\nCada elemento estético con aes() es un asociación (“mapping”) entre una señal visual y una variable\n\nposición (p.e., en los ejes x e y)\ncolor (color “exterior”)\nrelleno (color “interior”), fill\nforma (de los puntos), shape\ntipo de línea,\ntamaño, size\n\nCada geom acepta solo un subconjunto de todos los elementos estéticos.\n\nEn la ayuda de cada geom se puede ver qué asignaciones acepta en aes()."
  },
  {
    "objectID": "docs/Tema04.html#esquisse-una-interfaz-gráfica",
    "href": "docs/Tema04.html#esquisse-una-interfaz-gráfica",
    "title": "Tema 04 - Visualización de datos",
    "section": "esquisse: una interfaz gráfica ",
    "text": "esquisse: una interfaz gráfica \n\nesquisse implementa de forma visual (“arrastrar y soltar”) la lógica de composición de gráficos de ggplot2\n\nOtras herramientas como Tableau o PowerBI o Gapminder siguen la misma idea\n\nEjecutamos esquisser() para crear el gráfico, eligiendo datos \n\n\n#install.packages(\"esquisse\")\nlibrary(esquisse)\nesquisser()                         \n\ndata(\"mpg\")\nesquisser(mpg, viewer = \"browser\")   # lanzar visor externo   \n\n\nSe pueden elegir muchos (no todos) aspectos del gráfico que veremos en este tema: tipo de gráfico, asignaciones estéticas, títulos, apariencia, etc.\nGenera un posible código de R que crea el gráfico\n\n\nTambién se puede descargar el gráfico creado"
  },
  {
    "objectID": "docs/Tema04.html#gráficos-como-objetos-de-r",
    "href": "docs/Tema04.html#gráficos-como-objetos-de-r",
    "title": "Tema 04 - Visualización de datos",
    "section": "Gráficos como objetos de R",
    "text": "Gráficos como objetos de R\n\nhousing   &lt;- read_csv(\"data/landdata-states.csv\")\nhp2001Q1  &lt;- housing[housing$Date == 2001.00,] \ngraf_base &lt;- ggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n                geom_point()\n\n\nSe pueden agregar capas a este objeto gráfico y mostrarlo\n\n\ngraf_base + geom_line()                  # ¿tiene sentido este gráfico?\ngraf_base + geom_point(aes(shape = region)) \n\n\nAñadimos una señal visual de formas (o color, etc.), NO para “embellecer” sino para representar la información de una variable adicional\nNO saturar el gráfico con estéticas fijas o información innecesaria\n\n\ngraf_base + geom_point(aes(size = Home.Price.Index,   \n                 color=Home.Value))      # ¿qué aportan estas variables?"
  },
  {
    "objectID": "docs/Tema04.html#asociación-estética-y-asignación-de-opción-fija",
    "href": "docs/Tema04.html#asociación-estética-y-asignación-de-opción-fija",
    "title": "Tema 04 - Visualización de datos",
    "section": "Asociación estética y Asignación de opción fija",
    "text": "Asociación estética y Asignación de opción fija\n\nUna asociación (“mapping”) estética, con aes(), visualiza una variable\n\n\nUna opción estética establece, fuera de aes(), un valor fijo de la señal visual\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(shape = \"cross\",  color=\"red\")   \n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(aes(shape = region, color=Home.Value))\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(aes(shape = region, color=Home.Value),\n             size = 3)\n\n\nNota: region, carácter convertido a factor, se representa en escala categórica"
  },
  {
    "objectID": "docs/Tema04.html#más-geoms-smoothers-y-texto",
    "href": "docs/Tema04.html#más-geoms-smoothers-y-texto",
    "title": "Tema 04 - Visualización de datos",
    "section": "Más geoms: “Smoothers” y Texto",
    "text": "Más geoms: “Smoothers” y Texto\n\nNo todos los geoms son formas simples: aquí, por defecto, una línea (función no lineal estimada) y un área (intervalo de confianza de la predicción)\n\n\ngraf_base + geom_smooth()\ngraf_base + geom_smooth(method = lm, se = FALSE)  \n\n\nCada geom acepta un conjunto particular de asignaciones: geom_text() acepta etiquetas\n\n\ngraf_base + geom_text(aes(label=State), size = 3)\n\n\nSi queremos el punto y la etiqueta de texto\n\n\n#install.packages(\"ggrepel\") \nlibrary(ggrepel)\ngraf_base + geom_text_repel(aes(label=State), size = 3)"
  },
  {
    "objectID": "docs/Tema04.html#comentario",
    "href": "docs/Tema04.html#comentario",
    "title": "Tema 04 - Visualización de datos",
    "section": "Comentario",
    "text": "Comentario\n\nCada objeto geométrico puede tener características propias\n\nusar datos distintos para diferentes objetos,\nutilizar diferentes estéticas en distintos objetos, etc..\n\nPor ejemplo, usamos solo un subconjunto de los datos para el objeto geométrico de texto\n\n\ngraf_base + geom_point() + \n  geom_text_repel(\n    data = hp2001Q1 %&gt;% filter(State %in% c(\"NY\",\"NJ\",\"KY\")), \n    mapping = aes(label=State), size = 3)"
  },
  {
    "objectID": "docs/Tema04.html#transformaciones-estadísticas",
    "href": "docs/Tema04.html#transformaciones-estadísticas",
    "title": "Tema 04 - Visualización de datos",
    "section": "Transformaciones Estadísticas",
    "text": "Transformaciones Estadísticas\n\nEn algunos gráficos, como el de dispersión, cada punto grafica unas coordenadas (x e y) iguales al valor original de las variables a representar (aunque podemos transformarlas)\n\n\nggplot(hp2001Q1, aes(x = log(Land.Value), y = Structure.Cost)) + \n      geom_point()\n\n\nOtros gráficos representan estadísticas obtenidas a partir de las variables (no las variables directamente)\n\n\n\n\nPara “smoother”, se calcula una regresión\nPara un gráfico de caja, se calculan estadísticos descriptivos\n\n\nggplot(hp2001Q1, \n       aes(y = Home.Value/1000)) +  \n  geom_boxplot()"
  },
  {
    "objectID": "docs/Tema04.html#modificar-las-transformaciones-estadísticas",
    "href": "docs/Tema04.html#modificar-las-transformaciones-estadísticas",
    "title": "Tema 04 - Visualización de datos",
    "section": "Modificar las Transformaciones Estadísticas",
    "text": "Modificar las Transformaciones Estadísticas\n\nEn geoms que representan estadísticas, podemos cambiar qué calcular o cuáles representar\nUn histograma (variables continuas) depende de qué intervalos definamos para calcular las frecuencias: podemos cambiar el número de grupos (bins) o su ancho (binwidth) o fijar los rangos (breaks)\n\n\ngraf &lt;- ggplot(housing, aes(x = Home.Value))\ngraf + geom_histogram(stat = \"bin\", binwidth=4000)\ngraf + geom_histogram(stat = \"bin\", bins=40)\n\n\nTambién podemos representar la densidad, en lugar de frecuencias absolutas\n\n\ngraf + geom_histogram(stat = \"density\" )  \ngraf + geom_histogram(aes(y=..density..)) + geom_density() # o ambas\n\n\nEn un gráfico de barras (variables discretas), por defecto se calculan frecuencias de una variable, pero podemos querer representar el valor de otra variable:\n\n\nggplot(housing, aes(x = region)) + geom_bar()\nhousing %&gt;% count(region) %&gt;% mutate(prop = n/sum(n)) %&gt;% \n  ggplot(aes(x = region, y = prop)) + geom_bar(stat = \"identity\")"
  },
  {
    "objectID": "docs/Tema04.html#escalas-control-de-la-asociación-estética",
    "href": "docs/Tema04.html#escalas-control-de-la-asociación-estética",
    "title": "Tema 04 - Visualización de datos",
    "section": "Escalas: control de la asociación estética",
    "text": "Escalas: control de la asociación estética\n\naes() establece la variable asignada, no cómo se representa\n\naes(shape = region): qué forma para cada región\naes(color = Home.Value): qué color para cada valor\n\nLas funciones para modificar la escala siguen el esquema scale_&lt;estética&gt;_&lt;tipo&gt;\n\n\nArgumentos habituales para la escala:\n\nname: título de la escala (en eje o leyenda)\nlimits: el mínimo y el máximo de la escala\nbreaks: valores donde deberían aparecer las etiquetas\nlabels: las etiquetas que aparecen en cada break\n\nFunciones específicas de escala pueden tener argumentos adicionales"
  },
  {
    "objectID": "docs/Tema04.html#ejemplos-de-modificación-de-escala",
    "href": "docs/Tema04.html#ejemplos-de-modificación-de-escala",
    "title": "Tema 04 - Visualización de datos",
    "section": "Ejemplos de modificación de escala",
    "text": "Ejemplos de modificación de escala\n\ng2 &lt;- ggplot(housing, aes(y = State, x = Home.Price.Index)) + \n  geom_point(aes(color = Date))\n\n\nCambiamos las etiquetas para el eje vertical\n\n\ng2 &lt;- g2 + scale_y_discrete(name=\"Abrev. Estado\")\n\n\nModificamos breaks, etiquetas y colores de la escala de color\n\n\ng2 + scale_color_continuous(breaks = c(1975.00, 1994.00, 2013.00),\n            labels = c(1975, 1994, 2013), low = \"blue\", high = \"red\")\n\n\nUna escala diferente para color, interpolando entre tres colores\n\n\ng2 + scale_color_gradient2(breaks = c(1975.00, 1994.00, 2013.00),\n                           labels = c(1975, 1994, 2013),\n                        low = \"blue\", high = \"red\", mid = \"gray60\", \n                        midpoint = 1994.00)"
  },
  {
    "objectID": "docs/Tema04.html#listado-parcial-de-escalas-disponibles",
    "href": "docs/Tema04.html#listado-parcial-de-escalas-disponibles",
    "title": "Tema 04 - Visualización de datos",
    "section": "Listado (parcial) de escalas disponibles",
    "text": "Listado (parcial) de escalas disponibles"
  },
  {
    "objectID": "docs/Tema04.html#facetas-pequeños-múltiplos",
    "href": "docs/Tema04.html#facetas-pequeños-múltiplos",
    "title": "Tema 04 - Visualización de datos",
    "section": "Facetas (pequeños múltiplos)",
    "text": "Facetas (pequeños múltiplos)\n\nPara facilitar la comparación de gráficos (no solo objetos geométricos), se divide en subgráficos para distintos subconjuntos de los datos\n\n\ngraf_estad &lt;- ggplot(housing, aes(x = Date, y = Home.Value))\ngraf_estad +  geom_line(aes(color = State))        # gráfico confuso\n\n\nfacet_wrap() para facetas en función de variable discreta (usando “fórmula”)\n\n\ngraf_estad +  geom_line() + facet_wrap(~State, ncol = 10)\n\n\nfacet_grid() para facetas en dos dimensiones\n\n\ng3 &lt;- ggplot(data = housing %&gt;% filter(Year&gt;2005)) + \n               geom_histogram(aes(x=Home.Value))\ng3 +  facet_grid(region ~ Year)\n\ng3 + facet_grid(region ~ .)     # También solo por filas \ng3 + facet_grid(. ~ region)     # o columnas"
  },
  {
    "objectID": "docs/Tema04.html#contexto-con-labs-título-ejes-leyendas",
    "href": "docs/Tema04.html#contexto-con-labs-título-ejes-leyendas",
    "title": "Tema 04 - Visualización de datos",
    "section": "Contexto con labs(): título, ejes, leyendas",
    "text": "Contexto con labs(): título, ejes, leyendas\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n labs(\n   title = \"Relación entre coste de la construcción y valor del terreno\",\n   subtitle = \"Datos del Primer Trimestre de 2001\",\n   caption = \"Fuente: Elaboración propia\")\n\n\nEs una buena idea que los nombres de ejes, leyendas, etc. sean descripciones claras de las variables (y sus unidades)\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost/1000, x = Land.Value/1000)) + \n  scale_x_log10() + \n  geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Valor del terreno (miles de $), escala logarítmica\",\n       y = \"Valor de la construcción (miles de $)\",\n       colour = \"Región\") +\n  scale_y_continuous(breaks=seq(80,200,40),labels=seq(80,200,40) )\n\n\n¿Qué hace la escala logarítmica? ¿Y usar x = log(Land.Value/1000)?"
  },
  {
    "objectID": "docs/Tema04.html#otros-elementos-de-contexto",
    "href": "docs/Tema04.html#otros-elementos-de-contexto",
    "title": "Tema 04 - Visualización de datos",
    "section": "Otros elementos de contexto",
    "text": "Otros elementos de contexto\n\n\nYa vimos geom_text() para asociar una variable a un estética de etiqueta\nannotate() añade objetos geométricos no asociados a variables: “text”, “rect”, “segment”, “pointrange”\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost/1000, x = Land.Value/1000)) +\n  geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10()+\n  annotate(\"text\", x = 140, y = 180, label = \"casa cara\") +\n  annotate(\"text\", x = 110, y = 150, label = \"R ^ 2 == 0.026\", \n           parse = TRUE)\n\n\nSe pueden añadir líneas de referencias verticales, horizontals o diagonales\n\n\n  g2 +\n    geom_vline(aes(xintercept = 1), linetype = 3, color = \"black\")"
  },
  {
    "objectID": "docs/Tema04.html#cambiar-colores",
    "href": "docs/Tema04.html#cambiar-colores",
    "title": "Tema 04 - Visualización de datos",
    "section": "Cambiar colores",
    "text": "Cambiar colores\n\nSe puede cambiar manualmente la combinación (paleta) de colores por defecto dando el nombre o el código hexadecimal HTML de color\n\n\ngraf &lt;- ggplot(hp2001Q1, aes(x = region, y = Home.Value, fill = region)) + geom_boxplot()\ngraf + scale_fill_manual(values = c(\"red\", \"green\", \"blue\", \"yellow\", \"gray\"))\ngraf +\n  scale_fill_manual(values = c(\"#004f71\", \"#465a01\", \"#981d97\", \"#00FFFF\", \"#848484\"))\n\n\nDe igual forma se podría cambiar la forma con scale_shape_manual()\n\n\nEs recomendable usar paletas predefinidas, con criterios de diseño y visualización de información, como RColorBrewer o viridis (replica matplotlib de Python)\n\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\ngraf + scale_fill_brewer(palette = \"Set3\")\ngraf + scale_fill_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "docs/Tema04.html#temas",
    "href": "docs/Tema04.html#temas",
    "title": "Tema 04 - Visualización de datos",
    "section": "Temas",
    "text": "Temas\n\nPodemos definir el estilo general del gráfico: etiquetas de los ejes, fondo del gráfico, apariencia de las leyendas, etc.\n\n\ngraf + theme_gray()       # predeterminado\ngraf + theme_linedraw()\ngraf + theme_light()\ngraf + theme_minimal()\ngraf + theme_dark()\ngraf + theme_classic()\n\n\nCiertos elementos específicos del tema pueden ser cambiados con theme() y guardados para definir temas personalizados (para aplicarlos después)\n\n\nNuevamente es recomendable usar temas creados por expertos en diseño y comunicación\n\n\n#install.packages(\"ggthemes\")\nlibrary(ggthemes)\ngraf +  theme_economist() +  #  del equipo de diseño gráfico de \"The Economist\"   \n  scale_fill_economist()"
  },
  {
    "objectID": "docs/Tema04.html#comentarios-finales",
    "href": "docs/Tema04.html#comentarios-finales",
    "title": "Tema 04 - Visualización de datos",
    "section": "Comentarios finales",
    "text": "Comentarios finales\n\nGuardar los gráficos: en la pestaña , lista desplegable  o comando ggsave()\n\n\nggsave(\"my-plot.pdf\")\n\n\nAyuda en RStudio, Help &gt; Cheatsheets &gt; Data Visualization with ggplot2\nFuentes de información con chuletas de R y RStudio aquí\n\nexisten versiones en castellano de algunas de ellas."
  },
  {
    "objectID": "docs/Tema04.html#poniéndolo-todo-junto",
    "href": "docs/Tema04.html#poniéndolo-todo-junto",
    "title": "Tema 04 - Visualización de datos",
    "section": "Poniéndolo todo junto",
    "text": "Poniéndolo todo junto\n\nEstamos en condiciones de recrear gráficos profesionales como este de The Economist"
  },
  {
    "objectID": "docs/Tema00ej2.html",
    "href": "docs/Tema00ej2.html",
    "title": "Tema 0. Ejercicio 2",
    "section": "",
    "text": "Datos Económicos con quantmod\nLa biblioteca quandmod nos permite acceder directamente desde R datos macroeconomicos de muchos países disponibles en FRED.\n\nSe busca un dato (concreto) de, por ejemplo, inflación en España: “Inflation, consumer prices for Spain; Percent, Annual, Not Seasonally Adjusted”\nAsí, averiguamos el “symbol” o nombre interno de la variable\n\n\nlibrary(quantmod)\ngetSymbols(\"FPCPITOTLZGESP\",src='FRED')\nplot(FPCPITOTLZGESP)\n\nstr(FPCPITOTLZGESP)\n\nplot(FPCPITOTLZGESP[1:20,])\n\n\nNOTA: para usar las series quantmod con la función de gráficos plot(), especialmente con más de una serie a la vez, es conveniente convertirlas en vectores con as.numeric()\n\n\ngetSymbols(\"FPCPITOTLZGESP\", src = 'FRED')\nx &lt;- as.numeric(FPCPITOTLZGESP)\nplot(FPCPITOTLZGESP)\n\ngetSymbols(\"IRLTLT01ESA156N\", src = \"FRED\")\ny &lt;- as.numeric(IRLTLT01ESA156N)\nplot(x[-c(1:20)], y)\n\nTambién se pueden obtener datos de Yahoo Finance, averiguando el símbolo de una acción: ej., “Telefonica, Equity - NYQ”\n\ngetSymbols('TEF',src='yahoo')\ndim(TEF)\nplot(TEF$TEF.Close)\n\nEsta biblioteca también incluye funciones de análisis como gráficos específicos\n\ncandleChart(TEF[-(1:3650),], up.col = \"black\", dn.col = \"red\", \n            theme = \"white\")\n\n\ngetSymbols('^IBEX',src='yahoo')\ncandleChart(IBEX[1:20,], up.col = \"black\", dn.col = \"red\", theme = \"white\")\n\ncandleChart(IBEX[-(1:3150),], up.col = \"black\", dn.col = \"red\", theme = \"white\")\n\n\n\nVuestro ejercicio\nElegid una serie de datos de Yahoo Finance y dos de FRED. Debéis escribir un fichero de código de R con los comando necesarios para\n\ncargar los datos\nrealizar un breve análisis descriptivo de la serie de Yahoo Finance y un grafico de velas\nrealizar un breve análisis descriptivo de una de los dos series de FRED y un gráfico con su evolución temporal\nrealizar un análisis gráfico (gráfico de dispersión) y numérico (correlación) de las dos series de FRED\n\nNo os olvidéis de incluir algunos (breves pero descriptivos) comentarios en vuestro código sobre qué hacéis y por qué.\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema00ej2_123456787.R"
  },
  {
    "objectID": "docs/Tema10.html#proceso-de-modelización",
    "href": "docs/Tema10.html#proceso-de-modelización",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Proceso de modelización",
    "text": "Proceso de modelización\n\ntidymodels es una colección de paquetes para el proceso de modelización (NO implementa modelos) con los principios de tidyverse\n\n\n\n\ninstall.packages(\"tidymodels\")\n\n\nlibrary(tidymodels)\n\n\n\n\n\n\n\n\n\n\n\n\nOtros paquetes “similares”: mlr3, caret, H2O"
  },
  {
    "objectID": "docs/Tema10.html#pre-procesado-partición-inicial",
    "href": "docs/Tema10.html#pre-procesado-partición-inicial",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Pre-procesado: partición inicial",
    "text": "Pre-procesado: partición inicial\n\ndplyr transforma los datos para adecuarlos a la modelización, pero tidymodels permite transformaciones específicas para un modelo concreto\ninitial_split(): particionar los datos en prueba y entrenamiento.\n\n\nlibrary(mosaicData)\nset.seed(9753)\nRailTrail_part &lt;- RailTrail %&gt;% initial_split(prop = .8)\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;% mutate(income = factor(income))\nset.seed(7482)\ncenso_part &lt;- censo %&gt;% initial_split(prop = .8)\n\n\nLas funciones training() y testing() acceden a cada submuestra\n\n\nRailTrail_entren &lt;- RailTrail_part %&gt;% training()\nRailTrail_prueb  &lt;- RailTrail_part %&gt;% testing()"
  },
  {
    "objectID": "docs/Tema10.html#pre-procesado-recetas",
    "href": "docs/Tema10.html#pre-procesado-recetas",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Pre-procesado: recetas",
    "text": "Pre-procesado: recetas\n\nLas recetas definen las transformaciones a aplicar\nrecipe() tiene como primer argumento una fórmula (rol de las variables)\nLuego se añaden pasos con step_\n\nstep_filter(), step_arrange(), step_rm(), etc.\nstep_naomit()\nstep_impute_mean(), step_impute_linear(), step_impute_knn() \n\n\n\nSe aplican a una variable, todas o un subconjunto con all_outcomes(), all_predictors(), all_numeric(), all_nominal(), contains(), etc.\n\nstep_dummy(all_predictors(), -all_numeric())"
  },
  {
    "objectID": "docs/Tema10.html#pre-procesado-recetas-cont.",
    "href": "docs/Tema10.html#pre-procesado-recetas-cont.",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Pre-procesado: recetas (cont.)",
    "text": "Pre-procesado: recetas (cont.)\n\nSe pueden añadir términos polinomiales con step_poly(), interacciones de variables con step_interact(), discretizar variables con step_cut(),etc.\nSe centran variables con step_center() o se estandarizan con step_scale()\nSe crea un objeto de receta (y luego combinarlo con otras partes del proceso)\n\n\nreceta_lm1 &lt;- training(RailTrail_part) %&gt;%            # Datos: NO crucial\n  recipe(volume ~ cloudcover + precip + avgtemp) %&gt;%\n  step_poly(avgtemp, degree = 6) %&gt;%                  \n  step_center(all_predictors(), -all_nominal()) %&gt;%\n  step_scale(all_numeric(), -all_outcomes()) \n\nreceta_logit1 &lt;- training(censo_part) %&gt;%\n  recipe(income ~ age + education + race + sex + capital_gain)\n\n\nTambién se podría preparar la receta con prep() y aplicar las transformaciones con juice() o bake()"
  },
  {
    "objectID": "docs/Tema10.html#definir-el-modelo",
    "href": "docs/Tema10.html#definir-el-modelo",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Definir el modelo",
    "text": "Definir el modelo\n\ntidymodels define un modelo con una interfaz unificada para distintas bibliotecas (con otros nombres de argumentos)\n\n\nmodelo_lm1     &lt;- linear_reg(mode= \"regression\", penalty = 0) %&gt;%\n                    set_engine(\"lm\") \n\nmodelo_glmnet1 &lt;- linear_reg(penalty = 0)  %&gt;% set_mode(\"regression\") %&gt;% \n                        set_engine(\"glmnet\")\n\n\nmodelo_logit1 &lt;- logistic_reg(mode= \"classification\", penalty = 0) %&gt;% set_engine(\"glm\")\n\n\nSe podría estimar (entrenar) el modelo con fit()"
  },
  {
    "objectID": "docs/Tema10.html#flujos-de-trabajo-workflow",
    "href": "docs/Tema10.html#flujos-de-trabajo-workflow",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Flujos de trabajo: workflow()",
    "text": "Flujos de trabajo: workflow()\n\nCombina preprocesado y definición del modelo en un único objeto de flujos\n\n\nlm1_flujo &lt;- workflow() %&gt;%\n  add_recipe(receta_lm1) %&gt;%      \n  add_model(modelo_lm1)\n\n\nUn flujo existente se modifica con update_recipe() , update_model(), etc.\n\n\nSe prepara todo en una única llamada de fit()\n\n\nlm1_flujo_est &lt;- lm1_flujo %&gt;% fit(data = RailTrail_part %&gt;% training()) \n\nlogit1_flujo_est &lt;-  workflow() %&gt;% add_recipe(receta_logit1) %&gt;%      \n                        add_model(modelo_logit1) %&gt;% fit(censo_part %&gt;% training())\n\n\nEste objeto contiene tanto la receta para transformar los datos como el modelo estimado para mostrar los resultados o predecir"
  },
  {
    "objectID": "docs/Tema10.html#flujos-de-trabajo-workflow-cont.",
    "href": "docs/Tema10.html#flujos-de-trabajo-workflow-cont.",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Flujos de trabajo: workflow() (cont.)",
    "text": "Flujos de trabajo: workflow() (cont.)\n\nSe puede extraer la receta para aplicar la transformación a unos datos (p.e., comprobamos que tienen varianza 1 con var())\n\n\nlm1_flujo_est %&gt;% extract_recipe() %&gt;% bake(RailTrail_part %&gt;% training()) \nlm1_flujo_est %&gt;% extract_recipe() %&gt;% bake(RailTrail_part %&gt;% testing())\n\n\nTambién se pueden extraer los resultados de la estimación. Con funciones de broom se convierten a tibbles para trabajar con ellos (p.e., kable() en un documento)\n\n\nlm1_flujo_est %&gt;% extract_fit_parsnip() %&gt;% tidy()      # resultados de la estimación\nlm1_flujo_est %&gt;% extract_fit_parsnip() %&gt;% glance()    # otros detalles de la estimación\n\n\nbroom::augment() calcula predicciones del modelo, residuos, etc.\n\n\nmodelo &lt;- lm1_flujo_est %&gt;% extract_fit_parsnip()\nmodelo$fit %&gt;% augment()"
  },
  {
    "objectID": "docs/Tema10.html#predicción",
    "href": "docs/Tema10.html#predicción",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Predicción",
    "text": "Predicción\n\nLa función predict() (de parsnip) predice valores numéricos, clases, probabilidad de cada categoría, intervalos de confianza, etc.\nDevuelve un tibble que podemos añadir a los datos con bind_cols()\n\n\n lm1_flujo_est %&gt;% \n  predict(new_data = RailTrail_prueb) %&gt;% \n  bind_cols(RailTrail_prueb %&gt;% select(volume))     # Variable predicha .pred\n\nlogit1_flujo_est %&gt;% \n  predict(censo_part %&gt;% testing())                # clase predicha .pred_class\n\nlogit1_flujo_est %&gt;% \n  predict(censo_part %&gt;% testing(), type = \"prob\")    # probabilidades de cada categoría\n\n\nNotad que se procesan automáticamente los datos donde se predice"
  },
  {
    "objectID": "docs/Tema10.html#validación-del-modelo",
    "href": "docs/Tema10.html#validación-del-modelo",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Validación del Modelo",
    "text": "Validación del Modelo\n\nDado un tibble con valores/clases observados (truth) y predichos (estimate), se calcula una métrica (rmse(), rsq(), accuracy(), etc.) o varias (metrics())\n\n\nlm1_flujo_est %&gt;% predict(RailTrail_prueb) %&gt;% \n  bind_cols(RailTrail_prueb) %&gt;%  \n  metrics(truth=volume, estimate= .pred)           #   mae(truth=volume, estimate= .pred)\n\nlogit1_flujo_est %&gt;%  predict(censo_part %&gt;% testing()) %&gt;% \n   bind_cols(censo_part %&gt;% testing()) %&gt;%   \n  conf_mat(truth=income, estimate= .pred_class)           # clase predicha=\n                                                          #  mayor probabilidad predicha\n\nmis_metricas &lt;- metric_set(accuracy, spec, sens)             # métricas específicas\nlogit1_flujo_est %&gt;%  predict(censo_part %&gt;% testing()) %&gt;% \n  bind_cols(censo_part %&gt;% testing()) %&gt;%\n  mis_metricas(truth=income, estimate= .pred_class)"
  },
  {
    "objectID": "docs/Tema10.html#validación-del-modelo-cont.",
    "href": "docs/Tema10.html#validación-del-modelo-cont.",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Validación del Modelo (cont.)",
    "text": "Validación del Modelo (cont.)\n\nSi predecimos probabilidades, se pueden obtener la curva ROC y la AUC\n\n\nlogit1_probs &lt;- logit1_flujo_est %&gt;% \n                    predict(censo_part %&gt;% testing(), type = \"prob\") %&gt;%\n                    bind_cols(censo_part %&gt;% testing()) \n\nlogit1_probs %&gt;% roc_auc(income, `.pred_&lt;=50K`) \n\nlogit1_probs %&gt;% roc_curve(income, `.pred_&lt;=50K`) %&gt;%  autoplot()\n\n\nCon más de dos clases, se predice la probabilidad de cada clase y la clase predicha es la más frecuente\n\nLa matriz de confusión es similar, pero de dimensiones \\(\\small k \\times k\\)\nLa accuracy sigue teniendo la misma interpretación\nLa ROC-AUC se calcula para cada clase frente a las demás"
  },
  {
    "objectID": "docs/Tema10.html#el-proceso-de-validación-cruzada",
    "href": "docs/Tema10.html#el-proceso-de-validación-cruzada",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "El proceso de validación cruzada",
    "text": "El proceso de validación cruzada\n\nvfold_cv() crea las particiones en los datos sin procesar\n\n\nset.seed(9753)\nRailTrail_cv &lt;- RailTrail %&gt;% vfold_cv(v=10) # objeto de 10 grupos\n\n\nSe puede acceder a los datos de entrenamento y prueba de cada uno de ellos con analysis() y assessment(), respectivamente\n\n\nRailTrail_cv$splits[[1]] %&gt;% analysis() %&gt;% dim()\nRailTrail_cv$splits[[1]] %&gt;% assessment() %&gt;% dim()\n\n\nfit_resamples(), similar a fit(), sobre un flujo de trabajo ya definido y el objeto completo de remuestras de valicación cruzada …\n\n\nlm1_flujo_cv_est &lt;- lm1_flujo  %&gt;% \n                        fit_resamples(RailTrail_cv)"
  },
  {
    "objectID": "docs/Tema10.html#el-proceso-de-validación-cruzada-cont.",
    "href": "docs/Tema10.html#el-proceso-de-validación-cruzada-cont.",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "El proceso de validación cruzada (cont.)",
    "text": "El proceso de validación cruzada (cont.)\n\n… y el objeto creado contiene los valores de las métricas\n\n\nlm1_flujo_cv_est %&gt;% collect_metrics()      # promedio sobre 10 iteraciones\nlm1_flujo_cv_est$.metrics %&gt;% bind_rows()   # valores en cada iteración\n\n\nSe pueden cambiar varias opciones del proceso\n\n\nlm1_flujo_cv_est &lt;- lm1_flujo  %&gt;% \n                        fit_resamples(\n                          resamples = RailTrail_cv, \n                          metrics   = metric_set(rmse, mae),\n                          control   = control_resamples(save_pred = TRUE)\n                        )"
  },
  {
    "objectID": "docs/Tema10.html#selección-de-hiperparámetros-tuning",
    "href": "docs/Tema10.html#selección-de-hiperparámetros-tuning",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Selección de hiperparámetros: tuning",
    "text": "Selección de hiperparámetros: tuning\n\nAlgunos parámetros, denominados hiperparámetros, no pueden aprenderse directamente durante el entrenamiento del modelo (ej., \\(\\small \\lambda\\) en LASSO)\n\n\n\n\nProceso de ajuste (tuning):\n\nen una parte de la muestra de entrenamiento, se estiman los parámetros dado un valor del hiper-parámetro\nen la otra parte, se mide el error asociado a ese hiper-parámetro para validar el mejor valor\nse elige el valor con mejor métrica de error en validación\n\n\n\n\n\n\n\\(\\Downarrow\\)\n\n\n\\(\\hspace{0.1cm}\\)"
  },
  {
    "objectID": "docs/Tema10.html#proceso-de-tuning",
    "href": "docs/Tema10.html#proceso-de-tuning",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Proceso de tuning",
    "text": "Proceso de tuning\n\nSe pueden identificar los hiperparámetros a ajustar en la receta y/o el modelo\n\n\nmodelo_LASSO &lt;- linear_reg(mode= \"regression\", \n                           penalty = tune() ) %&gt;%\n                    set_engine(\"glmnet\") \n\nflujo_LASSO_tuning &lt;- workflow() %&gt;%\n  add_recipe(receta_lm1) %&gt;% \n  add_model(modelo_LASSO)\n\nflujo_LASSO_tuning %&gt;% parameters()\n\n\nSe establecen las combinaciones de valores sobre las que se buscará con grid_random(), grid_max_entropy() o grid_regular()\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 15), trans = NULL), levels = 51)\n                                   # rango,                 # número de valores"
  },
  {
    "objectID": "docs/Tema10.html#proceso-de-tuning-cont.",
    "href": "docs/Tema10.html#proceso-de-tuning-cont.",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Proceso de tuning (cont.)",
    "text": "Proceso de tuning (cont.)\n\nSe usa tune_grid() de forma a similar a fit_resamples() en las remuestras por Validación Cruzada de la muestra de entrenamiento\n\n\nset.seed(9753)\nRailTrail_entren_cv &lt;- RailTrail_entren %&gt;% vfold_cv(v=10)\n\nLASSO_tuned &lt;- flujo_LASSO_tuning %&gt;% tune_grid( resamples = RailTrail_entren_cv, \n                                                 metrics   = metric_set(rmse, mae),\n                                                 grid      = LASSO_grid               )\n\n\nPodemos explorar visualmente el ajuste para distintos valores\n\n\nLASSO_tuned %&gt;% autoplot()\n\npenalty &lt;- LASSO_tuned %&gt;% collect_metrics() %&gt;% filter(.metric == \"mae\")\npenalty %&gt;% ggplot(aes(x=penalty, y=mean)) +  scale_x_log10() +\n              geom_line() + geom_point(color=\"red\") + \n              geom_errorbar(aes(ymin=mean-std_err, ymax=mean+std_err), color=\"gray\")"
  },
  {
    "objectID": "docs/Tema10.html#estimación-del-modelo-completo",
    "href": "docs/Tema10.html#estimación-del-modelo-completo",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Estimación del modelo completo",
    "text": "Estimación del modelo completo\n\nNOTA: debemos probar manualmente varios rangos y valores buscando la U\nSe puede ver numéricamente el mejor o los cinco mejores candidatos: recordar que, por la variabilidad, varios valores son igualmente aceptables\n\n\nLASSO_tuned %&gt;% show_best(\"mae\")\nmejor_lambda &lt;- LASSO_tuned %&gt;% select_best(\"rmse\")\n\n\nActualizamos el flujo de trabajo con un valor, ej., de select_best()\n\n\nflujo_final &lt;- flujo_LASSO_tuning %&gt;% \n        finalize_workflow(mejor_lambda)  # finalize_workflow(parameters = list(penalty=8.5))\n\n\nDebemos estimar el modelo en los datos completos de entrenamiento\n\n\nflujo_final %&gt;%  fit(data = RailTrail_entren) %&gt;%  broom::tidy()"
  },
  {
    "objectID": "docs/Tema10.html#finalizando-y-evaluando-el-modelo",
    "href": "docs/Tema10.html#finalizando-y-evaluando-el-modelo",
    "title": "Tema 10 - Modelización con tidymodels",
    "section": "Finalizando y evaluando el modelo",
    "text": "Finalizando y evaluando el modelo\n\nFinalmente, podemos usar last_fit(): ajusta al modelo finalizado en los datos de entrenamiento y lo evalúa en los de prueba.\n\n\nfinal_fit &lt;- flujo_final %&gt;% last_fit(RailTrail_part)\n\nfinal_fit %&gt;% collect_metrics()\nfinal_fit %&gt;% collect_predictions()\n\n\nfinal_fit &lt;- flujo_final %&gt;% last_fit(split   = RailTrail_part,\n                                      metrics = metric_set(rmse, mae))\nfinal_fit %&gt;% collect_metrics()"
  },
  {
    "objectID": "docs/Tema00.html#introducción",
    "href": "docs/Tema00.html#introducción",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Introducción",
    "text": "Introducción\n\nDebéis tener instalados los programas gratuitos R y RStudio\nNos familiarizaremos con los conceptos y comandos básicos de programación en R\nR es un lenguaje interpretado: ejecuta las instrucciones directamente en la consola\n\n\nRStudio es un entorno de desarrollo integrado (IDE) que combina varias herramientas para facilitar el uso de R: consola, editor para escribir comandos, ayuda, etc.\n\n\n\nUn editor de texto NO es un procesador de texto (como Word): solo importa el texto sin formato (negrita, etc.)"
  },
  {
    "objectID": "docs/Tema00.html#r-studio",
    "href": "docs/Tema00.html#r-studio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "R Studio",
    "text": "R Studio"
  },
  {
    "objectID": "docs/Tema00.html#empezando-con-r",
    "href": "docs/Tema00.html#empezando-con-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Empezando con R",
    "text": "Empezando con R\n\nEscribimos comandos en la consola y se ejecutan pulsando Enter:\n\nLa tecla de tabulador  ofrece opciones de autocompletado\nEjecutar algo que no es un comando de R devuelve un error\n\n\n\n2 + 2\n3 * (1 - 4)^2\nsqrt(log(5/2))\npi\nhola\n\n\n\nOperadores aritméticos habituales: +,-,*,/, %/%, %%\nFunciones o constantes incorporadas: log, sqrt, abs, exp, round, pi\n\nabs(-5)\n9 %/% 4\n9 %% 4\n\nSi intentamos evaluar algo que NO es un comando de R o no está correctamente escrito, tendremos un ERROR\nEs NORMAL cometer errores\n\n\n\nO en el Editor de RStudio y se envían a la consola la o las líneas seleccionadas para ser evaluadas con el icono  o con el atajo de teclado Ctrl+Enter\nNOTA: en MacOS, usad la tecla Command en lugar de Ctrl"
  },
  {
    "objectID": "docs/Tema00.html#archivos-de-guion-scripts",
    "href": "docs/Tema00.html#archivos-de-guion-scripts",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Archivos de guion (“scripts”)",
    "text": "Archivos de guion (“scripts”)\n\nEs preferible incluir varios comandos en un archivo de texto para ejecutarlos\nSe puede replicar el proceso de cálculos paso a paso (no como Excel) \nCreamos un nuevo archivo con el icono  o en el menú File &gt; New File &gt; R script (atajo Ctrl + Mays + N)\nGuardamos el archivo con  o en File &gt; Save (atajo Ctrl + S), eligiendo un directorio y nombre de extensión “.R” (por defecto) o “.r”\nEn un archivo de guion (guardado), RStudio marca las líneas con error y muestra el mensaje de error al pasar el puntero"
  },
  {
    "objectID": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "href": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Trabajar con ficheros de guion",
    "text": "Trabajar con ficheros de guion\n\nCada comando es “una” línea y se ejecutan secuencialmente\nUn comando se puede extender visualmente más de una línea hasta completarse: p.e., hasta cerrar los paréntesis.\n\nEscribimos log(, en otra línea 9 y ejecutamos: la consola cambia de &gt; a + \nNo hace “nada” esperando que completemos el comando.\n\n\n\n\nNO LO VEREMOS: se pueden incluir más de un comando por línea, separados por “;”, pero el código es menos legible\nPodemos ejecutar todo el archivo:\n\nseleccionando todas las líneas Ctrl + A y luego \n\n\n\nusando  con “echo” o sin “echo” (no muestra resultados en consola)\n\nEn ambos casos, se para la ejecución cuando encuentra error\n\n\n\n\nEl carácter # marca el inicio de un comentario: lo que sigue se “ignora” (no se ejecuta) en R\n\n\n# Pueden ir al principio de la línea \n2 + 2 # o después de una instrucción\n\n\nComentar es un buen hábito: ayuda a entender/recordar qué hacemos\nNotad que RStudio tiene resaltado de sintaxis: distinto color para comentarios, números, funciones, etc."
  },
  {
    "objectID": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "href": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Directorio de Trabajo. Proyectos.",
    "text": "Directorio de Trabajo. Proyectos.\n\nConviene organizar los archivos relacionados con un mismo tema en una estructura de (sub)directorios a partir de un directorio de trabajo principal \nEsto puede hacerse manualmente, pero RStudio permite definir proyectos para gestionarlo fácilmente a través del menú File o desplegando el icono en la parte superior derecha \n\n\n\nPara conocer el directorio de trabajo actual\n\n\ngetwd()\n\n\nInicialmente el directorio de trabajo es el directorio por defecto del usuario del SO (“~”), donde “/” es el separador de directorios\n\nen Windows: C:/Users/nombre/Documents\nen MacOS: /Users/nombre\nen Linux: /home/nombre\n\n\n\nWindows usa la barra invertida “\\” (‘backward slash’ en lugar de ‘forward slash’) como separador de directorio en una ruta\n\n\nPERO “\\” tiene una función “especial” para cadenas de caracteres en programación: denotar caracteres especiales (“escapar”)\n\n\nSi “insistimos” en usarla, será su versión “escapada”: (C:\\\\Usuarios\\\\nombre\\\\Mis Documentos)\nEn el explorador de archivos (de Windows y de MacOS) la ruta “~” está en castellano (p.e., C:\\Usuarios\\nombre\\Documentos), pero internamente en inglés\n\n\n\nDesde el menú File &gt; New Proyect o desde el icono, creamos un nuevo proyecto que estará asociado a un directorio de trabajo.\n\nEl nombre del proyecto será el nombre del directorio\nTambién se crea un archivo con el mismo nombre y extensión “.Rproj”\n\nTenemos la opción de usar un Nuevo Directorio para el nuevo proyecto, seleccionando una ubicación y un nombre para el proyecto=directorio en esa ubicación\nO bien elegimos un directorio ya existente para nuestro proyecto"
  },
  {
    "objectID": "docs/Tema00.html#proyectos-cont.",
    "href": "docs/Tema00.html#proyectos-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Proyectos (cont.)",
    "text": "Proyectos (cont.)\n\nCuando cerramos y volvemos a abrir RStudio, tendremos activo el último proyecto abierto: ej., \nTanto desde el menú como desde el icono de gestión de proyectos, podemos\n\ncerrar el proyecto actual, File &gt; Close Projects,\nabrir otros proyectos guardados: File &gt; Open Project o File &gt; Recent Projects\n\nPara trabajar en R con un archivo del proyecto, accedemos usando la ruta relativa al directorio de trabajo:\n\nsi están en el raíz del directorio: codigo.R, misdatos.Rdata\nsi están en un subdirectorio, indicamos la ruta separando directorios por /: datos/ventas.Rdata, datos/ano2020/ingresos.Rdata\n\nLa pestaña  en el cuadrante inferior-derecho ofrece una forma visual de abrir, crear, copiar, mover o eliminar archivos o directorios, etc.\n\n\nEvitad caracteres “raros” (acentos, espacios, etc.) en directorios y ficheros"
  },
  {
    "objectID": "docs/Tema00.html#funciones-en-r",
    "href": "docs/Tema00.html#funciones-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Funciones en R",
    "text": "Funciones en R\n\nLas expresiones que aceptan argumentos se denominan funciones.\n\n\nexp(2)\nceiling(5.2)\n\n\n\n\n\nAlgunos argumentos son obligatorios, otros tienen valores por defecto que se pueden omitir\nLos argumentos se pueden especificar por nombre o por orden.\n\n\nlog(2, base=2)\nlog(2, 10)\nlog(base = 10, x = 2)\n\n\n¿Cómo sabemos la manera de usar una función (ej. argumentos necesarios) o comando de R?\n\n\n\nNO omitir los argumentos tiene ventajas\n\nClaridad\nLos argumentos no tienen que especificarse en orden (sin nombre del argumento debe seguirse el orden establecido)"
  },
  {
    "objectID": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "href": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Ayuda en R y RStudio",
    "text": "Ayuda en R y RStudio\n\nRStudio tiene autocompletado y ayuda flotante para funciones y otros elementos de R\n\nP.e., si empezamos a escribir la función log, se muestra la forma esperada de trabajar con esa función\n\nRStudio también tiene una pestaña para buscar ayuda\n\n\nLas búsquedas online o las IAs (como chatGPT o Bard) pueden ser útiles.\nPERO debemos tener un conocimiento mínimo para aprovechar realmente una solución\n\nhay muchas formas de hacer lo mismo en R: una respuesta correcta puede no ajustarse a lo que ya sabemos\n\nNO uséis copiar-pegar sin entender el código: copiar-pensar-adaptar\n\n\n\nSe puede usar ?? para buscar ayuda en la consola sobre algo de lo que se desconoce el nombre concreto de la función\n\n\nNO siempre estará la solución exacta a nuestro problema\nLas soluciones pueden utilizar enfoques que requieren conocer comandos de extensiones (bibliotecas) de R"
  },
  {
    "objectID": "docs/Tema00.html#el-operador-de-asignación",
    "href": "docs/Tema00.html#el-operador-de-asignación",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El operador de asignación",
    "text": "El operador de asignación\n\nEl operador &lt;- almacena un contenido en un objeto con un nombre,1 que incluye letras, números y algunos carácteres especiales (“.”, “_”)\n\n\n\nalt - = &lt;-\nUn objeto es simplemente algo almacenado en la memoria de R\nImportante: recordar almacenar nuestros cálculos y resultados en objetos para poder reutilizarlos.\n\na menudo no es “recomendado”, es una necesidad\n\n\n\n\nx &lt;- 2*3    # asignación, no muestra resultado\nx           # ejecutamos mostrar la variable   # print(x)\n(x &lt;- 2)    # asignación e impresión a la vez\n\n\nR es “case-sensitive”: x y X son dos objetos distintos\nLos objetos asignados pueden usarse posteriormente, p.e., para generar otros a partir de ellos\n\n\ny &lt;- x + 5  # asignamos y a partir del VALOR de x\n(x &lt;- x*3)  # re-asignamos x a partir de ella misma\ny           # NO cambia con el nuevo valor de x           \n\n\n\nSe prefiere &lt;- para diferenciar asignación de objetos (NO solo asignaremos números) del concepto de igualdad matemática\nY se evita la confusión con = usado para dar valores a un argumento, log(2, base=10), y con la igualdad en comparaciones (==)\nTambién se puede mostrar con print(x) o con show(x)\nUn error habitual: object not found. Porque hemos creado x y luego queremos usar X…\nCuando se asigna a partir del objeto x, en la expresión aparece el contenido x en ese momento (no x propiamente dicho)\nEn Excel, si cambia un valor en una celda, cambian aquellas que la referencian.\n\n\nTambién se puede asignar con ="
  },
  {
    "objectID": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "href": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El Espacio de Trabajo en R ",
    "text": "El Espacio de Trabajo en R \n\nEl espacio de trabajo es el conjunto de objetos activos en memoria, resultado de todos los comandos ejecutados previamente\nEn RStudio, la pestaña  muestra los objetos y su valor\nPara mostrar y eliminar objetos del espacio de trabajo:\n\n\nls()        # mostrar objetos\nrm(y)       # eliminar el objeto \"y\"\nrm(a,b,c)   # eliminar varios objetos (separados por comas)\n\n\nBorramos todos los objetos con  en el Environment o el comando\n\n\nrm( list=ls() )\n\n\nGuardamos el contenido del entorno de trabajo con  (o al cerrar RStudio), pero es innecesario si tenemos la secuencia de comandos\n\n\n\nNotar que el Environment también tiene una pestaña de History con todos los comandos ejecutados durante la sesión.\nVeremos cómo guardar datos en R con más detalle"
  },
  {
    "objectID": "docs/Tema00.html#mensajes-de-error-y-warning",
    "href": "docs/Tema00.html#mensajes-de-error-y-warning",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Mensajes de “Error” y “Warning”",
    "text": "Mensajes de “Error” y “Warning”\n\nEn programación, cometer errores es normal\nEn muchos errores, R se “quejará” mostrando mensajes en rojo\n\nAviso: R ofrece un resultado (y continuará al siguiente comando), PERO indica que puede haber algo “no deseado”\nError: para la ejecución, sin resultado, e “informa” de la razón\n\nAlgunos mensajes son claros, pero otros requieren más investigación\n\n\nPeor que un mensaje de error: escribimos (copiamos) un código que funciona pero no hace lo que queremos…\nEl ordenador NO se equivoca: hace lo que le pedimos según unas reglas bien definidas por R, que debemos conocer\n\nSed cuidadosos, pensad y entended cada paso del código \n\n\n\n\nAlgunos mensajes son intimidantes (en rojo!) … e indescifrables\nAviso: “He hecho lo que he podido para entender lo que pides (log. de un número negativo!), pero a lo mejor no es lo que quieres”\nConocer las “reglas” es saber programar (hablar) en ese lenguaje\nComo toda convención, algunas reglas de R pueden ser “arbitrarias”\n\np.e., log(-1) podría ser error y seq(from = 10, to = 2, by = 1) interpretado como una cuenta atrás\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y =="
  },
  {
    "objectID": "docs/Tema00.html#tipos-de-objetos-en-r",
    "href": "docs/Tema00.html#tipos-de-objetos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Tipos de Objetos en R",
    "text": "Tipos de Objetos en R\n\nTODO en R es un objeto, cada uno con distintas propiedades y, por tanto, distintas formas de trabajar con él\n\n\n\nR es un lenguaje orientado a objetos\n\n\n\nAdemás de las funciones, los principales objetos con los que trabajaremos son:\n\nvectores\nfactores\nlistas\nconjuntos de datos (“data frames”)\n\nAdemás, estos objetos pueden contener varios tipos de datos o variables:\n\nentero\nnumérico (números reales) \nlógico (valores verdadero/falso)\ncaracteres"
  },
  {
    "objectID": "docs/Tema00.html#vectores",
    "href": "docs/Tema00.html#vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores",
    "text": "Vectores\n\nUn vector es una secuencia de datos elementales, creados con el operador “c()” (combinar)\n\n\nxvect &lt;- c(2.5,-4.1,6.4,8.2)           # vector numérico\nwvect &lt;- c(3,0,-1,2)                   # vector de enteros\nyvect &lt;- c(\"hola\", 'adios')            # vector de caracteres \nzvect &lt;- c(FALSE, TRUE, T, F)          # vector lógico\n\n\n\nLos caracteres puede ir entre comillas simples ` o dobles \"\nT y F atajo para TRUE y FALSE\n\n\n\nPodemos crear vectores a partir de otros vectores o usando comandos\n\n\n\n\nyvect &lt;- c(1,3,5,7,9)\nz &lt;- c(xvect, yvect)\n\n\n\n\n\nx &lt;- rep(1, times=4)\ny &lt;- seq(from = 10, to = 1, by = -1)\n\n\n\n\nPara incrementos unitarios consecutivos se usa :\n\n\nz &lt;- 1:10       # equivale a z &lt;- seq(1,10,1)"
  },
  {
    "objectID": "docs/Tema00.html#clase-de-un-vector",
    "href": "docs/Tema00.html#clase-de-un-vector",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Clase de un vector",
    "text": "Clase de un vector\n\nLa clase de un objeto es única (solo un tipo de elementales) y puede conocerse en el Environment o con str()\n\n\nstr(yvect)\n\n\n\ncon class()\nTambién se puede conocer la clase/modo con is() o mode()\n\n\nstr() sirve para cualquier tipo de objeto: p.e., funciones: str(log)\n\n\n\nSi se mezclan tipos distintos, R busca una clase que “acomode” a todos\n\n\nvcr &lt;- c(\"lunes\", 2) \n\n\nForzamos que un objeto sea tratado con una clase concreta, con as.integer(), as.numeric(), as.character() y as.logical()\n\nSi no se puede convertir a número, devuelve NA (con un “warning”)\n\n\n\n\n“lunes” no puede ser un número pero “2” sí se puede representar como carácter\n\nel carácter “2” NO es lo mismo que el número 2: no se pueden hacer operaciones matemáticas\n\nLas funciones is.numeric(), is.numeric(), is.logical() e is.character() comprueban si un objeto es del tipo indicado, devolviendo un valor lógico.\nDebemos diferenciar entre la clase de un objeto y como se muestra (formatea): ver la función format()\n\n\n\nNO se pueden realizar operaciones incompatibles entre clases\n\nCuidado con las comillas: NO es lo mismo un objeto (su contenido) que el carácter de su nombre\n\n\n\na &lt;- 4\nc &lt;- 'a' + 1"
  },
  {
    "objectID": "docs/Tema00.html#atributos-de-un-objecto-vector",
    "href": "docs/Tema00.html#atributos-de-un-objecto-vector",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Atributos de un objecto Vector",
    "text": "Atributos de un objecto Vector\n\nLos vectores pueden tener nombres: una “etiqueta” (única) para cada elemento del vector\nLos nombres de un vector son un vector de caracteres de la misma longitud\n\n\naltura &lt;- c(176, 165, 189, 155, 168)\naltura\nnames(altura) &lt;- c(\"Jose\", \"Maria\", \"Juan\", \"Elena\", \"Rosa\")\nnames(altura)\naltura\n\n\n\nObviamente podemos asignar el vector creándolo con c() o a partir de un vector existente\nNotad cómo cambian las propiedades (cómo se ve el vector) tras aplicarle un nombre"
  },
  {
    "objectID": "docs/Tema00.html#aritmética-de-vectores",
    "href": "docs/Tema00.html#aritmética-de-vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Aritmética de vectores",
    "text": "Aritmética de vectores\n\nLa mayoría de los operadores se aplican elemento-a-elemento\n\n\n\n\na &lt;- seq(1,3,1)\nb &lt;- seq(6,8,1)\n\n\n\n\n\na+b\na*b\n\n\n\n\nCon diferentes longitudes, se repite el vector corto cuanto sea necesario\n\n\n\n\nb &lt;- 6:9\na + b\n# a veces es lo que queremos!  \na + 1\n\n\n\n\n\nSi las dimensiones no son múltiplos exactos…\n\n\nb &lt;- 1:12  \na+b   # Warning!     \n\n\n\n\nAlgunas funciones relevantes\n\n\n\n\nlength(xvect)   # longitud\nsort(xvect)     # ordenar\nmax(xvect)      # máximo\nmin(xvect)      # mínimos\nsum(xvect)      # suma \nprod(xvect)     # producto \n\n\n\n\n\nmean(xvect)     # media \nvar(xvect)      # varianza\ntable(xvect)    # frecuencias\n\nsummary(xvect)  # estadísticos \n\n\n\n\n\nEs MUY CONVENIENTE revisar cuidadosamente las dimensiones de los vectores antes de una operación, aunque R va a proceder de una forma bien definida…"
  },
  {
    "objectID": "docs/Tema00.html#vectores-lógicos",
    "href": "docs/Tema00.html#vectores-lógicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores lógicos",
    "text": "Vectores lógicos\n\nObtenemos objeto lógico enunciando una relación que puede ser cierta o falsa \nEstos enunciados incluyen comparaciones básicas de igualdad o desigualdad\n\n\n\n\n1 == 1  # TRUE\n1 != 3  # TRUE\n1 &gt; 2   # FALSE\n\n\n\n\n\na &lt;- 3 \na &gt;= 3       # TRUE\na + 1 &lt;= 10  # FALSE\n\n\n\n\nO combinar varios enunciados con operadores Y (&), O (|) y NO (!):\n\n\nPara conjuntos, x %in% Y es cierto cuando x es un elemento de Y\n\n\n\nNotad la doble igualdad == para el operador lógico de igualdad\nNuevamente podemos confundir los objetos hola y adios con sus caracteres\n\n\n\nEn vectores las operaciones son elemento a elemento\n\n\n\n\naltura &gt;= c(175,165,195,165,168)\naltura == 155\naltura &gt; 160 & altura &lt;= 180\n\n\n\n\n\naltura &lt; 160 | altura &gt;= 180\n\ncondicion &lt;- !(altura &lt;= 170)\n\n\n\n\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y ==\naprender lógico para selección: paro de hombre,paro de hombre jovenes\ncondiciones compuesta: venta media de hombres de valencia y alicante en realidad es un enunciado formal con OR\n(recordad que esto también pasaba en gretl y en general aprender lógica)"
  },
  {
    "objectID": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "href": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Acceso a los elementos de un vector",
    "text": "Acceso a los elementos de un vector\n\nSe utiliza el operador [] (paréntesis cuadrado)1 y\n\n\n\nCon [[ ]] se enfatiza acceso a un elemento: esto es importante en otros objetos (listas, datos) pero no en vectores (ambas formas son equivalentes)\n\n\n\nPosiciones de los elementos, usando un vector de enteros\n\n\naltura[3]\naltura[c(1,3,5)]\n\n\nCon enteros negativos, indicamos posiciones que NO queremos\n\n\naltura[-c(2,4)] \n\n\n\nimporta el orden de las posiciones: altura[c(3,1)] frente altura[c(1,3)]\n\n\n\nNombres de los elementos, usando un vector de caracteres\n\n\naltura[ \"Juan\" ]\naltura[ c(\"Jose\", \"Elena\") ]\n\n\nCondición que satisfacen los elementos, usando un vector lógico\n\n\naltura[altura &gt; 180 | altura &lt; 160]\n\n\n\nerror por comillas se puede hablar diferencias de altura[pos] y altura[“pos”] y altura[“Juan”]: confusió de comillas y diferencia entre objeto y caracter de nombre de objeto\nLa función which() también puede ser útil para posiciones lógicas\n\n\nTambién con [[ ]]"
  },
  {
    "objectID": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector-cont.",
    "href": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Acceso a los elementos de un vector (cont.)",
    "text": "Acceso a los elementos de un vector (cont.)\n\nLos vectores de selección pueden ser un objeto previamente asignado en los tres casos; p.e.,\n\n\npos &lt;- (altura &gt; 180 | altura &lt; 160)\naltura[pos]\n\n\nPodemos seleccionar un subconjunto del vector para trabajar con él\n\n\nalturaExtremo &lt;- altura[pos]\nmean(alturaExtremo)\n\n\nCon la asignación se pueden cambiar elementos específicos de un vector (o añadir nuevos)\n\n\naltura[3] &lt;- 196\n\naltura[c(\"María\", \"Luis\")] &lt;- c(169, 175)"
  },
  {
    "objectID": "docs/Tema00.html#factores",
    "href": "docs/Tema00.html#factores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Factores",
    "text": "Factores\n\nLos factores son un tipo de objeto de R específico para trabajar con información cualitativa\nLos datos originales pueden estar codificados de forma poco clara para el análisis (género como número o abreviatura)\nSe usa factor() para crear un vector de tipo factor, con argumentos para los niveles y sus etiquetas\n\n\ngenero   &lt;- c(1, 2, 2, 1, 1)\ngenero_f &lt;- factor(genero, \n                    labels = c(\"Mujer\", \"Hombre\"), \n                    levels = c(1,2))\n\n\n\nNotar que el comando factor() se extiende en el editor en varias lineas (no es “una” línea por comando)\nEn la consola, se indica que sigue siendo el mismo comando en múltiples líneas con + en lugar de &gt;\n\n\n\nTambién podemos crear un factor con orden\n\n\nsatisf   &lt;- c(\"Alto\", \"Bajo\", \"Alto\", \"Bajo\", \"Medio\")\nsatisf_f &lt;- factor(satisf, order = TRUE,\n                        levels = c(\"Bajo\", \"Medio\", \"Alto\"))"
  },
  {
    "objectID": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "href": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Resumiendo” un vector numérico o un factor",
    "text": "“Resumiendo” un vector numérico o un factor\n\nLa función summary() devuelve los principales estadísticos descriptivos de un vector numérico\n\n\nsummary(altura)\n\n\n\nEl “resultado” de summary() también es un objeto de R: se puede asignar y trabajar con él\n\na &lt;- summary(altura)\nstr(a)\na[1:2]\n\n\nPara información cualitativa, la media y otros estadísticos no tienen sentido\n\n\nsummary(genero)\ngenero  &lt;- c(1, 20, 20, 1, 1)  # dos categorías igualmente\nsummary(genero)\n\n\nLa función summary() ofrece resultados diferentes según el tipo de objeto (porque tiene distintas propiedades)\n\n\nsummary(genero_f)"
  },
  {
    "objectID": "docs/Tema00.html#matrices",
    "href": "docs/Tema00.html#matrices",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Matrices",
    "text": "Matrices\n\nLas matrices son una extensión de vectores a dos dimensiones.\n\n\nSe pueden crear con matrix() o uniendo vectores filas o vectores columnas (de las mismas dimensiones) con cbind() y rbind()\n\n\n\n\nr1 &lt;- 1:4\nr2 &lt;- c(4, 8, 5, 10)\nM1 &lt;- rbind(r1, r2)\n\n\n\n\n\nc1 &lt;- 11:12\nc2 &lt;- 25:26\nc3 &lt;- c(14, 25)\nM2 &lt;- cbind(c1, c2, c3)\n\n\n\n\nPodemos usarlos para añadir nuevas filas, columnas u otra matriz\n\n\n\nSi no tienen dimensiones compatibles, R repetirá (como ya vimos en aritmética de vectores)\n\nM1 &lt;- cbind(matrx, c(90,95))\nM2 &lt;- rbind(matrx, c(40, -20, 25))\nA &lt;- cbind(c(40,30), c(70, 75))\ncbind(M1, A)\nB &lt;- cbind(c(40, 2), c(-20, 1), c(25, 1))\nrbind(matrx, B)\n\n\nPodemos dar nombres a columnas y filas\n\n\ncolnames(M2) &lt;- c(\"ene\", \"feb\", \"mar\")\nrownames(M2) &lt;- c(\"gast\", \"ingr\")"
  },
  {
    "objectID": "docs/Tema00.html#matrices-cont.",
    "href": "docs/Tema00.html#matrices-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Matrices (cont.)",
    "text": "Matrices (cont.)\n\n\nNotad que NO podemos usar la función names() vista anteriormente porque solo aplica a vectores\nTambién se puede especificar los nombres al crear con matrix con argumento dimnames\n\nmeses &lt;- c(\"ene\", \"feb\", \"mar\")\nmatrx &lt;- matrix(data = c(100, 60, 55, 75, 110, 85),\nnrow = 2,dimnames=list(c(\"gast\", \"ingr\"), meses))\n\n\nUsamos los paréntesis cuadrados para acceder a los elementos (o una sub-matriz) por posición, nombre o condición lógica\n\n\n\n\nM2[1,3]                 \nM2[\"ingr\", \"ene\"]      \nM2[c(1:2),c(1,3)]\n\n\n\n\n\nM2[2,]      # fila entera\nM2[,\"feb\"]  # columna entera\n\n\n\n\n\nNotad que en matrices tiene más sentido el doble paréntesis cuadrado [[ ]] (debería preferirse para acceder a un elemento por su posición sobre el total)\n\n\n\nLas operaciones habituales son elemento a elemento: la matrices deben tener las mismas dimensiones (o R repetirá elementos)\n\n\n\n\nmatrx + M2\nmatrx * M2\n\n\n\n\n\nmatrx - 3\nmatrx * 10 \n\n\n\n\n\nComo en el caso de vectores, si las dimensiones no son iguales, se repiten elementos\nEn las operaciones con escalares , realmente se han “expandido” los escalares a una matriz de dimensiones equivalentes (una matriz con todos los elementos iguales al escalar)\n\n\n\nSe pueden hacer todo tipo operaciones matriciales con R como multiplicación matricial, %*%, transponer, t(M1), invertir, solve(A), etc.\nTambién existen funciones para matrices: diag(), rowSums(), colMeans(), etc."
  },
  {
    "objectID": "docs/Tema00.html#listas",
    "href": "docs/Tema00.html#listas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Listas",
    "text": "Listas\n\nUna lista es una colección genérica de objetos: similares a los vectores, pero conteniendo objetos de distintos tipos\n\n\nx &lt;- 1:30\nmiLista &lt;- list(\"hola\", x, list(1:4, \"X\"))\nmiLista\n\n\nLa función str también se puede usar para listas\n\n\nstr(miLista)\n\n\n\nVeremos que muchos objetos de R son listas\nTambién vemos las propiedades del objeto en el Environment\n\n\n\nPodemos añadir nombres a los elementos de una lista o dáreselos al generarla:\n\n\nnames(miLista) &lt;- c(\"saludo\", \"vec\", \"lista\")\nmiLista &lt;- list(saludo=\"hola\", vec=x, lista=list(1:4, \"X\"))"
  },
  {
    "objectID": "docs/Tema00.html#listas-cont.",
    "href": "docs/Tema00.html#listas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Listas (cont.)",
    "text": "Listas (cont.)\n\nCon [] extraemos elementos por posición o por nombre, como listas\n\n\nclass(miLista[\"vec\"])\nmiLista[2] + 2     # operación incompatible entre clases\n\n\nCon [[ ]] (por posición o por nombre) o con $(solo por nombre) extraemos los elementos en su clase original\n\n\n\n\nclass(miLista$\"vec\")\n\n\n\n\n\nclass(miLista[[2]])\nmiLista[[\"vec\"]] + 2\n\n\n\n\n\nNota: el uso de [ ] y [[ ]] también se aplica a “data frames”\nEs importante entender el tipo de objeto de obtenemos con una forma de acceso u otra, por las operaciones que podemos realizar y por las transformaciones que se permiten\nP.e., podemos acceder a elementos individuales de la (sub-)lista con [[ ]], pero no con [ ]:\n\nmiLista[[2]][2]\nmiLista[2][2]   # lista de longitud 1\n\n\nunlist() convierte una lista en vector, usando la clase que pueda ajustarse a todos los objetos (elementales)"
  },
  {
    "objectID": "docs/Tema00.html#data-frames",
    "href": "docs/Tema00.html#data-frames",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Data Frames”",
    "text": "“Data Frames”\n\nEs un tipo de objetos específico para facilitar el análisis de datos: una colección de variables por columnas y observaciones por filas.\nSe pueden crear con data.frame() a partir de vectores existentes, dando nombres a las variables, o de matrices\n\nA diferencia de las matrices, las columnas pueden ser de tipo diferentes\n\n\n\naltura &lt;- c(177, 178, 168, 164, 186, 162, 160)\npeso   &lt;- c(75, 85, 70, 60, 80, 65, 54)\ngenero &lt;- factor(c(1,2,2,2,1,1,2), \n                labels = c(\"Mujer\", \"Hombre\"))\ndatos &lt;- data.frame(\"Altura\"=altura, \"Peso\"=peso, \"Genero\"= genero)\nclass(datos) \n\n\n\nLos “data frames” son una colección (técnicamente, una lista) de vectores que corresponde a cada variable.\nPor ser listas, pueden tener columnas de tipos de diferentes, a diferencia de las matrices\n\n\n\nSe puede visualizar con View(datos) o en “Enviroment” de RStudio\n\n\nView(datos)\n\n\nO solo una parte de los datos con head() y tail()"
  },
  {
    "objectID": "docs/Tema00.html#trabajando-con-data-frames",
    "href": "docs/Tema00.html#trabajando-con-data-frames",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Trabajando con “Data Frames”",
    "text": "Trabajando con “Data Frames”\n\nPodemos acceder a columnas por su nombre con $ o por nombre o posición de la columna con [[ ]]\n\n\nvectAltura &lt;- datos$Altura    # objeto resultante = vector\ndatos[[2]] == datos[[\"Peso\"]]\n\n\n\nnotar\n\naltura_vect[1] == datos$altura[1]\ndatos[[2]][1] == datos[[\"peso\"]][1]\n\n\nTambién se puede usar notación de matrices. \n\n\ndatos[,1]           # 1ª columna  = vector\ndatos[1,c(\"Altura\", \"Genero\")]   # data frame\ndatos[1:3,1:2]                   # data frame\n\n\nTambién seleccionamos usando filtros basados en condiciones lógicas\n\n\nd1 &lt;- datos[datos$Altura &gt; 165,]           # data.frame\nd2 &lt;- datos[datos$Altura %in% c(177,178), \"Altura\"] # vector"
  },
  {
    "objectID": "docs/Tema00.html#trabajando-con-data-frames-cont.",
    "href": "docs/Tema00.html#trabajando-con-data-frames-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Trabajando con “Data Frames” (cont.)",
    "text": "Trabajando con “Data Frames” (cont.)\n\nLa función subset() extrae parte de los datos, basado en una condición lógica; devuelve siempre un “data frame”\n\n\nD1 &lt;- subset(datos, Altura &gt; 165)   \nD2 &lt;- subset(datos, subset = Altura %in% c(177,178),\n                    select = Altura) \n\n\nGeneramos nuevas variables con el vector de asignación\n\n\ndatos$Altura_m &lt;- datos$Altura / 100\n\n\n\nTambién se puede usar (pero NO recomendable) attach(): carga un objeto en el “Global Environment” y no es necesario poner su nombre para acceder a las variables con $\n\n\nÚtil con solo un conjunto de datos o si no hay lugar de confusión (no hay el mismo nombre de variable en diferentes conjuntos de datos)\nSe deja de vincular con detach()\n\n\nPara ordenar un conjunto de datos por una variable, order() crea un vector de posiciones de orden\n\n\n\nEn general, no generaremos nuestros conjuntos de datos sino que los incorporaremos como objetos a R de varias formas."
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-libraries",
    "href": "docs/Tema00.html#bibliotecas-libraries",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (“libraries”)",
    "text": "Bibliotecas (“libraries”)\n\nUna biblioteca contiene nuevos objetos de R: funciones, datos, etc.\nPara instalar una nueva biblioteca (se hace una vez), en Tools &gt; Install packages o en  o con el comando \n\n\ninstall.packages(\"AER\")\n\n\nMantenemos actualizados los paquetes, en el menú Tools o en \nLa biblioteca solo está disponible si se carga en la sesión actual\n\n\nlibrary(AER)\n\n\nNota: en adelante, la bibliotecas que carguemos se suponen instaladas\nEn  vemos las bibliotecas instaladas y las cargadas aparecen marcadas \n\n\n\nR puede extenderse con capacidades adicionales instalando paquetes con bibliotecas\nSe instala UNA VEZ, se carga en cada sesión que se usa\nPodemos ver las bibliotecas cargadas en \n\nmirarlo antes y después de library(AER)\no por línea de comandos\n\n\n\nLa ayuda contiene información sobre las funciones de una biblioteca, incluyendo ejemplos de uso (“vignettes”) en algunos casos\n\nlibrary(help=utils)\n\nPodemos descargar una biblioteca de memoria con detach()\nLa función require() es “similar” a library()"
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-cont.",
    "href": "docs/Tema00.html#bibliotecas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (cont.)",
    "text": "Bibliotecas (cont.)\n\nEl nombre completo de un objeto es biblioteca::nombre\n\nLa biblioteca solo es necesaria si no se ha cargado o dos objetos diferentes tienen el mismo nombre en bibliotecas distintas\n\n\n\n\n\nbase::log(1)\nlog(1)\n\n\n\n\n\nlibrary(Hmisc)\nfind(\"units\")\n\n\n\n\n\nEn la Ayuda, vemos la biblioteca a la que pertenece una función (entre llaves)\nEl nombre completo es necesario si hay conflicto entre bibliotecas: contienen objetos con el mismo nombre\n\n\n\nTambién se usa nombre completo si no se ha cargado la biblioteca\nPara mostrar todos los datos de las bibliotecas cargadas\n\n\ndata()\n\n\nLos podemos cargar en el “Environment” y obtener información detallada en la ayuda (ej., nombre de variables)\n\n\ndata(\"Affairs\")\nhelp(\"Affairs\")"
  },
  {
    "objectID": "docs/Tema00.html#datos-nativos-en-r",
    "href": "docs/Tema00.html#datos-nativos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos “nativos” en R",
    "text": "Datos “nativos” en R\n\nGuardamos objetos del espacio de trabajo con save() (en una ruta relativa al directorio de trabajo)\n\n\nx &lt;- 1:20\ny &lt;- 2 * x ^ 2 + 1\nsave(x, file=\"data/x.RData\")      # un objeto, o varios\nsave(x, y, file=\"data/xy.RData\")  #   separados por comas\n\n\n\nExtensiones .RData, .rda, .rds, …\nO todo el workspace con save.image() (= icono )\n\n\n\nPara cargar datos al espacio de trabajo, con load() (= icono )\n\n\nload(\"data/xy.RData\")\n\n\nEn la pestaña de : doble-clic carga un archivo de datos\nNota: este tipo de archivo puede contener varios objetos, incluidas varios conjuntos de datos\n\n\n\nEs posible cargar directamente desde internet:\n\nload(url(\"https://github.com/albarran/BigDataEcon/raw/main/data/altura.RData\"))\n\nTambién se eliminan archivos con la función unlink()"
  },
  {
    "objectID": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "href": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos en otros formatos externos a R",
    "text": "Datos en otros formatos externos a R\n\nVarias bibliotecas permiten trabajar con distintos tipos de archivos de datos; entre otros:\n\nTexto, con delimitadores o de ancho fijo: utils (R base), readr\nHojas de cálculo: readxl, openxlsx \nFormatos de software estadístico: haven, foreign\n\n\n\n\nDos bibliotecas a veces ofrecen comandos distintos que hacen lo mismo\nPero tienen distintas opciones y sus opciones por defecto son diferentes (p.e., cómo tratan los caracteres: ¿se convierten a factores?)\n\n\n\nDescargad estos ejemplos: renta.txt, sex_data.csv, beauty.xls, nsw.dta\nEn  de RStudio, tenemos acceso visual para cargar algunos formatos (con la biblioteca necesaria instalada)\nrio es un meta-paquete (instala otras bibliotecas) para importar y exportar varios formatos de datos de forma sencilla\n\nA partir de la extensión del archivo, detecta el formato y, por tanto, la biblioteca necesaria\n\n\n`"
  },
  {
    "objectID": "docs/Tema00.html#importar-y-exportar-con-rio",
    "href": "docs/Tema00.html#importar-y-exportar-con-rio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Importar y exportar con rio",
    "text": "Importar y exportar con rio\n\nrio permite trabajar con varios formatos de forma simple y unificada (el mismo comando para todos)\n\nP.e., datos nativos de R, archivos de texto (también comprimidos), hojas de cálculo, formatos de software estadístico, Google Sheets, json\nEn la Ayuda se incluye una presentación completa del paquete\n\nEl comando import() se usa para leer los datos\n\n\nlibrary(rio)\nsex   &lt;- import(\"data/sex_data.csv\")\nrenta &lt;- import(\"data/renta.txt\")\nbeauty &lt;- import(\"data/beauty.xls\")\nnsw    &lt;- import(\"data/nsw.dta\")    # formato Stata"
  },
  {
    "objectID": "docs/Tema00.html#importar-y-exportar-con-rio-cont.",
    "href": "docs/Tema00.html#importar-y-exportar-con-rio-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Importar y exportar con rio (cont.)",
    "text": "Importar y exportar con rio (cont.)\n\nLas opciones por defecto para un archivo pueden no ser adecuadas (p.e., el tipo de separador con .csv)\nLa Ayuda describe los argumentos para cambiarlas\n\na veces, pasando argumentos del comando de la biblioteca original\n\nPodemos exportar datos a un tipo de formato con export()\n\n\nexport(nsw, \"data/nsw.csv\")\n\n\nO convertir un archivo del disco a otro formato con convert()"
  },
  {
    "objectID": "docs/Tema00.html#otras-fuentes-de-datos",
    "href": "docs/Tema00.html#otras-fuentes-de-datos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Otras fuentes de datos",
    "text": "Otras fuentes de datos\n\nLa biblioteca httr tiene la función GET() para descargar una página web\nBibliotecas con datos muy utilizados: pwt (“Penn World Tables”)\nBibliotecas con funciones para acceder directamente a datos online (con APIs públicas)\n\nrdbnomics para los datos gratuitos de https://db.nomics.world/\nOECD para los datos de la OCDE\neurostat (incluye datos del INE español)\nquandl (de pago)\nquantmod y tidyquant\nMicroDatosEs con microdatos del INE (ej., EPA)"
  },
  {
    "objectID": "docs/Tema00.html#gráficos-básicos",
    "href": "docs/Tema00.html#gráficos-básicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Gráficos Básicos",
    "text": "Gráficos Básicos\n\nPodemos representar gráficos de dos variables o funciones\n\n\n\n\nx &lt;- c(3, 4, 5, 6, 7, 8, 9)\ny &lt;- c(5, 6, 8, 9, 5, 9, 10)\n\n\n\n\n\nplot(x,y)\ncurve(x^2, from=-2, to=2)\n\n\n\n\nEl resultado aparece en la pestaña Plots de RStudio\n\n\n\n\n\nPodemos cambiar opciones (ver Ayuda de plot.default) como type (puntos, líneas, etc.), símbolo de punto (pch), tipo de línea (lty), ancho de línea (lwd), color (col), título, etiquetas de los ejes, etc.\n\n\nplot(x, y, type=\"b\", pch=3)\nplot(x, y, type=\"l\", lty=2, lwd=2)\nplot(x, y, xlab=\"Eje X\", ylab=\"Eje Y\", main=\"Mi título\")\n\n\nSe pueden cambiar más opciones con par(), combinar gráficos, añadir líneas, texto, etc. y exportar los gráficos"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables discretas",
    "text": "Estadísticos descriptivos: variables discretas\n\nPara variables discretas (factores), table() calcula distribuciones de frecuencias de una variable o conjuntas: el resultado es un objeto\n\n\ndata(\"PSID1982\", package = \"AER\")\n(frec   &lt;- table(PSID1982$occupation) )\n(frec_c &lt;- table(PSID1982$occupation, PSID1982$ethnicity))\n\n\n\nEl objeto es una “tabla” es una variante de vector o matrices con nombres\nSe podría opera con él: table(PSID1982$occupation) / sum(table(PSID1982$occupation)))\n\n\n\nPodemos mostrar frecuencias relativas con prop.table()\n\n\n\n\nprop.table(frec)\nprop.table(frec_c)\n\n\n\n\n\nprop.table(frec_c, margin = 1)\nprop.table(frec_c, margin = 2)\n\n\n\n\n\nRecordad: conceptos de distribución marginal (probabilidad de un valor en X), distribución conjunta (prob. de un valor de X Y uno de Y ) y distribución condicional (prob. de Y dado un valor de X)\n(In)dependencia y distribuciones conjunta y marginal: p.e., la distribución de trabajos es distinta en general o condicional a ser afroamericano\n\nsabiendo que una persona es afroamericano, es más probable que sea cualificado (mayor renta, etc.)\n\n\n\n\nTambién es informativa su representación con gráficos de barras\n\n\nbarplot(frec, horiz = T)\nbarplot(prop.table(frec_c), beside = T)\n\n\n\nbarplot(prop.table(frec_c)) en otros casos puede ser más informativo que aquí\nTambién se puede representar con gráficos de tarta: pie(frec)\nLos gráficos admiten (casi) todas las opciones de plot() como títulos, etc. y otras específicas"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas",
    "text": "Estadísticos descriptivos: variables continuas\n\ndata(ceosal1, package='wooldridge')\n\n\nYa hemos visto funciones de estadísticos como mean(), var(), etc.\n\n\nmedian(ceosal1$salary)\nvar(ceosal1$salary)\n\n\nquantile(ceosal1$salary, \n         probs=c(0.25, 0.75) ) # 1er y 3er cuartil\n\nsummary(ceosal1$salary)  # de una variable (vector)\nsummary(ceosal1)         # de todo el conjunto de datos  \n\ncov(ceosal1$salary, ceosal1$roe)  # covarianza\ncor(ceosal1$salary, ceosal1$roe)  # correlación\n\n\n\nRecordad el tratamiento diferente de factores en summary()\nOtras funciones de estadísticos: min(), max(), range(), sum()"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas (cont.)",
    "text": "Estadísticos descriptivos: variables continuas (cont.)\n\nPara variables continuas, las frecuencias de valores en un intervalo se pueden tabular o graficar en un histograma\n\n\n\nEn teoría, cada obervación de una variable continua tiene valores distinto; en la práctica se repiten pero no tanto como en las discretas\n\n\n\nhist(ceosal1$roe)   # intervalos automáticos\nhist(ceosal1$roe, freq=F,       # densidad, no casos\n     breaks=c(0,5,10,20,30,60)) # intervalos explícitos\n\n\nO la densidad (versión suavizada del histograma)\n\n\nplot(density(ceosal1$roe))\n\n\n\nSe pueden combinar histograma y densidad ejecutando hist(x) y luego lines(density(x))\n\n\nLa función de distribución acumulada empírica es otra representación de la distribución de una variable (en especial, continua)\n\nplot(ecdf(ceosal1$roe))\n\nLa definición de valor atípico/extremo es “arbitraria”. Aquí es 1.5 veces el rango intercuartículo por encima/debajo de la caja.\n\n\n\nUn gráfico de caja ofrece información resumida de la distribución: mediana, 1er y 3er cuartil, y valores “extremos”\n\n\nboxplot(ceosal1$roe, horizontal=T)\nboxplot(ceosal1$roe~ceosal1$consprod)\n\n\n\nEl símbolo \\~ en R indica que una variable es función de otras: en este caso, la distribución de roe se reprensenta en función de los valores de otra"
  },
  {
    "objectID": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "href": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Valores ausentes (“missing values”): NA",
    "text": "Valores ausentes (“missing values”): NA\n\nMuchos conjuntos de datos tienen valores ausentes de ciertas observaciones para algunas variables: ej., descargad earn.RData\n\n\nSabemos si una observación es NA y la frecuencia total:\n\n\n\n\nload(\"data/earn.RData\")\nx &lt;- earn$earnings\n\n\n\n\n\nis.na(x)\ntable(is.na(x))\n\n\n\n\n\nRecordemos también any(is.na(x)) (hay algun NAs?) o which(is.na(x)) (qué elementos son NA)\n\n\n\nPor defecto en R, un cálculo con NAs es NA: debemos decir que los elimine explícitamente (y ser conscientes de lo que implica)\n\n\n\n\nmean(x)\n\n\n\n\n\nmean(x, na.rm=TRUE)\n\n\n\n\n\nsum(), quantile() y otras tienen la opción de na.rm=TRUE\nen cor() la opción es diferente: cor(x, earn$age, use=\"complete.obs\")\n\n\n\nna.omit() elimina observaciones con NAs de una o varias variables\n\n\nearn2 &lt;- na.omit(earn)\n\n\n¿Cómo tratar los NAs? Eliminarlos implica selección muestral y la alternativa de imputar valores implica supuestos sobre éstos\n\n\n\nTambién podemos filtrar y &lt;- x[!is.na(x)] u otras formas\nOtra función útil complete.cases()\n\ns &lt;- complete.cases(x)\nearnComplete &lt;- earn[s,]\n\nPara reemplazar valores (si pensamos que tiene sentido): y &lt;- replace(x, which(is.na(x)), -1)\nLos estadísticos con la muestra sin NA pueden no ser representativos de la población total: solo muestrear en barrio pobre es igual de poco representativo que haya menos respuestas en el barrio rico\nsuponer que podemos imputar renta solo con edad, genero y educación es restrictivo…"
  },
  {
    "objectID": "docs/Tema00.html#estadísticas-por-grupos-aggregate",
    "href": "docs/Tema00.html#estadísticas-por-grupos-aggregate",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticas por grupos: aggregate",
    "text": "Estadísticas por grupos: aggregate\n\nPara obtener estadísticas de una variable por grupos definidos por otra, podemos filtrar los datos\n\n\nmean(ceosal1$roe[ceosal1$indus==1])\nmean(subset(ceosal1, indus==0)$roe)\n\n\nPero la función aggregate() lo hace más sencillo y devuelve un data frame\n\n\naggregate(roe ~ indus, data=ceosal1,  FUN=mean)\n\n\nTambién en función de varias variables\n\n\naggregate(roe ~ indus + finance, data=ceosal1,  FUN=mean)\n\n\nNotar la notación de formulas en R: ~ indica “en función de”, separando las variables con +\n\n\n\nPREGUNTA: cómo se haría con regresión?\n\nlm(data=ceosal1, roe ~ indus)\n\nTambién aggregate(ceosal1$roe, by=list(ceosal1$indus), FUN=mean)\nVariaas variables en función de otra:\n\naggregate( cbind(earnings, age) ~ year, data=earn2, FUN=mean )\n\nO de varias variables en función de varias variables\n\na &lt;- aggregate( cbind(earnings, age) ~ year + degree, data=earnComplete, mean )\nstr(a) # 'a' es un data frame!"
  },
  {
    "objectID": "docs/Tema00.html#funciones-para-distribuciones-de-probabilidad",
    "href": "docs/Tema00.html#funciones-para-distribuciones-de-probabilidad",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Funciones para distribuciones de probabilidad",
    "text": "Funciones para distribuciones de probabilidad\n\nDensidad (variables continuas) o de masa (variables discretas) de probabilidad de un valor x:\n\ndbinom(), dunif(), dlogis(), dnorm(), dchisq(), dt(), dF()\n\n\n\n\nPara una variabla discreto la fmp da la probabilidad de la variable aleatoria X tome exactamente el valor x\n\nx &lt;- 0:10\nfx &lt;- dbinom(x, 10, 0.2)\nplot(x,fx)\n\ncurve(dnorm(x), -5, 5): un punto de la campana\n\n\n\nDistribución acumulada por debajo de x\n\npbinom(), punif(), plogis(), pnorm(), pchisq(), pt(), pF()\n\n\n\n-todo el área acumlada por debajo de un valor en la campana normal - pnorm(1.96)-pnorm(-1.96) = 0.95 :\n\nnotar que pnorm(1.96)=0.975 y qnorm(0.975)=1.96\n\n\n\nValor cuya probabilidad acumulada es el cuartil q\n\nqbinom(), qunif(), qlogis(), qnorm(), qchisq(), qt(), qF()\n\nGenerador de números (pseudo)aleatorios:\n\nrbinom(), runif(), rlogis(), rnorm(), rchisq(), rt(), rF()\n\n\n\nset.seed(7675)\nrnorm(5)\n\n\n\nUn ordenador (no cuántico) ofrece números de un secuencia determinista tan compleja que no es distinguible de la aleatoriedad"
  },
  {
    "objectID": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "href": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Nota sobre programación “avanzada”",
    "text": "Nota sobre programación “avanzada”\n\nComo en todo lenguaje de programación R, tiene funciones para\n\nEjecución condicional if(): una parte del código se ejecuta solo si se cumple una condición\nBucles for(): se repite un mismo bloque de código mientras se itera por los valores de vector\nCrear funciones propias con function()\n\nUna variante de la ejecución condicional, solo para crear variables según una condición\n\n\ndata(\"Affairs\", package = \"AER\")\nAffairs$univers &lt;- ifelse(Affairs$education&gt;15, 1, 0)\n\n\n\nTanto if-else como for pueden escribirse en una sola línea sin \\{ si solo incluye un comando en el bloque entre llaves:\n\nif (p&lt;=0.05) decision &lt;- \"Rechazar H0\" else decision &lt;- \"NO Rechazar H0\"\n\nPueden anidarse if-else, for y ambos\nOtros comandos de bucles: while, repeat, replicate, apply, lapply, y otros (map) en bibliotecas adicionales"
  },
  {
    "objectID": "docs/Tema00.html#simulaciones",
    "href": "docs/Tema00.html#simulaciones",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Simulaciones",
    "text": "Simulaciones\n\nEn la realidad, los datos se consideran una muestra de una población con parámetros desconocidos: estimamos para inferir sus valores\nUn ordenador permite razonar “a la inversa”: fijar los parámetros de la población, generar una muestra aleatoria de esa distribución y estimar\n“Vemos” la variabilidad muestral de los estimadores: p.e., las medias de muestras obtenidas de la misma distribución son distintas\n\n\n\n\nset.seed(543210)\nsample1 &lt;- rnorm(100,10,2)\nmean(sample1)\n\n\n\n\n\n#\nsample2 &lt;- rnorm(100,10,2)\nmean(sample2)\n\n\n\n\nNo debe sorprendernos y, de hecho, sabemos cómo es esa variabilidad: si \\(Y_i \\sim N(\\mu, \\sigma^2)\\), entonces \\(\\bar{Y}=\\frac{1}{n} \\sum_{i=1}^n Y_i \\sim N(\\mu, \\frac{\\sigma^2}{n})\\)"
  },
  {
    "objectID": "docs/Tema00.html#simulaciones-cont.",
    "href": "docs/Tema00.html#simulaciones-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Simulaciones (cont.)",
    "text": "Simulaciones (cont.)\n\nLos bucles for permiten repetir el proceso muchas veces\n\n\n\n\nset.seed(123456)\nr &lt;- 10000\nybar &lt;- numeric(r)\n\n\n\n\n\nfor (j in 1:r) {\n  sample &lt;- rnorm(100,10,2)\n  ybar[j] &lt;- mean(sample)\n}\n\n\n\n\nY comprobar si se cumple la teoría estadística\n\n\n\n\nybar[1:20]\nmean(ybar)\nvar(ybar)\n\n\n\n\n\nplot(density(ybar))\ncurve(dnorm(x,10, 2/sqrt(100)), \n       add=TRUE,lty=2)"
  },
  {
    "objectID": "docs/Tema00.html#propiedades-asintóticas",
    "href": "docs/Tema00.html#propiedades-asintóticas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Propiedades asintóticas",
    "text": "Propiedades asintóticas\n\nEl análisis asintótico se ocupa del comportamiento de los estimadores cuando el tamaño muestral es grande\nPara una muestra de tamaño \\(n\\) de una población (de “cualquier” distribución) \\(Y\\sim (\\mu, \\sigma^2)\\),\n\nsegún la ley de los grandes números, \\(E(\\bar{Y}) \\to \\mu\\) cuando \\(n \\to \\infty\\)\nsegún el teorema central del límite, \\(\\bar{Y} \\overset{a}{\\sim} N(\\mu, \\sigma^2/n)\\)\n\n\n\n\n\nset.seed(123456)\nr &lt;- 10000\nybar &lt;- numeric(r) \nn &lt;- 10  # 10, 50, 100, 1000\n\n\n\n\n\nfor (j in 1:r) {  \n  sample &lt;- rchisq(n,1) \n  ybar[j] &lt;- mean(sample) \n}\nplot(density(ybar))\n\n\n\n\nMás ejemplos en esta aplicación escrita totalmente en R\n\n\n\nsegun LGN, también \\(Var(\\bar{Y})\\to 0\\)"
  },
  {
    "objectID": "docs/Tema06ej.html",
    "href": "docs/Tema06ej.html",
    "title": "Tema 6. Ejercicio.",
    "section": "",
    "text": "Apartado a)\n\nIniciar un nuevo documento de Quarto desde el menú Archivo. Adapta el encabezado para que tenga, al menos, un título y tu nombre como autor o autora. (Puedes eliminar el resto del contenido para los siguientes apartados, dejando espacio tras la cabecera).\nNOTA: recuerda que deberías crear cada archivo .R o .qmd con los que trabajes como parte de un proyecto de RStudio.\n\n\nCrea una primera sección del documento, p.e., con el nombre “Apartado a)”. Para cada apartado posterior debes crear una nueva sección correspondiente al apartado.\nEscribe un breve frase introductoria general, una lista que enumere las dos variables que elegiste para el ejercicio de Visualización de Datos, incluye un enlace a una página web e inserta una imagen.\nNota: Puedes usar, aquí y en cualquier otra parte del documento, negritas o cursivas cuando lo consideres oportuno.\n\n\nGuarda el documento con un nombre con el siguiente formato que incluye vuestro número de DNI: Tema06ej_123456789.qmd\nRenderiza tu documento para visualizar el documento html creado.\nComprueba en el mismo directorio donde tienes el archivo .qmd se ha creado un archivo con extensión html; nota que también se ha creado un subdirectorio con el mismo nombre que contiene todo lo necesario para visualizar el archivo html.\nCambia a otro formato de salida en el encabezado YAML y genera otro documento de salida.\nComprueba de nuevo que tienes un archivo de salida (.pdf o .docx) en el mismo directorio donde está el archivo .qmd.\nBorra el documento html y el subdirectorio con el mismo nombre generados previamente. Cambia la opción de YAML para que se genere un html autocontenido. Comprueba que puedes visualizar el archivo. Comentar.\n\n\n\nApartado b)\n\nEscribe una línea de texto (NO celda de código) que incluya (entre el texto) código de R para mostrar la media de la variable mpg del conjunto de datos mtcars.\nCrear y dar un nombre a una sub-sección que incluya lo siguiente.\n\nTres celdas, todos con el código summary(mtcars). El primero debe mostrar el código, pero no el resultado; el segundo sólo mostrar el resultado (no el código); el tercero debe mostrar ambos. Antes de cada celda, incluye una frase explicando qué va a pasar.\nCargar las bibliotecas AER y Hmisc en una nueva celda de código. Cambia los valores de warning, error y message y renderiza el documento para observar los cambios. Comentar los cambios brevemente y qué forma de presentación prefieres para tu documento.\n\nCrear y dar nombre a otra sub-sección.\n\nAñadir un celda con el código a &lt;- 2, fijando la opción para que NO se evalúe. Añadir otra celda posterior con código b &lt;- 3 + a y que sí se evalúe. Renderizar el documento y comprobar que da un error.\nCambiar las opciones del segundo fragmento para que se pueda renderizar un documento de salida.\n\n\n\n\nApartado c)\n\nCrear una celda con el código para mostrar un gráfico de puntos con los datos de mtcars para las variables disp (tamaño del depósito) y mpg (consumo).\n\nAñadir en la celda de código (no usando ggplot) un título del gráfico (aparece en la parte inferior).\nCambiar en la cabecera la opción de ancho de la figura. Observar cómo cambia y elegir el que consideréis mejor, explicando muy brevemente vuestra elección.\n\n\n\nCrear una nueva celda de código que incluya dos gráficos de caja, para disp y para mpg, que se muestren uno al lado del otro.\n\n\n\nApartado d)\n\nCrear una sub-sección. Incluir una nueva celda de código (que sí se evalúe) para mostar mtcars y summary(mtcars).\nCrear una sub-sección. Incluir un nuevo fragmento de código (que sí evalúe) y que incluya:\n\ncargar la biblioteca knitr para poder usar la función kable()\nmostrar el resultado de kable(mtcars) y kable(summary(mtcars))\n\nComentar las diferencias con el apartado anterior, d.i), y y qué forma de presentación prefieres para tu documento.\n\n\n\nApartado e)\n\nIncluir la opción df-print: paged en la cabecera. Comprobar el efecto antes y después de incluirlo sobre cómo se muestra el conjunto de datos (“data frame”) mtcars en los apartados d.i) y d.ii).\nComentar las diferencias y qué forma de presentación prefieres para tu documento.\nIncluye la opción code-fold: true en la cabecera. Comprobar cómo cambia el documento y comentar brevemente qué forma de presentación prefieres para tu documento.\nElige un tema entre estos y aplícalo al documento.\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema06ej_123456789.qmd\nTema06ej_123456789.zip"
  },
  {
    "objectID": "docs/Tema09.html#introducción",
    "href": "docs/Tema09.html#introducción",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Introducción",
    "text": "Introducción\n\nMCO puede estimar modelos con muchos regresores (ej., polinomios e interacciones para relaciones no lineales), pero ¿qué variables incluimos?\nCuando crece el número de parámetros \\(\\small k\\) relativo al de observaciones \\(\\small n\\):\n\nmenor precisión (+ varianza) \\(\\Rightarrow\\) no solución única de MCO con \\(\\small k&gt;n\\)\nmodelo complejo y menos interpretable\\(\\Rightarrow\\) selección de variables\n\n\n\nSelección de variables: excluir variables irrelevantes y ajustar ese modelo reducido por mínimos cuadrados ordinarios\nRestricción de los coeficientes estimados puede reducir la varianza, a costa de un aumento insignificante del sesgo (Regresión Regularizada/Penalizada) \nReducción de la dimensionalidad: usar \\(\\small M&lt;k\\) combinaciones lineales (proyecciones) y estimar por mínimos cuadrados (PCR, PLS)"
  },
  {
    "objectID": "docs/Tema09.html#métodos-de-selección-de-variables",
    "href": "docs/Tema09.html#métodos-de-selección-de-variables",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Métodos de selección de variables",
    "text": "Métodos de selección de variables\n\nSelección del mejor subconjunto: estimar \\(\\small 2^k\\) modelos posibles con cada combinación de regresores y elegir aquel con menor error \\(\\Rightarrow\\) prohibitivo!\nAlternativas factibles (consideran un menor número de modelos)\n\nSelección paso a paso hacia adelante: añadir un regresor cada vez, eligiendo aquel con menor error en cada paso \nSelección paso a paso hacia atrás (no factible si \\(\\small k&gt;n\\))\nSelección mixta: en cada paso se añaden variables de forma secuencial, pero también se eliminan algunas (p-valor alto)\n\nNo tienen criterio riguroso, no llevan a la misma solución y no garantizan encontrar el mejor subconjunto (ej., elimina pronto un regresor importante)"
  },
  {
    "objectID": "docs/Tema09.html#ajustes-mediante-penalización",
    "href": "docs/Tema09.html#ajustes-mediante-penalización",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Ajustes mediante penalización",
    "text": "Ajustes mediante penalización\n\nLos métodos de ajuste ofrecen una estimación indirecta del error de prueba, en la muestra de entrenamiento mediante supuestos (erróneos?)\nEl \\(\\small SCR\\) de entrenamiento siempre se reduce si el modelo es más flexible \\(\\Rightarrow\\) añadir una penalización por número de parámetros\n\nCriterio de Información de Akaike: \\(\\small AIC = \\frac{1}{n}\\left( SCR + 2 k \\widehat{\\sigma}^2 \\right)\\)\n\n\\(\\small \\widehat{\\sigma}^2\\) un estimación de la varianza del error\n\nCriterio de Información Bayesiano: \\(\\small BIC = \\frac{1}{n}\\left( SCR + log(n) k \\widehat{\\sigma}^2 \\right)\\)\n\\(\\small R^2-ajustado = 1- \\frac{SCR/(n-k-1)}{SCT/(n-1)}\\) \n\n\n\nValidación cruzada ofrece una estimación más directa pero es más costosa (computacionalmente, menor tamaño muestral para estimar)"
  },
  {
    "objectID": "docs/Tema09.html#métodos-de-regularización",
    "href": "docs/Tema09.html#métodos-de-regularización",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Métodos de regularización",
    "text": "Métodos de regularización\n\nEn MCO: \\(\\small \\min_{\\beta} SCR={\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\nEn Regresión Penalizada o Regularizada, se añade una restricción que limite (reduzca) los coeficientes estimados \\[\\small \\min_{\\beta} SCR \\text { sujeto a }R(\\beta) \\leq t\\]\n\ndonde \\(R(\\cdot)\\) es una medida del tamaño de los coeficientes\nNO se penaliza a la constante (media de \\(\\small Y\\)), solo el impacto de \\(\\small X\\)\n\nLa restricción limita la importancia de las \\(\\small X\\) para explicar \\(\\small Y\\): empeora el ajuste (sesgo), pero reduce la varianza \\(\\Rightarrow\\) previene “overfitting”\nPermite ajustar un modelo que contenga todos los regresores"
  },
  {
    "objectID": "docs/Tema09.html#métodos-de-regularización-cont.",
    "href": "docs/Tema09.html#métodos-de-regularización-cont.",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Métodos de regularización (cont.)",
    "text": "Métodos de regularización (cont.)\n\nReescribiendo el problema (Lagrangiano): \\(\\small \\min_{\\beta} SCR+\\lambda R(\\beta)\\)\n\\(\\lambda \\geq 0\\) es un parámetro de ajuste (“tuning parameter”)\n\n\n\n\n\n\n\n\n\nMétodo\nPenalización por tamaño = \\(R(\\boldsymbol{\\beta})\\)\nNorma\n\n\n\n\nMCO\n0\n\n\n\nLASSO\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\\(\\ell_1\\): \\(||\\boldsymbol{\\beta}||_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\n\nRidge Regression\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_2^2 =\\sum_{j=1}^{k}\\beta_j^2\\)\n\\(\\ell_2\\): \\(||\\boldsymbol{\\beta}||_2=\\sqrt{\\sum_{j=1}^{k}\\beta_j^2}\\)\n\n\nRed Elásica\n\\(\\alpha\\lVert\\boldsymbol{\\beta}\\rVert_1 + (1-\\alpha)\\lVert\\boldsymbol{\\beta}\\rVert_2^2\\)"
  },
  {
    "objectID": "docs/Tema09.html#penalización-de-contracción",
    "href": "docs/Tema09.html#penalización-de-contracción",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Penalización de contracción",
    "text": "Penalización de contracción\n\n\n\nPara un \\(\\scriptsize \\lambda\\) dado: \\(\\small \\widehat{\\beta}^R_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}\\beta_j^2\\)\n\n\n\\[\n\\small\n\\widehat{\\beta}^L_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}|\\beta_j|\n\\]\n\n\n\nTratamos de ajustarnos a los datos minimizando SCR, PERO se recompensa a los coeficientes cercanos a cero\nDebemos estandarizar los regresores: \\(\\scriptsize \\widetilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{ \\frac{1}{n}\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2}}\\)\n\nmisma escala, misma “cercanía a cero”\n\nEn MCO, si multiplicamos \\(\\scriptsize X_j\\) por \\(\\scriptsize c\\), su coeficiente estimado se reescala por \\(\\scriptsize 1/c\\): el valor predicho \\(\\scriptsize \\widehat{\\beta_j}X_j\\) no cambia \\(\\Rightarrow\\) \\(SCR\\) no cambia\nEn Regresión Regularizada, la penalización sí cambia al reescalar \\(\\Rightarrow\\) los coeficientes estimados pueden cambiar drásticamente"
  },
  {
    "objectID": "docs/Tema09.html#regularización-y-trade-off-sesgo-varianza",
    "href": "docs/Tema09.html#regularización-y-trade-off-sesgo-varianza",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Regularización y “Trade-off” sesgo-varianza",
    "text": "Regularización y “Trade-off” sesgo-varianza\n\n¿Por qué la regularización mejoraría el ajuste sobre MCO?\n\\(\\small \\lambda\\)= importancia de la penalización (cuanto se contraen los coeficientes)\n\n\\(\\small \\lambda\\) pequeño (cercano a MCO): mayor flexibilidad (\\(-\\) sesgo, \\(+\\) varianza)\n\\(\\small \\lambda &gt;&gt; 0\\), todos los coeficientes a cero: menor flexibilidad (\\(+\\) sesgo, \\(-\\) varianza)\n\nRegularización funciona mejor cuando MCO tiene alta varianza: intercambia un poco más de sesgo por una gran reducción de la varianza\n“Ridge Regression” sigue incluyendo todos los regresores (ningún coeficiente exactamente cero): puede complicar la interpretación con muchos\nLASSO (least absolute shrinkage and selection operator): también contrae hacia cero, algunos exactamente cero (selección de variables)"
  },
  {
    "objectID": "docs/Tema09.html#ridge-regression-y-lasso",
    "href": "docs/Tema09.html#ridge-regression-y-lasso",
    "title": "Tema 09 - Selección y Regularización",
    "section": "“Ridge Regression” y LASSO",
    "text": "“Ridge Regression” y LASSO\n\n\n\n\n\n\n\n\n“Ridge regression” domina con muchos regresores igualmente importantes\nLASSO con pocos regresores importantes y muchos inútiles\nLASSO es una alternativa a los contrastes de significatividad (sin formalización estadística)\n\n\n\n\nNotad que LASSO es un método orientado a la predicción: NO se debe usar para afirmaciones de causalidad (los coeficientes están sesgados)\nPERO se puede estimar por MCO la especificación de variables seleccionada por LASSO"
  },
  {
    "objectID": "docs/Tema09.html#eligiendo-el-hiper-parámetro-de-ajuste",
    "href": "docs/Tema09.html#eligiendo-el-hiper-parámetro-de-ajuste",
    "title": "Tema 09 - Selección y Regularización",
    "section": "Eligiendo el (hiper-)parámetro de ajuste",
    "text": "Eligiendo el (hiper-)parámetro de ajuste\n\nElegir un rango de valores para \\(\\small \\lambda\\)\nCalcular el error mediante validación cruzada para cada valor de \\(\\small \\lambda\\)\nSeleccionar el valor con menor error (probar varios rangos para encontrar forma de U)\nVolver a ajustar el modelo usando todas las observaciones y el valor del parámetro de ajuste seleccionado.\n\n\nVentaja sobre la selección de regresores: SOLO necesitamos ajustar un modelo para cada valor de \\(\\small \\lambda\\)\nRegla de parquedad paramétrica: dado un conjunto de modelos igualmente buenos (dentro de un error estándar del menor error), elegir el más simple"
  },
  {
    "objectID": "docs/Tema09.html#glmnet-para-regresión-lineal",
    "href": "docs/Tema09.html#glmnet-para-regresión-lineal",
    "title": "Tema 09 - Selección y Regularización",
    "section": "glmnet para regresión lineal",
    "text": "glmnet para regresión lineal\n\nlibrary(mosaicData)\nlibrary(glmnet)\n\nx &lt;- model.matrix(data = RailTrail, volume ~ spring + summer + fall + \n                    weekday + poly(avgtemp, 6))\n\nfit.lmreg &lt;- glmnet(x = x, y = RailTrail$volume, family=\"gaussian\", \n                    lambda=2, alpha=.5)\ncoef(fit.lmreg)\n\n\nElegimos el parámetro de regularización mediante validación cruzada\n\n\nset.seed(1)\ncv.glmnet(x, RailTrail$volume) %&gt;% plot()"
  },
  {
    "objectID": "docs/Tema09.html#glmnet-para-regresión-logística",
    "href": "docs/Tema09.html#glmnet-para-regresión-logística",
    "title": "Tema 09 - Selección y Regularización",
    "section": "glmnet para regresión logística",
    "text": "glmnet para regresión logística\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;%\n  mutate(income = as.integer(factor(income))-1)\n\nx &lt;- model.matrix(income ~ education + relationship + poly(age,2) + \n                    workclass + occupation, \n              family = \"binomial\", data = censo)\nfit.glmreg &lt;- glmnet(x = x, y = censo$income, lambda=0.001, alpha=1)\ncoef(fit.glmreg)\n\n# validación cruzada para elegir parámetro de regularización\nset.seed(1)  \ncv.glmnet(x, censo$income) %&gt;% plot()"
  },
  {
    "objectID": "docs/Tema04ej.html",
    "href": "docs/Tema04ej.html",
    "title": "Tema 4. Ejercicio.",
    "section": "",
    "text": "Datos\nUtilizaremos de los datos las Penn World Tables (una famosa fuente de datos macro-económicos), disponibles en la biblioteca “pwt10” de R.\n\nInstalad el paquete de R pwt10 y cargad el conjunto de datos pwt10.01.\nEn la ayuda de R, podéis encontrar la descripción de las variables.\n\n\n\nApartado a)\nEn este apartado, reproduciremos (el gráfico de “The Economist” visto en clase (donde se relacionaba Corrupción y Desarrollo Humano) usando otras dos variables que tenga sentido relacionar.\n\nDebéis elegir la información de solo uno de los años disponibles.\nLa reproducción del gráfico es aproximada; p.e., no es necesario que el interior de los puntos esté vacio o colocar el \\(R^2\\)\n\nPara obtener la información del continente, instalad el paquete de R countries. Además de un conjunto de datos con una lista de países mundiales con sus nombres en diferentes idiomas y sus códigos estandarizados, esta biblioteca tiene una una función country_info() para obtener adicional sobre los países. En particular, si tenemos un vector, digamos, mispaises, de códigos ISO3 (que es usado por la variable isocodeen la Penn World Table), podemos obtener el continente de esas lista de paises con este código:\n\ncountry_info(countries = mispaises, fields = \"continents\")\n\n\nPara obtener el vector de países que existen en las PWT debéis usar los comandos de transformación de datos de tidyverse. \nAlgunos países pertenecen a dos continentes; debéis asignarlos a uno de ellos. Pista: separate().\n\n\n\nApartado b)\nPara el año elegido, mostrar un diagrama de caja de la distribución de una de vuestras dos variables para cada continente.\nRealizar algunos ajustes (mínimos) al gráfico como dar color a los diagramas (asociado al continente), poner título al gráfico, los ejes, etc.\n\n\n\n\nApartado c)\nElegid los datos para un periodo de diez años (los que queráis). Mostrar en un gráfico el histograma de una de vuestras dos variables, en el periodo completo de diez años. Mostrar en otro gráfico la densidad de dicha variable para el periodo completo de diez años y para cada año.\nNuevamente, modificar la forma de visualización añadiendo las señales visuales, escalas y/o contextos que consideréis necesario.\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema04ej_123456787.R"
  },
  {
    "objectID": "Contenidos.html",
    "href": "Contenidos.html",
    "title": "Contenidos",
    "section": "",
    "text": "(11-Sept. a 15-Sept.)\n\nIntroducción\nTema 0 - Introducción a R y a RStudio\nTema 0 - Ejercicio 1\nTema 0 - Ejercicio 2\n\n\n\n\n\n(18-Sept. a 22-Sept.)\n\nFecha límite de entrega de los ejercicios del Tema 0: vie., 22-sept., 23:59h\nTema 01 - Transformación de datos\nTema 01 - Ejercicio 1\n\n\n\n\n\n(25-Sept. a 29-Sept.)\n\nTema 02 - Manipulación de datos relacionales"
  },
  {
    "objectID": "Contenidos.html#semana-1",
    "href": "Contenidos.html#semana-1",
    "title": "Contenidos",
    "section": "",
    "text": "(11-Sept. a 15-Sept.)\n\nIntroducción\nTema 0 - Introducción a R y a RStudio\nTema 0 - Ejercicio 1\nTema 0 - Ejercicio 2"
  },
  {
    "objectID": "Contenidos.html#semana-2",
    "href": "Contenidos.html#semana-2",
    "title": "Contenidos",
    "section": "",
    "text": "(18-Sept. a 22-Sept.)\n\nFecha límite de entrega de los ejercicios del Tema 0: vie., 22-sept., 23:59h\nTema 01 - Transformación de datos\nTema 01 - Ejercicio 1"
  },
  {
    "objectID": "Contenidos.html#semana-3",
    "href": "Contenidos.html#semana-3",
    "title": "Contenidos",
    "section": "",
    "text": "(25-Sept. a 29-Sept.)\n\nTema 02 - Manipulación de datos relacionales"
  },
  {
    "objectID": "Contenidos.html#semana-4",
    "href": "Contenidos.html#semana-4",
    "title": "Contenidos",
    "section": "Semana 4",
    "text": "Semana 4\n(2-Oct. a 6-Oct.)\n\nTema 02 - Ejercicio"
  },
  {
    "objectID": "Contenidos.html#semana-5",
    "href": "Contenidos.html#semana-5",
    "title": "Contenidos",
    "section": "Semana 5",
    "text": "Semana 5\n(09-Oct. a 13-Oct.)\n\nTema 03 - Datos Ordenados"
  },
  {
    "objectID": "Contenidos.html#semana-6",
    "href": "Contenidos.html#semana-6",
    "title": "Contenidos",
    "section": "Semana 6",
    "text": "Semana 6\n(16-Oct. a 20-Oct.)\n\nTema 04 - Visualización de Datos\nTema 04 - Ejercicio\n\nFecha límite de entrega: lun., 30-oct., 23:59h\n\nTema 05 - Análisis Exploratorio de Datos"
  },
  {
    "objectID": "Contenidos.html#semana-7",
    "href": "Contenidos.html#semana-7",
    "title": "Contenidos",
    "section": "Semana 7",
    "text": "Semana 7\n(23-Oct. a 27-Oct.)\n\nTema 06 - Ejercicio\n\nFecha: mie. 8-Nov. 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-8",
    "href": "Contenidos.html#semana-8",
    "title": "Contenidos",
    "section": "Semana 8",
    "text": "Semana 8\n(30-Oct. a 3-Nov.)\n\nTema 07 - Fundamentos Estadísticos"
  },
  {
    "objectID": "Contenidos.html#semana-9",
    "href": "Contenidos.html#semana-9",
    "title": "Contenidos",
    "section": "Semana 9",
    "text": "Semana 9\n(6-Nov. a 10-Nov.)\n\nTema 05 - Ejercicio\n\nFecha: mie. 29-Nov. 23:59h\n\nTema 07 - Ejercicio\n\nFecha: mie. 29-Nov. 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-10",
    "href": "Contenidos.html#semana-10",
    "title": "Contenidos",
    "section": "Semana 10",
    "text": "Semana 10\n(13-Nov. a 17-Nov.)\n\nTema 08 - Aprendizaje Estadístico"
  },
  {
    "objectID": "Contenidos.html#semana-11",
    "href": "Contenidos.html#semana-11",
    "title": "Contenidos",
    "section": "Semana 11",
    "text": "Semana 11\n(20-Nov. a 26-Nov.)\n\nTema 09 - Selección y Regularización\nTema 10 - Modelización con tidymodels"
  },
  {
    "objectID": "Contenidos.html#semana-12",
    "href": "Contenidos.html#semana-12",
    "title": "Contenidos",
    "section": "Semana 12",
    "text": "Semana 12\n(27-Nov. a 03-Dic.)\n\nTema 11 - kNN\nTema 12 - Métodos basados en árboles"
  },
  {
    "objectID": "Contenidos.html#semana-13",
    "href": "Contenidos.html#semana-13",
    "title": "Contenidos",
    "section": "Semana 13",
    "text": "Semana 13\n(04-Dic. a 10-Dic.)\n\nTema 10 - Ejercicio\nEjemplo de Proyecto Final"
  },
  {
    "objectID": "Evaluacion.html",
    "href": "Evaluacion.html",
    "title": "Evaluación",
    "section": "",
    "text": "Nota: información adicional sobre segunda convocatoria y posibles contingencias en la ficha de la asignatura\n\n\n\n\nEjercicios teórico-prácticos durante el periodo de clases (30%)\n\npreguntas y pequeños ejercicios en clase\nprácticas a entregar\n\nTrabajo empírico final (50%)\nExamen final (20%)\nRequisito: asistir al menos a un 80% de las clases.\n\n\n\n\n\nTrabajo empírico final (50%)\nExamen final (50%)"
  },
  {
    "objectID": "Evaluacion.html#evaluación-continua",
    "href": "Evaluacion.html#evaluación-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Ejercicios teórico-prácticos durante el periodo de clases (30%)\n\npreguntas y pequeños ejercicios en clase\nprácticas a entregar\n\nTrabajo empírico final (50%)\nExamen final (20%)\nRequisito: asistir al menos a un 80% de las clases."
  },
  {
    "objectID": "Evaluacion.html#evaluación-no-continua",
    "href": "Evaluacion.html#evaluación-no-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Trabajo empírico final (50%)\nExamen final (50%)"
  },
  {
    "objectID": "Datos.html",
    "href": "Datos.html",
    "title": "Datos",
    "section": "",
    "text": "A lo largo de las clases utilizaremos varios conjuntos de datos de ejemplo.\n\nTema 0:\n\nrenta.txt\nsex_data.csv\nbeauty.xls\nnsw.dta\nearn.RData\n\nTema 1:\n\nEmpleados\n\nTema 4:\n\nlanddata-states.csv\n\nTema 5:\n\nBankMarketing.csv\nBostonHousing.csv\n\nTema 7:\n\ndiscount.csv\n\nTema 8:\n\ncensus.csv"
  }
]