[
  {
    "objectID": "Datos.html",
    "href": "Datos.html",
    "title": "Datos",
    "section": "",
    "text": "A lo largo de las clases utilizaremos varios conjuntos de datos de ejemplo.\n\nTema 0:\n\nrenta.txt\nsex_data.csv\nbeauty.xls\nnsw.dta\nearn.RData\n\nTema 1:\n\nlanddata-states.csv\n\nTema 2:\n\nVentasTabla\nEmpleados\n\nTema 3:\n\nDosTablas\n\nTema 5:\n\nBankMarketing.csv\nBostonHousing.csv\n\nTema 6:\n\ndescuento.csv\ncensus.csv\nhealth_insurance.csv"
  },
  {
    "objectID": "Evaluacion.html",
    "href": "Evaluacion.html",
    "title": "Evaluación",
    "section": "",
    "text": "Nota: información adicional sobre segunda convocatoria y posibles contingencias en la ficha de la asignatura\n\n\n\n\nEjercicios teórico-prácticos (35%): prácticas a entregar durante el periodo de clases\nTrabajo empírico final (50%)\nParticipación (15%): preguntas y pequeños ejercicios en clase\nRequisito: asistir al menos a un 80% de las clases.\n\n\n\n\n\nTrabajo empírico final (65%)\nExamen final (35%)"
  },
  {
    "objectID": "Evaluacion.html#evaluación-continua",
    "href": "Evaluacion.html#evaluación-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Ejercicios teórico-prácticos (35%): prácticas a entregar durante el periodo de clases\nTrabajo empírico final (50%)\nParticipación (15%): preguntas y pequeños ejercicios en clase\nRequisito: asistir al menos a un 80% de las clases."
  },
  {
    "objectID": "Evaluacion.html#evaluación-no-continua",
    "href": "Evaluacion.html#evaluación-no-continua",
    "title": "Evaluación",
    "section": "",
    "text": "Trabajo empírico final (65%)\nExamen final (35%)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "docs/Tema08.html#proceso-de-modelización",
    "href": "docs/Tema08.html#proceso-de-modelización",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Proceso de modelización",
    "text": "Proceso de modelización\n\ntidymodels es una colección de paquetes para el proceso de modelización (NO implementa modelos) con los principios de tidyverse\n\n\nlibrary(tidymodels)\n\n\n\n\n\nOtros paquetes “similares”: mlr3, caret, H2O\ntidymodels se llama vetiver en python"
  },
  {
    "objectID": "docs/Tema08.html#partición-inicial",
    "href": "docs/Tema08.html#partición-inicial",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Partición inicial",
    "text": "Partición inicial\n\nNO usamos todos los datos para estimar\ninitial_split(): particionar los datos en prueba y entrenamiento.\n\nprimer argumento: datos (se pasa por tubería %&gt;%)\nsegundo argumento: proporción de datos dedicados a entrenamiento\n\n\n\ntidymodels crea objetos (listas) con toda la información y ofrece funciones para acceder a ella\n\n\nlibrary(mosaicData)\nlibrary(tidyverse)\nset.seed(101)\nrailtrailPart &lt;- RailTrail %&gt;% \n                    mutate(dayType = parse_factor(dayType)) %&gt;% \n                    initial_split(prop = .8)\n\n\nLas funciones training() y testing() acceden a cada submuestra"
  },
  {
    "objectID": "docs/Tema08.html#recetas-de-transformación",
    "href": "docs/Tema08.html#recetas-de-transformación",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Recetas de transformación",
    "text": "Recetas de transformación\n\nAunque ya hemos limpiado los datos de forma general, podemos considerar transformaciones específicas para algunas estimaciones\n\nAlgunos modelos necesitan que las variables sean transformadas de una forma concreta (ej., estandarizar)\nIncluso para un mismo modelo, podemos considerar diferentes especificaciones diferentes: sin usar NA o imputándolos, usando distintas variables (ej., con o sin interacciones)\n\n\n\n\nLas recetas, recipe(), definen las transformaciones a aplicar:\n\nSu principal argumento es una fórmula, que define el rol de las variables: variable dependiente y predictores\nSe encadenan (con %&gt;%) pasos con step_* para las transformaciones\n\nUna referencia completa aquí y aquí"
  },
  {
    "objectID": "docs/Tema08.html#algunos-pasos-habituales",
    "href": "docs/Tema08.html#algunos-pasos-habituales",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Algunos pasos habituales",
    "text": "Algunos pasos habituales\n\nPara un modelo concreto, podemos realizar cambios (como en tidyverse): step_select(), step_filter(), step_mutate(), …\n\nTambién transformaciones directas: step_log()\n\n\n\n¿Cómo tratar los valores ausentes en este modelo?\n\nelimina las observaciones con valores ausentes: step_naomit()\nimputar los valores ausentes de los predictores: step_impute_mean(), step_impute_linear(), step_impute_knn(), etc..\n\n\n\n\nEstandarizar variables para que tengan media cero, step_center(), varianza uno, step_scale(), o ambas step_normalize()\n\n\nCrear polinomios, step_poly(), y discretizar, step_cut()"
  },
  {
    "objectID": "docs/Tema08.html#algunos-pasos-habituales-cont.",
    "href": "docs/Tema08.html#algunos-pasos-habituales-cont.",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Algunos pasos habituales (cont.)",
    "text": "Algunos pasos habituales (cont.)\n\nPara variables cualitativas, podemos agrupar categorías poco frecuentes: step_other()\nEn general, tidymodels exige crear explícitamente variables binarias (dummy) para las categorías de las variables cualitativas: step_dummy()\n\nalgunos modelos necesitan dummies para todas las categorías: se añade la opcion one_hot = TRUE\n\n\n\n\nNOTA: algunas fuentes (ej., chatGPT) sugieren eliminar variables con poca variabilidad, step_zv() y step_nzv(), o con alta correlación, step_corr(). Esto NO es estrictamente necesario para ningún modelo\n\nEsto lo debemos haber detectado en el AED."
  },
  {
    "objectID": "docs/Tema08.html#algunos-pasos-habituales-y-3",
    "href": "docs/Tema08.html#algunos-pasos-habituales-y-3",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Algunos pasos habituales (y 3)",
    "text": "Algunos pasos habituales (y 3)\n\nLas interacciones también funcionan de forma diferente en tidymodels\nPara variables cuantitativas, x1 y x2, step_interact(~ x2:x1) añade solo una nueva variable: la inteacción x2:x1\n\ncon step_interact(~ (x2 + x3):x1) creamos múltiples interacciones\n\nPara variables binarias, step_interact(~ d1:d2) añade la interacción\nPara variables cualitativas, hemos debido crear antes las dummies. Para evitar escribir manualmente cada combinación podemos usar start_with():\n\nstep_interact(~ starts_with(\"F1\"):x1) para una variable categórica F1 y una continua x1\nstep_interact(~ starts_with(\"F1_\"):starts_with(\"F2_\")) para dos variables categóricas F1 y F2"
  },
  {
    "objectID": "docs/Tema08.html#preparando-la-receta",
    "href": "docs/Tema08.html#preparando-la-receta",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Preparando la receta",
    "text": "Preparando la receta\n\n\nTODOS los pasos se pueden aplicar a una variable o varias con all_outcomes(), all_predictors(), all_numeric(), all_nominal(), all_nominal_predictors(), all_numeric_predictors(), all_of(c(\"var1\", \"var2\"), contains(), etc.\n\n\n\nSe crea un objeto de receta para usarlo después con otras partes del proceso\n\n\nreceta1 &lt;-railtrailPart %&gt;% training() %&gt;%             \n  recipe(volume ~ cloudcover + precip + hightemp + dayType) %&gt;%\n  step_scale(all_predictors(), -all_nominal()) %&gt;%\n# step_scale(all_numeric(), -all_outcomes()) %&gt;% \n  step_dummy(dayType) %&gt;% \n  step_poly(hightemp, degree = 6)  \n\n\nPodría prep()ararse y aplicar las transformaciones con juice() o bake() (veremos otra alternativa más general)"
  },
  {
    "objectID": "docs/Tema08.html#definir-el-modelo",
    "href": "docs/Tema08.html#definir-el-modelo",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Definir el modelo",
    "text": "Definir el modelo\n\ntidymodels define un modelo de un tipo con una interfaz unificada para distintas bibliotecas \n\n\nUna función que define el tipo de modelo, con argumentos específicos de ese modelo (la lista de funciones/modelos aquí)\nSe fija el tipo de problema (mode): regresión o clasificación\nSe establece la biblioteca (engine) con la que se implementará\n\n\nmodelo_lm1  &lt;- linear_reg(mode= \"regression\", engine = \"lm\", \n                             penalty = 0)\n\nmodelo_glm1 &lt;- linear_reg(mode= \"regression\", engine = \"glmnet\", \n                             penalty = 0)\n\n\nSe puede estimar (entrenar) el modelo con fit()"
  },
  {
    "objectID": "docs/Tema08.html#flujos-de-trabajo-workflow",
    "href": "docs/Tema08.html#flujos-de-trabajo-workflow",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Flujos de trabajo: workflow()",
    "text": "Flujos de trabajo: workflow()\n\nUn flujo de trabajo combina la receta de preprocesado y la definición del modelo en un único objeto para su uso posterior\n\n\nflujo_lm1 &lt;- workflow() %&gt;%\n  add_recipe(receta1) %&gt;%      \n  add_model(modelo_lm1)\n\n\nPodríamos modificar un flujo existente con update_recipe() , update_model(), etc.\n\n\n\nUsando la función fit() con unos datos y un flujo de trabajo,\n\nla receta aplica el preprocesado a los datos definidos aquí\nse estima el modelo definido con los datos procesados\n\n\n\nflujo_lm1_est &lt;- flujo_lm1 %&gt;% \n                   fit(data = railtrailPart %&gt;% training())"
  },
  {
    "objectID": "docs/Tema08.html#flujo-de-trabajo-estimado",
    "href": "docs/Tema08.html#flujo-de-trabajo-estimado",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Flujo de trabajo estimado",
    "text": "Flujo de trabajo estimado\n\nEl objeto del flujo estimado almacena información previa (receta, modelo, datos), resultados (estimaciones, predicciones) para usar de varias formas\n\n\nExtraer la receta y aplicar la transformación a unos datos\n\n\nreceta_extr &lt;- flujo_lm1_est %&gt;% extract_recipe() \n\nreceta_extr %&gt;% bake(railtrailPart %&gt;% training()) \nreceta_extr %&gt;% bake(railtrailPart %&gt;% testing())\n\n\nExtraer los resultados de la estimación; pueden convertirse a conjunto de datos (y mostrar en tablas con kable())\n\n\nestim_extraida &lt;- flujo_lm1_est %&gt;% extract_fit_parsnip() \n\nestim_extraida %&gt;% tidy()      # resultados de la estimación\nestim_extraida %&gt;% glance()    # otros detalles de la estimación"
  },
  {
    "objectID": "docs/Tema08.html#flujo-de-trabajo-estimado-cont.",
    "href": "docs/Tema08.html#flujo-de-trabajo-estimado-cont.",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Flujo de trabajo estimado (cont.)",
    "text": "Flujo de trabajo estimado (cont.)\n\n\nEl proceso es igual para problemas de clasificación.\n\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;% select(-1) %&gt;% \n  mutate(across(where(is.character),~as.factor(.x)))\nset.seed(8697)\ncensoPart &lt;- censo %&gt;% initial_split(prop = .8)\n\nreceta_log1 &lt;- training(censoPart) %&gt;%\n  recipe(income ~ age + education_1 + capital_gain)\nmodelo_log1 &lt;- logistic_reg(mode= \"classification\", engine = \"glm\", \n                             penalty = 0)\n\nflujo_log1 &lt;- workflow() %&gt;%\n  add_recipe(receta_log1) %&gt;%      \n  add_model(modelo_log1)\n\nflujo_log1_est &lt;- flujo_log1 %&gt;% \n                   fit(data = censoPart %&gt;% training()) \n\n\nestim_extraida_log &lt;- flujo_log1_est %&gt;% extract_fit_parsnip() \n\nestim_extraida_log %&gt;% tidy() \nestim_extraida_log %&gt;% glance()"
  },
  {
    "objectID": "docs/Tema08.html#predicción",
    "href": "docs/Tema08.html#predicción",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Predicción",
    "text": "Predicción\n\n\nLa función predict() (de parsnip) tiene dos argumentos principales: un flujo de trabajo estimado y un conjunto de datos (nuevo como los datos de prueba u otros valores)\n\nEl flujo estimado almacena la receta para transformar los datos\nTambién contiene los resultados de la estimación (“parámetros” del modelo) que se aplican a los datos transformados para predecir\n\n\n\nflujo_lm1_est %&gt;% \n  predict(new_data = railtrailPart %&gt;% testing())\n\n\nDevuelve un conjunto de datos (tibble) con predicciones:\n\npara problemas de regresión: valores numéricos (type = \"numeric\", por defecto), intervalos de confianza (type = \"conf_int\"), etc.\npara problemas de clasificación: clases/categorías (type = \"class\", por defecto), las probabilidades de cada categoría (type = \"prob\")"
  },
  {
    "objectID": "docs/Tema08.html#métricas-de-error",
    "href": "docs/Tema08.html#métricas-de-error",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Métricas de error",
    "text": "Métricas de error\n\n\nLa función last_fit() ajusta el flujo en los datos de entrenamiento y obtiene predicciones en los de prueba, para calcular las métricas (ver listado):\n\n\nflujo_lm1_finalfit &lt;- flujo_lm1 %&gt;% \n                    last_fit(split = railtrailPart,\n                             metrics = metric_set(rmse, mae)) \nflujo_lm1_finalfit %&gt;% collect_metrics()\n\nflujo_log1_finalfit &lt;- flujo_log1 %&gt;% \n                      last_fit(split = censoPart,\n                             metrics = metric_set(accuracy, roc_auc))\nflujo_log1_finalfit %&gt;% collect_metrics()\n\n\nTambién podemos trabajar con las predicciones en la muestra de prueba:\n\n\npredic_log1 &lt;- flujo_log1_finalfit %&gt;% collect_predictions() \npredic_log1 %&gt;% roc_auc(income, `.pred_&lt;=50K`) \npredic_log1 %&gt;% roc_curve(income, `.pred_&lt;=50K`) %&gt;% autoplot()\n\n\nNOTA: con más de dos clases, la matriz de confusión tiene dimensión \\(\\small k \\times k\\) y se calcula una ROC-AUC para cada clase frente a las demás"
  },
  {
    "objectID": "docs/Tema08.html#validación-cruzada",
    "href": "docs/Tema08.html#validación-cruzada",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Validación cruzada",
    "text": "Validación cruzada\n\nEn lugar de initial_split(), podemos usar vfold_cv() para crear particiones\n\n\nset.seed(101)\nrailtrailPartCV &lt;- RailTrail %&gt;% \n                    mutate(dayType = parse_factor(dayType)) %&gt;% \n                    vfold_cv(v=10) \n\n\nPodemos acceder a la información de cada bloque (splits)\n\n\nEl flujo de trabajo puede ser el mismo que ya hemos visto \nLa estimación del modelo se realiza usando fit_resamples() \n\n\nflujo_lm1_CVest &lt;- flujo_lm1  %&gt;% fit_resamples(\n                      resamples = railtrailPartCV, \n                      metrics   = metric_set(rmse, mae) )\n\n\n… y el objeto creado contiene los valores de las métricas\n\n\nflujo_lm1_CVest %&gt;% collect_metrics()      # promedio"
  },
  {
    "objectID": "docs/Tema08.html#selección-de-hiperparámetros-tuning",
    "href": "docs/Tema08.html#selección-de-hiperparámetros-tuning",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Selección de hiperparámetros: tuning",
    "text": "Selección de hiperparámetros: tuning\n\nLos hiperparámetros (ej., \\(\\small \\lambda\\) en LASSO) no se aprenden junto con el resto de parámetos sino mediante un proceso de ajuste (tuning), dividiendo la muestra de entrenamiento en dos\n\n\n\n\nEn una se ajusta el modelo dado un valor del hiperparámetro\nEn la otra se mide el error asociado a cada valor para elegir el hiperparámetro con mejor métrica\n\n\n\n\n\\(\\Downarrow\\)\n\n\n\n\nEn la muestra de entrenamiento usaremos validación cruzada:"
  },
  {
    "objectID": "docs/Tema08.html#proceso-de-tuning",
    "href": "docs/Tema08.html#proceso-de-tuning",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Proceso de tuning",
    "text": "Proceso de tuning\n\nUsamos una partición de initial_split() y la misma receta anterior (aunque no era necesario antes, el pre-procesado ya estandarizaba los regresores)\nEn la definición del modelo debemos identificar los hiperparámetros a ajustar\n\n\nmodelo_LASSO &lt;- linear_reg(mode= \"regression\", engine = \"glmnet\",\n                           penalty = tune(), mixture = 1 ) \n\nflujo_LASSO &lt;- workflow() %&gt;%\n  add_recipe(receta1) %&gt;% \n  add_model(modelo_LASSO)\n\nflujo_LASSO %&gt;% extract_parameter_set_dials()\n\n\nDefinimos un conjunto de valores a probar (grid); p.e., con grid_regular() buscamos en un intervalo un número de valores (otras opciones aquí)\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 15), trans = NULL), \n                                   levels = 51)"
  },
  {
    "objectID": "docs/Tema08.html#proceso-de-tuning-cont.",
    "href": "docs/Tema08.html#proceso-de-tuning-cont.",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Proceso de tuning (cont.)",
    "text": "Proceso de tuning (cont.)\n\nSe usa tune_grid() de forma a similar a fit_resamples(), usando una sub-partición de la muestra de entrenamiento por validación cruzada\n\n\nset.seed(9753)\nrailtrail_entrenCV &lt;- railtrailPart %&gt;% training() %&gt;% \n                          vfold_cv(v=10)\nflujo_LASSO_ajust &lt;- flujo_LASSO %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\n\nPodemos visualizar el ajuste y obtener los mejores valores (por la variabilidad, varios son igualmente aceptables)\n\n\nflujo_LASSO_ajust %&gt;% autoplot()\nflujo_LASSO_ajust %&gt;% show_best(metric = \"mae\")\nmejor_lambda &lt;- flujo_LASSO_ajust %&gt;% select_best(metric = \"rmse\")\n\n\nNOTA: debemos probar manualmente varios rangos y valores buscando la U"
  },
  {
    "objectID": "docs/Tema08.html#finalizando-y-evaluando-el-modelo",
    "href": "docs/Tema08.html#finalizando-y-evaluando-el-modelo",
    "title": "Tema 08 - Modelización con tidymodels",
    "section": "Finalizando y evaluando el modelo",
    "text": "Finalizando y evaluando el modelo\n\n\nActualizamos el flujo de trabajo para dar un valor a los hiperparámetros\n\n\nflujo_LASSO_final &lt;- flujo_LASSO %&gt;% \n        finalize_workflow(mejor_lambda)  \n        # finalize_workflow(parameters = list(penalty=8.5))\n\n\nDebemos estimar el modelo en los datos completos de entrenamiento, para mostrar resultados de estimación o predecir\n\n\nflujo_LASSO_final_est &lt;-  flujo_LASSO_final %&gt;%  \n              fit(data = railtrailPart %&gt;% training())\nflujo_LASSO_final_est %&gt;%  extract_fit_parsnip() %&gt;% tidy()\n\n\nPara obtener las métricas, usamos last_fit()\n\n\nLASSO_final_fit &lt;- flujo_LASSO_final %&gt;% \n                    last_fit(split = railtrailPart,\n                             metrics = metric_set(rmse, mae)) \nLASSO_final_fit %&gt;% collect_metrics()"
  },
  {
    "objectID": "docs/Tema02.html#limpieza-y-doma-de-datos",
    "href": "docs/Tema02.html#limpieza-y-doma-de-datos",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Limpieza y “doma” de datos ",
    "text": "Limpieza y “doma” de datos \n\n\n\n\nUn análisis de datos adecuado requiere (mucho) tiempo de trabajo “sucio” \ntidyverse incluye una colección de bibliotecas con herramientes eficientes para el proceso de “tratamiento de datos” (“data wrangling”)\n\n\nEl objetivo es tener un conjunto de datos ordenado y limpio para poder realizar análisis de manera eficiente\nEsto puede requerir seleccionar columnas, filtrar filas, crear nuevas variables, ordenar, agrupar, resumir, etc."
  },
  {
    "objectID": "docs/Tema02.html#qué-son-datos-ordenados-tidy-data",
    "href": "docs/Tema02.html#qué-son-datos-ordenados-tidy-data",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "¿Qué son datos ordenados (‘tidy data’)?",
    "text": "¿Qué son datos ordenados (‘tidy data’)?\n1.- Cada columna es una variable: mide el mismo atributo entre unidades\n2.- Cada fila es una observación (caso): misma unidad a través de atributos\n3.- Cada celda es un valor\n\n\n\n\nTenemos información similar y no redundante en una misma tabla\n\n\nEs una forma natural (variable = vector columna) para trabajar con datos \n\n\ntidyverse es eficiente con datos ordenados"
  },
  {
    "objectID": "docs/Tema02.html#datos-no-ordenados",
    "href": "docs/Tema02.html#datos-no-ordenados",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Datos no ordenados",
    "text": "Datos no ordenados\n\n\n\n\n\n\n\n\nOtras estructuras como esta pueden tener sentido para mostrar información (o por convenciones)\n\n\nLa visualización es atractiva, PERO sobran filas para analizar los datos: ej., total de personas con hijos y sin pareja entre 30 y 39 años"
  },
  {
    "objectID": "docs/Tema02.html#funciones-de-transformación-de-datos",
    "href": "docs/Tema02.html#funciones-de-transformación-de-datos",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Funciones de transformación de datos",
    "text": "Funciones de transformación de datos\n\nLa mayoría de operaciones pueden realizarse combinando 5 “verbos” \n\nNOTA: existe una colección de “chuletas” de R, p.e., para transformación.\n\nTodos tienen como primer argumento un data frame, los siguientes describen qué hacer (con columnas o filas) y devuelven otro data frame\n\n1.- select(): selecciona variables por nombres o posiciones de columnas, separados por comas\n\n\n\n\nselect(presidential, name, party)\nselect(presidential, 1:2, 4)"
  },
  {
    "objectID": "docs/Tema02.html#filtrar-filas",
    "href": "docs/Tema02.html#filtrar-filas",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Filtrar filas",
    "text": "Filtrar filas\n2.- filter(): conserva filas en las que la condición lógica es verdadera\n\n\n\n\nfilter(presidential, party == \"Republican\")\nfilter(presidential, start &gt; 1973 & party == \"Democratic\")\n\n\nSe pueden combinar (anidar) porque ambas toman y devuelve un data frame, pero así son difíciles de leer\n\n\nselect(filter(presidential, start &gt; 1973), name)"
  },
  {
    "objectID": "docs/Tema02.html#el-operador-de-tubería",
    "href": "docs/Tema02.html#el-operador-de-tubería",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "El operador de tubería %>%",
    "text": "El operador de tubería %&gt;%\n\ndatos %&gt;% filter(condition) equivale a filter(datos, condition)\n\nAplicable a cualquier función: 10 %&gt;% log() es log(10)\n\nEl anidamiento es fácil:\n\nTomar presidential y pasarlo a filtrar (produce un nuevo data frame); \nTomar este resultado y pasarlo a seleccionar.\n\n\n\npresidential %&gt;% \n  filter(start &gt; 1973) %&gt;% \n  select(name)\n\n\nAtajo de teclado: Cmd / Ctrl + Mays + M\nTambién existe una tubería en R base: |&gt;"
  },
  {
    "objectID": "docs/Tema02.html#crear-nuevas-variables",
    "href": "docs/Tema02.html#crear-nuevas-variables",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Crear nuevas variables",
    "text": "Crear nuevas variables\n\n\n3.-mutate(): añade nuevas columnas, creando variables según una fórmula a partir de otras\n\n\n\n\n\n\ntambién rename(): cambiar el nombre de una columna \n\n\n\n\n\n\n# evitar \"machacar\" la fuente original\nmypresidents &lt;- presidential %&gt;%          \n                  mutate(duracion = end - start) \n\n# crear varias, separadas por coma\npresidential %&gt;% mutate(sigloXXI = start &gt; 2000,   \n                        duracion = end - start,    \n                        duracio2 = duracion*2   )  \n\npresidential %&gt;% rename(nombre = name)"
  },
  {
    "objectID": "docs/Tema02.html#ordenar-filas",
    "href": "docs/Tema02.html#ordenar-filas",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Ordenar filas",
    "text": "Ordenar filas\n\n\n4.- arrange(): re-ordena las filas todas las columnas de un data frame\n\nen orden ascendente (por defecto) o descendente con desc()\n\n\n\n\n\n\n\n\n\nmypresidents %&gt;% arrange(desc(duracion))\n\n# ordenar por más de una columna: primero por duración, \n# en caso de empate por partido\nmypresidents %&gt;% arrange(desc(duracion), party)"
  },
  {
    "objectID": "docs/Tema02.html#resumir-todo-el-conjunto-de-datos",
    "href": "docs/Tema02.html#resumir-todo-el-conjunto-de-datos",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Resumir todo el conjunto de datos",
    "text": "Resumir todo el conjunto de datos\n5.- summarize(): colapsa valores de un data frame en una sola fila resumen\n\n\n\n\nEspecificando cómo se reducirá una columna entera de datos en un solo valor.\n\n\nlibrary(lubridate)\nmypresidents %&gt;%\n  summarize(\n    media_duracion = mean(duracion),\n    N = n(),                        # n(): cuenta número de filas\n    first_year = min(year(start)),  # year(): año de una fecha\n    num_dems = sum(party == \"Democratic\") )\n\n\nsummarize() suele usarse en conjunción con group_by()"
  },
  {
    "objectID": "docs/Tema02.html#group_by",
    "href": "docs/Tema02.html#group_by",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "group_by()",
    "text": "group_by()\n\ngroup_by(): cambia el alcance de cada función para que no actúe sobre todo el data frame sino en grupos individuales \n¿Cuál es la duración media de los demócratas y de los republicanos? Hacerlo por separado no es eficiente: especificamos que las filas deben ser agrupadas \n\n\nmypresidents %&gt;% group_by(party) %&gt;%         # solo \"marca\" dos grupos \n  summarize(N = n(),                         # nuevas variables\n            media_duracion = mean(duracion)) # \n\n\nNuevo conjunto de datos con nuevas variables (columnas) a un distinto nivel de observación (fila): una fila para cada valor del grupo\n\n\nRelacionado con Tablas dinámicas en Excel (y SUMAR.SI/SUMIF)\nungroup() elimina la agrupación para volver a operar en datos desagrupados\n\n\nmypresidents %&gt;% group_by(party) %&gt;% mutate(MD = mean(duracion)) %&gt;% \n  ungroup() %&gt;% arrange(duracion) %&gt;%  slice_head(n=1)"
  },
  {
    "objectID": "docs/Tema02.html#seleccionar-muchas-variables",
    "href": "docs/Tema02.html#seleccionar-muchas-variables",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Seleccionar muchas variables",
    "text": "Seleccionar muchas variables\n\nlibrary(nycflights13)           # incluye flights:  19 variables\nselect(flights, year:arr_time)  # desde variable \"year\" hasta \"arr_time\"\nselect(flights, -(year:day))    # todas menos \"year, month, day\"\n\n\nFunciones a utilizar dentro de select():\n\nstarts_with(\"abc\"): nombres que comienzan con “abc”.\nends_with(\"xyz\"): nombres que acaban con “xyz”.\ncontains(\"ijk\"): nombres que contienen “ijk”.\nnum_range(\"x\", 1:3): para x1, x2 y x3.\nmatches(): nombres que coinciden con una expresión regular"
  },
  {
    "objectID": "docs/Tema02.html#algunos-verbos-adicionales",
    "href": "docs/Tema02.html#algunos-verbos-adicionales",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Algunos verbos adicionales",
    "text": "Algunos verbos adicionales\n\nslice(), slice_head(), slice_sample(): extrae filas por posición o aleatoriamente\n\n\nmypresidents %&gt;% slice_head(n=3)\n\n\ndrop_na() y replace_na(): elimina/reemplaza filas con valores ausentes\ndistinct(): extrae sólo las filas únicas (una o varias variables)\n\n\nmypresidents %&gt;% distinct(party)\n\n\ncount(): cuenta los valores únicos de una o más variables\n\n\nmypresidents %&gt;% count(party)    # mypresidents %&gt;% group_by(party) %&gt;% summarize(n=n())\nmypresidents %&gt;% count(party, sort = TRUE)\n\n\nacross(): aplica la misma transformación a múltiples columnas\n\n\nflights %&gt;% mutate(across(air_time:distance, ~ log(.x)+1))\nflights %&gt;% mutate(across(is.character, ~ parse_factor(.x)))"
  },
  {
    "objectID": "docs/Tema02.html#funciones-para-crear-variables",
    "href": "docs/Tema02.html#funciones-para-crear-variables",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Funciones para crear variables",
    "text": "Funciones para crear variables\n\nOperadores aritméticos (+, -, *, /, ^, %/%, %%) y lógicos (&lt;, &lt;=, &gt;, &gt;=, !=)\nFunciones como log(), lag(), lead(), cumsum(), row_number() etc.\n\n\nMuchas funciones son equivalentes a otras de R base:\n\nparse_number(), parse_factor(), etc. por as.number(), as.factor(), etc.\nbind_cols() y bind_rows() por cbind() y rbind()\nif_else(): ejecución condicional por ifelse() (también case_when())\n\n\n\nflights %&gt;% mutate(retraso = if_else(dep_delay &gt; 0, \"tarde\", \"bien\")) \nflights %&gt;% mutate(retraso = if_else(dep_delay &gt; 0, \"tarde\",    # encadenados\n                                if_else(dep_delay &lt;0, \"bien\", \"normal\")))\n\n\nDiscretizar variables: cut_interval(), cut_number(), cut_width()"
  },
  {
    "objectID": "docs/Tema02.html#funciones-de-resumen-útiles",
    "href": "docs/Tema02.html#funciones-de-resumen-útiles",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Funciones de resumen útiles",
    "text": "Funciones de resumen útiles\n\nMedidas de centralidad y de dispersión: mean(x), median(x), sd(x), IQR(x) \nMedidas de rango: min(x), quantile(x, 0.25), max(x)\nMedidas de posición: first(x), nth(x, 2), last(x).\nSumas, productos, etc.\nConteos:\n\nn(): observaciones totales (tamaño del grupo)\nsum(!is.na(x)): observaciones no ausentes\nn_distinct(x): filas distintas en x"
  },
  {
    "objectID": "docs/Tema02.html#cuatro-representaciones-de-los-mismos-datos",
    "href": "docs/Tema02.html#cuatro-representaciones-de-los-mismos-datos",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Cuatro representaciones de los mismos datos",
    "text": "Cuatro representaciones de los mismos datos\n\n\n\nlibrary(tidyverse)\ntable1     # datos ordenados\ntable2     # varios valores por celda\n\n\n\n\n\n\n\n\n\ntable3     # más de una variable en una columna\ntable4a \ntable4b\n\n\ntable4a y table4b ofrecen información útil para presentación"
  },
  {
    "objectID": "docs/Tema02.html#mismos-datos-dos-formatos-ancho-o-largo",
    "href": "docs/Tema02.html#mismos-datos-dos-formatos-ancho-o-largo",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Mismos datos, dos formatos: ancho o largo",
    "text": "Mismos datos, dos formatos: ancho o largo\n\n\n\nLa utilidad de almacenar los datos en un rectángulo ancho (“wide”) o en uno largo (“long”) depende de qué queramos hacer\n\nP.e., Excel prefiere el formato largo para tablas dinámicas, fórmulas de agregación (SUMAR.SI) y algunos gráficos\n\n\n\n\n\n\n\n\nEl cambio de forma entre formatos es una tarea habitual del analista de datos.\nCambiar entre representación larga y ancha se conoce como pivotar (o girar)\n\n\ntable4a        # formato ancho\ntable1         # formato largo"
  },
  {
    "objectID": "docs/Tema02.html#pivot_longer-de-ancho-a-largo",
    "href": "docs/Tema02.html#pivot_longer-de-ancho-a-largo",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "pivot_longer(): de ancho a largo",
    "text": "pivot_longer(): de ancho a largo\n\nPivotar las variables en dos nuevas columnas (deben crearse)\n\n\n\n\npivot_longer(table4a, \n             cols=2:3, \n             names_to = \"year\", \n             values_to = \"cases\") \n\n\n\n\n\n\n\ndata frame a cambiar de forma\nnombres o índices de las columnas que representan valores, no variables\nlos nombres de esas antiguas variables van como valores a nueva variable\nlos valores de las antiguas celdas van a otra nueva variable"
  },
  {
    "objectID": "docs/Tema02.html#pivot_longer-de-ancho-a-largo-cont.",
    "href": "docs/Tema02.html#pivot_longer-de-ancho-a-largo-cont.",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "pivot_longer(): de ancho a largo (cont.)",
    "text": "pivot_longer(): de ancho a largo (cont.)\n\nRecordad que existen formas equivalentes de hacer lo mismo\n\n\ntable4a %&gt;% pivot_longer(cols = `1999`:`2000`, \n                         values_to = \"cases\", names_to = \"year\")\n\n\nNotar que los nombres de columna son caracteres y cuando son números van entre ` (evita confusión con índice de posición)\n\n\nDeberíamos cambiar el tipo de las nuevas variables\n\n\ntable4a %&gt;% \n  pivot_longer(2:3, names_to = \"year\", values_to = \"cases\") %&gt;%\n  mutate(year= parse_number(year))"
  },
  {
    "objectID": "docs/Tema02.html#pivot_wider-de-largo-a-ancho",
    "href": "docs/Tema02.html#pivot_wider-de-largo-a-ancho",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "pivot_wider(): de largo a ancho",
    "text": "pivot_wider(): de largo a ancho\n\n\n\ntable2 %&gt;%\n    pivot_wider(names_from = type,  \n                values_from = count)\n\n\n\n\n\n\n\nel data frame a cambiar de forma\nnombre de la variable de cuyos valores vienen los nuevos nombres de columnas\nnombre de la variable de la que tomar los valores para las nuevas columnas\n\n\n\n\ntable1 %&gt;% select(-population) %&gt;%            # Tabla de presentación \n    pivot_wider(names_from = year, values_from = cases)"
  },
  {
    "objectID": "docs/Tema02.html#dos-funciones-útiles",
    "href": "docs/Tema02.html#dos-funciones-útiles",
    "title": "Tema 02 - Tratamiento de datos (una tabla)",
    "section": "Dos funciones útiles",
    "text": "Dos funciones útiles\n\nseparate(): dividir una columna en múltiples variables indicando un separador o vector de posiciones en las que dividir\n\n\ntable3 %&gt;% separate(rate, into = c(\"cases\", \"population\"), sep = \"/\")\ntable3 %&gt;% separate(year, into = c(\"century\", \"year\"), sep = 2)\n\n\nCon convert = TRUE intenta convertir el tipo (no mantener carácter)\n\n\ntable3 %&gt;% separate(rate, into = c(\"cases\", \"population\"), \n                    convert = TRUE)\n\n\nunite(): combinar múltiples columnas en una\n\n\ntable5 %&gt;% \n  unite(new, century, year, sep = \"-\")"
  },
  {
    "objectID": "docs/Tema04.html#el-sistema-de-publicaciones-quarto",
    "href": "docs/Tema04.html#el-sistema-de-publicaciones-quarto",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "El sistema de publicaciones Quarto",
    "text": "El sistema de publicaciones Quarto\n\n\n\nOrientado al análisis de datos reproducible: combina código, resultados y comentarios\nÚtil como cuaderno de trabajo del código y para comunicar resultados en un documento final para tomar decisiones\n\n\n\n\n\n\n\nInstalar Quarto para vuestro sistema operativo desde aquí\nLa guía y referencia completa de Quarto están en su Web\nUn documento de Quarto se renderiza, procesando cada componente (código, resultado de ejecutarlo y texto) para producir documentos en varios formatos: html, PDF, Word, presentaciones, etc."
  },
  {
    "objectID": "docs/Tema04.html#documentos-de-quarto-crear-y-guardar",
    "href": "docs/Tema04.html#documentos-de-quarto-crear-y-guardar",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Documentos de Quarto: Crear y Guardar",
    "text": "Documentos de Quarto: Crear y Guardar\n\nCreamos un proyecto de Quarto en File &gt; New Project &gt; New Directory &gt; Quarto Project o en el icono de proyectos \n\nIgnoramos el documento que se crea por defecto\n\nCreamos un nuevo documento a partir de una plantilla en RStudio con  o File &gt; New File &gt; Quarto Document\n\nPodemos elegir Título, Autor/a y formato de salida (HTML, por defecto)\n\n\n\nSe guarda con  o con File &gt; Save, con extensión .qmd\nSe renderiza con  al formato de salida elegido \nEn el botón de engranaje  se pueden cambiar algunas opciones\n\np.e., dónde se visualiza la salida (en ventana aparte o en RStudio)"
  },
  {
    "objectID": "docs/Tema04.html#documentos-de-quarto-formato-de-salida",
    "href": "docs/Tema04.html#documentos-de-quarto-formato-de-salida",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Documentos de Quarto: formato de salida",
    "text": "Documentos de Quarto: formato de salida\n\nEl renderizado crea un archivo en el mismo directorio donde está el archivo de Quarto .qmd\nEn el caso de HTML, se crea tanto un archivo con extensión .html como un subdirectorio del mismo nombre con componentes necesarios (ej., imágenes, css)\n\nsolo podemos visualizar correctamente el archivo .html en cualquier navegador si copiamos a otro lugar tanto el .html como el subdirectorio\n\nPara crear PDFs, se necesita una distribución de LaTeX: instala una escribiendo en la pestaña de “Terminal” (a la derecha de la consola):\n\n\nquarto install tool tinytex"
  },
  {
    "objectID": "docs/Tema04.html#documentos-de-quarto-texto-con-markdown",
    "href": "docs/Tema04.html#documentos-de-quarto-texto-con-markdown",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Documentos de Quarto: Texto con Markdown",
    "text": "Documentos de Quarto: Texto con Markdown\n\nLos componentes de texto están escritos en Markdown: un conjunto ligero de convenciones para archivos de texto sin formato. Por ejemplo,\n\ntodo lo escrito entre dos * como **Hola** se renderiza en negritas\nse utiliza # para indicar encabezados de secciones\n\nEn el menú de ayuda tenemos una descripción completa (Markdown quick reference) y “chuletas” (Cheatsheets)\nTambién son útiles la web de Quarto y este libro online.\n\n\nRStudio incorpora un editor visual de documentos de Quarto, similar a un procesador de texto"
  },
  {
    "objectID": "docs/Tema04.html#editor-visual-de-quarto-en-rstudio",
    "href": "docs/Tema04.html#editor-visual-de-quarto-en-rstudio",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Editor Visual de Quarto en RStudio",
    "text": "Editor Visual de Quarto en RStudio\n\nEn documentos .qmd, se puede elegir entre editar la fuente (source) de Markdown, como texto sencillo, o editar el documento de forma Visual en \nEn el modo visual, en esa misma barra de herramientas se tienen accesos a\n\nformatos de texto (negritas, cursivas, encabezamientos) y listas\ninsertar enlaces, imágenes, notas a pie de página, tablas\nincluir ecuaciones (en LaTeX)\ntambién insertar directamente código HTML, comentarios, etc.\n\nSe puede configurar la corrección ortográfica en Tools &gt; Global Options &gt; Spelling: agregar/seleccionar el diccionario de Español"
  },
  {
    "objectID": "docs/Tema04.html#formato-en-la-cabecera-el-bloque-yaml",
    "href": "docs/Tema04.html#formato-en-la-cabecera-el-bloque-yaml",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Formato en la cabecera: el bloque YAML",
    "text": "Formato en la cabecera: el bloque YAML\n\nAl principio del documento, entre dos líneas con ---, se pueden especificar varias opciones del documento: título, autor, fecha, formato de salida\n\n\nLos formatos de salida son html, pdf, docx (y otros en Quarto Presentations)\nTambién se especifican opciones globales del documento, algunas específicas de cada tipo de salida (ver la referencia para html y otros formatos)\n  ---\n  title: \"Título\"\n  author: Autor \n  date: 15-octubre-2023\n  format:\n    html:\n      toc: true              # índice\n      number-sections: true  # secciones numeradas\n      embed-resources: true  # archivo html autocontenido\n      theme: united          # más temas: https://bootswatch.com/3/\n  ---"
  },
  {
    "objectID": "docs/Tema04.html#fragmentos-o-celdas-de-código",
    "href": "docs/Tema04.html#fragmentos-o-celdas-de-código",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Fragmentos o celdas de código ",
    "text": "Fragmentos o celdas de código \n\nInsertamos código en medio del texto con el icono (visual) \n\nSi pulsamos , escribimos r y luego un código, el documento de salida incluirá el resultado de ejecutar el código\n\n\n\n\nPodemos incluir un fragmento de código (de varias líneas), con , en el desplegable  o Ctrl + Alt + I \n\nSe puede personalizar cómo se muestran varios aspectos del código y de sus resultados\nbien para una celda concreta de código, incluyendo opciones de celda\no para todo el documento en la cabecera: las opciones de html están en la sección de código de su referencia (y similar para otros formatos)"
  },
  {
    "objectID": "docs/Tema04.html#opciones-para-una-celda-de-código",
    "href": "docs/Tema04.html#opciones-para-una-celda-de-código",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Opciones para una celda de código",
    "text": "Opciones para una celda de código\n\n\nLas opciones se incluyen al principio de una celda precedidas por #|\necho: true muestra el código en la salida (o no con echo: false)\neval: true ejecuta el código (o no con eval: false)\n\nSi un fragmento no se evalúa, sus resultados no se muestran y ni están para otras celdas posteriores (p.e., cargar datos o una biblioteca para usar luego)\n\noutput: true incluye los resultados del código\n\n\ninclude: false no incluye ni el código ni su resultado, pero se evalúa\nSe muestran (o no) los mensajes, errores y avisos de ejecutar un código con las opciones message, error y warning, respectivamente.\nlabel: etiqueta para identificar la celda\n\n\nLa lista completa de opciones aquí y aquí"
  },
  {
    "objectID": "docs/Tema04.html#opciones-para-una-celda-de-código-cont.",
    "href": "docs/Tema04.html#opciones-para-una-celda-de-código-cont.",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Opciones para una celda de código (cont.)",
    "text": "Opciones para una celda de código (cont.)\n\n\ncode-fold: true oculta el código pero da opción a mostrarlo\nCómo mostrar resultados de texto y numéricos:\n\nresults: hide (no mostrar)\nresults: hold (mostrar todo, no el resultado de cada línea)\n\n \nfig-cap y tbl-cap para los títulos de las figuras y tablas\nCómo mostrar los gráficos: fig-show\n\nhide y hold son como en results\nasis muestra el gráfico como se generó\nanimate concatena varios gráficos en una animación\n\n\n\nfig-width y fig-height: dimensiones (reales, en pulgadas) de una figura\nout-width y out-height: ídem en el documento de salida (% de las reales)"
  },
  {
    "objectID": "docs/Tema04.html#opciones-para-una-celda-de-código-y-3",
    "href": "docs/Tema04.html#opciones-para-una-celda-de-código-y-3",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Opciones para una celda de código (y 3)",
    "text": "Opciones para una celda de código (y 3)\n\n\nfig-align: mostrar la figura centrada o alineada a derecha o izquierda\nlayout-ncol: en cuantas columnas se componen los resultados\n\n```{r}\n#| layout-ncol: 2\n#| fig-show: hold\nggplot(data = cars) + geom_histogram(aes(x = speed))  # izquierda\nggplot(data = cars) + geom_histogram(aes(x = dist))   # derecha\n```"
  },
  {
    "objectID": "docs/Tema04.html#opciones-globales-para-todas-las-celdas",
    "href": "docs/Tema04.html#opciones-globales-para-todas-las-celdas",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Opciones globales para todas las celdas",
    "text": "Opciones globales para todas las celdas\n\nEn la cabecera, especificamos opciones por defecto para las celdas de código\n\np.e., de ejecución como echo, eval, etc. en execute (ver aquí y aquí)\n---\nexecute:\n  echo: false\n  warning: false\n---\n\n\n\nTambién otras opciones que ya hemos visto (aquí listado completo para html)\n\n    ---\n    format:\n      html:\n        code-fold: true\n        cap-location: bottom\n        fig-align: center\n        df-print: paged      # cómo visualizar tablas\n    ---"
  },
  {
    "objectID": "docs/Tema04.html#ejecución-de-código-en-un-documento-.qmd",
    "href": "docs/Tema04.html#ejecución-de-código-en-un-documento-.qmd",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Ejecución de código en un documento .qmd",
    "text": "Ejecución de código en un documento .qmd\n\nRenderizar un .qmd crea un espacio de trabajo para ejecutar el código distinto del que vemos en RStudio (diferentes objetos, bibliotecas, etc.)\n\nsi no estamos en un proyecto, el directorio de trabajo puede diferente\n\nComprobamos los resultados del código del .qmd ejecutándolo sin renderizar: línea a línea, la celda completa con  o todas las anteriores con \n\nasí, el código pasa a la consola y sí forma parte del espacio de la sesión actual\nnos aseguramos de que no hay errores (ej., objetos previos no definidos)\n\n\n\nPara garantizar que la sesión actual incluye sólo resultados de las celdas del .qmd, incluimos una celda inicial con include: false con\n\nrm(list = ls()): al ejecutar todas las celdas previas, empezamos con una sesión sin objetos previos \nTodas las bibliotecas (ej., tidyverse) que utilizaremos en varias celdas"
  },
  {
    "objectID": "docs/Tema04.html#mejorar-la-salida-de-tablas",
    "href": "docs/Tema04.html#mejorar-la-salida-de-tablas",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Mejorar la salida de tablas",
    "text": "Mejorar la salida de tablas\n\nLos resultados de muchas funciones de R no son visualmente “profesionales” en el documento de salida de .qmd\nVarias bibliotecas cambian algunas salidas por defecto (printr) u ofrecen funciones para mejorarlas (pander, xtable) \n\n\nUn enfoque “fácil”:\n\ncrear un data frame con los resultados que queremos mostrar en la tabla\nusar la función kable() de la biblioteca knitr para mostrarlo\n\nLa biblioteca kableExtra ofrece más opciones.\n\nbroom::tidy() (de tidyverse) convierte mucho objetos de R (como listas con resultados de comandos) en tibbles\n\n\nOtras bibliotecas similares: modelsummary (convierte listas en tablas)"
  },
  {
    "objectID": "docs/Tema04.html#comentarios-finales",
    "href": "docs/Tema04.html#comentarios-finales",
    "title": "Tema 04 - Introducción a Quarto",
    "section": "Comentarios finales",
    "text": "Comentarios finales\n\nDashboards (tableros): son presentaciones visuales e interactivas de los resultados claves de un análisis que permiten una comunicación más efectiva\n\nQuarto permite crear dashboards con tablas, gráficos y otros elementos\nEjemplos de sus capacidades usando el paquete shiny, shinydashboards o flexdashboard\n\nJupyter Notebook: son otra forma de combinar texto, código y resultados en un documento. Desarrollados para Python, admiten varios lenguajes de programación (como Quarto)\n\nse crean, visualizan y ejecutan en navegadores web, pero son fácilmente modificables, localmente u online en JupyterLab o con Google Colab\nQuarto renderiza libros de Jupyter, creados en .qmd o en su propio formato\n\n\n\nMuchas herramientas están preparadas para Python y R porque se usan a menudo indistintamente o combinados"
  },
  {
    "objectID": "docs/Tema03.html#múltiples-tablas-de-datos",
    "href": "docs/Tema03.html#múltiples-tablas-de-datos",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Múltiples tablas de datos",
    "text": "Múltiples tablas de datos\n\nAnalizar datos suele implicar múltiples tablas\n\ndiferentes orígenes: ej., dptos. de empresa (personal, ventas, almacén)\nalmacenamiento más eficiente: elementos “similares” dentro de una tabla y diferentes entre ellas\n\nPara poder combinar la información los datos deben ser relacionales: cada par de tablas están relacionadas mediante identificadores llamados claves\n\n\nP.e., la biblioteca nycflights13 contiene varias tablas: el nombre de la compañía está “codificado” en flights y se puede encontrar en airlines\n\n\nflights %&gt;% select(dep_time,arr_time,carrier:dest) \nairlines\n\n\nAmbas tablas contienen un identificador común clave (“key”): carrier"
  },
  {
    "objectID": "docs/Tema03.html#relaciones-entre-tablas",
    "href": "docs/Tema03.html#relaciones-entre-tablas",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Relaciones entre tablas",
    "text": "Relaciones entre tablas"
  },
  {
    "objectID": "docs/Tema03.html#datos-relacionales",
    "href": "docs/Tema03.html#datos-relacionales",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Datos relacionales",
    "text": "Datos relacionales\n\nTipos de claves:\n\nPrimaria (o interna): identifican de forma única cada observación en una tabla. Puede ser una sola variable (en planes) o múltiples (en weather)\n\nSubrogada = número de fila, si la tabla carece de identificación única\n\nSecundaria (o externa): señala a la clave primaria de otra tabla \n\n\n\nUna clave primaria y una externa (asociada) en otra tabla forman una relación:\n\nde uno-a-muchos (ej., vuelos y aviones), de uno-a-uno, de muchos-a-muchos (ej., aerolíneas y aeropuertos), de muchos-a-uno\n\nOperaciones que se pueden realizar con dos tablas: uniones de transformación, uniones de filtro y operaciones de conjunto"
  },
  {
    "objectID": "docs/Tema03.html#uniones-de-transformación",
    "href": "docs/Tema03.html#uniones-de-transformación",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Uniones de transformación",
    "text": "Uniones de transformación\n\nAñaden nuevas variables a una tabla desde filas coincidentes en otra.\nEjemplo:\n\n\n\n\n\ncbind() o bind_columns(): nuevas columnas para filas en el mismo orden\n\n\nDos argumentos obligatorios: las tablas que se unen\n\n\n# queremos añadir el nombre de las compañias en la tabla de vuelos\nflights2 &lt;- flights %&gt;% \n              select(year:day, hour, origin, dest, carrier, tailnum)\nairlines"
  },
  {
    "objectID": "docs/Tema03.html#argumento-by-cómo-se-emparejan-las-tablas",
    "href": "docs/Tema03.html#argumento-by-cómo-se-emparejan-las-tablas",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Argumento by: ¿Cómo se emparejan las tablas?",
    "text": "Argumento by: ¿Cómo se emparejan las tablas?\n\nLas claves (variables que relacionan ambas tablas) se indican, para una variable, con by = \"varX\" o, para varias, con by = c(\"varX\", \"varY\")\n\n\nflights2 %&gt;% inner_join(airlines, by = \"carrier\") \nflights2 %&gt;% inner_join(weather, \n                by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\"))\n\n\nSi se omite el argumento by, se usan todas las variables en común. Esto no siempre es deseable: ej., año no es lo mismo en flights y planes\nColumnas con el mismo nombre (ej., año) se desambigúan con un sufijo\n\n\nflights2 %&gt;% left_join(planes, by = c(\"tailnum\"))\n\n\nby = c(\"x1\" = \"y1\", \"x2\" = \"y2\") para emparejar la variable x1 en la primera tabla con la variable y1 en la segunda, y la variable x2 con y2\n\n\nflights2 %&gt;% left_join(airports, \n                  by = c(\"dest\" = \"faa\"))    # aeropuerto de destino"
  },
  {
    "objectID": "docs/Tema03.html#unión-interna",
    "href": "docs/Tema03.html#unión-interna",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Unión interna",
    "text": "Unión interna\n\ndf1 &lt;- tibble(clave = c(1:3), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(clave = c(1:2, 4), val_y = c(\"y1\",\"y2\",\"y4\"))\n\n\ninner_join(x, y) sólo incluye observaciones que coincidan en x y y.\n\n\ndf1 %&gt;% inner_join(df2, by = \"clave\")"
  },
  {
    "objectID": "docs/Tema03.html#uniones-externas",
    "href": "docs/Tema03.html#uniones-externas",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Uniones externas",
    "text": "Uniones externas\n\n\n\nCuando una fila no coincide en una unión externa, las nuevas variables se rellenan como valores ausentes \nleft_join(df1, df2): mantiene todas las observaciones en x, coincidan o no con la de y\n\n(no se pierden observaciones de la tabla primaria)\n\nright_join(df1, df2): mantiene todas las observaciones en y\nfull_join(df1, df2): incluye todas las observaciones de x e y"
  },
  {
    "objectID": "docs/Tema03.html#claves-duplicadas",
    "href": "docs/Tema03.html#claves-duplicadas",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Claves duplicadas",
    "text": "Claves duplicadas\n\nSi una coincidencia no es única, se generan todas las combinaciones posibles (producto cartesiano) de las observaciones coincidentes\n\n\n\n\nEn una tabla: añade información en una relación de uno a muchos.\n\n\n\n\n\n\n\nEn ambas tablas: igualmente, todas las combinaciones posibles\n\n\n\n\nposible error: NO hay clave primaria única"
  },
  {
    "objectID": "docs/Tema03.html#uniones-de-filtro",
    "href": "docs/Tema03.html#uniones-de-filtro",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Uniones de filtro",
    "text": "Uniones de filtro\n\nFiltra las observaciones de la tabla de la izquierda basándose en si coinciden o no con una observación de la otra tabla\nSe tiene un subconjunto de las filas de la tabla de la izquierda\n\n\n\n\nsemi_join(x, y) mantiene las observaciones en x que están en y\n\n\n\ndf1 %&gt;% semi_join(df2, \n          by = \"clave\")\n\n\n\n\nanti_join(x, y) elimina las observaciones en x que están en y\n\n\n\ndf1 %&gt;% anti_join(df2, \n          by = \"clave\")"
  },
  {
    "objectID": "docs/Tema03.html#uniones-de-filtro-cont.",
    "href": "docs/Tema03.html#uniones-de-filtro-cont.",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Uniones de filtro (cont.)",
    "text": "Uniones de filtro (cont.)\n\nClaves duplicadas: en uniones de filtro sólo importa la existencia de una coincidencia, NO qué observación coincida \\(\\Rightarrow\\) NUNCA duplica filas\n\n\n\n\n\nLas uniones de filtro son útiles para diagnosticar desajustes de uniones (qué observaciones serán emparejadas)\n\n\nflights %&gt;% anti_join(planes, by = \"tailnum\") %&gt;%   # vuelos sin información del avión\n              count(tailnum, sort = TRUE)\n\n\nPueden ser equivalentes a usar filter(), con tablas previamente resumidas, pero permiten filtrados complejos fácilmente"
  },
  {
    "objectID": "docs/Tema03.html#operaciones-de-conjunto",
    "href": "docs/Tema03.html#operaciones-de-conjunto",
    "title": "Tema 03 - Manipulación de datos relacionales",
    "section": "Operaciones de conjunto",
    "text": "Operaciones de conjunto\n\nTrabajan con filas completas, comparando valores de cada variable.\nEsperan que x e y tengan las mismas variables, y tratan las observaciones (filas) como elementos de un conjunto.\nÚtil cuando se quiere dividir un filtro complejo en piezas más simples.\n\n\ndf1 &lt;- tibble(x = 1:2, y = c(1, 1))\ndf2 &lt;- tibble(x = c(1,1), y = 1:2)\n\nintersect(df1, df2)     # solo filas tanto en df1 como en df2\nunion(df1, df2)         # filas únicas en ambas tablas df1 y df2` \nunion_all(df1, df2)     # todas las filas de df1 y df2, manteniendo duplicados \nsetdiff(df1, df2)       # filas en df1, pero no en df2\nsetdiff(df2, df1)"
  },
  {
    "objectID": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "href": "docs/0Intro.html#datificación-de-la-vida-diaria",
    "title": "Introducción",
    "section": "“Datificación” de la vida diaria",
    "text": "“Datificación” de la vida diaria\n\n\n\n\nIBM: en 2025 más de 175 zettabytes (175 billones de gigas) requerirán de distintos análisis\nForbes: 2,5 trillones de bytes de datos cada día\nThe 4 Vs of big data: Volume, Velocity, Variety, Veracity"
  },
  {
    "objectID": "docs/0Intro.html#importancia-de-los-datos",
    "href": "docs/0Intro.html#importancia-de-los-datos",
    "title": "Introducción",
    "section": "Importancia de los datos",
    "text": "Importancia de los datos\n\nNeelie Kroes (Comisaria Europea para la Agenda Digital): “Data is the oil of the new economy, […], the new oil for the digital era”\n\n\nNuevas oportunidades para las empresas: analítica de negocios para la toma de decisiones.\nMcKinsey: “aquellas organizaciones que adoptan analítica de negocios como cultura tienen 23 veces más probabilidades de adquirir clientes, seis veces más probabilidades de retener a esos clientes y 19 veces más probabilidades de ser rentables” (Bokman et al., 2018).\nMás ejemplos importancia del análisis de datos en economía, aquí y aquí, y en la empresa"
  },
  {
    "objectID": "docs/0Intro.html#objetivos",
    "href": "docs/0Intro.html#objetivos",
    "title": "Introducción",
    "section": "Objetivos",
    "text": "Objetivos\n\nAprender a extraer información de los datos\n\n\n\n\n\nUsando técnicas computacionales y estadísticas"
  },
  {
    "objectID": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "href": "docs/0Intro.html#aprendiendo-a-analizar-datos",
    "title": "Introducción",
    "section": "Aprendiendo a analizar datos",
    "text": "Aprendiendo a analizar datos\n\nEs una inversión de futuro en el trabajo aquí y aquí\nDebemos conocer las técnicas y NO esperar magia"
  },
  {
    "objectID": "docs/0Intro.html#análitica-cadena-de-valor",
    "href": "docs/0Intro.html#análitica-cadena-de-valor",
    "title": "Introducción",
    "section": "Análitica: Cadena de Valor",
    "text": "Análitica: Cadena de Valor"
  },
  {
    "objectID": "docs/0Intro.html#tipos-de-análisis",
    "href": "docs/0Intro.html#tipos-de-análisis",
    "title": "Introducción",
    "section": "Tipos de Análisis",
    "text": "Tipos de Análisis"
  },
  {
    "objectID": "docs/0Intro.html#ciclo-de-vida-del-análisis-de-datos",
    "href": "docs/0Intro.html#ciclo-de-vida-del-análisis-de-datos",
    "title": "Introducción",
    "section": "Ciclo de Vida del Análisis de Datos",
    "text": "Ciclo de Vida del Análisis de Datos"
  },
  {
    "objectID": "docs/Tema10ej1.html",
    "href": "docs/Tema10ej1.html",
    "title": "Tema 10. Ejemplo 1",
    "section": "",
    "text": "En este ejemplo, utilizamos el conjunto de datos descuento.csv. Tenemos información de las ventas realizadas a un cliente y algunas características de éste:\n\n\n\n\n\n\n\n\nVariable\nTipo\nDescripción\n\n\n\n\nventas\nNumérica\nVentas registradas (en euros).\n\n\nrenta\nNumérica\nRenta disponible del cliente (en euros).\n\n\ndescuento\nCategórica\n¿Ha recibido descuento? (1 = sí, 0 = no).\n\n\nzona\nCategórica\nZona de residencia: “ciudad”, “capital” o “pueblo”.\n\n\nedad\nNumérica\nEdad del cliente (en años).\n\n\nmujer\nCategórica\nGénero del cliente (1 = mujer, 0 = hombre).\n\n\neduc\nNumérica\nNivel educativo del cliente (en años).\n\n\n\n\n\n\nCargamos los datos y les damos el tipo de variable adecuado\n\n\nlibrary(tidyverse)\ndescuento &lt;- read_csv(\"data/descuento.csv\") %&gt;% \n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))"
  },
  {
    "objectID": "docs/Tema10ej1.html#carga-de-datos",
    "href": "docs/Tema10ej1.html#carga-de-datos",
    "title": "Tema 10. Ejemplo 1",
    "section": "",
    "text": "Cargamos los datos y les damos el tipo de variable adecuado\n\n\nlibrary(tidyverse)\ndescuento &lt;- read_csv(\"data/descuento.csv\") %&gt;% \n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))"
  },
  {
    "objectID": "docs/Tema10ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "href": "docs/Tema10ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "title": "Tema 10. Ejemplo 1",
    "section": "Paso 0: Partición en Entrenamiento y Prueba",
    "text": "Paso 0: Partición en Entrenamiento y Prueba\n\nUsamos initial_split() para generar el objeto que almacena las dos particiones\n\n\nlibrary(tidymodels)\n\nset.seed(123)\ndescuentoPart &lt;- initial_split(descuento, prop = 0.8)"
  },
  {
    "objectID": "docs/Tema10ej1.html#paso-1-preparar-los-datos-y-especificación",
    "href": "docs/Tema10ej1.html#paso-1-preparar-los-datos-y-especificación",
    "title": "Tema 10. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\n\nPara kNN, debemos estandarizar las variables numéricas continuas. NO tenemos que incluir transformaciones no lineales (ni es necesario discretizar), puesto que este es un método no paramétrico que permite una relación general entre la variable dependiente y los predictores, sin suponer una forma funcional específica.\nRespecto a las variables categóricas, debemos crear una variable binaria (dummy) para cada categoría (es decir, no tenemos un grupo omitido),\n\n\nrecetakNN1 &lt;- descuentoPart %&gt;% training() %&gt;% \n  recipe(ventas ~ renta + descuento + zona + edad + mujer + educ) %&gt;% \n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\nrecetakNN2 &lt;- recetakNN1 %&gt;% \n  step_log(ventas)"
  },
  {
    "objectID": "docs/Tema10ej1.html#paso-2-entrenamiento",
    "href": "docs/Tema10ej1.html#paso-2-entrenamiento",
    "title": "Tema 10. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\n\nDefinimos un modelo de kNN, preparando para ajustar los hiperparámetros. Es igual para ambas especificaciones.\nCon la biblioteca kknn, podemos ajustar el hiperparámetro de número de vecinos. También podríamos probar distintas formas de medir la distancia entre los puntos. En este caso usamos la distancia al cuadrado, dist_power = 2; también se puede usar la distancia como valor absoluto, dist_power = 1.\n\n\nmodelo_knn &lt;- nearest_neighbor(mode= \"regression\", engine = \"kknn\",\n                               neighbors = tune(), dist_power = 2) \n\n\n\nPaso 2.B: Creación del flujo de trabajo\nCreamos los flujos de trabajo combinando la receta y modelo\n\nflujo_knn1 &lt;- workflow() %&gt;%\n  add_recipe(recetakNN1) %&gt;%      \n  add_model(modelo_knn)\n\n\nflujo_knn2 &lt;- workflow() %&gt;%\n  add_recipe(recetakNN2) %&gt;%      \n  add_model(modelo_knn)\n\n\n\nPaso 2.C: Estimación del flujo\n\nPaso 2.C.1: Ajuste del hiperparámetros\n\nDefinimos las particiones de validación cruzada en la muestra de entrenamiento que vamos a utilizar, para ambos casos:\n\n\nset.seed(9753)\ndescuento_entrenCV &lt;- descuentoPart %&gt;% training() %&gt;% \n                          vfold_cv(v=10)\n\n\n\nProceso de ajuste para la especificación en niveles\n\nDeberíamos realizar una búsqueda probando varios rangos y valores para el hiperparámetro.\n\n\nknn_grid1 &lt;- grid_regular(neighbors(range = c(1, 20), trans = NULL), \n                                   levels = 20)\n\n\nflujo_knn1_ajust &lt;- flujo_knn1 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = knn_grid1            )\n\nflujo_knn1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nElegimos el mejor hiperparámetro según el error cuadrático medio\n\n\nflujo_knn1_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_nn1 &lt;- flujo_knn1_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nProceso de ajuste para la especificación en logaritmos\n\nknn_grid2 &lt;- grid_regular(neighbors(range = c(1, 20), trans = NULL), \n                                   levels = 20)\n\n\nflujo_knn2_ajust &lt;- flujo_knn2 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = knn_grid2            )\n\nflujo_knn2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nflujo_knn2_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_nn2 &lt;- flujo_knn2_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nPaso 2.C.2: Finalizando y estimando\n\nFinalizamos los flujos\n\n\nflujo_knn1_final &lt;- flujo_knn1 %&gt;% \n        finalize_workflow(mejor_nn1)  \n\nflujo_knn2_final &lt;- flujo_knn2 %&gt;% \n        finalize_workflow(mejor_nn2) \n\n\nEn este caso, NO tiene mucho sentido estimar el modelo del flujo finalizado con los datos de entrenamiento. Como este modelo es no paramétrico NO tenemos coeficientes estimados que mostrar. Tampoco hay una forma fácil de calcular la importancia de las variables u otras formas de interpretar el modelo.\n\n\nflujo_knn1_final_est &lt;-  flujo_knn1_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\n\nflujo_knn2_final_est &lt;-  flujo_knn2_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())"
  },
  {
    "objectID": "docs/Tema06ej1.html",
    "href": "docs/Tema06ej1.html",
    "title": "Tema 06. Ejercicio 1",
    "section": "",
    "text": "El siguiente conjunto de datos tiene información sobre el volumen de usuarios de un camino ciclista (“via verde”) en EE.UU. Tenéis más información en la ayuda de RStudio.\n\nlibrary(tidyverse)\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nLa comisión gestora, PVPC, quiere entender la relación entre el volumen de usuarios y variables explicativas como incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon  \n\\tag{1}\\]\n\nmodelo1 &lt;- lm(data = RailTrail,\n              volume ~ hightemp + cloudcover + weekday + precip)"
  },
  {
    "objectID": "docs/Tema06ej1.html#datos",
    "href": "docs/Tema06ej1.html#datos",
    "title": "Tema 06. Ejercicio 1",
    "section": "",
    "text": "El siguiente conjunto de datos tiene información sobre el volumen de usuarios de un camino ciclista (“via verde”) en EE.UU. Tenéis más información en la ayuda de RStudio.\n\nlibrary(tidyverse)\nlibrary(mosaicData)\ndata(\"RailTrail\")\n\nLa comisión gestora, PVPC, quiere entender la relación entre el volumen de usuarios y variables explicativas como incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:\n\\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\varepsilon  \n\\tag{1}\\]\n\nmodelo1 &lt;- lm(data = RailTrail,\n              volume ~ hightemp + cloudcover + weekday + precip)"
  },
  {
    "objectID": "docs/Tema06ej1.html#apartado-1",
    "href": "docs/Tema06ej1.html#apartado-1",
    "title": "Tema 06. Ejercicio 1",
    "section": "Apartado 1",
    "text": "Apartado 1\nPara este apartado, trabajaréis con un coeficiente concreto de la Ecuación 1 estimada anteriormente. El coeficiente dependerá de la última cifra de vuestro DNI o similar:\n\nsi es 1, 4 o 7, con el de hightemp\nsi es 2, 5 o 8, con el de cloudcover\nsi es 3, 6 o 9, con el de weekday\nsi es 0, con el de precip\n\n\nSuponiendo que los errores del modelo siguen una distribución normal, \\(\\widehat{\\beta} \\sim N\\left(\\beta, Var(\\widehat{\\beta})\\right)\\) y \\((n-k)*s^2 / Var(\\varepsilon) \\sim \\chi^2_{(n-k)}\\), donde \\(n\\) es el número de observaciones, \\(k\\) es el número de coeficientes (incluida la constante) y \\(s^2\\) es la estimación de la varianza del error. Calcular el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error.\n\n\nUsar bootstrap para obtener el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error. Debéis fijar como semilla vuestro DNI para realizar un bucle como el visto en clase.\n\n\nComentar BREVEMENTE las diferencias en los intervalos de confianza de ambos apartados. \n\n\nNotas\n\nLos resultados de una estimación están almacenados en el objeto creado aplicando summary() a la función lm().\n\n\nsum.modelo1 &lt;- summary(modelo1)\n\n## Para todos los coeficientes (filas) \n## el valor estimado y su error estándar (dos columnas)\nsum.modelo1$coefficients[,1:2]\n\n## Varianza del error del modelo\nsum.modelo1$sigma**2 \n\n## R-cuadrado\nsum.modelo1$r.squared\n\n\nIntervalo de confianza al 95% para el coeficiente estimado: \\(\\widehat{\\beta} \\pm z_{0.975} \\cdot \\sqrt{\\operatorname{Var}(\\widehat{\\beta})}\\), donde \\(z_{0.975}\\) es el valor crítico de la distribución normal estándar .\nIntervalo de confianza al 95% para la varianza del error: \\(\\left( \\frac{(n - k) \\cdot s^2}{\\chi^2_{0.975, (n - k)}}, \\frac{(n - k) \\cdot s^2}{\\chi^2_{0.025, (n - k)}} \\right)\\), donde \\(\\chi^2_{0.975, (n - k)}\\) y \\(\\chi^2_{0.025, (n - k)}\\) son los valores críticos de la distribución \\(\\chi^2\\) con \\(n - k\\) grados de libertad, correspondientes a los percentiles del 97.5% y 2.5%, respectivamente.\nEn R, los valores críticos se obtienen con qnorm() y qchisq() (mirad la ayuda)."
  },
  {
    "objectID": "docs/Tema06ej1.html#apartado-2",
    "href": "docs/Tema06ej1.html#apartado-2",
    "title": "Tema 06. Ejercicio 1",
    "section": "Apartado 2",
    "text": "Apartado 2\nRealizamos un análsis exploratorio de los datos y encontramos la siguiente forma para la relación no lineal entre el número de visitantes y la temperatura.\n\n\n\n\n\n\n\n\n\nPresentar en una tabla los resultados de estimar la Ecuación 1 y añadir primero la temperatura al cuadrado, después también la temperatura al cubo, la temperatura elevada a la cuarta potencia y finalmente elevada a la quinta potencia. Comentar qué modelo elegirías, es decir, qué grado del polinomio en temperatura captura mejor la relación no lineal descrita anteriormente. ¿Podríamos tener una relación no lineal distinta de la descrita por un polinomio?\n\nNotas sobre tablas de resultados en Quarto\n\nPodemos combinar tidy() (de la biblioteca broom) con las funciones de la biblioteca kableExtra para incluir tablas de estadísticos descriptivos o de resultados de regresión. En el documento de Quarto, se debe incluir la opción results: markup.\n\n\nlibrary(broom)\nlibrary(kableExtra)\nmodelo1 %&gt;% tidy() %&gt;% kbl() %&gt;% kable_classic()\n\n\nNotad que tras usar tidy() tenemos un conjunto de datos. Por tanto, podemos usar comandos conocidos para manipular la tabla, p.e., no mostrar todas las columnas.\n\n\nmodelo1 %&gt;% tidy() %&gt;% select(term:std.error) %&gt;% kbl() %&gt;% kable_paper()\n\n\nCon modelsummary(), podemos mostrar los resultados de uno o varios modelos en la misma tabla. También debemos incluir la opción results: markup.\n\nConsideramos el siguiente modelo: \\[\nvolume = \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip + \\beta_5 \\cdot spring + \\beta_6 \\cdot summer + \\varepsilon\n\\]\n\nlibrary(modelsummary)\nmodelo2 &lt;- lm(data = RailTrail,\n                volume ~ hightemp + cloudcover + weekday + precip + \n                          spring + summer)\n\nmodelsummary(list(\"Modelo 1\" = modelo1, \"Modelo 2\" = modelo2), \n             gof_map = c(\"nobs\", \"r.squared\", \"adj.r.squared\", \"F\", \"rmse\") ,\n              stars = T)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Modelo 1\n                Modelo 2\n              \n        \n        + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n        \n                \n                  (Intercept)\n                  76.826   \n                  45.483  \n                \n                \n                             \n                  (62.710) \n                  (79.724)\n                \n                \n                  hightemp   \n                  5.549*** \n                  5.696***\n                \n                \n                             \n                  (0.781)  \n                  (1.164) \n                \n                \n                  cloudcover \n                  -8.503*  \n                  -8.353* \n                \n                \n                             \n                  (3.339)  \n                  (3.435) \n                \n                \n                  weekdayTRUE\n                  -35.045  \n                  -37.062+\n                \n                \n                             \n                  (21.752) \n                  (22.280)\n                \n                \n                  precip     \n                  -106.483*\n                  -98.904*\n                \n                \n                             \n                  (40.720) \n                  (42.137)\n                \n                \n                  spring     \n                           \n                  31.239  \n                \n                \n                             \n                           \n                  (32.082)\n                \n                \n                  summer     \n                           \n                  9.424   \n                \n                \n                             \n                           \n                  (47.504)\n                \n                \n                  Num.Obs.   \n                  90       \n                  90      \n                \n                \n                  R2         \n                  0.500    \n                  0.509   \n                \n                \n                  R2 Adj.    \n                  0.476    \n                  0.473   \n                \n                \n                  F          \n                  21.208   \n                  14.322  \n                \n                \n                  RMSE       \n                  89.67    \n                  88.85"
  },
  {
    "objectID": "docs/Tema06ej1.html#apartado-3",
    "href": "docs/Tema06ej1.html#apartado-3",
    "title": "Tema 06. Ejercicio 1",
    "section": "Apartado 3",
    "text": "Apartado 3\nRealizamos un nuevo análisis exploratorio para la relación entre el número de visitas y la nubosidad (como porcentaje de cielo cubierto por nubes, en una escala continua de 0 a 10).\n\n\n\n\n\n\n\n\n\nDado lo que observamos en el gráfico, vamos a discretizar cloudcover. Primero, consideramos solo dos grupos: hasta 7.5 y más de 7.5. Luego, consideramos tres rangos: entre 0 y 5, entre 5 y 7.5, y mayor de 7.5. Finalmente, consideramos cuatro categorías: [0,2.5], (2.5,5], (5, 7.5] y (7.5, 10]. Presentar en una tabla el modelo de la Ecuación 1, con la variable cloudclover, y todas las variantes donde la hemos discretizado. Discutir qué especificación preferís y por qué.\n\nNotas\n\nComo hemos visto en las transparencias, se puede discretizar una variable con cut() (o cut_width(), cut_interval(), etc.), generando un factor con categorías dadas por los puntos de corte: ej., cut(cloudcover, breaks=c(0, 7.5, 10), include.lowest = T)\nTambién se podría generar una variable binaria para cada categoria con ifelse() (o if_else())"
  },
  {
    "objectID": "docs/Tema06ej1.html#apartado-4",
    "href": "docs/Tema06ej1.html#apartado-4",
    "title": "Tema 06. Ejercicio 1",
    "section": "Apartado 4",
    "text": "Apartado 4\nFinalmente, vamos a considerar otra variante de la ecuación Ecuación 1 donde los efectos de la temperatura (hightemp) y de la nubosidad (cloudcover) no son constantes, sino que su efecto es heterogéneo en función de otros factores, en este caso si es un día laborable (weekday). Estimaremos el siguiente modelo\n\\[\n\\begin{aligned}\nvolume &= \\beta_0 + \\beta_1 \\cdot hightemp + \\beta_2 \\cdot cloudcover + \\beta_3 \\cdot weekday + \\beta_4 \\cdot precip  \\\\\n&+ \\beta_5 \\cdot hightemp \\cdot weekday + \\beta_4 \\cdot  cloudcover \\cdot weekday + \\varepsilon\n\\end{aligned}\n\\tag{2}\\]\n\nmodelo1.H &lt;- lm(data = RailTrail, volume ~ (hightemp + cloudcover)*weekday + precip)\n\nPresentar en una tabla los resultado de estimar la ecuación Ecuación 1 y de la ecuación Ecuación 2. Discutir si evidencia de que la temperatura y la nubosidad afectan de manera diferente a las visitas en función de otros factores. ¿Qué modelo preferiría?"
  },
  {
    "objectID": "docs/Tema06ej1.html#entrega",
    "href": "docs/Tema06ej1.html#entrega",
    "title": "Tema 06. Ejercicio 1",
    "section": "Entrega",
    "text": "Entrega\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema06ej1_123456789.qmd\nTema06ej1_123456789.zip"
  },
  {
    "objectID": "docs/Tema10.html#k-nn",
    "href": "docs/Tema10.html#k-nn",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "k-NN",
    "text": "k-NN\n\nMétodos paramétricos = supuesto funcional para la esperanza condicional\n\nvariable numérica: \\(E[y|\\mathbf{X}=x_0]=f(x_0)=\\beta_0+\\beta_1 x_0\\)\nvariable categórica: \\(\\Pr(y=j|\\mathbf{X}=x_0) =f_j(x_0)=\\Lambda(\\beta_{0j}+\\beta_{1j} x_0)\\)\n\n\n\nk-NN estima la esperanza condicional de forma no parámetrica \nIdea: el valor esperado de \\(y\\) para una observación debe ser “similar” al de otras observaciones “cercanas” (por su valor en \\(\\mathbf{X}\\))\n\nmismo valor de \\(x_0 \\Rightarrow\\ \\) mismo valor esperado de \\(y\\)\n\\(f(\\mathbf{X})\\ \\) no se supone conocida y fija"
  },
  {
    "objectID": "docs/Tema10.html#algoritmo-k-nn",
    "href": "docs/Tema10.html#algoritmo-k-nn",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Algoritmo k-NN",
    "text": "Algoritmo k-NN\n\n\n\nDada una muestra de entrenamiento y una nueva observación \\(\\mathbf{x^*}\\)\n\n\nIdentificar \\(k&gt;0\\quad\\) observaciones cercanas según una norma, ej., \\(||x^*-x_i||_2\\)\nSe asigna a \\(y^*\\) la media o la clase mayoritaria de las observaciones cercanas\n\n\n\n\n\n\n\n\n\nEl valor “óptimo” de \\(k\\) se elige mediante validación cruzada.\n\n\\(k\\) bajo (= algoritmo demasiado flexible): alta varianza y sesgo bajo\nAl aumentar \\(k\\) (menos flexible), menor varianza, pero mayor sesgo"
  },
  {
    "objectID": "docs/Tema10.html#algoritmo-k-nn-comentarios",
    "href": "docs/Tema10.html#algoritmo-k-nn-comentarios",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Algoritmo k-NN: comentarios",
    "text": "Algoritmo k-NN: comentarios\n\nSu utilidad depende de la geometría de los datos\n\nconviene centrar y reescalar los datos\nprobar varias medidas de distancia: valor absoluto \\(|x^*-x_i|\\quad\\) o norma \n\n\n\nLa distancia solo se puede calcular para variables continuas: convertir factores en dummies (una para cada categoría) \nNO es necesario incluir transformaciones no lineales de los regresores (ej., polinomios, interacción, etc.) en la receta\n\n\nLASSO (modelo lineal) puede no ser informativo sobre la elección de variables para este algoritmo\n\n\nImplementación en R con bibliotecas class y kknn"
  },
  {
    "objectID": "docs/Tema10.html#naive-bayes-1",
    "href": "docs/Tema10.html#naive-bayes-1",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "‘Naive Bayes’",
    "text": "‘Naive Bayes’\n\nEn un problema de clasificacón para una variable categórica \\(y\\), tenemos que estimar \\(\\Pr(y=c|\\mathbf{x})\\)\n\nDada una observación nueva \\(\\mathbf{x^*}\\), podemos calcular la probabilidad de cada clase\nClasificamos esta observación en la clase con mayor probabilidad\n\nEn regresión logística, usamos un modelo paramétrico para la probabilidad \\(\\Pr(y=c|\\mathbf{x}) = \\Lambda(\\beta_0 + \\beta_1 \\mathbf{x})\\)\n¿Y si usamos el Teorema de Bayes? \\[ \\Pr(y|\\mathbf{x}) = \\dfrac{\\Pr(y,\\mathbf{x})}{\\Pr(\\mathbf{x})} = \\dfrac{\\Pr(\\mathbf{x}|y)\\Pr(y)}{\\Pr(\\mathbf{x})} \\]"
  },
  {
    "objectID": "docs/Tema10.html#ejemplo-con-una-sola-variable-explicativa",
    "href": "docs/Tema10.html#ejemplo-con-una-sola-variable-explicativa",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Ejemplo con una sola variable explicativa",
    "text": "Ejemplo con una sola variable explicativa\n\nEn lo datos de ingresos en el Censo EE.UU., ¿cuál es la probabilidad de ser de renta alta (&gt; 50 mil dólares) si el individuo es blanco?\n\n\\[\\Pr(&gt;50K|white) = \\dfrac{\\Pr(white|&gt;50K)\\Pr(&gt;50K)}{\\Pr(white)}\\]\n\nDe los datos obtenemos estas probalidades para predecir en datos nuevos"
  },
  {
    "objectID": "docs/Tema10.html#naive-bayes-caso-general",
    "href": "docs/Tema10.html#naive-bayes-caso-general",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "‘Naive Bayes’: caso general",
    "text": "‘Naive Bayes’: caso general\n\nSupuesto simplificador con varias variables explicativas: estas son condicionalmente independientes (poco realista=naive) \\[ \\Pr(\\mathbf{x}|y)=\\prod_{j=1}^p \\Pr(x_j|y)\\]\nSe puede mejorar la estimación de las probabilidades condicionales \\(\\Pr(x_j|y)\\) usando estimadores no-paramétricos de la densidad (“kernels”)\nEn tidymodels se usa el motor naivebayes de la biblioteca discrim\nNO necesita preprocesado de los datos salvo que las variables explicativas categóricas deben incluirse como factores\nTenemos dos hiper-parámetros relacionados con la estimación de la densidad: smoothness (suavizado del “kernel”) y corrección de Laplace"
  },
  {
    "objectID": "docs/Tema10.html#svm",
    "href": "docs/Tema10.html#svm",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "SVM",
    "text": "SVM\n\nPara un problema de clasificación, SVM encuentra el hiperplano que mejor separa los datos por su clase\nCon dos variables explicativas, se puede visualizar en un gráfico en 2D\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl hiperplano es una línea cuyos coeficientes debemos encontrar: \\(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0\\)\n\n\n\n\nEl hiperplano óptimo tiene mayor margen = distancia a los datos más cercanos (llamados vectores de soporte)"
  },
  {
    "objectID": "docs/Tema10.html#svm-cont.",
    "href": "docs/Tema10.html#svm-cont.",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "SVM (cont.)",
    "text": "SVM (cont.)\n\nLos datos no suelen ser linealmente separables: se usa una función \\(\\phi(z)\\), denominada kernel, para transformar los datos a un nuevo espacio de mayor dimensión\n\n\n\n\n\nPara regresión SVM usa el “truco del kernel” para realizar un análisis de regresión lineal en el espacio de mayor dimensionalidad"
  },
  {
    "objectID": "docs/Tema10.html#svm-y-3",
    "href": "docs/Tema10.html#svm-y-3",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "SVM (y 3)",
    "text": "SVM (y 3)\n\nLas variables numéricas deben ser estandarizadas y centradas; las variables categóricas deben ser convertidas a variables dummies\nEn tidymodels se pueden usar\n\nkernels: lineal con svm_linear(), radial con svm_rbf() y polinomial con svm_poly()\nmediante las bibliotecas LiblineaR (solo kernel lineal) y kernlab\n\nTodos tienen un hiperparámetro de coste, cost, de predecir en el lado incorrecto del margen\nExisten hiperparámetros adicionales para kernel radial (rbf_sigma) y polinomial (degree, scale_factor)\nEn problemas de regresión existe otro hiperparámetro más, margin"
  },
  {
    "objectID": "docs/Tema10.html#redes-neuronales-artificiales",
    "href": "docs/Tema10.html#redes-neuronales-artificiales",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Redes Neuronales (artificiales)",
    "text": "Redes Neuronales (artificiales)\n\nUna red neuronal es una implementación matemática de modelos de estudio del cerebro humano: un grafo dirigido en varias fases.\n\n\n\n\n\n\n\n\n\n\n\n\nUn nodo para cada variable de entrada\nNodos especificados como capas ocultas\nCada nodo oculto se conecta a nuevas variables de salida\n\n\nDos nodos adicionales de control: uno conectado a los nodos ocultos y otro al de salida"
  },
  {
    "objectID": "docs/Tema10.html#redes-neuronales-nodos-percertrones",
    "href": "docs/Tema10.html#redes-neuronales-nodos-percertrones",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Redes Neuronales: nodos-percertrones",
    "text": "Redes Neuronales: nodos-percertrones\n\nEn cada nodo oculto se procesa, combinan, agrega la información de los nodos precedentes mediante unos pesos\n\n\n\n\n\n\n\n\n\nEsto es “similar” a una regresión logística"
  },
  {
    "objectID": "docs/Tema10.html#redes-neuronales-procedimiento",
    "href": "docs/Tema10.html#redes-neuronales-procedimiento",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "Redes Neuronales: procedimiento",
    "text": "Redes Neuronales: procedimiento\n\nEl algoritmo busca iterativamente el conjunto óptimo de pesos (“coeficientes”) para cada nodo.\nEntonces, la red neuronal puede hacer predicciones para nuevas entradas ejecutando estos valores a través de la red."
  },
  {
    "objectID": "docs/Tema10.html#deep-learning",
    "href": "docs/Tema10.html#deep-learning",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "‘Deep Learning’",
    "text": "‘Deep Learning’"
  },
  {
    "objectID": "docs/Tema10.html#ensembling.-boosting-1",
    "href": "docs/Tema10.html#ensembling.-boosting-1",
    "title": "Tema 10 - Más algoritmos de aprendizaje supervisado",
    "section": "‘Ensembling’. ‘Boosting’",
    "text": "‘Ensembling’. ‘Boosting’\n\nLos métodos de ensembling (“juntar”) usan varios algoritmos para obtener una mejor predicción que la de cada algoritmo por separado\n\nYa hablamos de Boostrap aggregation o bagging: es un caso particular de model averaging, a su vez un tipo de ensembling\nOtros tipos incluyen: clasificador óptimo bayesiano, Bayesian model averaging, Bayesian model combination, bucket of models, stacking, etc.\n\nBoosting es un tipo muy popular de ensembling donde cada nuevo modelo se entrena dando más peso a las observaciones que se predijeron peor en el anterior\n\nSuele funcionar mejor que bagging, pero tiene una mayor tendencia al sobreajuste\nLa implementación más común es Adaboost (aunque nueva variantes parecen mejorarlo)"
  },
  {
    "objectID": "docs/Tema02ej1.html",
    "href": "docs/Tema02ej1.html",
    "title": "Tema 2. Transformación de Datos. Ejercicio 1",
    "section": "",
    "text": "Entrega del ejercicio\nEste ejercicio se realizará en clase y NO cuenta para los alumnos de evaluación NO continua (aunque es recomendable como práctica).\n\n\nPregunta 1\nDescargad este archivo (comprimido) con datos en texto separados por punto y coma con la siguiente información de los empleados de una empresa: el identificador de empleado (ID), sus dos apellidos y su nombre, su género (hombre o mujer) y el valor de las ventas realizadas por dicho empleado en un periodo concreto, dado por año y mes.\nEn clase haremos estos apartados tanto usando un programa de hoja de cálculo (como Excel, LibreOffice Calc o Google Sheets) como usando R.\n\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores.\n\n\nElige como identificador del empleado las cuatro últimas cifras de tu DNI o similar (Nota: no tener en cuenta los ceros empezando por la izquierda: ej., para 0104 debes usar 104). Encontrar el periodo (año y mes) en el que sus ventas relativas al total de ventas de la empresa en ese periodo (proporción vendida por ese empleado en un periodo) fueron mayores.\n\n\nRepetir el apartado a) para cada empleado de la empresa, es decir, encontrar el periodo (año y mes) en el que sus ventas totales fueron mayores.\n\n\n¿En qué periodo (año y mes) hubo más ventas en total en la empresa y cuántas fueron?\n\n\nRepresentar la evolución temporal de las ventas anuales totales realizadas por los hombres y por las mujeres de la empresa.\nPresentar un gráfico de barras con el número de hombres y de mujeres empleados en la empresa en cada año.\nPresentar una tabla con la media de ventas anuales de hombres y de mujeres en los años 2000, 2005 y 2010."
  },
  {
    "objectID": "docs/Tema06.html#métodos-estadísticos-1",
    "href": "docs/Tema06.html#métodos-estadísticos-1",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Métodos Estadísticos",
    "text": "Métodos Estadísticos\n\n\n\nLa modelización mediante métodos estadísticos permite\n\nEncontrar patrones \nInterpretar datos \n\n\n\n\n\n\n\n\n\nLos datos (casos observados) son una muestra de una población mayor (casos potenciales)\n\n\nLas ventas salen de una población teórica uniforme entre 0 y 20 (media = 10)\n\n\ntibble(x = runif(n=1e7, min = 0, max = 20)) %&gt;% pull(x) %&gt;% mean()\n\n\n¿Cómo de fiable es un estadístico (ej., la media) calculado en una muestra?\n\n\nset.seed(9915)\ntibble(x = runif(n=25, min = 0, max = 20)) %&gt;% pull(x) %&gt;% mean()"
  },
  {
    "objectID": "docs/Tema06.html#variabilidad-muestral",
    "href": "docs/Tema06.html#variabilidad-muestral",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Variabilidad muestral",
    "text": "Variabilidad muestral\n\nCon todas las muestras potenciales de tamaño \\(\\small n\\) conoceríamos la distribución muestral de un estadístico (información calculada en una muestra)\n\nSimulemos la distribución para la media en muchas muestras de \\(\\small n=25\\)\n\n\n\n\n\nset.seed(101)\nnsim &lt;- 1000\nN &lt;- 25\nybar &lt;- numeric(nsim)\n\n\n\nfor (j in 1:nsim) { \n  muestra &lt;- runif(n=N, 0, 20) \n  ybar[j] &lt;- mean(muestra) \n}\n\n\n\n\n\nas_tibble(ybar) %&gt;% ggplot(aes(x=value)) + geom_density() +\n  geom_vline(xintercept = 10)\n\n\n¿Es posible cuantificar la incertidumbre con UNA MUESTRA?\n\n\nSuponiendo que los datos son normales, la media tiene una distribución normal\nTeorema Central del Límite: para datos de cualquier distribución, \\(\\overline{Y} \\overset{a}{\\sim} N(\\mu, \\sigma^2/n)\\) cuando \\(n \\to \\infty\\)"
  },
  {
    "objectID": "docs/Tema06.html#procedimiento-bootstrap",
    "href": "docs/Tema06.html#procedimiento-bootstrap",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Procedimiento Bootstrap",
    "text": "Procedimiento Bootstrap\n\n\nIdea: pensar en la ÚNICA muestra como si fuera la población\n\n\nset.seed(101)\nUNICAmuestra &lt;- tibble(x=runif(n=25, 0, 20))\n\n\nTomar muchas remuestras (muestras de Bootstrap) con reemplazamiento\n\np.e., para (1,2,3) incluye los casos (1,1,2), (1,1,3), (2,2,1), etc. \n\n\n\nlibrary(rsample)\nnboot &lt;- 1000\nremuestras &lt;- bootstraps(UNICAmuestra, times = nboot)\n\n\nEn cada remuestra, se puede calcular cualquier estadístico\n\n\ndistrib &lt;- list()\nfor (r in 1:nboot) {\n  remuestra_r &lt;- remuestras$splits[[r]] %&gt;% as_tibble()\n  media_r  &lt;- remuestra_r %&gt;% pull(x) %&gt;% mean()\n  sd_r     &lt;- sd(remuestra_r$x)\n  distrib[[r]] &lt;- list(medias = media_r, sds =sd_r ) \n}\ndistribDF &lt;- distrib %&gt;% bind_rows()"
  },
  {
    "objectID": "docs/Tema06.html#procedimiento-bootstrap-cont.",
    "href": "docs/Tema06.html#procedimiento-bootstrap-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Procedimiento Bootstrap (cont.)",
    "text": "Procedimiento Bootstrap (cont.)\n\n\nEste procedimiento permite generar variación (de remuestras) a partir de una única muestra\nLa distribución muestral bootstrap NO es la distribución muestral, pero aproxima sus aspectos principales sin supuestos (normalidad, TCL)\n\n\ndistribDF %&gt;% ggplot(aes(x=medias)) + geom_density()\n\n# Error estándar de la media\nmediaSE &lt;- distribDF %&gt;% pull(medias) %&gt;% sd()\n\n# Intervalos de confianza al 95% para la media\nmediaIC &lt;- distribDF %&gt;% pull(medias) %&gt;% quantile(c(0.025, 0.975))\n\n\nPuede aplicarse a cualquier estadístico (media, varianzas, regresión, etc.)"
  },
  {
    "objectID": "docs/Tema06.html#aprendizaje-estadístico-o-automático",
    "href": "docs/Tema06.html#aprendizaje-estadístico-o-automático",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Aprendizaje Estadístico o Automático",
    "text": "Aprendizaje Estadístico o Automático\n\nAprendizaje automático (machine learning, ML) o estadístico (statiscal learning): conjunto de técnicas algorítmicas para extraer información de los datos\n\n\nTipos principales\n\n\nAprendizaje supervisado: escenarios en los que para cada observación de las mediciones \\(X_i\\) hay una respuesta asociada \\(Y_i\\) (“supervisa” el aprendizaje)\n\nAprendemos la respuesta de casos nuevos a partir de casos previos\n\nAprendizaje no supervisado: no hay una respuesta asociada a las mediciones de \\(X_i\\) para supervisar el análisis que generará un modelo.\n\nAprendemos rasgos no medidos a partir de casos “no etiquetados”: ej. observaciones similares organizadas en grupos distintos"
  },
  {
    "objectID": "docs/Tema06.html#aprendizaje-supervisado",
    "href": "docs/Tema06.html#aprendizaje-supervisado",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Aprendizaje supervisado",
    "text": "Aprendizaje supervisado\n\n\\[\n\\small Y = f(X) + \\varepsilon\n\\]\n\nModelo para la variable dependiente (de respuesta) en función de factores observados (predictores/características) y no observados (\\(\\small \\varepsilon\\))\n \n\n\\(f\\) representa la información/relación sistemática que \\(X\\) (género, educación, etc.) ofrecen sobre un resultado medido \\(Y\\) (ej. renta)\n\nObjetivos:\n\n\nPredecir el valor esperado de \\(\\small Y\\) para casos nuevos \nComprender cómo afectan al resultado esperado de \\(\\small Y\\) cambios en los valores de las características\n\np.e., tiene la experiencia un efecto positivo o nula sobre la renta esperada\n¡cuidado con afirmaciones de causalidad!\n\n\n\nEn ambos casos, tenemos que estimar (“aprender”) la \\(f\\) desconocida"
  },
  {
    "objectID": "docs/Tema06.html#aprendizaje-supervisado-cont.",
    "href": "docs/Tema06.html#aprendizaje-supervisado-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Aprendizaje supervisado (cont.)",
    "text": "Aprendizaje supervisado (cont.)\n\nDos formas de especificar la relación \\(f\\)\n\nModelo paramétrico: supone un forma de \\(f\\) que depende de parámetros desconocidos, p.e., lineal \\(f(x) =\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\)\nModelo no paramétrico: ajustar \\(f\\) a los datos sin supuestos funcionales\n\nmás flexibilidad y mejor ajuste, pero más difícil de estimar e interpretar\n\n\nLa capacidad predictiva de un modelo mejora si incluimos más variables explicativas (modelo más flexible)\n\n\nDependiendo de la naturaleza de la variable dependiente, tenemos:\n1.- Problemas de Regresión: variable de respuesta cuantitativa (toma valores numéricos)\n2.- Problemas de Clasificación: variable de respuesta cualitativa (toma valores en una de \\(C\\) categorías o clases)"
  },
  {
    "objectID": "docs/Tema06.html#modelo-de-regresión-lineal",
    "href": "docs/Tema06.html#modelo-de-regresión-lineal",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Modelo de Regresión Lineal",
    "text": "Modelo de Regresión Lineal\n\n\nEs un modelo paramétrico para problemas de regresión que supone una relación lineal entre \\(\\small Y\\) y \\(\\small X\\): \\(\\quad \\small \\color{blue}{ventas = \\beta_0 + \\beta_1 renta + \\beta_2 descuento + u}\\)\n\n\nLa constante \\(\\small \\color{blue}{\\beta_0= E(ventas|renta=0, descuento=0)}\\): valor esperado de \\(\\small Y\\), ventas, cuando todas las variables explicativas son cero\n\nen este caso, la renta es 0 y el individuo no tiene descuento\n\nLa pendiente de una variable continua \\(\\small \\color{blue}{\\beta_1 = \\frac{\\delta E(ventas|renta,descuento)}{\\delta{renta}}}\\): cambio esperado de \\(\\small Y\\), ventas, cuando la variable explicativa, renta, aumenta en una unidad, manteniendo el resto de variables constantes (en este caso, un valor dado para descuento)\n\nen algunos caso también puede verse como \\(\\small \\beta_1 = E(ventas|renta=x+1,descuento=d)-E(ventas|renta=x,descuento=d)\\)\n\nPara variables discretas binarias \\(\\small \\color{blue}{\\beta_2 = E(ventas|renta=x,descuento=1)-E(ventas|renta=x,descuento=0)}\\): diferencia del valor esperado de \\(\\small Y\\), ventas, para el grupo indicado por la variable (tienen descuento) respecto al grupo de referencia (no tienen descuento), mateniendo el resto de variables (en este caso, renta) constante"
  },
  {
    "objectID": "docs/Tema06.html#regresión-lineal-estimación",
    "href": "docs/Tema06.html#regresión-lineal-estimación",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Lineal: Estimación",
    "text": "Regresión Lineal: Estimación\n\n\nObjetivo: estimar los coeficientes poblacionales desconocidos a partir de una muestra\nEl error de estimación o residuo es \\(\\small \\hat{e}_i = y_i - \\hat{y}_i\\), donde la predicción a partir del modelo estimado es \\(\\small \\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1 X_1+ \\dots + \\hat{\\beta}_k X_p\\)\nLos coeficientes estimados son los que minimizan la Suma Cuadrática de Residuos: la suma total de distancias entre los datos observados y predichos\n\n\n\n\n\n\n\n\\[\n\\small SCR=\\sum_{i=1}^{n} \\hat{e}_i^2= \\sum_{i=1}^{n} ( y_i - \\hat{y}_i)^2\n\\]\n\n\nEsto equivale a las condiciones derivadas de suponer \\(\\small E(\\varepsilon|X)=0\\)"
  },
  {
    "objectID": "docs/Tema06.html#regresión-lineal-estimación-cont.",
    "href": "docs/Tema06.html#regresión-lineal-estimación-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Lineal: Estimación (cont.)",
    "text": "Regresión Lineal: Estimación (cont.)\n\n\nLos parámetros del modelo \\(f(.)\\) estimado, en este caso los \\(\\small \\beta_j\\), son estadísticos con variabilidad muestral, medida por su error estándar \\(\\small se(\\widehat{\\beta}_j)\\) \n\nEstos se usan para construir intervalos de confianza y para contrastar hipótesis sobre los parámetros poblacionales, p.e., significatividad (\\(\\small \\beta_1=0\\)) y signo\n\n\n\nLa función lm() con la notación de fórmula crea un objeto lista con resultados \n\n\ndescuento &lt;- read.csv(\"data/descuento.csv\") %&gt;% \n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))\nmodelo &lt;- lm(data = descuento, ventas ~ renta + descuento)\n(sum.modelo &lt;- summary(modelo))\nnobs(modelo)\n\n\nLa predicción \\(\\widehat{y}\\) también está sujeta a incertidumbre por la estimación: se puede calcular su error estándar e intervalos de confianzas\n\n\npred &lt;- predict(modelo, type = \"response\", \n                se.fit = T, interval = \"confidence\")\ncbind(descuento$ventas, pred$fit, pred$se.fit) %&gt;% head()"
  },
  {
    "objectID": "docs/Tema06.html#ampliando-el-modelo-de-regresión-lineal",
    "href": "docs/Tema06.html#ampliando-el-modelo-de-regresión-lineal",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Ampliando el Modelo de Regresión Lineal",
    "text": "Ampliando el Modelo de Regresión Lineal\n\nPara incorporar información cualitativa en el modelo, se debe incluir una variable binaria para cada categoría, excepto una (grupo de referencia)\n\nLos coeficientes de cada variable binaria son el efecto diferencial de ese grupo respecto al grupo de referencia\nAl incluir un factor, se crean automáticamente las variables binarias\n\n\n\n\nlm(data = descuento, ventas ~ zona) %&gt;% summary()\nlm(data = descuento, ventas ~ renta + descuento + zona) %&gt;% summary()\n\n\n\n\nPodemos modelizar relaciones no lineales entre la variable dependiente y las explicativas incluyendo transformaciones de variables como logaritmos, polinomios, interacciones, etc.\nPERO la interpretación del cambio de un regresor sobre \\(\\small Y\\) es diferente"
  },
  {
    "objectID": "docs/Tema06.html#regresión-lineal-superando-la-linealidad",
    "href": "docs/Tema06.html#regresión-lineal-superando-la-linealidad",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Lineal: superando la linealidad",
    "text": "Regresión Lineal: superando la linealidad\n\n\nUsando logaritmos, modelizamos cambios porcentuales en las variables\n\n\nlm(data=descuento, log(ventas) ~ log(renta) + descuento) %&gt;% summary()\nlm(data=descuento, log(ventas) ~ renta + descuento) %&gt;% summary()\n\n\nUsando polinomios en los regresores, modelizamos efectos no lineales; esto implica que el efecto de \\(\\small X\\) sobre \\(\\small Y\\) depende de \\(\\small X\\)\n\n\nlm(data=descuento, ventas ~ edad + I(edad^2) ) %&gt;% summary()\nggplot(descuento, aes(x=edad, y=ventas)) + geom_point() + \n  geom_smooth(method = \"lm\", formula = y ~ x + I(x^2))\n\n\nOtra forma de permitir no linealidades es discretizando variables continuas: permite efectos “escalón” diferentes para distintos valores\n\n\nlm(data=descuento, ventas ~ \n     cut(edad, seq(20, 60, 5), include.lowest = T)) %&gt;% summary()\nggplot(descuento, aes(x=edad, y=ventas)) + geom_point() + \n  geom_smooth(method = \"lm\", \n              formula = y ~ cut(x, seq(20, 60, 5), include.lowest = T))"
  },
  {
    "objectID": "docs/Tema06.html#regresión-lineal-superando-la-linealidad-cont.",
    "href": "docs/Tema06.html#regresión-lineal-superando-la-linealidad-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Lineal: superando la linealidad (cont.)",
    "text": "Regresión Lineal: superando la linealidad (cont.)\n\nIncluyendo interacciones entre variables, el efecto de un regresor dependerá de otro regresor: la “pendiente” cambia con el valor de la otra variable\n\nAl incluir una interacción siempre deben incluirse los factores principales (NO sólo edad:renta)\n\n\n\nlm(data=descuento, ventas ~ edad*renta)  %&gt;% summary()\nlm(data=descuento, ventas ~ renta*mujer) %&gt;% summary()\n\nggplot(descuento, aes(x=renta, y=ventas, color = mujer)) + \n  geom_point() + geom_smooth(method = \"lm\", formula = y ~ x,\n                               se = FALSE)"
  },
  {
    "objectID": "docs/Tema06.html#regresión-lineal-comentarios-finales",
    "href": "docs/Tema06.html#regresión-lineal-comentarios-finales",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Lineal: comentarios finales",
    "text": "Regresión Lineal: comentarios finales\n\n\nLos resultados de (todos) estos modelos informan de la relación entre los regresores y la variables dependiente\n“Correlación no implica causalidad”, salvo en ensayos científicos aleatorios controlados, también llamados pruebas A/B\n\n\n\n\n\n\nLa selección de variables es importante: evita sesgos o aumenta la variabilidad\n\n\nlm(data = descuento, ventas ~ descuento) %&gt;% summary()\nlm(data = descuento, ventas ~ descuento + renta) %&gt;% summary()\nlm(data = descuento, ventas ~ renta) %&gt;% summary()\nlm(data = descuento, ventas ~ renta + educ) %&gt;% summary()\n\n\n\n\n\n\nAlgunos sugieren “pruebas” para los problemas en el modelo lineal; eso es erróneo:\n\nNo linealidad: hemos visto que modeliza relaciones no lineales\nNo normalidad: innecesaria, con TCL o bootstrap.\nColinearidad: simplemente elimina la variable colineal.\nHeterocedasticidad y autocorrelación: solo necesitamos errores estándar robustos"
  },
  {
    "objectID": "docs/Tema06.html#regresión-logística",
    "href": "docs/Tema06.html#regresión-logística",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Logística",
    "text": "Regresión Logística\n\nUn modelo de regresión lineal para respuestas binarias no es adecuado porque genera predicciones fuera del rango \\(\\small [0,1]\\)\n\n\n\n\nSolución: aplicar al índice lineal una transformación, la función logística \\(\\small \\Lambda (z)=\\frac{e^z}{1+e^z}\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe manera que \\(\\small \\Pr(Y=1|X)= f(x)= \\color{blue}{\\Lambda( \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_k x_k)} \\in [0,1]\\)\n\n\n\nComo el modelo siempre es no lineal, el coeficiente NO coincide con la magnitud del efecto de un cambio en los regresores sobre la probabilidad. PERO sí coinciden en su signo (y significatividad)\n\n\nNO se puede minimizar la SCR; el objetivo es maximizar la probabilidad (verosimilitud) de observar los unos y ceros en los datos"
  },
  {
    "objectID": "docs/Tema06.html#regresión-logística-cont.",
    "href": "docs/Tema06.html#regresión-logística-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Logística (cont.)",
    "text": "Regresión Logística (cont.)\n\nLa regresión logística se puede estimar en R con la función glm(), de forma similar a lm(); podemos incluir variables explicativas tanto cuantitativas como cualitativas, interacciones, etc.\n\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;%\n  mutate(across(where(is.character), ~parse_factor(.x)))\n\nlogit &lt;- glm(data = censo, income ~  race + age + I(age^2) + log(hours_per_week)*sex + \n      education_1  + capital_gain + capital_loss, \n         family = \"binomial\") \nlogit %&gt;%  summary()\n\n\nComo en el modelo lineal, podemos calcular predicciones de la probabilidad tanto en los mismos datos como en unos nuevos\n\n\npredict(logit, type=\"response\")\n\nlogit2 &lt;- logit &lt;- glm(data = censo, income ~  age + education_1, \n         family = \"binomial\")\nsummary(logit2)\npredict(logit2, type=\"response\",\n        newdata = tibble(age=c(20,60), education_1=c(9,16)))"
  },
  {
    "objectID": "docs/Tema06.html#regresión-logística-con-más-de-dos-clases",
    "href": "docs/Tema06.html#regresión-logística-con-más-de-dos-clases",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Regresión Logística con más de dos clases",
    "text": "Regresión Logística con más de dos clases\n\nLa regresión logística se puede generalizar a situaciones con múltiples clases (modelos multinomiales) con un índice lineal para cada clase \\[\n\\small\n\\Pr(Y=c|X)=\\frac{e^{\\beta_{0c}+\\beta_{1c}X_1+\\dots+\\beta_{kc}X_k}}{\\sum_{l=1}^{C}e^{\\beta_{0l}+\\beta_{1l}X_1+\\dots+\\beta_{kl}X_k}}\n\\]\nLa librería glmnet() permite la estimación de estos modelos\n\n\n\nhealth &lt;- read_csv(\"data/health_insurance.csv\") %&gt;% \n  mutate(across(where(is.character), ~parse_factor(.x)))\n\nlibrary(glmnet)\nx &lt;- model.matrix(product ~ age + gender, data = health)\nmod.glmnet &lt;- glmnet(x = x, y = health$product, family = \"multinomial\", \n                     lambda = 0, type.multinomial = \"grouped\")\ncoef(mod.glmnet) \npredict(mod.glmnet, newx=x, type = \"response\")  # probabilidad de cada clase\npredict(mod.glmnet, newx=x, type = \"class\")     # clase"
  },
  {
    "objectID": "docs/Tema06.html#error-de-predicción",
    "href": "docs/Tema06.html#error-de-predicción",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Error de predicción",
    "text": "Error de predicción\n\nUn modelo es mejor si sus predicciones se ajusten mejor a las observaciones\nEl error de predicción es \\(y - \\widehat{y} = f(X) - \\widehat{f}(X)  + \\varepsilon\\)\n\n\\(f - \\widehat{f}\\) = error reducible (eligiendo modelo)\n\\(\\varepsilon\\) = error irreducible (variables no observadas)\n\nLa función de pérdida (o coste) evalúa cómo valoramos las desviaciones"
  },
  {
    "objectID": "docs/Tema06.html#métricas-de-error-de-predicción-cuantitativa",
    "href": "docs/Tema06.html#métricas-de-error-de-predicción-cuantitativa",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Métricas de error de predicción (cuantitativa)",
    "text": "Métricas de error de predicción (cuantitativa)\n\nMean Square Error (Error Cuadrático Medio): \\(\\small MSE(y,\\widehat{y})={\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\n\npenaliza grandes desviaciones\n\\(\\small R^2\\) y \\(\\small R^2\\)-ajustado son variantes del MSE, pero solo sirven para comparar modelos con la misma variable dependiente.\n\nRoot Mean Square Error: \\(\\small RMSE(y,\\widehat{y})=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\n\nmismas unidades que \\(\\small y\\)\n\nMean Absolute Error: \\(\\small MAE(y,\\widehat{y})=\\frac{1}{n}\\sum_{i=1}^{n}\\left|y-\\widehat{y}\\right|\\)\n\n\n\nOtras medidas basadas en distintas funciones de pérdida, la verosimilitud del modelo (\\(\\small AIC\\), \\(\\small BIC\\)), etc"
  },
  {
    "objectID": "docs/Tema06.html#seleccionar-el-mejor-modelo",
    "href": "docs/Tema06.html#seleccionar-el-mejor-modelo",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Seleccionar el mejor modelo",
    "text": "Seleccionar el mejor modelo\n\n¿Podemos predecir el número de visitantes en función de la temperatura?\n\n\nlibrary(mosaicData)\ndata(RailTrail)\nRailTrail %&gt;% ggplot(aes(x = hightemp, y = volume)) + \n  geom_point() +  geom_smooth()\n\n\n¿Cuál es el mejor modelo?\n\n\\(\\small volume = \\beta_0 + \\beta_1 hightemp + \\varepsilon\\)\n\\(\\small volume = \\beta_0 + \\beta_1 hightemp + \\beta_2 hightemp^2 + \\varepsilon\\)\n…\n\\(\\small volume = \\beta_0 + \\beta_1 hightemp + \\dots + \\beta_{22} hightemp^{22} + \\varepsilon\\)\n\n\n\nRailTrail %&gt;% ggplot(aes(x = hightemp, y = volume)) + \n  geom_point() + \n  geom_smooth(method = 'lm', formula = y ~ poly(x,22) ) + \n  coord_cartesian(ylim = c(100,750))"
  },
  {
    "objectID": "docs/Tema06.html#muestras-de-entrenamiento-y-de-prueba",
    "href": "docs/Tema06.html#muestras-de-entrenamiento-y-de-prueba",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Muestras de entrenamiento y de prueba",
    "text": "Muestras de entrenamiento y de prueba\n\nLas métricas de error (ej., \\(\\small MSE\\)) suelen calcularse para predicciones de los mismos datos usados para ajustar/estimar el modelo (in-sample prediction)\n\nEsta muestra se denomina muestra de entrenamiento (training sample)\n\nPERO queremos saber qué tal se predicen casos nuevos (out-sample prediction)\nUsar las métricas en muestras de entrenamiento implica problemas de “overfitting”: sobreajuste a las características de la muestra concreta\n\nUn modelo menos flexible podría tener menor error de predicción con casos nuevos\n\n\n\nDebemos calcular las métricas de error con observaciones que el modelo NO ha usado antes: muestra de prueba (test sample)"
  },
  {
    "objectID": "docs/Tema06.html#overfitting",
    "href": "docs/Tema06.html#overfitting",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "“Overfitting”",
    "text": "“Overfitting”\n\n\n\n\n\nSiempre que aumenta la flexibilidad, el MSE\n\ndisminuye en la muestra de entrenamiento\ntiene forma de U en la muestra de prueba\n\nNota: el MSE en entrenamiento es siempre menor que en prueba"
  },
  {
    "objectID": "docs/Tema06.html#mse-en-la-muestra-de-prueba",
    "href": "docs/Tema06.html#mse-en-la-muestra-de-prueba",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "MSE en la muestra de prueba",
    "text": "MSE en la muestra de prueba\n\\[\n\\small\nE\\left[\\left(y-\\widehat{f}(x)\\right)^2\\right] =\nE\\left[\\left(f(x)-\\widehat{f}(x) + \\varepsilon\n+ E\\left[\\widehat{f}(x)\\right]-E\\left[\\widehat{f}(x)\\right] \\right)^2\\right] =\n\\]\n\\[\n\\small\n=\\underbrace{\\left[E\\left(\\widehat{f}(x)\\right)-f(x)\\right]^2}_{(1)} + \\underbrace{E\\left(\\left[\\widehat{f}(x)-E\\left(\\widehat{f}(x)\\right)\\right]^2\\right)}_{(2)}+Var(\\varepsilon)\n\\]\n\n\\(\\small (1)=\\left[Sesgo\\left(\\widehat{f}(x)\\right)\\right]^2\\): error por supuestos erróneos en \\(f\\)\n\najuste insuficiente (underfit) al perder relaciones relevantes entre \\(X\\) e \\(Y\\)\n\n\\(\\small (2)=Var\\left(\\widehat{f}(x)\\right)\\): sensibilidad a fluctuaciones en el entrenamiento\n\nsi el algoritmo modela puro ruido en entrenamiento, ajustará bien allí, pero predecirá mal casos nuevos (overfit)"
  },
  {
    "objectID": "docs/Tema06.html#trade-off-varianzasesgo",
    "href": "docs/Tema06.html#trade-off-varianzasesgo",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "“Trade-off” Varianza–Sesgo",
    "text": "“Trade-off” Varianza–Sesgo\n\n\n\n\n\n\n\nEl sesgo se reduce y la varianza aumenta con la complejidad del modelo \\(\\Rightarrow\\) encontrar un método (ej., flexibilidad) para el que ambos sean bajos\n\n\nNO es posible minimizar simultáneamente ambas fuentes de error: memorización (en entrenamiento) vs. generalización de resultados"
  },
  {
    "objectID": "docs/Tema06.html#medir-el-error-en-la-clasificación",
    "href": "docs/Tema06.html#medir-el-error-en-la-clasificación",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Medir el Error en la Clasificación",
    "text": "Medir el Error en la Clasificación\n\nLos modelos de clasificación NO predicen directamente la categoría, sino la probabilidad de que una observación pertenezca a cada categoría\n\n\nLa clase predicha será aquella con mayor probabilidad. En el caso binario, implicar superar el umbral de 0.5 (se deben probar varios valores)\n\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;%\n  mutate(income = parse_factor(income))\nlogit &lt;- glm(data = censo, income ~ capital_gain,  \n             family = \"binomial\")\nprob.predict &lt;- predict(logit, type = \"response\")\n\numbral &lt;- 0.5\ncat.predict  &lt;- if_else(prob.predict &gt; umbral, 1, 0) \ncbind(censo$income, cat.predict, prob.predict) %&gt;% head(10)\n\n\nComo no tiene sentido diferencia de clases (variables categóricas), NO se pueden calcular medidas como el MSE y otros relacionados"
  },
  {
    "objectID": "docs/Tema06.html#matriz-de-confusión",
    "href": "docs/Tema06.html#matriz-de-confusión",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Matriz de Confusión",
    "text": "Matriz de Confusión\n\nTabular categorías observadas frente a las categorías predichas\n\n\n\n\n\n\n\n\n\n\n\nCLASE OBSERVADA\n\n\n\n.\nPOSITIVO (1)\nNEGATIVO (0)\n\n\n\n\nCLASE PREDICHA\n\n\nPOSITIVO (1)\nVerdadero Positivo [VP]\nFalso Positivo [FP]\n\n\n\n\n(Error Tipo I)\n\n\nNEGATIVO (0)\nFalso Negativo [FN]\nVerdadero Negativo [VN]\n\n\n\n(Error Tipo II)\n\n\n\n\n\n\n\ntable(cat.predict, censo$income)\n\n\nExisten varias medidas derivadas de la matriz de confusión"
  },
  {
    "objectID": "docs/Tema06.html#métricas-con-la-matriz-de-confusión",
    "href": "docs/Tema06.html#métricas-con-la-matriz-de-confusión",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Métricas con la matriz de confusión",
    "text": "Métricas con la matriz de confusión\n\nTasa de observaciones correctamente clasificadas (exactitud o accuracy)\n\n\\[\n\\scriptsize ACCUR=\\frac{VP+VN}{VP+FP+VN+FN}\n\\]\n\nNo es informativo cuando algunas clases son infrecuentes (datos desequilibrados)\n\nsi hay poco fraude/enfermos (ej., 5%), predecir que nunca hay fraude implica \\(\\scriptsize ACCUR=95\\%\\), PERO NO detecta fraude/enfermedad\n\n\n\nEl estadístico Kappa (\\(\\small \\kappa\\)) es una medida similar, pero que ajusta por lo se esperaría solo por azar (corrigiendo en parte el desequilibrio entre clases)."
  },
  {
    "objectID": "docs/Tema06.html#métricas-con-la-matriz-de-confusión-cont.",
    "href": "docs/Tema06.html#métricas-con-la-matriz-de-confusión-cont.",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Métricas con la matriz de confusión (cont.)",
    "text": "Métricas con la matriz de confusión (cont.)\n\nLa tasa de verdaderos positivos o sensibilidad (recall) es el porcentaje de verdaderos positivos sobre el total de positivos observados \\[\n\\scriptsize TVP=SENSIT=\\frac{VP}{VP+FN}\n\\]\n\nej., tasa de fraude/enfermos existentes que se detectan correctamente\n\n\n\nLa tasa de verdaderos negativos o especificidad es el porcentaje de verdaderos negativos sobre el total de negativos observados \\[\n\\scriptsize TVN=ESPECIF=\\frac{VN}{VN+FP}\n\\]\n\nej., tasa de “otras” opciones que se clasifican correctamente\nTasa de falsos positivos: \\(\\scriptsize TFP = 1 - TVN = 1 - ESPECIF\\)"
  },
  {
    "objectID": "docs/Tema06.html#métricas-con-la-matriz-de-confusión-y-3",
    "href": "docs/Tema06.html#métricas-con-la-matriz-de-confusión-y-3",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Métricas con la matriz de confusión (y 3)",
    "text": "Métricas con la matriz de confusión (y 3)\n\nLa exactitud equilibrada (Balanced Accuracy) es una media de la sensibilidad y de la especificidad\n\n\nLa precisión o valor de predicción positivo es la cantidad de verdaderos positivos sobre el total de positivos predichos\n\n\\[\n\\scriptsize PREC=\\frac{VP}{VP+FP}\n\\]\n\nLa familia de medidas \\(\\small F_{\\beta}\\) es una ratio de la importancia ponderada de la sensibilidad y de la precisión: \\(\\scriptsize F_{\\beta}=\\frac{(1+\\beta)^2 \\times SENSIT \\times PREC}{\\beta^2 \\times SENSIT + PREC}\\)\n\nPara \\(\\scriptsize \\beta&lt;1\\), se da menos importancia a la sensibilidad: los falsos positivos se consideran más costosos\nPara \\(\\scriptsize \\beta&gt;1\\), los falsos negativos son más costosos y para \\(\\scriptsize \\beta=1\\) son igualmente costosos"
  },
  {
    "objectID": "docs/Tema06.html#curva-roc-receiver-operating-characteristic",
    "href": "docs/Tema06.html#curva-roc-receiver-operating-characteristic",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Curva ROC (“Receiver Operating Characteristic”)",
    "text": "Curva ROC (“Receiver Operating Characteristic”)\n\n\nRepresenta TVP (eje y) frente a TFP (eje x) en diferentes umbrales : reducir el umbral clasifica más elementos como positivos (verdaderos y falsos)\n\n\n\n\n\nLa curva ROC informa del grado de separabilidad: dado un nivel de TFP, el clasificador es mejor cuanto mayor sea TVP"
  },
  {
    "objectID": "docs/Tema06.html#auc-area-under-the-curve",
    "href": "docs/Tema06.html#auc-area-under-the-curve",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "AUC (“area under the curve”)",
    "text": "AUC (“area under the curve”)\n\nLa AUC es el área bajo la curva ROC: ofrece una medida agregada de rendimiento entre 0 (todas las clasificaciones incorrectas) y 1 (todas correctas)\n\n\nResume la curva ROC y permite comparar curvas que se cruzan"
  },
  {
    "objectID": "docs/Tema06.html#extensiones.-métricas-adicionales",
    "href": "docs/Tema06.html#extensiones.-métricas-adicionales",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Extensiones. Métricas adicionales",
    "text": "Extensiones. Métricas adicionales\n\nCon más de dos clases, se realiza un análisis AUC-ROC para cada categoría (frente a las demás) y se promedian (ej., ponderando por casos en cada clase) \n\n\nCon clases desequilibradas, se puede preferir en lugar de la ROC un gráfico de precisión frente sensibilidad (precision-recall) y su correspondiente AUC (PR-AUC)\n\n\nExisten múltiples funciones de pérdida (o coste de clasificación) posibles.\n\nLas relacionadas con la curva de ganancia consideran el coste de alcanzar un cierto nivel de sensibilidad\nOtras se basan en la función de verosimilud o la entropía como medidas de pérdida (ej. mean log loss)"
  },
  {
    "objectID": "docs/Tema06.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "href": "docs/Tema06.html#evaluación-de-modelos-entrenamiento-y-prueba",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Evaluación de Modelos: entrenamiento y prueba",
    "text": "Evaluación de Modelos: entrenamiento y prueba\n\nPara minimizar problemas de underfit y, sobre todo, de overfit, DEBEMOS dividir aleatoriamente el conjunto de datos en dos partes:\n\n\n\n\n\n\n\n\n\nEntrenamiento (80-90%): datos sobre los que se construye/estima el modelo\nPrueba(20-10%): se usa el modelo construido para predecir y se evalúa con datos no vistos antes\n\n\n\n\n¿Por qué renunciar a parte de los datos si sabemos que un tamaño muestral grande es importante? Evaluar correctamente un modelo lo es mucho más\nLa estimación del error en prueba puede ser volátil dependiendo de las observaciones incluidas en cada grupo"
  },
  {
    "objectID": "docs/Tema06.html#evaluación-de-modelos-validación-cruzada",
    "href": "docs/Tema06.html#evaluación-de-modelos-validación-cruzada",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Evaluación de Modelos: Validación cruzada",
    "text": "Evaluación de Modelos: Validación cruzada\n\nPara evitar que los datos sean sensibles a una partición concreta, se usa validación cruzada (cross-validation o rotation estimation)\nSe repite varias veces y de forma ordenada el proceso de remuestreo para la partición en grupos de entrenamiento y prueba (similar a bootstrap)\nPermite utilizar todas las observaciones de la muestra, tanto para estimar como para evaluar el modelo (aunque no a la vez)"
  },
  {
    "objectID": "docs/Tema06.html#validación-cruzada-de-k-bloques",
    "href": "docs/Tema06.html#validación-cruzada-de-k-bloques",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Validación cruzada de K bloques",
    "text": "Validación cruzada de K bloques\n\nSe divide, aleatoriamente y ex-ante, la muestra en K subconjuntos (normalmente, 5 o 10)\n\n\n\n\n\n\n\n\nUn subconjunto se usa como prueba y el K-1 restantes como entrenamiento\nSe repite el proceso durante k iteraciones, con cada posible subconjunto de datos de prueba.\n\n\n\nSe obtiene una métrica de error en cada iteración; se promedian para obtener un único resultado de evaluación\nEs el tipo más habitual de validación cruzada"
  },
  {
    "objectID": "docs/Tema06.html#validación-cruzada-aleatoria-rcv-y-loocv",
    "href": "docs/Tema06.html#validación-cruzada-aleatoria-rcv-y-loocv",
    "title": "Tema 06 - Modelización. Aprendizaje estadístico",
    "section": "Validación cruzada aleatoria (RCV) y LOOCV",
    "text": "Validación cruzada aleatoria (RCV) y LOOCV\n\n\n\n\n\n\n\nRCV: en cada iteración se realiza la particion aleatoria (con reemplazamiento) entre entrenamiento y prueba\nLas observaciones pueden “repetir” como prueba\n\n\n\n\n\n\n\n\n\nLOOCV (leave one out CV): solo una observación se usa como prueba en cada iteración y el resto como entrenamiento\nSe realizan \\(n\\) iteraciones; se calcula una media sobre \\(n\\) resultados"
  },
  {
    "objectID": "docs/Tema05.html#de-los-datos-en-bruto-a-la-información",
    "href": "docs/Tema05.html#de-los-datos-en-bruto-a-la-información",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "De los datos en bruto a la información",
    "text": "De los datos en bruto a la información\n\n\n\n\n\nAED es una fase inicial importante, con dos objetivos:\n\nConocer nuestros datos e identificar problemas \\(\\Longrightarrow\\) Preprocesamiento\n\nqué variables, tipo de información, calidad (información faltante, inconsistencias, problemas en combinación de datos.)\n\nAnálisis descriptivo: identificar patrones y encontrar escenarios de análisis\n\n\n\nNO hay una “receta”: el proceso es diferente con distintos datos o con los mismos datos para diferentes objetivos\nEs un proceso iterativo para descubrir información"
  },
  {
    "objectID": "docs/Tema05.html#primera-aproximación-a-los-datos",
    "href": "docs/Tema05.html#primera-aproximación-a-los-datos",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Primera aproximación a los datos",
    "text": "Primera aproximación a los datos\n\nContexto: conocimiento previo de nuestros datos, aquí o aquí\n\nfuente (de dónde han salido), cómo están almacenados (.csv, .xlsx, …)\n“diccionario”: información de cada variable (descripción, unidades, etc.)\n\n\n\nCargar los datos\n\n\nBank &lt;- read_csv2(\"data/BankMarketing.csv\")\nBoston &lt;- read_csv(\"data/BostonHousing.csv\")\n\n\nReconocimiento inicial de las características de los datos: número de observaciones y de variables, tipo de cada variable, etc.\n\n\n\n\nglimpse(Bank)  # str(Bank)\n\n\n\n\nView(Bank)     # head(Bank)\n\n\n\n\nNO TODO lo que hagamos se incluirá en un documento para comunicar"
  },
  {
    "objectID": "docs/Tema05.html#primera-aproximación-a-los-datos-cont.",
    "href": "docs/Tema05.html#primera-aproximación-a-los-datos-cont.",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Primera aproximación a los datos (cont.)",
    "text": "Primera aproximación a los datos (cont.)\n\nLimpiar y procesar los datos para asegurar que son ordenados:\n\n¿Tienen las variables la información y el tipo adecuado? P.e.: job en Bank. Convertimos datos a factores, numéricas, etc.\nEliminar filas vacías, observaciones duplicadas\nRenombrar variables (para mayor claridad), generar nuevas\nDetectar inconsistencias en texto, fechas, unidades, etc. \n\n\n¿Mantenemos solo algunas variables u observaciones?\n\nCaso destacado: identificar cuántos NAs en cada variable\n\n\n\n\n\nBank %&gt;%  is.na() %&gt;% summary()\nBank %&gt;% summary()\n\n\n\nload(\"data/earn.RData\")\nearn %&gt;% is.na() %&gt;% summary()\n\n\n\n\nNO ES UNA RECETA: más adelante podemos volver atrás, para rehacer o tomar decisiones (qué hacer con NAs al modelizar)"
  },
  {
    "objectID": "docs/Tema05.html#análisis-de-variación-univariante",
    "href": "docs/Tema05.html#análisis-de-variación-univariante",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Análisis de Variación (“univariante”)",
    "text": "Análisis de Variación (“univariante”)\n\n\nLa variación es la tendencia de los valores de una variable a cambiar entre medidas (p.e., educación de dos personas o ventas de dos empresas) \n\n\n\nLas técnicas para analizar el patrón de variación, es decir, la distribución de valores, dependen del tipo de variable\nVariables Categóricas (previamente convertidas a factores):\n\nConteos, Porcentajes, Moda\n\ncon summary(), table(), mode() o summarize(), count()\n\nVisualización: Gráficos de Barras (también, quizás, circulares)\n\nVariables Numéricas:\n\nEstadísticas Descriptivas: Mínimo, Máximo, Media, Mediana, Moda\n\ncon summary() o summarize() con funciones para estadísticos\n\nDispersión: Rango, Varianza, Desviación Estándar, Cuartiles.\nVisualización: Histogramas, Densidades, Boxplots."
  },
  {
    "objectID": "docs/Tema05.html#visualizando-distribuciones",
    "href": "docs/Tema05.html#visualizando-distribuciones",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Visualizando distribuciones",
    "text": "Visualizando distribuciones\n\n\nVariables Categóricas: gráficos de barras para conteos o porcentajes\n\n\ng0 &lt;- ggplot(data = Bank) \ng0 + geom_bar(aes(x = job)) + \n        theme(axis.text.x = element_text(angle = 90))\ng0 + geom_bar( aes(x = \"\", fill = education))\n\n\nBank %&gt;% count(education) %&gt;% mutate(prop = n / sum(n)) %&gt;% \n  ggplot() + geom_bar(aes(x = education, y = prop), stat = \"identity\")\n\nBank %&gt;% ggplot(aes(x = education)) +\n  geom_bar(aes(y = ..prop.., group = 1))\n\n\nPara variables continuas, usar un histograma o densidad (o ambos)\n\n\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 5)\ng0 + geom_density(mapping = aes(x = balance)) + scale_x_log10()\nBoston %&gt;%  ggplot(aes(x=medv)) + \n  geom_histogram(aes(y=..density..)) + geom_density() \n\n\nConsideramos varios anchos del intervalo: pueden revelar diferentes patrones\n\n\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 1)\ng0 + geom_histogram(mapping = aes(x = age), binwidth = 10)"
  },
  {
    "objectID": "docs/Tema05.html#visualizando-distribuciones-cont.",
    "href": "docs/Tema05.html#visualizando-distribuciones-cont.",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Visualizando distribuciones (cont.)",
    "text": "Visualizando distribuciones (cont.)\n\nLos gráficos de caja también aportan información para distribuciones continuas\n\n\nggplot(Boston) + geom_boxplot(mapping = aes(y = medv))"
  },
  {
    "objectID": "docs/Tema05.html#aspectos-a-prestar-atención",
    "href": "docs/Tema05.html#aspectos-a-prestar-atención",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Aspectos a prestar atención",
    "text": "Aspectos a prestar atención\n\n\nDetectar inconsistencias en la distribución de valores o en las categorías: p.e., “unknown” en job de Bank\nValores frecuentes, concentración en valores concretos (p.e., ceros, números “redondos”, etc.): ¿por qué se producen? ¿son “esperables”?\n\n\n¿Tienen sentido las categorías de las variables cualitativas?\n\nagrupar valores con pocas observaciones\ncrear categorías más “finas”o más agregadas (ej. de países a continentes)\n\n\n\n¿Sería preferible discretizar alguna variable continua? Ej., grupos de edad\nVariables con alta dispersión o distribución asimétrica (logs?)\n\n\nVariables con información redundante, homogeneizar valores, normalidad(?)\n\n\nValores inusuales (“atípicos” o “outliers”): no encajan en el patrón general\n\n¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?"
  },
  {
    "objectID": "docs/Tema05.html#otras-herramientas-para-aed",
    "href": "docs/Tema05.html#otras-herramientas-para-aed",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Otras herramientas para AED",
    "text": "Otras herramientas para AED\n\n\nPara una primera aproximación automática , pero NO todas para incluir en un informe final: con las bibliotecas skimr (o modelsummary) y DataExplorer\n\n\nlibrary(skimr)\nskim(Bank)        # ¿para incluir en un informe?\nmodelsummary::datasummary_skim(Bank)\n\n\nlibrary(DataExplorer)\nplot_bar(Bank)        # para TODAS las variables categóricas\nplot_histogram(Bank)  # para TODAS las variables numéricas\n\n\nEl paquete janitor contiene herramientas para limpieza de datos\nLa biblioteca dlookr ofrece heramientas para diagnóstico y exploración de datos (entre otras), devolviendo data frame (para usar con kable())\n\n\nlibrary(dlookr)     # en MacOS, puede pedir instalar XQuartz\nBank %&gt;% diagnose()\nBank %&gt;% describe() %&gt;%\n  select(described_variables, skewness, mean, p25, p50, p75) %&gt;% \n  filter(!is.na(skewness)) %&gt;% arrange(desc(abs(skewness)))\nBank %&gt;% group_by(education) %&gt;% \n  describe(age, balance, campaign, pdays) \n\nBank %&gt;% mutate(across(where(is.character), ~parse_factor(.x))) %&gt;% \n  eda_web_report()"
  },
  {
    "objectID": "docs/Tema05.html#análisis-de-covariación-multivariante",
    "href": "docs/Tema05.html#análisis-de-covariación-multivariante",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Análisis de Covariación (“multivariante”)",
    "text": "Análisis de Covariación (“multivariante”)\n\nLa variación describe el comportamiento dentro de una variable\nLa covariación describe relaciones entre variables: tendencia a que sus valores cambien juntos\nÚtil para formular modelos, que explican patrones complejos de los datos\n\n¿qué explica la relación sugerida por el patrón de covariación?\n¿cómo de fuerte es la relación?\n¿otras variables pueden afectar a la relación? ¿varían por subgrupos?\n\nCovariación implica que los valores de una variable se pueden predecir a partir de otra\n\n¿es la covariación una relación causal?"
  },
  {
    "objectID": "docs/Tema05.html#una-variable-continua-y-una-categórica",
    "href": "docs/Tema05.html#una-variable-continua-y-una-categórica",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Una variable continua y una categórica",
    "text": "Una variable continua y una categórica\n\n¿Es diferente la distribución de Y (continua) por categorías de X? Si \\(\\small{\\Pr(Y|X=x_1) = \\Pr(Y|X=x_0) =  \\Pr(Y)} \\Rightarrow\\) Y NO depende de X\n\n\n1.- mediante el histograma o densidad (en el mismo gráfico o diferentes)\n\nggplot(Bank) + geom_density(aes(x = balance, color = default)) + \n  scale_x_log10()\nggplot(Bank) + geom_density(aes(x = balance)) + facet_wrap(~default) + \n  scale_x_log10()\nggplot(Bank) + geom_density(aes(x = balance, color = education)) + \n  scale_x_log10()\nggplot(Boston) + geom_density(aes(x=lstat, color=as.factor(chas))) \n\n2.- mediante gráficos de caja: menos información pero más fácil de comparar\n\nggplot(Boston) + geom_boxplot(aes(x=medv, y=as.factor(chas)))\nggplot(Bank) + geom_boxplot(aes(x=duration, y=as.factor(y)))\n\n\n\nSi un grupo es mucho más pequeño, es difícil ver las diferencias\nSe pueden necesitar reordenar las categorías de un factor, rotar los ejes, etc."
  },
  {
    "objectID": "docs/Tema05.html#correlación-entre-una-variable-continua-y-una-categórica",
    "href": "docs/Tema05.html#correlación-entre-una-variable-continua-y-una-categórica",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "“Correlación” entre una variable continua y una categórica",
    "text": "“Correlación” entre una variable continua y una categórica\n\nLa regresión simple también describe una relación: equivale a calcular la media de la variable continua por grupos definidos por la categórica\n\n\n\\[\nE[Y|X]=\\beta_0+\\beta_1 X \\Rightarrow\n\\begin{cases}\nE[Y|X=0] &=\\beta_0 \\\\\nE[Y|X=1]&=\\beta_0+\\beta_1\n\\end{cases}\n\\]\n\n\nsummary(lm(data = Bank, balance ~ education))\nBank %&gt;% group_by(education) %&gt;% summarise(media = mean(balance))\n\nBank %&gt;% group_by(y) %&gt;% summarise(media = mean(duration))\n\n\n¿Mediante la correlación? NO tiene sentido cuando una variable es categórica\n\n\nPara variables dependientes categóricas veremos una variante de regresión lineal: regresión logística"
  },
  {
    "objectID": "docs/Tema05.html#dos-variables-categóricas",
    "href": "docs/Tema05.html#dos-variables-categóricas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables categóricas",
    "text": "Dos variables categóricas\n\n\nTabular o visualizar la frecuencia absoluta (conteo) para cada combinación\n\n\ntable(Bank$job, Bank$education)\nBank %&gt;% count(job, education) %&gt;% \n  pivot_wider(names_from = education, values_from = n)\n\nBank %&gt;%  ggplot(aes(x=education)) + geom_bar(aes(fill=job)) \nBank %&gt;%  ggplot(aes(x=education)) + geom_bar(aes(fill=job), position=\"dodge\")\n\n\nO para las frecuencias relativas (proporciones)\n\n\ntable(Bank$job, Bank$education) %&gt;% prop.table(margin = 2)\nBank %&gt;% count(job, education) %&gt;% \n  group_by(education) %&gt;% mutate(prop= n/sum(n)) %&gt;% select(-n) %&gt;% \n  pivot_wider(names_from = education, values_from = prop)  \n\nBank %&gt;% ggplot(aes(x=education)) + geom_bar(aes(fill=job), position = \"fill\") \n\nBank %&gt;% count(job, education) %&gt;% \n  group_by(education) %&gt;% mutate(prop= n/sum(n)) %&gt;% \n  ggplot() + geom_bar(aes(x=education, y=prop, fill = job), \n                      stat = \"identity\")"
  },
  {
    "objectID": "docs/Tema05.html#dos-variables-continuas",
    "href": "docs/Tema05.html#dos-variables-continuas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Dos variables continuas",
    "text": "Dos variables continuas\n\n\nLa forma obvia de visualizar relaciones entre variables continuas es un gráfico de dispersión; añadir smoothers ayuda a apreciar un patrón en los puntos\n\n\nggplot(Boston, aes(y=medv, x=lstat)) + geom_point() + geom_smooth()\nggplot(Boston, aes(y=medv, x=lstat)) + geom_point() + geom_smooth() +\n  scale_y_log10()\n\n\nCon la bibliteca GGally obtenemos una primera visión de conjunto\n\n\nlibrary(GGally)\nBoston %&gt;% select(-chas) %&gt;% ggpairs()\n\n\nOtra opción categorizar una variable continua y usar las técnicas anteriores\n\n\nBank %&gt;% mutate(agegroup=cut(age, breaks=seq(20, 70, by=10))) %&gt;% \n  ggplot()  + geom_boxplot(aes(x= balance, y =agegroup))"
  },
  {
    "objectID": "docs/Tema05.html#correlación-entre-variables-continuas",
    "href": "docs/Tema05.html#correlación-entre-variables-continuas",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Correlación entre variables continuas",
    "text": "Correlación entre variables continuas\n\nPodemos calcular modelos de regresión con dos variables continuas\n\n\nsummary(lm(data = Boston, medv ~ lstat) )\n\n\nY también correlaciones para dos o múltiples variables\n\n\ncor(Boston$medv, Boston$lstat, use = \"complete.obs\")\n\nlibrary(dlookr)\nBoston %&gt;% correlate()\nBoston %&gt;% select(medv, lstat) %&gt;%  correlate() \nBoston %&gt;% group_by(chas) %&gt;%  correlate() \n\n\nO visualizar las correlaciones\n\n\nBoston %&gt;% select(-chas) %&gt;% correlate() %&gt;% plot()\n\nlibrary(corrplot)\ncorrplot(cor(Boston))\ncorrplot.mixed(cor(Boston))"
  },
  {
    "objectID": "docs/Tema05.html#más-herramientas-de-aed-automático",
    "href": "docs/Tema05.html#más-herramientas-de-aed-automático",
    "title": "Tema 05 - Análisis Exploratorio de Datos (AED)",
    "section": "Más herramientas de AED “automático”",
    "text": "Más herramientas de AED “automático”\n\nMuchas partes del AED son parcialmente “automatizables”: muchos paquetes tratan de facilitar esas partes\nRadiant puede instalarse o probarse online\n\nSirve tanto para análisis exploratorio, visualización y transformación como para algunas modelizaciones\n\nAlgunas bibliotecas permiten explorar datos y/o realizar visualizaciones y tableros fácilmente de forma interactiva: GwalkR, explore\n\n\nInformes automatizados con dlookr, DataExplorer, DataMaid, smartEDA\n\n\nlibrary(dlookr)\nBank %&gt;% mutate(across(where(is.character), ~parse_factor(.x))) %&gt;% \n  eda_web_report(target = \"y\")\n\n\nAlgunos componentes del AED y sobre todo la interpretación del AED son específica de los datos y del objetivo del estudio"
  },
  {
    "objectID": "docs/Tema03ej.html",
    "href": "docs/Tema03ej.html",
    "title": "Tema 03. Datos Relacionales. Ejercicio.",
    "section": "",
    "text": "Entrega del ejercicio\nEste ejercicio se realizará en clase y NO cuenta para los alumnos de evaluación NO continua (aunque es recomendable como práctica).\n\n\nPreguntas\nEn este ejercicio vamos a utilizar, por un lado, los datos de este archivo (comprimido) con datos en texto separados por punto y coma con la siguiente información de los empleados de una empresa: el identificador de empleado (ID), sus dos apellidos y su nombre, su género (hombre o mujer) y el valor de las ventas realizadas por dicho empleado en un periodo concreto, dado por año y mes. Por otro lado, disponemos de este archivo Excel con dos hojas: regiones, con la clave de las regiones donde la empresa tiene sedes y el nombre completo de cada región, y regionEmpleado, con el identificador de cada individuo y la región a la que pertenece.\n\nMostrar en una tabla el nombre y apellidos del empleado de cada región con mayores ventas totales en el periodo de tiempo analizado.\n\n\nMostrar el nombre completo de la región con más ventas cada año.\n\n\nMostrar los nombres y apellidos de los empleado “misteriosos”: es decir, aquellos que no sabemos a qué región pertenecen."
  },
  {
    "objectID": "docs/Tema08ej2.html",
    "href": "docs/Tema08ej2.html",
    "title": "Tema 08. Ejercicio 2",
    "section": "",
    "text": "Usamos datos del Censo de EE.UU. con la siguiente información\n\nlibrary(tidyverse)\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;% select(-1) \n\n\n\n\nage\nedad\n\n\nworkclass\ntipo de trabajo del individuo\n\n\nfnlwgt\npeso en el censo (no relevante)\n\n\neducation\nnivel educativo\n\n\neducation_1\naños de educación\n\n\nmarital_status\nestado civil\n\n\noccupation\nprofesión de la persona\n\n\nrelationship\nrelación con el principal miembro del hogar\n\n\nrace\norigen racial de la persona\n\n\nsex\ngénero\n\n\ncapital_gain\nganancias de capital\n\n\ncapital_loss\npérdidas de capital\n\n\nhours_per_week\nhoras trabajadas a la semana\n\n\nnative_country\npaís de origen\n\n\nIncome\nrenta mayor o menor de 50 mil dólares"
  },
  {
    "objectID": "docs/Tema08ej2.html#datos",
    "href": "docs/Tema08ej2.html#datos",
    "title": "Tema 08. Ejercicio 2",
    "section": "",
    "text": "Usamos datos del Censo de EE.UU. con la siguiente información\n\nlibrary(tidyverse)\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;% select(-1) \n\n\n\n\nage\nedad\n\n\nworkclass\ntipo de trabajo del individuo\n\n\nfnlwgt\npeso en el censo (no relevante)\n\n\neducation\nnivel educativo\n\n\neducation_1\naños de educación\n\n\nmarital_status\nestado civil\n\n\noccupation\nprofesión de la persona\n\n\nrelationship\nrelación con el principal miembro del hogar\n\n\nrace\norigen racial de la persona\n\n\nsex\ngénero\n\n\ncapital_gain\nganancias de capital\n\n\ncapital_loss\npérdidas de capital\n\n\nhours_per_week\nhoras trabajadas a la semana\n\n\nnative_country\npaís de origen\n\n\nIncome\nrenta mayor o menor de 50 mil dólares"
  },
  {
    "objectID": "docs/Tema08ej2.html#paso-0-partición-en-entrenamiento-y-prueba",
    "href": "docs/Tema08ej2.html#paso-0-partición-en-entrenamiento-y-prueba",
    "title": "Tema 08. Ejercicio 2",
    "section": "Paso 0: Partición en Entrenamiento y Prueba",
    "text": "Paso 0: Partición en Entrenamiento y Prueba\n\nUsamos initial_split() para generar el objeto que almacena las dos particiones\n\n\nlibrary(tidymodels)\nset.seed(8697)\ncensoPart &lt;- censo %&gt;% initial_split(prop = .8)"
  },
  {
    "objectID": "docs/Tema08ej2.html#paso-1-preparar-los-datos-y-especificación",
    "href": "docs/Tema08ej2.html#paso-1-preparar-los-datos-y-especificación",
    "title": "Tema 08. Ejercicio 2",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\nEn este ejercicio, vamos a considerar modelos de regresión logística y de regresión logística regularizada mediante LASSO. Usaremos la misma especificación inicial en todos los casos: la categoría de renta va a depender de la raza, la edad (un polinomio de grado 6), horas de trabajo (un polinomio de grado 6), el género, la educación (education_1), ganancias de capital, pérdidas de capital, ocupación y estado civil; además, incluiremos interacciones de la raza y el género entre ellas y con el resto de variables.\nEn general, debería justificarse las variables incluidas (p.e., por los resultados del análisis exploratorio) y considerar variantes de las especificaciones (variables incluidas) para el caso de la regresión logística al menos. En el caso de LASSO, esto no es importante porque siempre podemos incluir la especificación más general y el propio algoritmo selecciona las variables a incluir.\nPreparamos las recetas con la especificación para estos modelos. Nota: agrupamos las categorías minoritarias de estado civil, raza y ocupación en una categoría de “Otros” con un umbral (threshold) del 6%.\n\nPara regresión logística:\n\n\nreceta &lt;- censoPart %&gt;% training() %&gt;% \n          recipe(income ~ race + age + hours_per_week + \n                    sex + education_1 + capital_gain + capital_loss + \n                    occupation + marital_status ) %&gt;%\n          step_poly(age, degree = 6) %&gt;%\n          step_poly(hours_per_week, degree = 6) %&gt;%\n          step_other(marital_status, race, occupation, threshold = 0.06) %&gt;%\n          step_dummy(all_nominal(), -all_outcomes()) %&gt;% \n          step_interact(~ starts_with(\"race\"):(starts_with(\"age\") + starts_with(\"hours_per_week\") + \n                    starts_with(\"sex\") + education_1 + capital_gain + capital_loss +\n                    starts_with(\"occupation\") + starts_with(\"marital_status\"))) %&gt;% \n          step_interact(~ starts_with(\"sex\"):(starts_with(\"age\") + starts_with(\"hours_per_week\")+\n                    education_1 + capital_gain + capital_loss +\n                    starts_with(\"occupation\") + starts_with(\"marital_status\")))\n\n\nPara regresión logística regularizada mediante LASSO:\n\n\nrecetaReg &lt;- censoPart %&gt;% training() %&gt;% \n          recipe(income ~ race + age + hours_per_week + \n                    sex + education_1 + capital_gain + capital_loss + \n                    occupation + marital_status ) %&gt;%\n          step_scale(all_predictors(), -all_nominal()) %&gt;%\n          step_poly(age, degree = 6) %&gt;%\n          step_poly(hours_per_week, degree = 6) %&gt;%\n          step_other(marital_status, race, occupation, threshold = 0.06) %&gt;%\n          step_dummy(all_nominal(), -all_outcomes()) %&gt;% \n          step_interact(~ starts_with(\"race\"):(starts_with(\"age\") + starts_with(\"hours_per_week\") + \n                    starts_with(\"sex\") + education_1 + capital_gain + capital_loss +\n                    starts_with(\"occupation\") + starts_with(\"marital_status\"))) %&gt;% \n          step_interact(~ starts_with(\"sex\"):(starts_with(\"age\") + starts_with(\"hours_per_week\")+\n                    education_1 + capital_gain + capital_loss +\n                    starts_with(\"occupation\") + starts_with(\"marital_status\")))\n\n\nPodéis comprobar que nuestro modelo tiene muchas variables, es decir, muchos parámetros:\n\n\nreceta %&gt;% prep() %&gt;% bake(censoPart %&gt;% training()) %&gt;% dim()"
  },
  {
    "objectID": "docs/Tema04ej_123456789.html",
    "href": "docs/Tema04ej_123456789.html",
    "title": "Ejercicio Tema 04",
    "section": "",
    "text": "Este es mi primer documento de Quarto y usando RStudio y R.\n\n\n\n\n\nNotad que podemos cambiar el tamaño (y otras cosas) de la imagen de forma visual.\nRecordad el directorio de trabajo: el documento .Qmd se guarda allí.\nEn el Tema 3, elegí las variables\n\nhc: el (índice de) capital humano por persona, basado en años de educación y rentabilidad de la educación.\nrtfpna: la productividad total de los factores, en precios (nacionales) constantes de 2011"
  },
  {
    "objectID": "docs/Tema04ej_123456789.html#celdas-de-código",
    "href": "docs/Tema04ej_123456789.html#celdas-de-código",
    "title": "Ejercicio Tema 04",
    "section": "Celdas de código",
    "text": "Celdas de código\nMuestra código pero no resultado (porque no lo evalúa)\n\n\nCode\n2+3\nsummary(mtcars)\n\n\nMuestra resultado pero no código\n\n\n[1] 5\n\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\nMuestra ambos (por defecto)\n\n\nCode\n2+3\n\n\n[1] 5\n\n\nCode\nsummary(mtcars)\n\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\nNO quiero que muestre mensajes para evitar “ensuciar” el documento\n\n\nCode\nlibrary(AER)\nlibrary(Hmisc)"
  },
  {
    "objectID": "docs/Tema04ej_123456789.html#evaluando-o-no-evaluando",
    "href": "docs/Tema04ej_123456789.html#evaluando-o-no-evaluando",
    "title": "Ejercicio Tema 04",
    "section": "Evaluando o no evaluando",
    "text": "Evaluando o no evaluando\n\n\nCode\n(a &lt;- 2+3)\nsummary(mtcars$mpg)\n\n\nLa siguiente celda da error si la anterior no se evalúa, por eso cambiamos eval a true\n\n\nCode\nb &lt;- 3 +a\n\n\nOtras opciones (no pedidas). Evaluar pero sin mostar el resultado\n\n\nCode\n(a &lt;- 2+3)\nsummary(mtcars$mpg)\n\n\nNo hay problema con esto\n\n\nCode\nb &lt;- 3 +a\n\n\nY de esta forma\n\n\nCode\n(a &lt;- 2+3)\nsummary(mtcars$mpg)\n\n\ntampoco hay problema con esto\n\n\nCode\nb &lt;- 3 +a\n\n\nNotar el efecto de retener (hold) los resultados\n\n\nCode\n(a &lt;- 2+3)\nsummary(mtcars$mpg)"
  },
  {
    "objectID": "docs/Tema04ej_123456789.html#mostrar-un-conjunto-de-datos-y-su-resumen",
    "href": "docs/Tema04ej_123456789.html#mostrar-un-conjunto-de-datos-y-su-resumen",
    "title": "Ejercicio Tema 04",
    "section": "Mostrar un conjunto de datos y su resumen",
    "text": "Mostrar un conjunto de datos y su resumen\n\nCode\nmtcars\n\n\n  \n\n\nCode\nsummary(mtcars)\n\n  mpg             cyl             disp             hp       \nMin. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0\n1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5\nMedian :19.20 Median :6.000 Median :196.3 Median :123.0\nMean :20.09 Mean :6.188 Mean :230.7 Mean :146.7\n3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0\nMax. :33.90 Max. :8.000 Max. :472.0 Max. :335.0\ndrat wt qsec vs\nMin. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000\n1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000\nMedian :3.695 Median :3.325 Median :17.71 Median :0.0000\nMean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375\n3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000\nMax. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000\nam gear carb\nMin. :0.0000 Min. :3.000 Min. :1.000\n1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000\nMedian :0.0000 Median :4.000 Median :2.000\nMean :0.4062 Mean :3.688 Mean :2.812\n3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000\nMax. :1.0000 Max. :5.000 Max. :8.000"
  },
  {
    "objectID": "docs/Tema04ej_123456789.html#mostrarlas-con-kableextra",
    "href": "docs/Tema04ej_123456789.html#mostrarlas-con-kableextra",
    "title": "Ejercicio Tema 04",
    "section": "Mostrarlas con kableExtra()",
    "text": "Mostrarlas con kableExtra()\n\nCode\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nCode\nmtcars %&gt;% kbl()  %&gt;%\n  kable_styling()\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\n\nCode\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_styling()\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n\nMin. :10.40\nMin. :4.000\nMin. : 71.1\nMin. : 52.0\nMin. :2.760\nMin. :1.513\nMin. :14.50\nMin. :0.0000\nMin. :0.0000\nMin. :3.000\nMin. :1.000\n\n\n\n1st Qu.:15.43\n1st Qu.:4.000\n1st Qu.:120.8\n1st Qu.: 96.5\n1st Qu.:3.080\n1st Qu.:2.581\n1st Qu.:16.89\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:3.000\n1st Qu.:2.000\n\n\n\nMedian :19.20\nMedian :6.000\nMedian :196.3\nMedian :123.0\nMedian :3.695\nMedian :3.325\nMedian :17.71\nMedian :0.0000\nMedian :0.0000\nMedian :4.000\nMedian :2.000\n\n\n\nMean :20.09\nMean :6.188\nMean :230.7\nMean :146.7\nMean :3.597\nMean :3.217\nMean :17.85\nMean :0.4375\nMean :0.4062\nMean :3.688\nMean :2.812\n\n\n\n3rd Qu.:22.80\n3rd Qu.:8.000\n3rd Qu.:326.0\n3rd Qu.:180.0\n3rd Qu.:3.920\n3rd Qu.:3.610\n3rd Qu.:18.90\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:4.000\n3rd Qu.:4.000\n\n\n\nMax. :33.90\nMax. :8.000\nMax. :472.0\nMax. :335.0\nMax. :4.930\nMax. :5.424\nMax. :22.90\nMax. :1.0000\nMax. :1.0000\nMax. :5.000\nMax. :8.000\n\n\n\n\n\n\nCode\nmtcars %&gt;% kbl()  %&gt;%\n  kable_classic(full_width = F)\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\n\nCode\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_minimal()\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\n\nMin. :10.40\nMin. :4.000\nMin. : 71.1\nMin. : 52.0\nMin. :2.760\nMin. :1.513\nMin. :14.50\nMin. :0.0000\nMin. :0.0000\nMin. :3.000\nMin. :1.000\n\n\n\n1st Qu.:15.43\n1st Qu.:4.000\n1st Qu.:120.8\n1st Qu.: 96.5\n1st Qu.:3.080\n1st Qu.:2.581\n1st Qu.:16.89\n1st Qu.:0.0000\n1st Qu.:0.0000\n1st Qu.:3.000\n1st Qu.:2.000\n\n\n\nMedian :19.20\nMedian :6.000\nMedian :196.3\nMedian :123.0\nMedian :3.695\nMedian :3.325\nMedian :17.71\nMedian :0.0000\nMedian :0.0000\nMedian :4.000\nMedian :2.000\n\n\n\nMean :20.09\nMean :6.188\nMean :230.7\nMean :146.7\nMean :3.597\nMean :3.217\nMean :17.85\nMean :0.4375\nMean :0.4062\nMean :3.688\nMean :2.812\n\n\n\n3rd Qu.:22.80\n3rd Qu.:8.000\n3rd Qu.:326.0\n3rd Qu.:180.0\n3rd Qu.:3.920\n3rd Qu.:3.610\n3rd Qu.:18.90\n3rd Qu.:1.0000\n3rd Qu.:1.0000\n3rd Qu.:4.000\n3rd Qu.:4.000\n\n\n\nMax. :33.90\nMax. :8.000\nMax. :472.0\nMax. :335.0\nMax. :4.930\nMax. :5.424\nMax. :22.90\nMax. :1.0000\nMax. :1.0000\nMax. :5.000\nMax. :8.000\n\n\n\n\n\nLa presentación es más elegante en el segundo caso"
  },
  {
    "objectID": "docs/Tema00.html#introducción",
    "href": "docs/Tema00.html#introducción",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Introducción",
    "text": "Introducción\n\nDebéis tener instalados los programas gratuitos R y RStudio\nNos familiarizaremos con los conceptos y comandos básicos de programación en R\nR es un lenguaje interpretado: ejecuta las instrucciones directamente en la consola\n\n\nRStudio es un entorno de desarrollo integrado (IDE) que combina varias herramientas para facilitar el uso de R: consola, editor para escribir comandos, ayuda, etc.\n\n\n\nUn editor de texto NO es un procesador de texto (como Word): solo importa el texto sin formato (negrita, etc.)"
  },
  {
    "objectID": "docs/Tema00.html#r-studio",
    "href": "docs/Tema00.html#r-studio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "R Studio",
    "text": "R Studio"
  },
  {
    "objectID": "docs/Tema00.html#empezando-con-r",
    "href": "docs/Tema00.html#empezando-con-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Empezando con R",
    "text": "Empezando con R\n\nEscribimos comandos en la consola y se ejecutan pulsando Enter:\n\nLa tecla de tabulador  ofrece opciones de autocompletado\nEjecutar algo que no es un comando de R devuelve un error\n\n\n\n2 + 2\n3 * (1 - 4)^2\nsqrt(log(5/2))\npi\nhola\n\n\n\nOperadores aritméticos habituales: +,-,*,/, %/%, %%\nFunciones o constantes incorporadas: log, sqrt, abs, exp, round, pi\n\nabs(-5)\n9 %/% 4\n9 %% 4\n\nSi intentamos evaluar algo que NO es un comando de R o no está correctamente escrito, tendremos un ERROR\nEs NORMAL cometer errores\n\n\n\nO en el Editor de RStudio y se envían a la consola la o las líneas seleccionadas para ser evaluadas con el icono  o con el atajo de teclado Ctrl+Enter\nNOTA: en MacOS, usad la tecla Command en lugar de Ctrl"
  },
  {
    "objectID": "docs/Tema00.html#archivos-de-guion-scripts",
    "href": "docs/Tema00.html#archivos-de-guion-scripts",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Archivos de guion (“scripts”)",
    "text": "Archivos de guion (“scripts”)\n\nEs preferible incluir varios comandos en un archivo de texto para ejecutarlos\nSe puede replicar el proceso de cálculos paso a paso (no como Excel) \nCreamos un nuevo archivo con el icono  o en el menú File &gt; New File &gt; R script (atajo Ctrl + Mays + N)\nGuardamos el archivo con  o en File &gt; Save (atajo Ctrl + S), eligiendo un directorio y nombre de extensión “.R” (por defecto) o “.r”\nEn un archivo de guion (guardado), RStudio marca las líneas con error y muestra el mensaje de error al pasar el puntero"
  },
  {
    "objectID": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "href": "docs/Tema00.html#trabajar-con-ficheros-de-guion",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Trabajar con ficheros de guion",
    "text": "Trabajar con ficheros de guion\n\nCada comando es “una” línea y se ejecutan secuencialmente\nUn comando se puede extender visualmente más de una línea hasta completarse: p.e., hasta cerrar los paréntesis.\n\nEscribimos log(, en otra línea 9 y ejecutamos: la consola cambia de &gt; a + \nNo hace “nada” esperando que completemos el comando.\n\n\n\n\nNO LO VEREMOS: se pueden incluir más de un comando por línea, separados por “;”, pero el código es menos legible\nPodemos ejecutar todo el archivo:\n\nseleccionando todas las líneas Ctrl + A y luego \n\n\n\nusando  con “echo” o sin “echo” (no muestra resultados en consola)\n\nEn ambos casos, se para la ejecución cuando encuentra error\n\n\n\n\nEl carácter # marca el inicio de un comentario: lo que sigue se “ignora” (no se ejecuta) en R\n\n\n# Pueden ir al principio de la línea \n2 + 2 # o después de una instrucción\n\n\nComentar es un buen hábito: ayuda a entender/recordar qué hacemos\nNotad que RStudio tiene resaltado de sintaxis: distinto color para comentarios, números, funciones, etc."
  },
  {
    "objectID": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "href": "docs/Tema00.html#directorio-de-trabajo.-proyectos.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Directorio de Trabajo. Proyectos.",
    "text": "Directorio de Trabajo. Proyectos.\n\nConviene organizar los archivos relacionados con un mismo tema en una estructura de (sub)directorios a partir de un directorio de trabajo principal \n\n\nRStudio permite definir proyectos para gestionarlo fácilmente a través del menú File o desplegando el icono en la parte superior derecha \n\n\n\nPara conocer el directorio de trabajo actual\n\n\ngetwd()\n\n\nInicialmente el directorio de trabajo es el directorio por defecto del usuario del SO (“~”), donde “/” es el separador de directorios\n\nen Windows: C:/Users/nombre/Documents\nen MacOS: /Users/nombre\nen Linux: /home/nombre\n\n\n\nWindows usa la barra invertida “\\” (‘backward slash’ en lugar de ‘forward slash’) como separador de directorio en una ruta\n\n\nPERO “\\” tiene una función “especial” para cadenas de caracteres en programación: denotar caracteres especiales (“escapar”)\n\n\nSi “insistimos” en usarla, será su versión “escapada”: (C:\\\\Usuarios\\\\nombre\\\\Mis Documentos)\nEn el explorador de archivos (de Windows y de MacOS) la ruta “~” está en castellano (p.e., C:\\Usuarios\\nombre\\Documentos), pero internamente en inglés\n\n\n\nDesde el menú File &gt; New Proyect o desde el icono, creamos un nuevo proyecto:\n\nPodemos usar un Nuevo Directorio o elegir una ubicación ya existente\nEl nombre del proyecto será el nombre del directorio\nTambién se crea un archivo con el mismo nombre y extensión “.Rproj”\n\nAl abrir RStudio, tenemos activo el último proyecto abierto: ej., \nTanto desde el menú como desde el icono de gestión de proyectos, podemos\n\ncerrar el proyecto actual, File &gt; Close Projects,\nabrir otros proyectos guardados: File &gt; Open Project o File &gt; Recent Projects"
  },
  {
    "objectID": "docs/Tema00.html#proyectos-cont.",
    "href": "docs/Tema00.html#proyectos-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Proyectos (cont.)",
    "text": "Proyectos (cont.)\n\nPara trabajar con un archivo, usamos la ruta relativa al directorio de trabajo:\n\nsi están en el raíz del directorio: codigo.R, misdatos.Rdata\nsi están en un subdirectorio, indicamos la ruta separando directorios por /: datos/ventas.Rdata, datos/ano2020/ingresos.Rdata\n\nLa pestaña  en el cuadrante inferior-derecho ofrece una forma visual de abrir, crear, copiar, mover o eliminar archivos o directorios, etc.\n\n\nEvitad caracteres “raros” (acentos, espacios, etc.) en directorios y ficheros\nNOTA. El Explorador de Archivos de Windows y Finder de MacOS, no muestran defecto las extensiones de los archivos.\n\nPuede ser confuso para distinguir entre dos archivos con el mismo nombre y diferente extensión: proyecto.R y proyecto.Rproj\nConsultad cómo mostrarlas: p.e., para Windows y MacOS"
  },
  {
    "objectID": "docs/Tema00.html#funciones-en-r",
    "href": "docs/Tema00.html#funciones-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Funciones en R",
    "text": "Funciones en R\n\nLas expresiones que aceptan argumentos se denominan funciones.\n\n\nexp(2)\nceiling(5.2)\n\n\n\n\n\nAlgunos argumentos son obligatorios, otros tienen valores por defecto que se pueden omitir\nLos argumentos se pueden especificar por nombre o por orden.\n\n\nlog(2, base=2)\nlog(2, 10)\nlog(base = 10, x = 2)\n\n\n¿Cómo sabemos la manera de usar una función (ej. argumentos necesarios) o comando de R?\n\n\n\nNO omitir los argumentos tiene ventajas\n\nClaridad\nLos argumentos no tienen que especificarse en orden (sin nombre del argumento debe seguirse el orden establecido)"
  },
  {
    "objectID": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "href": "docs/Tema00.html#ayuda-en-r-y-rstudio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Ayuda en R y RStudio",
    "text": "Ayuda en R y RStudio\n\nRStudio tiene autocompletado y ayuda flotante para funciones y otros elementos de R\n\nP.e., si empezamos a escribir la función log, se muestra la forma esperada de trabajar con esa función\n\nRStudio también tiene una pestaña para buscar ayuda\n\n\nLas búsquedas online o las IAs (como chatGPT, Gemini o Copilot) pueden ser útiles.\nPERO debemos tener un conocimiento mínimo para aprovechar realmente una solución\n\nhay muchas formas de hacer lo mismo en R: una respuesta correcta puede no ajustarse a lo que ya sabemos\n\nNO uséis copiar-pegar sin entender el código: copiar-pensar-adaptar\n\n\n\nSe puede usar ?? para buscar ayuda en la consola sobre algo de lo que se desconoce el nombre concreto de la función\n\n\nNO siempre estará la solución exacta a nuestro problema\nLas soluciones pueden utilizar enfoques que requieren conocer comandos de extensiones (bibliotecas) de R"
  },
  {
    "objectID": "docs/Tema00.html#el-operador-de-asignación",
    "href": "docs/Tema00.html#el-operador-de-asignación",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El operador de asignación",
    "text": "El operador de asignación\n\nEl operador &lt;- almacena un contenido en un objeto con un nombre,1 que incluye letras, números y algunos carácteres especiales (“.”, “_”)\n\n\n\nalt - = &lt;-\nUn objeto es simplemente algo almacenado en la memoria de R\nImportante: recordar almacenar nuestros cálculos y resultados en objetos para poder reutilizarlos.\n\na menudo no es “recomendado”, es una necesidad\n\n\n\n\nx &lt;- 2*3    # asignación, no muestra resultado\nx           # ejecutamos mostrar la variable   \nprint(x)\n(x &lt;- 2)    # asignación e impresión a la vez\n\n\nR es “case-sensitive”: x y X son dos objetos distintos\nLos objetos asignados pueden usarse posteriormente, p.e., para generar otros a partir de ellos\n\n\ny &lt;- x + 5  # asignamos y a partir del VALOR de x\n(x &lt;- x*3)  # re-asignamos x a partir de ella misma\ny           # NO cambia (en Excel, sí)\n\n\n\nSe prefiere &lt;- para diferenciar asignación de objetos (NO solo asignaremos números) del concepto de igualdad matemática\nY se evita la confusión con = usado para dar valores a un argumento, log(2, base=10), y con la igualdad en comparaciones (==)\nTambién se puede mostrar con print(x) o con show(x)\nUn error habitual: object not found. Porque hemos creado x y luego queremos usar X…\nCuando se asigna a partir del objeto x, en la expresión aparece el contenido x en ese momento (no x propiamente dicho)\nEn Excel, si cambia un valor en una celda, cambian aquellas que la referencian.\n\n\nTambién se puede asignar con ="
  },
  {
    "objectID": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "href": "docs/Tema00.html#el-espacio-de-trabajo-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "El Espacio de Trabajo en R ",
    "text": "El Espacio de Trabajo en R \n\nEl espacio de trabajo es el conjunto de objetos activos en memoria, resultado de todos los comandos ejecutados previamente\nEn RStudio, la pestaña  muestra los objetos y su valor\nLas funciones ls() y rm() muestran y eliminan respectivamente objetos del espacio de trabajo\n\n\n\n\n\nBorramos todos los objetos con  en el Environment o el comando\n\n\nrm( list=ls() )  # eliminar todos los objetos\nrm(y, x)         # eliminar solo algunos objetos\n\n\nGuardamos el contenido del entorno de trabajo con  (o al cerrar RStudio), pero es innecesario: ejecutando los comandos guardados en un archivo .R recuperamos los objetos\n\n\n\nNotar que el Environment también tiene una pestaña de History con todos los comandos ejecutados durante la sesión.\nVeremos cómo guardar datos en R con más detalle"
  },
  {
    "objectID": "docs/Tema00.html#mensajes-de-error-y-warning",
    "href": "docs/Tema00.html#mensajes-de-error-y-warning",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Mensajes de “Error” y “Warning”",
    "text": "Mensajes de “Error” y “Warning”\n\nEn programación, cometer errores es normal\nEn muchos errores, R se “quejará” mostrando mensajes en rojo\n\nAviso: R ofrece un resultado (y continuará al siguiente comando), PERO indica que puede haber algo “no deseado”\nError: para la ejecución, sin resultado, e “informa” de la razón\n\nAlgunos mensajes son claros, pero otros requieren más investigación\n\n\nPeor que un mensaje de error: escribimos (copiamos) un código que funciona pero no hace lo que queremos…\nEl ordenador NO se equivoca: hace lo que le pedimos según unas reglas bien definidas por R, que debemos conocer\n\nSed cuidadosos, pensad y entended cada paso del código \n\n\n\n\nAlgunos mensajes son intimidantes (en rojo!) … e indescifrables\nAviso: “He hecho lo que he podido para entender lo que pides (log. de un número negativo!), pero a lo mejor no es lo que quieres”\nConocer las “reglas” es saber programar (hablar) en ese lenguaje\nComo toda convención, algunas reglas de R pueden ser “arbitrarias”\n\np.e., log(-1) podría ser error y seq(from = 10, to = 2, by = 1) interpretado como una cuenta atrás\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y =="
  },
  {
    "objectID": "docs/Tema00.html#tipos-de-objetos-en-r",
    "href": "docs/Tema00.html#tipos-de-objetos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Tipos de Objetos en R",
    "text": "Tipos de Objetos en R\n\nTODO en R es un objeto, cada uno con distintas propiedades y, por tanto, distintas formas de trabajar con él\n\n\n\nR es un lenguaje orientado a objetos\n\n\n\nAdemás de las funciones, los principales objetos con los que trabajaremos son:\n\nvectores\nfactores\nconjuntos de datos (“data frames”)\nlistas\n\nEstos objetos pueden contener varios tipos de datos o variables:\n\nentero\nnumérico (números reales) \nlógico (valores verdadero/falso)\ncaracteres"
  },
  {
    "objectID": "docs/Tema00.html#vectores",
    "href": "docs/Tema00.html#vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores",
    "text": "Vectores\n\nUn vector es una secuencia de datos elementales, creados con el operador “c()” (combinar)\n\n\nx &lt;- c(2.5,-4.1,6.4,8.2)           # vector numérico\ny &lt;- c(3,0,-1,2)                   # vector de enteros\nw &lt;- c(\"hola\", 'adios')            # vector de caracteres \nz &lt;- c(FALSE, TRUE, T, F)          # vector lógico\n\n\n\nLos caracteres puede ir entre comillas simples ` o dobles \"\nT y F atajo para TRUE y FALSE\n\n\n\nPodemos crear vectores a partir de otros vectores o usando comandos\n\n\nz &lt;- c(x, y)\nx &lt;- rep(1, times=4)\ny &lt;- seq(from = 10, to = 1, by = -1)\nz &lt;- 1:10       # equivale a z &lt;- seq(1,10,1)\n\n\nUn vector sólo puede contener objetos de un único tipo elemental, que podemos conocer en el Environment o con str()"
  },
  {
    "objectID": "docs/Tema00.html#vectores-cont.",
    "href": "docs/Tema00.html#vectores-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores (cont.)",
    "text": "Vectores (cont.)\n\nSi se mezclan tipos distintos, R busca una clase que “acomode” a todos\n\n\nvcr &lt;- c(\"lunes\", 2) \n\n\nForzamos que un objeto sea tratado con una clase concreta, con as.integer(), as.numeric(), as.character() y as.logical()\n\nSi no se puede convertir a número, devuelve NA (con un “warning”)\n\n\n\n\n“lunes” no puede ser un número pero “2” sí se puede representar como carácter\n\nel carácter “2” NO es lo mismo que el número 2: no se pueden hacer operaciones matemáticas\n\nLas funciones is.numeric(), is.numeric(), is.logical() e is.character() comprueban si un objeto es del tipo indicado, devolviendo un valor lógico.\nDebemos diferenciar entre la clase de un objeto y como se muestra (formatea): ver la función format()\n\n\n\nNO se pueden realizar operaciones incompatibles entre clases\n\nCuidado con las comillas: NO es lo mismo un objeto (su contenido) que el carácter de su nombre\n\n\n\na &lt;- 4\nc &lt;- 'a' + 1\n\n\n\nLa clase de un objeto es única (solo un tipo de elementales) y puede conocerse en el Environment o con str()\n\n\nstr(y)\n\n\ncon class()\nTambién se puede conocer la clase/modo con is() o mode()\n\n\nstr() sirve para cualquier tipo de objeto: p.e., funciones: str(log)\n\n\n\nLos vectores pueden tener nombres (una “etiqueta” única para cada elemento): un vector de caracteres de la misma longitud asignado con names()\n\n\n\nLos nombres de un vector son un vector de caracteres de la misma longitud\n\n\naltura &lt;- c(176, 165, 189, 155, 168)\naltura\nnames(altura) &lt;- c(\"Jose\", \"Maria\", \"Juan\", \"Elena\", \"Rosa\")\nnames(altura)\naltura\n\n\n\n\nObviamente podemos asignar el vector creándolo con c() o a partir de un vector existente\nNotad cómo cambian las propiedades (cómo se ve el vector) tras aplicarle un nombre"
  },
  {
    "objectID": "docs/Tema00.html#aritmética-de-vectores",
    "href": "docs/Tema00.html#aritmética-de-vectores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Aritmética de vectores",
    "text": "Aritmética de vectores\n\nLa mayoría de los operadores se aplican elemento-a-elemento\n\n\n\n\na &lt;- seq(1,3,1)\nb &lt;- seq(6,8,1)\n\n\n\n\n\na+b\na*b\n\n\n\nCon diferentes longitudes, se repite el vector corto cuanto sea necesario\n\n\n\n\nb &lt;- 6:9\na + b\na + 1  # lo que queremos!\n\n\n\n\n\n\n\nAlgunas funciones relevantes\n\n\n\n\n\nlength(x)   # longitud\nsort(x)     # ordenar\nmax(x)      # máximo\nmin(x)      # mínimos\nsum(x)      # suma \nprod(x)     # producto \n\n\n\n\n\nmean(x)     # media \nvar(x)      # varianza\ntable(x)    # frecuencias\n\nsummary(x)  # estadísticos \n\n\n\n\nEs MUY CONVENIENTE revisar cuidadosamente las dimensiones de los vectores antes de una operación, aunque R va a proceder de una forma bien definida…"
  },
  {
    "objectID": "docs/Tema00.html#vectores-lógicos",
    "href": "docs/Tema00.html#vectores-lógicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Vectores lógicos",
    "text": "Vectores lógicos\n\nObtenemos un objeto lógico enunciando una relación que puede ser cierta o falsa , como comparaciones básicas de igualdad o desigualdad\n\n\n\n\n1 == 1  # TRUE\n1 != 3  # TRUE\n1 &gt; 2   # FALSE\n\n\n\n\n\na &lt;- 3 \na &gt;= 3       # TRUE\na + 1 &lt;= 10  # FALSE\n\n\n\nCombinamos varios enunciados con operadores Y (&), O (|) y NO (!)\n\n\nPara conjuntos, x %in% Y es cierto cuando x es un elemento de Y\n\n\n\nNotad la doble igualdad == para el operador lógico de igualdad\nNuevamente podemos confundir los objetos hola y adios con sus caracteres\n\n\n\naltura &lt;- c(176, 165, 189, 155, 168)\n\naltura &gt;= c(175, 165, 195, 165, 168)  # elemento a elemento\naltura == 155                         # elemento a elemento\naltura &gt; 160 & altura &lt;= 180\naltura &lt; 160 | altura &gt;= 180\nc(165,179) %in% altura\ncondicion &lt;- !(altura &lt;= 170)\n\n\n\nR ha ejecutado lo que le decimos, cumpliendo sus reglas:\n\nel argumento from se puede omitir\ntodo en R es un objeto: podemos pasar al argumento from un número o un objeto que contenga un número\npasamos un objeto lógico (from == 1) y lo convierte a la clase esperada, entero\n\nPor eso es importante la diferencia entre &lt;-, = y ==\naprender lógico para selección: paro de hombre,paro de hombre jovenes\ncondiciones compuesta: venta media de hombres de valencia y alicante en realidad es un enunciado formal con OR\n(recordad que esto también pasaba en gretl y en general aprender lógica)"
  },
  {
    "objectID": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "href": "docs/Tema00.html#acceso-a-los-elementos-de-un-vector",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Acceso a los elementos de un vector",
    "text": "Acceso a los elementos de un vector\n\nSe utiliza el operador [] (paréntesis cuadrado)1 y\n\n\n\nCon [[ ]] se enfatiza acceso a un elemento: esto es importante en otros objetos (listas, datos) pero no en vectores (ambas formas son equivalentes)\n\n\n\nPosiciones de los elementos, usando un vector de enteros\n\n\naltura[3]\naltura[c(1,3,5)]\n\n\nCon enteros negativos, indicamos posiciones que NO queremos\n\n\naltura[-c(2,4)] \n\n\n\nimporta el orden de las posiciones: altura[c(3,1)] frente altura[c(1,3)]\n\n\n\nCondición que satisfacen los elementos, usando un vector lógico\n\n\naltura[altura &gt; 180 | altura &lt; 160]\n\n\n(Si lo tienen) Nombres de los elementos, usando un vector de caracteres\n\n\n\nerror por comillas se puede hablar diferencias de altura[pos] y altura[“pos”] y altura[“Juan”]: confusió de comillas y diferencia entre objeto y caracter de nombre de objeto\nLa función which() también puede ser útil para posiciones lógicas\n\n\n\n\nLos vectores de selección pueden ser un objeto previamente asignado en los tres casos; p.e.,\n\n\npos &lt;- (altura &gt; 180 | altura &lt; 160)\naltura[pos]\n\n\nPodemos seleccionar un subconjunto del vector para trabajar con él\n\n\nalturaExtremo &lt;- altura[pos]\nmean(alturaExtremo)\n\n\nCon la asignación se pueden cambiar elementos específicos de un vector (o añadir nuevos)\n\n\naltura[3] &lt;- 196\n\naltura[c(\"María\", \"Luis\")] &lt;- c(169, 175)\n\n\nTambién con [[ ]]"
  },
  {
    "objectID": "docs/Tema00.html#factores",
    "href": "docs/Tema00.html#factores",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Factores",
    "text": "Factores\n\nLa información cualitativa se suele codificar como texto o números, pero NO tiene sentido numérico (ni de “texto”): representan clases o categorías\n\n\nPara destacar la naturaleza distinta de estos datos, existe un tipo de objeto específico en R: los factores\nAdemás de otras ventajas que veremos, permiten separar la representación original de las categorías (niveles) de cómo queremos mostrarlas (etiquetas)\n\n\ngenero   &lt;- c(2, 1, 2, 2, 2)\ngenero_f &lt;- factor(genero, levels = c(1, 2), \n                           labels = c(\"Mujer\", \"Hombre\"))\n\n\nSe asocia nivel 1 con “Mujer”, 2 con “Hombre”, etc.\nLas operaciones con factores se realiza con las etiquetas, no con los niveles\n\n\ngenero_f == 1       # NO existe valor 1\ngenero_f == \"Mujer\"\n\n\n\nNotar que el comando factor() se extiende en el editor en varias lineas (no es “una” línea por comando)\nEn la consola, se indica que sigue siendo el mismo comando en múltiples líneas con + en lugar de &gt;"
  },
  {
    "objectID": "docs/Tema00.html#factores-cont.",
    "href": "docs/Tema00.html#factores-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Factores (cont.)",
    "text": "Factores (cont.)\n\nTambién podemos usar as.factor() para convertir un vector en un factor\nPERO es conveniente especificar los niveles y las categorías porque si no, R los asigna alfabéticamente\n\n\ng &lt;- factor(genero)  # as.factor(genero) hace lo mismo\ng\n\n\nEn este caso la etiqueta del primer nivel encontrado en los datos (el número 2) es “1” y la del siguiente nivel (el número 1) es “2”\nTambién podemos tener factores con orden con la opción order = TRUE y enumerando los niveles en orden\n\n\nsatisf   &lt;- c(\"A\", \"B\", \"A\", \"B\", \"M\")\nsatisf_f &lt;- factor(satisf, order = TRUE, \n                    levels = c(\"B\", \"M\", \"A\"),\n                    labels = c(\"Bajo\", \"Medio\", \"Alto\"))\n\n\n\nSi etiquetas y niveles coinciden, no es necesario especificarlos\n\n\nsatisf   &lt;- c(\"Alto\", \"Bajo\", \"Alto\", \"Bajo\", \"Medio\")\nsatisf_f &lt;- factor(satisf, order = TRUE,\n                        levels = c(\"Bajo\", \"Medio\", \"Alto\"))"
  },
  {
    "objectID": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "href": "docs/Tema00.html#resumiendo-un-vector-numérico-o-un-factor",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Resumiendo” un vector numérico o un factor",
    "text": "“Resumiendo” un vector numérico o un factor\n\nLa función summary() devuelve los principales estadísticos descriptivos de un vector numérico\n\n\nsummary(altura)\n\n\n\nEl “resultado” de summary() también es un objeto de R: se puede asignar y trabajar con él\n\na &lt;- summary(altura)\nstr(a)\na[1:2]\n\n\nPara información cualitativa, la media y otros estadísticos no tienen sentido\n\n\nsummary(genero)\ngenero  &lt;- c(1, 20, 20, 1, 1)  # dos categorías igualmente\nsummary(genero)\n\n\nLa función summary() ofrece resultados diferentes según el tipo de objeto (porque tiene distintas propiedades)\n\n\nsummary(genero_f)\n\n\n: # - Se pueden crear con matrix(), a partir de un vector con todos los valores,  rellenando por []: # columnas (argumentobyrow = FALSE) y conocemos su dimensión condim()--&gt; []: #  []: # ```{r} []: # #| echo: false []: # matrx &lt;- matrix(data = c(100, 60, 55, 75, 110, 85), nrow = 2) []: # dim(matrx) []: # ``` []: #  []: # -  Se pueden crear conmatrix()o &lt;!--También se crear --&gt;uniendo vectores filas o vectores []: # columnas (de las mismas dimensiones) concbind()yrbind()[]: #  []: # :::: {.columns} []: #  []: # ::: {.column width=\"40%\"} []: #  []: #  []: # ```{r} []: # r1 &lt;- 1:4 []: # r2 &lt;- c(4, 8, 5, 10) []: # M1 &lt;- rbind(r1, r2) []: # ``` []: #  []: # :::  []: #  []: # ::: {.column width=\"5%\"} []: #  []: # ::: []: #  []: # ::: {.column width=\"45%\"} []: #  []: # ```{r} []: # c1 &lt;- 11:12 []: # c2 &lt;- 25:26 []: # c3 &lt;- c(14, 25) []: # M2 &lt;- cbind(c1, c2, c3) []: # ``` []: #  []: # ::: []: #  []: # :::: []: #  []: # * Podemos usarlos para añadir nuevas filas, columnas u otra matriz []: #  []: # ```{r} []: # #| echo: false []: # #| eval: false []: # M1 &lt;- cbind(matrx, c(90,95))           []: # M2 &lt;- rbind(matrx, c(40, -20, 25))     []: #  []: # A &lt;- cbind(c(40,30), c(70, 75)) []: # cbind(M1, A) []: #  []: # B &lt;- cbind(c(40, 2), c(-20, 1), c(25, 1)) []: # rbind(matrx, B) []: # ``` []: #  []: # ::: {.notes} []: # + Si no tienen dimensiones compatibles, R repetirá (como ya vimos en aritmética de vectores) []: #  []: #M1 &lt;- cbind(matrx, c(90,95))[]: #  []: #M2 &lt;- rbind(matrx, c(40, -20, 25))[]: #  []: #  []: #A &lt;- cbind(c(40,30), c(70, 75))[]: #  []: #cbind(M1, A)[]: #  []: #  []: #B &lt;- cbind(c(40, 2), c(-20, 1), c(25, 1))[]: #  []: #rbind(matrx, B)[]: #  []: # ::: []: #  []: # -   Podemos dar nombres a columnas y filas  []: #  []: # ```{r} []: # colnames(M2) &lt;- c(\"ene\", \"feb\", \"mar\") []: # rownames(M2) &lt;- c(\"gast\", \"ingr\") []: # ``` []: #  []: #  []: # ## Matrices (cont.) []: #  []: # &lt;!-- -   Podemos dar nombres a columnas y filas --&gt; []: #  []: # ```{r} []: # #| echo: false []: # colnames(M2) &lt;- c(\"ene\", \"feb\", \"mar\") []: # rownames(M2) &lt;- c(\"gast\", \"ingr\") []: # ``` []: #  []: # ::: {.notes} []: # -   Notad que NO podemos usar la funciónnames()vista anteriormente []: #     porque solo aplica a vectores []: #  []: # -  También se puede especificar los nombres al crear con matrix con argumentodimnames[]: #  []: #meses &lt;- c(“ene”, “feb”, “mar”)[]: #  []: #matrx &lt;- matrix(data = c(100, 60, 55, 75, 110, 85), []: #  []: # nrow = 2,dimnames=list(c(“gast”, “ingr”), meses))[]: # ::: []: #  []: # -   Usamos los paréntesis cuadrados para acceder a los elementos (o una sub-matriz) por posición, []: # nombre o condición lógica []: #  []: #  []: # ```{r} []: # #| echo: false []: # M2[4]   # posición total []: # M2[[4]]  []: # ``` []: #  []: #  []: #  []: # ```{r} []: # #| echo: false []: # M2[1,3]                  []: # M2[\"ingr\", \"ene\"]       []: # M2[c(1:2),c(1,3)] []: # ``` []: #  []: #  []: # :::: {.columns} []: #  []: # ::: {.column width=\"40%\"} []: #  []: #  []: # ```{r} []: # M2[1,3]                  []: # M2[\"ingr\", \"ene\"]       []: # M2[c(1:2),c(1,3)] []: # ``` []: #  []: # :::  []: #  []: # ::: {.column width=\"5%\"} []: #  []: # ::: []: #  []: # ::: {.column width=\"45%\"} []: #  []: # ```{r} []: # M2[2,]      # fila entera []: # M2[,\"feb\"]  # columna entera []: #  []: # ``` []: #  []: # ::: []: #  []: # :::: []: #  []: #  []: # ::: {.notes} []: #  []: # + Notad que en matrices tiene más sentido el doble paréntesis cuadrado[](debería preferirse []: # para acceder a un elemento por su posición sobre el total) []: #  []: # ::: []: #  []: # &lt;!-- []: # -   También se pueden extraer filas o columnas enteras []: # --&gt; []: #  []: # ```{r} []: # #| echo: false []: # M2[2,]      # por posición []: # M2[,\"feb\"]  # por nombre []: # ``` []: #  []: # &lt;!-- []: # ## Aritmética de Matrices  []: # --&gt; []: #  []: # -   Las operaciones habituales son elemento a elemento: la matrices deben tener las mismas []: # dimensiones (o R repetirá elementos) []: #  []: #  []: #  []: # :::: {.columns} []: #  []: # ::: {.column width=\"40%\"} []: #  []: #  []: # ```{r} []: # matrx + M2 []: # matrx * M2 []: # ``` []: #  []: # :::  []: #  []: # ::: {.column width=\"5%\"} []: #  []: # ::: []: #  []: # ::: {.column width=\"45%\"} []: #  []: # ```{r} []: # #| echo: false []: # matrx - 3 []: # matrx * 10  []: # matrx / 2 []: # ``` []: #  []: #  []: # ```{r} []: # matrx - 3 []: # matrx * 10  []: # ``` []: #  []: # ::: []: #  []: # :::: []: #  []: #  []: # ::: {.notes} []: #  []: # * Como en el caso de vectores, si las dimensiones no son iguales, se repiten elementos []: #  []: # * En las operaciones con escalares , realmente se han \"expandido\" los escalares a una matriz de []: # dimensiones equivalentes (una matriz con todos los elementos iguales al escalar) []: #  []: #  []: # ::: []: #  []: # -   Se pueden hacer todo tipo [operaciones matriciales con []: #     R](http://www.statmethods.net/advstats/matrix.html) como multiplicación matricial,%*%, []: # transponer,t(M1), invertir,solve(A), etc. []: #  []: # -   También existen funciones para matrices:diag(),rowSums(),colMeans(), etc. []: #  []: # &lt;!-- []: # ## Funciones para Matrices []: #  []: # * Para crear la matriz identidad de dimensiones $n\\times n$ []: # ```{r} []: # #| eval: false []: # #| echo: false []: # diag(n)      []: # ``` []: #  []: # * Para crear un matriz con los elementos del vectorvecen la diagonal []: # ```{r} []: # #| eval: false []: # #| echo: false []: # diag(vec)    []: # ``` []: #  []: # -   Se pueden calcular sumas o medias de las filas o columnas de una []: #     matriz []: #  []: # ```{r} []: # #| echo: false []: # rowSums(M2) []: # colMeans(M2) []: # ``` []: #  []: # ::: {.notes} []: #  []: # * Notar quemean(matrx)calcula la media de *todos* los elementos de la matriz (como si fuera un []: # vector) []: #  []: #  []: # -   También, se puede operar con un subconjunto de la matriz (que puede []: #     ser otra matriz o un vector) []: #  []: # ```{r} []: # #| echo: false []: # #| eval: false []: # colSums(M2[1:2,2:3]) []: # mean(M2[3,2:3]) []: # ``` []: #  []: # ::: []: # --&gt; []: #  []: # &lt;!-- []: # ## \"Arrays\" []: #  []: # * Un \"Array\" es un vector de \"n\" dimensiones. Se crea con la funciónarray[]: # ```{r} []: # x &lt;- array(c(1:8), dim =c(2,2,2) ) []: # x []: # ``` []: #  []: # * Se puede acceder a los elementos con paréntesis cuadrados []: # ```{r} []: # x[2,1,2] []: # x[,,1] []: # ``` []: #  []: # * Los nombres de todas las dimensiones de un \"array\" (includas matrices) se manejan con la función []: #dimnames`, además de al crearlos. : # : # + Es un tipo de objetos nuevos conocidos como listas. : # –&gt;"
  },
  {
    "objectID": "docs/Tema00.html#data-frames",
    "href": "docs/Tema00.html#data-frames",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Data Frames”",
    "text": "“Data Frames”\n\nEs un tipo de objetos específico para facilitar el análisis de datos: una colección de variables por columnas y observaciones por filas.\n\n\nCada columna es un vector con un nombre y tipos de datos (quizás) diferentes\n\n\naltura &lt;- c(177, 178, 168, 164, 186, 162, 160)\npeso   &lt;- c(75, 85, 70, 60, 80, 65, 54)\ngenero   &lt;- c(2, 1, 2, 2, 2, 1, 1)\ngenero_f &lt;- factor(genero, levels = c(1, 2), \n                           labels = c(\"Mujer\", \"Hombre\"))\ndatos &lt;- data.frame(\"Altura\"=altura, \"Peso\"=peso, \"Genero\"= genero_f)\n\n\n\nLos “data frames” son una colección (técnicamente, una lista) de vectores que corresponde a cada variable.\nPor ser listas, pueden tener columnas de tipos de diferentes, a diferencia de las matrices\n\n\n\nSe visualizan con View(datos) o en “Enviroment” o una parte con head() \n\n\nSeleccionamos columnas por nombre con $ o por nombre o posición con [[ ]]\n\n\nvectAltura &lt;- datos$Altura    # objeto resultante = vector\ndatos[[2]] == datos[[\"Peso\"]]"
  },
  {
    "objectID": "docs/Tema00.html#data-frames-cont.",
    "href": "docs/Tema00.html#data-frames-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "“Data Frames” (cont.)",
    "text": "“Data Frames” (cont.)\n\n\nnotar\n\naltura_vect[1] == datos$altura[1]\ndatos[[2]][1] == datos[[\"peso\"]][1]\n\n\nTambién podemos usar [] para seleccionar filas y columnas por posición, nombre y/o condición lógica\n\n\ndatos1 &lt;- datos[datos$Genero == \"Hombre\", 1:2]  # Altura y Peso de hombres        \n\n\n\n\n\nSuele ser mejor usar subset() que devuelve siempre un “data frame”\n\n\nD1 &lt;- subset(datos, Altura &gt; 165)   \nD2 &lt;- subset(datos, subset = Altura %in% c(177,178),\n                    select = c(Altura, Peso)) \n\n\nGeneramos nuevas variables con el vector de asignación\n\n\ndatos$Altura_m &lt;- datos$Altura / 100\n\n\n\nTambién se puede usar (pero NO recomendable) attach(): carga un objeto en el “Global Environment” y no es necesario poner su nombre para acceder a las variables con $\n\n\nÚtil con solo un conjunto de datos o si no hay lugar de confusión (no hay el mismo nombre de variable en diferentes conjuntos de datos)\nSe deja de vincular con detach()\n\n\nPara ordenar un conjunto de datos por una variable, order() crea un vector de posiciones de orden\n\n\n\nSe pueden añadir filas y columnas a un data frame con rbind() y cbind(), respectivamente, a partir de vectores u otros data frames"
  },
  {
    "objectID": "docs/Tema00.html#listas",
    "href": "docs/Tema00.html#listas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Listas",
    "text": "Listas\n\nUna lista es una colección de objetos de distinto tipo (a diferencia de un vector)\n\n\n\nVeremos que muchos objetos de R son listas\nTambién vemos las propiedades del objeto en el Environment\n\n\n\nLos elementos de una lista suelen tener nombres\n\n\nmiLista &lt;- list(saludo=\"hola\", vec=x, lista=list(1:4, \"X\"), \n                datos=datos)\n\n\nCon [[ ]] (por posición o por nombre) o con $(solo por nombre) extraemos los elementos en su clase original\n\n\nmiLista$vec\nmiLista[[2]] + 3\n\n\nTambién podemos usar [], pero devuelve una lista\n\n\n\nNota: el uso de [ ] y [[ ]] también se aplica a “data frames”\nEs importante entender el tipo de objeto de obtenemos con una forma de acceso u otra, por las operaciones que podemos realizar y por las transformaciones que se permiten\nP.e., podemos acceder a elementos individuales de la (sub-)lista con [[ ]], pero no con [ ]:\n\nmiLista[[2]][2]\nmiLista[2][2]   # lista de longitud 1\n\n\nunlist() convierte una lista en vector, usando la clase que pueda ajustarse a todos los objetos (elementales)"
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-libraries",
    "href": "docs/Tema00.html#bibliotecas-libraries",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (“libraries”)",
    "text": "Bibliotecas (“libraries”)\n\nUna biblioteca contiene nuevos objetos de R: funciones, datos, etc.\nPara instalar una nueva biblioteca (se hace una vez), en Tools &gt; Install packages o en  o con el comando \n\n\ninstall.packages(\"AER\")\n\n\nMantenemos actualizados los paquetes, en el menú Tools o en \nLa biblioteca solo está disponible si se carga en la sesión actual\n\n\nlibrary(AER)\n\n\nNota: en adelante, la bibliotecas que carguemos se suponen instaladas\nEn  vemos las bibliotecas instaladas y las cargadas aparecen marcadas \n\n\n\nR puede extenderse con capacidades adicionales instalando paquetes con bibliotecas\nSe instala UNA VEZ, se carga en cada sesión que se usa\nPodemos ver las bibliotecas cargadas en \n\nmirarlo antes y después de library(AER)\no por línea de comandos\n\n\n\nLa ayuda contiene información sobre las funciones de una biblioteca, incluyendo ejemplos de uso (“vignettes”) en algunos casos\n\nlibrary(help=utils)\n\nPodemos descargar una biblioteca de memoria con detach()\nLa función require() es “similar” a library()"
  },
  {
    "objectID": "docs/Tema00.html#bibliotecas-cont.",
    "href": "docs/Tema00.html#bibliotecas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Bibliotecas (cont.)",
    "text": "Bibliotecas (cont.)\n\nEl nombre completo de un objeto es biblioteca::nombre\n\nLa nombre de la biblioteca solo es necesaria si no se ha cargado o dos objetos diferentes tienen el mismo nombre en bibliotecas distintas\n\n\n\n\n\nbase::log(1)\nlog(1)\n\n\n\n\n\nlibrary(Hmisc)\nfind(\"units\")\n\n\n\n\nEn la Ayuda, vemos la biblioteca a la que pertenece una función (entre llaves)\nEl nombre completo es necesario si hay conflicto entre bibliotecas: contienen objetos con el mismo nombre\n\n\nTambién se usa nombre completo si no se ha cargado la biblioteca\n\n\n\nPara mostrar todos los datos de las bibliotecas cargadas\n\n\ndata()\n\n\nLos podemos cargar en el “Environment” y obtener información detallada en la ayuda (ej., nombre de variables)\n\n\ndata(\"Affairs\")\nhelp(\"Affairs\")"
  },
  {
    "objectID": "docs/Tema00.html#datos-nativos-en-r",
    "href": "docs/Tema00.html#datos-nativos-en-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos “nativos” en R",
    "text": "Datos “nativos” en R\n\nGuardamos objetos del espacio de trabajo con save() (en una ruta relativa al directorio de trabajo)\n\n\nx &lt;- 1:20\ny &lt;- 2 * x ^ 2 + 1\nsave(x, file=\"x.RData\")      # un objeto, o varios\nsave(x, y, file=\"data/xy.RData\")  #   separados por comas\n\n\n\nExtensiones .RData, .rda, .rds, …\nO todo el workspace con save.image() (= icono )\n\n\n\nPara cargar datos al espacio de trabajo, con load() (= icono )\n\n\nload(\"data/xy.RData\")\n\n\nEn la pestaña de : doble-clic carga un archivo de datos\nNota: este tipo de archivo puede contener varios objetos, incluidas varios conjuntos de datos\n\n\n\nEs posible cargar directamente desde internet:\n\nload(url(\"https://github.com/albarran/BigDataEcon/raw/main/data/altura.RData\"))\n\nTambién se eliminan archivos con la función unlink()"
  },
  {
    "objectID": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "href": "docs/Tema00.html#datos-en-otros-formatos-externos-a-r",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Datos en otros formatos externos a R",
    "text": "Datos en otros formatos externos a R\n\nVarias bibliotecas permiten trabajar con distintos formatos de datos, p.e.:\n\nTexto, con delimitadores o de ancho fijo: utils (R base), readr\nHojas de cálculo: readxl, openxlsx \nFormatos de software estadístico: haven, foreign\n\n\n\n\nDos bibliotecas a veces ofrecen comandos distintos que hacen lo mismo\nPero tienen distintas opciones y sus opciones por defecto son diferentes (p.e., cómo tratan los caracteres: ¿se convierten a factores?)\n\n\n\nDescargad estos ejemplos (UA cloud): renta.txt, sex_data.csv, beauty.xls, nsw.dta\nEn  de RStudio, tenemos acceso visual para cargar algunos formatos (con la biblioteca necesaria instalada)\nrio es un meta-paquete (instala otras bibliotecas) para importar y exportar varios formatos de datos de forma sencilla\n\nA partir de la extensión del archivo, detecta el formato y, por tanto, la biblioteca necesaria"
  },
  {
    "objectID": "docs/Tema00.html#importar-y-exportar-con-rio",
    "href": "docs/Tema00.html#importar-y-exportar-con-rio",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Importar y exportar con rio",
    "text": "Importar y exportar con rio\n\nrio permite trabajar con el mismo comando para todos los formatos, pero las opciones por defecto pueden no ser adecuadas\n\nEn la Ayuda se incluye una presentación completa del paquete\n\n\nEl comando import() se usa para leer los datos\n\n\nlibrary(rio)\nsex   &lt;- import(\"data/sex_data.csv\")\nrenta &lt;- import(\"data/renta.txt\")\nbeauty &lt;- import(\"data/beauty.xls\")\nnsw    &lt;- import(\"data/nsw.dta\")    # formato Stata\n\n\nPodemos exportar datos a un tipo de formato con export()\n\n\nexport(nsw, \"data/nsw.csv\")\n\n\nO convertir un archivo del disco a otro formato con convert()"
  },
  {
    "objectID": "docs/Tema00.html#otras-fuentes-de-datos",
    "href": "docs/Tema00.html#otras-fuentes-de-datos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Otras fuentes de datos",
    "text": "Otras fuentes de datos\n\nBibliotecas con datos muy utilizados: pwt (“Penn World Tables”)\nBibliotecas con funciones para obtener datos online (con APIs públicas)\n\ndatos de las OECD y eurostat (incluye datos del INE español)\nrdbnomics para los datos gratuitos de https://db.nomics.world/\ndatos económicos y financieros con quantmod y tidyquant\nquandl (de pago)\n\nqualtRics trabaja con software de encuestas qualtrics\nDescarga de páginas web y webscraping con las bibliotecas rvest y httr (función GET())\ngooglesheets4\nDBI accede con Bases de Datos relaciones (SQL)"
  },
  {
    "objectID": "docs/Tema00.html#gráficos-básicos",
    "href": "docs/Tema00.html#gráficos-básicos",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Gráficos Básicos",
    "text": "Gráficos Básicos\n\nPodemos representar gráficos de dos variables o funciones\n\n\n\n\nx &lt;- c(3, 4, 5, 6, 7, 8)\ny &lt;- c(5, 3, 7, 7, 5, 10)\n\n\n\n\n\nplot(x,y)\n\n\n\nEl resultado aparece en la pestaña Plots de RStudio\n\n\n\n\n\nPodemos cambiar opciones (ver Ayuda de plot.default) como type (puntos, líneas, etc.), símbolo de punto (pch), tipo de línea (lty), ancho de línea (lwd), color (col), título, etiquetas de los ejes, etc.\n\n\nplot(x, y, type=\"b\", pch=3)\nplot(x, y, type=\"l\", lty=2, lwd=2)\nplot(x, y, xlab=\"Eje X\", ylab=\"Eje Y\", main=\"Mi título\")\n\n\nSe pueden cambiar más opciones con par(), combinar gráficos, añadir líneas, texto, etc. y exportar los gráficos"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-discretas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables discretas",
    "text": "Estadísticos descriptivos: variables discretas\n\nPara variables discretas (factores), table() calcula distribuciones de frecuencias de una variable o conjuntas: el resultado es un objeto\n\n\ndata(\"PSID1982\", package = \"AER\")\n(frec  &lt;- table(PSID1982$occupation) )\n(frec2 &lt;- table(PSID1982$occupation, PSID1982$ethnicity))\n\n\n\nEl objeto es una “tabla” es una variante de vector o matrices con nombres\nSe podría opera con él: table(PSID1982$occupation) / sum(table(PSID1982$occupation)))\n\n\n\nPodemos mostrar frecuencias relativas con prop.table()\n\n\n\n\nprop.table(frec)\nprop.table(frec2)\n\n\n\n\n\nprop.table(frec2, margin = 1)\nprop.table(frec2, margin = 2)\n\n\n\n\nRecordad: conceptos de distribución marginal (probabilidad de un valor en X), distribución conjunta (prob. de un valor de X Y uno de Y ) y distribución condicional (prob. de Y dado un valor de X)\n(In)dependencia y distribuciones conjunta y marginal: p.e., la distribución de trabajos es distinta en general o condicional a ser afroamericano\n\nsabiendo que una persona es afroamericano, es más probable que sea cualificado (mayor renta, etc.)\n\n\n\n\nTambién es informativa su representación con gráficos de barras\n\n\nbarplot(frec, horiz = T)\nbarplot(prop.table(frec2), beside = T)\n\n\n\nbarplot(prop.table(frec2)) en otros casos puede ser más informativo que aquí\nTambién se puede representar con gráficos de tarta: pie(frec)\nLos gráficos admiten (casi) todas las opciones de plot() como títulos, etc. y otras específicas"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas",
    "text": "Estadísticos descriptivos: variables continuas\n\ndata(ceosal1, package='wooldridge')\n\n\nYa hemos visto funciones de estadísticos como mean(), var(), etc.\n\n\nmedian(ceosal1$salary)\nvar(ceosal1$salary)\n\n\nquantile(ceosal1$salary, \n         probs=c(0.25, 0.75) ) # 1er y 3er cuartil\n\nsummary(ceosal1$salary)  # de una variable (vector)\nsummary(ceosal1)         # de todo el conjunto de datos  \n\ncov(ceosal1$salary, ceosal1$roe)  # covarianza\ncor(ceosal1$salary, ceosal1$roe)  # correlación\n\n\n\nRecordad el tratamiento diferente de factores en summary()\nOtras funciones de estadísticos: min(), max(), range(), sum()"
  },
  {
    "objectID": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "href": "docs/Tema00.html#estadísticos-descriptivos-variables-continuas-cont.",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Estadísticos descriptivos: variables continuas (cont.)",
    "text": "Estadísticos descriptivos: variables continuas (cont.)\n\nPara variables continuas, las frecuencias de valores en un intervalo se pueden tabular o graficar en un histograma\n\n\n\nEn teoría, cada obervación de una variable continua tiene valores distinto; en la práctica se repiten pero no tanto como en las discretas\n\n\n\nhist(ceosal1$roe)   # intervalos automáticos\nhist(ceosal1$roe, freq=F,       # densidad, no casos\n     breaks=c(0,5,10,20,30,60)) # intervalos explícitos\n\n\nO la densidad (versión suavizada del histograma)\n\n\nplot(density(ceosal1$roe))\n\n\n\nSe pueden combinar histograma y densidad ejecutando hist(x) y luego lines(density(x))\n\n\nLa función de distribución acumulada empírica es otra representación de la distribución de una variable (en especial, continua)\n\nplot(ecdf(ceosal1$roe))\n\nLa definición de valor atípico/extremo es “arbitraria”. Aquí es 1.5 veces el rango intercuartículo por encima/debajo de la caja.\n\n\n\nUn gráfico de caja ofrece información resumida de la distribución: mediana, 1er y 3er cuartil, y valores “extremos”\n\n\nboxplot(ceosal1$roe, horizontal=T)\nboxplot(ceosal1$roe~ceosal1$consprod)\n\n\n\nEl símbolo \\~ en R indica que una variable es función de otras: en este caso, la distribución de roe se reprensenta en función de los valores de otra"
  },
  {
    "objectID": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "href": "docs/Tema00.html#valores-ausentes-missing-values-na",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Valores ausentes (“missing values”): NA",
    "text": "Valores ausentes (“missing values”): NA\n\nMuchos conjuntos de datos tienen valores ausentes de ciertas observaciones para algunas variables: ej., descargad (UA Cloud) earn.RData\n\n\nSabemos si una observación es NA y la frecuencia total:\n\n\n\n\nload(\"data/earn.RData\")\nx &lt;- earn$earnings\n\n\n\n\n\nis.na(x)\ntable(is.na(x))\n\n\n\n\nRecordemos también any(is.na(x)) (hay algun NAs?) o which(is.na(x)) (qué elementos son NA)\n\n\n\nPor defecto en R, un cálculo con NAs es NA: debemos decir que los elimine explícitamente (y ser conscientes de lo que implica)\n\n\n\n\nmean(x)\n\n\n\n\n\nmean(x, na.rm=TRUE)\n\n\n\n\nsum(), quantile() y otras tienen la opción de na.rm=TRUE\nen cor() la opción es diferente: cor(x, earn$age, use=\"complete.obs\")\n\n\n\nna.omit() elimina observaciones con NAs de una o varias variables\n\n\nearn2 &lt;- na.omit(earn)\n\n\n¿Cómo tratar los NAs? Eliminarlos implica selección muestral y la alternativa de imputar valores implica supuestos sobre éstos\n\n\n\nTambién podemos filtrar y &lt;- x[!is.na(x)] u otras formas\nOtra función útil complete.cases()\n\ns &lt;- complete.cases(x)\nearnComplete &lt;- earn[s,]\n\nPara reemplazar valores (si pensamos que tiene sentido): y &lt;- replace(x, which(is.na(x)), -1)\nLos estadísticos con la muestra sin NA pueden no ser representativos de la población total: solo muestrear en barrio pobre es igual de poco representativo que haya menos respuestas en el barrio rico\nsuponer que podemos imputar renta solo con edad, genero y educación es restrictivo…"
  },
  {
    "objectID": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "href": "docs/Tema00.html#nota-sobre-programación-avanzada",
    "title": "Tema 0: Introducción a R y RStudio (Posit)",
    "section": "Nota sobre programación “avanzada”",
    "text": "Nota sobre programación “avanzada”\n\nComo en todo lenguaje de programación R, tiene funciones para\n\nEjecución condicional if(): una parte del código se ejecuta solo si se cumple una condición\nBucles for(): se repite un mismo bloque de código mientras se itera por los valores de vector\nCrear funciones propias con function()\n\nUna variante de la ejecución condicional, solo para crear variables según una condición\n\n\ndata(\"Affairs\", package = \"AER\")\nAffairs$univers &lt;- ifelse(Affairs$education&gt;15, 1, 0)\n\n\n\nTanto if-else como for pueden escribirse en una sola línea sin \\{ si solo incluye un comando en el bloque entre llaves:\n\nif (p&lt;=0.05) decision &lt;- \"Rechazar H0\" else decision &lt;- \"NO Rechazar H0\"\n\nPueden anidarse if-else, for y ambos\nOtros comandos de bucles: while, repeat, replicate, apply, lapply, y otros (map) en bibliotecas adicionales"
  },
  {
    "objectID": "docs/Tema04ej.html",
    "href": "docs/Tema04ej.html",
    "title": "Tema 4. Quarto. Ejercicio.",
    "section": "",
    "text": "Apartado a)\n\nIniciar un nuevo proyecto de Quarto y crear un nuevo documento .qmd. Adapta el encabezado para que tenga, al menos, un título y tu nombre como autor o autora. (Puedes eliminar el resto del contenido para los siguientes apartados, dejando espacio tras la cabecera).\n\n\nCrea una primera sección del documento, p.e., con el nombre “Apartado a)”. Para cada apartado posterior debes crear una nueva sección correspondiente al apartado.\nEscribe un breve frase introductoria general, una lista que enumere las dos variables que elegiste para el ejercicio de Visualización de Datos, incluye un enlace a una página web e inserta una imagen.\nNota: Puedes usar, aquí y en cualquier otra parte del documento, negritas o cursivas cuando lo consideres oportuno.\n\n\nGuarda el documento con un nombre con el siguiente formato que incluye vuestro número de DNI: Tema04ej_123456789.qmd\nRenderiza tu documento para visualizar el documento html creado.\nComprueba en el mismo directorio donde tienes el archivo .qmd se ha creado un archivo con extensión html; nota que también se ha creado un subdirectorio con el mismo nombre que contiene todo lo necesario para visualizar el archivo html.\nCambia a otro formato de salida en el encabezado YAML y genera otro documento de salida.\nComprueba de nuevo que tienes un archivo de salida (.pdf o .docx) en el mismo directorio donde está el archivo .qmd.\nBorra el documento html y el subdirectorio con el mismo nombre generados previamente. Cambia la opción de YAML para que se genere un html autocontenido. Comprueba que puedes visualizar el archivo. Comentar.\n\n\n\nApartado b)\n\nEscribe una línea de texto (NO celda de código) que incluya (entre el texto) código de R para mostrar la media de la variable mpg del conjunto de datos mtcars.\nCrear y dar un nombre a una sub-sección que incluya lo siguiente.\n\nTres celdas, todos con el código summary(mtcars). El primero debe mostrar el código, pero no el resultado; el segundo sólo mostrar el resultado (no el código); el tercero debe mostrar ambos. Antes de cada celda, incluye una frase explicando qué va a pasar.\nCargar las bibliotecas AER y Hmisc en una nueva celda de código. Cambia los valores de warning, error y message y renderiza el documento para observar los cambios. Comentar los cambios brevemente y qué forma de presentación prefieres para tu documento.\n\nCrear y dar nombre a otra sub-sección.\n\nAñadir un celda con el código a &lt;- 2, fijando la opción para que NO se evalúe. Añadir otra celda posterior con código b &lt;- 3 + a y que sí se evalúe. Renderizar el documento y comprobar que da un error.\nCambiar las opciones del segundo fragmento para que se pueda renderizar un documento de salida.\n\n\n\n\nApartado c)\n\nCrear una celda con el código para mostrar un gráfico de puntos con los datos de mtcars para las variables disp (tamaño del depósito) y mpg (consumo).\n\nAñadir en la celda de código (no usando ggplot) un título del gráfico (aparece en la parte inferior).\n\n \n\n\nCrear una nueva celda de código que incluya dos gráficos de caja, para disp y para mpg, que se muestren uno al lado del otro.\n\n\n\nApartado d)\n\nCrear una sub-sección. Incluir una nueva celda de código (que sí se evalúe) para mostar mtcars y summary(mtcars).\nCrear una sub-sección. Incluir un nuevo fragmento de código (que sí evalúe) y que incluya:\n\ncargar la biblioteca kableExtra para poder usar la función kbl()\nmostrar el resultado de mtcars y summary(mtcars) con la función kbl() con distintas opciones de estilo (una guía completa aquí). Por ejemplo\n\n\n\nmtcars %&gt;% kbl()  %&gt;%\n  kable_styling()\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_styling()\n\nmtcars %&gt;% kbl()  %&gt;%\n  kable_classic(full_width = F)\nsummary(mtcars) %&gt;% kbl()  %&gt;%\n  kable_minimal()\n\nComentar las diferencias con el apartado anterior, d.i), y y qué forma de presentación prefieres para tu documento.\n\n\nApartado e)\n\nIncluir la opción df-print: paged en la cabecera. Comprobar el efecto antes y después de incluirlo sobre cómo se muestra el conjunto de datos (“data frame”) mtcars en los apartados d.i) y d.ii).\nComentar las diferencias y qué forma de presentación prefieres para tu documento.\nIncluye la opción code-fold: true en la cabecera. Comprobar cómo cambia el documento y comentar brevemente qué forma de presentación prefieres para tu documento.\nElige un tema entre estos y aplícalo al documento.\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de .qmd\nel resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema04ej_123456789.qmd\nTema04ej_123456789.zip"
  },
  {
    "objectID": "docs/Tema01.html#introducción",
    "href": "docs/Tema01.html#introducción",
    "title": "Tema 01 - Visualización de datos",
    "section": "Introducción",
    "text": "Introducción\n\nLa representación visual permite resumir información e identificar patrones que no se verían en los datos en bruto (en una hoja de cálculo).\nEn un buen gráfico, la audiencia encuentra obvias las ideas a transmitir, sin abrumar con muchos hallazgos\n\n\nUsaremos la biblioteca ggplot2, basada en la Gramática de Gráficos (Wilkinson, 2005)\n\nalgunos gráficos simples requieren más opciones que en R base\nPERO ofrece facilidades para gráficos complejos y profesionales\n\n\n\nOtras bibliotecas: rgl (gráfics 3D), ggvis (interactivos), plotly"
  },
  {
    "objectID": "docs/Tema01.html#elementos-básicos-de-un-gráfico-de-datos",
    "href": "docs/Tema01.html#elementos-básicos-de-un-gráfico-de-datos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Elementos básicos de un gráfico de datos",
    "text": "Elementos básicos de un gráfico de datos\n\nSeñales visuales: posición, longitud, área, etc.\nSistema de coordenadas: ¿cómo se organizan los puntos de datos?\n\ncartesiano, polar, geográfico\n\nEscala: ¿cómo se traduce la distancia en algo con significado?\n\nnumérica lineal, numérica logarítmica, categórica, de tiempo\n\nContexto: ¿en relación con qué?\n\ntítulos, leyendas, etiquetas de ejes, puntos/líneas de referencia\n\nOtros: facetas/pequeños múltiplos, capas, animaciones, etc.\n\n\n“Por encima de todo, mostrar los datos”"
  },
  {
    "objectID": "docs/Tema01.html#señales-visuales",
    "href": "docs/Tema01.html#señales-visuales",
    "title": "Tema 01 - Visualización de datos",
    "section": "Señales Visuales",
    "text": "Señales Visuales"
  },
  {
    "objectID": "docs/Tema01.html#la-gramática-de-gráficos",
    "href": "docs/Tema01.html#la-gramática-de-gráficos",
    "title": "Tema 01 - Visualización de datos",
    "section": "La “Gramática de Gráficos”",
    "text": "La “Gramática de Gráficos”\n\nEspecificar bloques independientes y combinarlos para crear cualquier visualización gráfica, como las frases a partir de nombres, verbos, objetos, etc.\nBloques de construcción de un gráfico\n\nDatos: data\nObjeto geométrico (qué dibujamos: líneas, puntos, barras, etc.): geom_*()\nAtributos estéticos (del objeto geométrico, como posición, color, forma, tamaño) que transmiten información de una variable: aes()\nEscalas (rango of valores, colores, etc.): scale_*()\nSistema de Coordenadas\nFacetas (pequeños múltiplos): facet_wrap(), facet_grid()"
  },
  {
    "objectID": "docs/Tema01.html#creando-un-ggplot",
    "href": "docs/Tema01.html#creando-un-ggplot",
    "title": "Tema 01 - Visualización de datos",
    "section": "Creando un “ggplot”",
    "text": "Creando un “ggplot”\n\nggplot(data = mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\nggplot(data = mpg) = gráfico vacío (coordenadas cartesianas, por defecto)\nAñadir capas con +: ej., objeto geométrico del tipo puntos = geom_point()\nEl argumento mapping, asociado a aes(), define cómo las variables son asignadas a propiedades visuales\n\nx e y especifican qué variables asignar a cada eje\n\n\n\nNOTA: el primer código define datos y estética para todas las capas que siguen; el segundo solo para el objeto geométrico de puntos."
  },
  {
    "objectID": "docs/Tema01.html#objetos-geométricos",
    "href": "docs/Tema01.html#objetos-geométricos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Objetos geométricos",
    "text": "Objetos geométricos\n\nCada geom_*() agrega un tipo diferente de capa/marcas en el gráfico \n\npuntos (geom_point, para diagramas de dispersión, de puntos, etc.)\nlíneas (geom_line, para series de tiempo, líneas de tendencia, etc.)\ndiagrama de caja (geom_boxplot)\netc.\n\n\n\nPara una lista de objetos geométricos disponibles, buscar las funciones que comienzan con geom_ en la Ayuda"
  },
  {
    "objectID": "docs/Tema01.html#elementos-estéticos-con-aes",
    "href": "docs/Tema01.html#elementos-estéticos-con-aes",
    "title": "Tema 01 - Visualización de datos",
    "section": "Elementos Estéticos con aes()",
    "text": "Elementos Estéticos con aes()\n\nElementos estéticos son “algo que se puede ver” (información)\nCada elemento estético con aes() es un asociación (“mapping”) entre una señal visual y una variable\n\nposición (p.e., en los ejes x e y)\ncolor (color “exterior”)\nrelleno (color “interior”), fill\nforma (de los puntos), shape\ntipo de línea,\ntamaño, size\n\nCada geom acepta solo un subconjunto de todos los elementos estéticos.\n\nEn la ayuda de cada geom se puede ver qué asignaciones acepta en aes()."
  },
  {
    "objectID": "docs/Tema01.html#esquisse-una-interfaz-gráfica",
    "href": "docs/Tema01.html#esquisse-una-interfaz-gráfica",
    "title": "Tema 01 - Visualización de datos",
    "section": "esquisse: una interfaz gráfica ",
    "text": "esquisse: una interfaz gráfica \n\nesquisse implementa de forma visual (“arrastrar y soltar”) la lógica de composición de gráficos de ggplot2\n\nSimilar a otras herramientas como Tableau o PowerBI o Gapminder\n\nEjecutamos esquisser() para crear el gráfico, eligiendo datos \n\n\n#install.packages(\"esquisse\")\nlibrary(esquisse)\nesquisser()                         \ndata(\"mpg\")\nesquisser(mpg, viewer = \"browser\")   # lanzar visor externo   \n\n\nSe pueden elegir muchos (no todos) aspectos del gráfico que veremos en este tema: tipo de gráfico, asignaciones estéticas, títulos, apariencia, etc.\nGenera un posible código de R para crea el gráfico\n\n\nTambién se puede descargar el gráfico creado"
  },
  {
    "objectID": "docs/Tema01.html#gráficos-como-objetos-de-r",
    "href": "docs/Tema01.html#gráficos-como-objetos-de-r",
    "title": "Tema 01 - Visualización de datos",
    "section": "Gráficos como objetos de R",
    "text": "Gráficos como objetos de R\n\nhousing   &lt;- rio::import(\"data/landdata-states.csv\")\nhp2001Q1  &lt;- housing[housing$Date == 2001.00,] \ngraf_base &lt;- ggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n                geom_point()\n\n\nSe pueden agregar capas a este objeto gráfico y mostrarlo\n\n\ngraf_base + geom_line()        # ¿tiene sentido este gráfico?\ngraf_base + geom_point(aes(shape = region)) \n\n\nAñadimos una señal visual de formas (o color, etc.), NO para “embellecer” sino para representar la información de una variable adicional\nNO saturar el gráfico con estéticas fijas o información innecesaria\n\n\ngraf_base + geom_point(aes(size = Home.Price.Index,   \n          color=Home.Value))    # ¿qué aportan estas variables?"
  },
  {
    "objectID": "docs/Tema01.html#asociación-estética-y-asignación-de-opción-fija",
    "href": "docs/Tema01.html#asociación-estética-y-asignación-de-opción-fija",
    "title": "Tema 01 - Visualización de datos",
    "section": "Asociación estética y Asignación de opción fija",
    "text": "Asociación estética y Asignación de opción fija\n\nUna asociación (“mapping”) estética, con aes(), visualiza una variable\n\n\nUna opción estética establece, fuera de aes(), un valor fijo de la señal visual\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(shape = \"cross\",  color=\"red\")   \n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(aes(shape = region, color=Home.Value))\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n  geom_point(aes(shape = region, color=Home.Value),\n             size = 3)\n\n\nNota: region, carácter convertido a factor, se representa en escala categórica"
  },
  {
    "objectID": "docs/Tema01.html#más-geoms-smoothers-y-texto",
    "href": "docs/Tema01.html#más-geoms-smoothers-y-texto",
    "title": "Tema 01 - Visualización de datos",
    "section": "Más geoms: “Smoothers” y Texto",
    "text": "Más geoms: “Smoothers” y Texto\n\nNo todos los geoms son formas simples: aquí, por defecto, una línea (función no lineal estimada) y un área (intervalo de confianza de la predicción)\n\n\ngraf_base + geom_smooth()\ngraf_base + geom_smooth(method = lm, se = FALSE)  \n\n\nCada geom acepta un conjunto particular de asignaciones: geom_text() acepta etiquetas\n\n\ngraf_base + geom_text(aes(label=State), size = 3)\n\n\nSi queremos el punto y la etiqueta de texto\n\n\n#install.packages(\"ggrepel\") \nlibrary(ggrepel)\ngraf_base + geom_text_repel(aes(label=State), size = 3)"
  },
  {
    "objectID": "docs/Tema01.html#comentario",
    "href": "docs/Tema01.html#comentario",
    "title": "Tema 01 - Visualización de datos",
    "section": "Comentario",
    "text": "Comentario\n\nCada objeto geométrico puede tener características propias\n\nusar datos distintos para diferentes objetos,\nutilizar diferentes estéticas en distintos objetos, etc..\n\nPor ejemplo, usamos solo un subconjunto de los datos para el objeto geométrico de texto\n\n\ngraf_base + geom_point() + \n  geom_text_repel(\n    data = subset(hp2001Q1, State %in% c(\"NY\",\"NJ\",\"KY\")), \n    mapping = aes(label=State), size = 3)"
  },
  {
    "objectID": "docs/Tema01.html#transformaciones-estadísticas",
    "href": "docs/Tema01.html#transformaciones-estadísticas",
    "title": "Tema 01 - Visualización de datos",
    "section": "Transformaciones Estadísticas",
    "text": "Transformaciones Estadísticas\n\nEn algunos gráficos, como el de dispersión, cada punto grafica unas coordenadas (x e y) iguales al valor original de las variables a representar (aunque podemos transformarlas)\n\n\nggplot(hp2001Q1, aes(x = log(Land.Value), y = Structure.Cost)) + \n      geom_point()\n\n\nOtros gráficos representan estadísticas obtenidas a partir de las variables (no las variables directamente)\n\n\n\n\nPara “smoother”, se calcula una regresión\nPara un gráfico de caja, se calculan estadísticos descriptivos\n\n\nggplot(hp2001Q1, \n       aes(y = Home.Value/1000)) +  \n  geom_boxplot()"
  },
  {
    "objectID": "docs/Tema01.html#modificar-las-transformaciones-estadísticas",
    "href": "docs/Tema01.html#modificar-las-transformaciones-estadísticas",
    "title": "Tema 01 - Visualización de datos",
    "section": "Modificar las Transformaciones Estadísticas",
    "text": "Modificar las Transformaciones Estadísticas\n\nPodemos cambiar qué estadísticas calcular o representar en geoms que representan estadísticas\nUn histograma (variables continuas) depende de qué intervalos definamos para calcular las frecuencias: podemos cambiar el número de grupos (bins) o su ancho (binwidth) o fijar los rangos (breaks)\n\n\ngraf &lt;- ggplot(housing, aes(x = Home.Value))\ngraf + geom_histogram(stat = \"bin\", binwidth=4000)\ngraf + geom_histogram(stat = \"bin\", bins=40)\n\n\nPodemos representar la densidad, en lugar de frecuencias absolutas\n\n\ngraf + geom_histogram(stat = \"density\" )  \n\n\nEn un gráfico de barras (variables discretas), se calculan por defecto frecuencias de una variable, pero podemos representar otra variable, con identity"
  },
  {
    "objectID": "docs/Tema01.html#escalas-control-de-la-asociación-estética",
    "href": "docs/Tema01.html#escalas-control-de-la-asociación-estética",
    "title": "Tema 01 - Visualización de datos",
    "section": "Escalas: control de la asociación estética",
    "text": "Escalas: control de la asociación estética\n\naes() establece la variable asignada, no cómo se representa\n\naes(shape = region): qué forma para cada región\naes(color = Home.Value): qué color para cada valor\n\nLas funciones para modificar la escala siguen el esquema scale_&lt;estética&gt;_&lt;tipo&gt;\n\n\nArgumentos habituales para la escala:\n\nname: título de la escala (en eje o leyenda)\nlimits: el mínimo y el máximo de la escala\nbreaks: valores donde deberían aparecer las etiquetas\nlabels: las etiquetas que aparecen en cada break\n\nFunciones específicas de escala pueden tener argumentos adicionales"
  },
  {
    "objectID": "docs/Tema01.html#ejemplos-de-modificación-de-escala",
    "href": "docs/Tema01.html#ejemplos-de-modificación-de-escala",
    "title": "Tema 01 - Visualización de datos",
    "section": "Ejemplos de modificación de escala",
    "text": "Ejemplos de modificación de escala\n\ng2 &lt;- ggplot(housing, aes(y = State, x = Home.Price.Index)) + \n  geom_point(aes(color = Date))\n\n\nModificamos breaks, etiquetas y colores de la escala de color\n\n\ng2 + scale_color_continuous(breaks = c(1975.00, 1994.00, 2013.00),\n            labels = c(1975, 1994, 2013), low = \"blue\", high = \"red\")\n\n\nUna escala diferente para color, interpolando entre tres colores\n\n\ng2 + scale_color_gradient2(breaks = c(1975.00, 1994.00, 2013.00),\n                           labels = c(1975, 1994, 2013),\n                        low = \"blue\", high = \"red\", mid = \"gray60\", \n                        midpoint = 1994.00)"
  },
  {
    "objectID": "docs/Tema01.html#listado-parcial-de-escalas-disponibles",
    "href": "docs/Tema01.html#listado-parcial-de-escalas-disponibles",
    "title": "Tema 01 - Visualización de datos",
    "section": "Listado (parcial) de escalas disponibles",
    "text": "Listado (parcial) de escalas disponibles"
  },
  {
    "objectID": "docs/Tema01.html#facetas-pequeños-múltiplos",
    "href": "docs/Tema01.html#facetas-pequeños-múltiplos",
    "title": "Tema 01 - Visualización de datos",
    "section": "Facetas (pequeños múltiplos)",
    "text": "Facetas (pequeños múltiplos)\n\nPara facilitar la comparación de gráficos (no solo objetos geométricos), se divide en subgráficos para distintos subconjuntos de los datos\n\n\ngraf_estad &lt;- ggplot(housing, aes(x = Date, y = Home.Value))\ngraf_estad +  geom_line(aes(color = State))        # gráfico confuso\n\n\nfacet_wrap() para facetas en función de variable discreta (usando “fórmula”)\n\n\ngraf_estad +  geom_line() + facet_wrap(~State, ncol = 10)\n\n\nfacet_grid() para facetas en dos dimensiones\n\n\ng3 &lt;- ggplot(data = housing %&gt;% filter(Year&gt;2005)) + \n               geom_histogram(aes(x=Home.Value))\ng3 +  facet_grid(region ~ Year)\n\ng3 + facet_grid(region ~ .)     # También solo por filas \ng3 + facet_grid(. ~ region)     # o columnas"
  },
  {
    "objectID": "docs/Tema01.html#contexto-con-labs-título-ejes-leyendas",
    "href": "docs/Tema01.html#contexto-con-labs-título-ejes-leyendas",
    "title": "Tema 01 - Visualización de datos",
    "section": "Contexto con labs(): título, ejes, leyendas",
    "text": "Contexto con labs(): título, ejes, leyendas\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost, x = Land.Value)) +\n geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n labs(\n   title = \"Relación entre coste de la construcción y valor del terreno\",\n   subtitle = \"Datos del Primer Trimestre de 2001\",\n   caption = \"Fuente: Elaboración propia\")\n\n\nEs una buena idea que los nombres de ejes, leyendas, etc. sean descripciones claras de las variables (y sus unidades)\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost/1000, x = Land.Value/1000)) + \n  scale_x_log10() + \n  geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Valor del terreno (miles de $), escala logarítmica\",\n       y = \"Valor de la construcción (miles de $)\",\n       colour = \"Región\") +\n  scale_y_continuous(breaks=seq(80,200,40),labels=seq(80,200,40) )\n\n\n¿Qué hace la escala logarítmica? ¿Y usar x = log(Land.Value/1000)?"
  },
  {
    "objectID": "docs/Tema01.html#otros-elementos-de-contexto",
    "href": "docs/Tema01.html#otros-elementos-de-contexto",
    "title": "Tema 01 - Visualización de datos",
    "section": "Otros elementos de contexto",
    "text": "Otros elementos de contexto\n\n\nYa vimos geom_text() para asociar una variable a un estética de etiqueta\nannotate() añade objetos geométricos no asociados a variables: “text”, “rect”, “segment”, “pointrange”\n\n\nggplot(hp2001Q1, aes(y = Structure.Cost/1000, x = Land.Value/1000)) +\n  geom_point(aes(color = region)) + geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10()+\n  annotate(\"text\", x = 140, y = 180, label = \"casa cara\") +\n  annotate(\"text\", x = 110, y = 150, label = \"R ^ 2 == 0.026\", \n           parse = TRUE)\n\n\nSe pueden añadir líneas de referencias verticales, horizontals o diagonales\n\n\n  g2 +\n    geom_vline(aes(xintercept = 1), linetype = 3, color = \"black\")"
  },
  {
    "objectID": "docs/Tema01.html#cambiar-colores",
    "href": "docs/Tema01.html#cambiar-colores",
    "title": "Tema 01 - Visualización de datos",
    "section": "Cambiar colores",
    "text": "Cambiar colores\n\nSe puede cambiar manualmente la combinación (paleta) de colores por defecto dando el nombre o el código hexadecimal HTML de color\n\n\ngraf &lt;- ggplot(hp2001Q1, \n            aes(x = region, y = Home.Value, fill = region)) + \n          geom_boxplot()\n\ngraf + scale_fill_manual(\n          values = c(\"red\", \"green\", \"blue\", \"yellow\", \"gray\"))\n\n\nDe igual forma se podría cambiar la forma con scale_shape_manual()\n\n\nEs recomendable usar paletas predefinidas, con criterios de diseño y visualización de información, como RColorBrewer o viridis \n\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\ngraf + scale_fill_brewer(palette = \"Set3\")\ngraf + scale_fill_brewer(palette = \"Dark2\")"
  },
  {
    "objectID": "docs/Tema01.html#temas",
    "href": "docs/Tema01.html#temas",
    "title": "Tema 01 - Visualización de datos",
    "section": "Temas",
    "text": "Temas\n\nPodemos definir el estilo general del gráfico: etiquetas de los ejes, fondo del gráfico, apariencia de las leyendas, etc.\n\n\ngraf + theme_gray()       # predeterminado\ngraf + theme_linedraw()\ngraf + theme_light()\ngraf + theme_minimal()\ngraf + theme_dark()\ngraf + theme_classic()\n\n\nCiertos elementos específicos del tema pueden ser cambiados con theme() y guardados para definir temas personalizados (para aplicarlos después)\n\n\nggthemes ofrece temas creados por profesionales en diseño y comunicación\n\n\n#install.packages(\"ggthemes\")\nlibrary(ggthemes)\ngraf +  theme_economist() +  # diseño gráfico de \"The Economist\"   \n  scale_fill_economist()"
  },
  {
    "objectID": "docs/Tema01.html#comentarios-finales",
    "href": "docs/Tema01.html#comentarios-finales",
    "title": "Tema 01 - Visualización de datos",
    "section": "Comentarios finales",
    "text": "Comentarios finales\n\nGuardar los gráficos: en la pestaña , lista desplegable  o comando ggsave()\n\n\nggsave(\"my-plot.pdf\")\n\n\nAyuda en RStudio, Help &gt; Cheatsheets &gt; Data Visualization with ggplot2\nFuentes de información con chuletas de R y RStudio aquí\n\nexisten versiones en castellano de algunas de ellas."
  },
  {
    "objectID": "docs/Tema05ej1.html",
    "href": "docs/Tema05ej1.html",
    "title": "Tema 05. Ejercicio 1",
    "section": "",
    "text": "La biblioteca tidyquant ofrece varias funcionalidades para obtener, transformar y visualizar datos económicos y financieros fácilmente. Aquí solo utilizaremos unas pocas de sus capacidades; podéis encontrar una descripción completa aquí.\nExisten varias funciones para obtener datos: tq_index() (para índices bursátiles), tq_exchange() (para bolsas de valores) y tq_get() para datos económicos y financieros de varias fuentes en la web.\n\n\nLa web de FRED dispone de datos económicos de muchos países.\n\nBuscamos un dato concreto: p. e., inflación en España que aparece como “Inflation, consumer prices for Spain; Percent, Annual, Not Seasonally Adjusted”\nAsí, averiguamos el “símbolo” o nombre interno de la variable\n\n\nlibrary(tidyquant)\nlibrary(tidyverse)\ndatos &lt;- tq_get(\"FPCPITOTLZGESP\", get = \"economic.data\", from = \"1960-01-01\")\n\nObtenemos unos datos ordenados con la fecha y el valor numérico de la variable disponibles para trabajar con las funciones de tidyverse. Podemos representar la evolución temporal de esta variable para todo el periodo o una parte (p.e., usando funciones como year() de lubridate)\n\nggplot(datos) + geom_line(aes(x=date, y=price))\n\ndatos %&gt;% filter(year(date)&gt;2000) %&gt;%       \n  ggplot() + geom_line(aes(x=date, y=price))\n\n\n\n\nPara obtener datos de acciones, averiguamos el símbolo de una acción en Yahoo Finance; por ejemplo, “Telefonica, Equity - NYQ” y “Banco de Santander, S.A. - NYQ”\n\nacciones &lt;- tq_get(c(\"TEF\", \"SAN\"), get = \"stock.prices\", complete_cases = FALSE)\n\nTenemos los datos ordenados en formato largo para las acciones (primero la serie de una acción y luego la de la otra) con información del precio de apertura, cierre, máximo y mínimo de la sesión, volumen negociado, etc.\n\n\n\n\nEsta biblioteca también incluye funciones de análisis específicos, como geoms de ggplot2 para nuevos tipos de gráficos. Podemos representar los distintos precios de una o de varias empresas (“símbolos”) a la vez.\n\nGráficos de barras\n\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_barchart(aes(open = open, high = high, low = low, close = close))\n\nacciones %&gt;%\n  filter(month(date) == 10 & year(date) == 2024) %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_barchart(aes(open = open, high = high, low = low, close = close)) +\n  facet_wrap(~symbol)\n\n\nGráficos de velas\n\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high, low = low, close = close)) \n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(date &gt;= \"2024-02-01\" & date &lt;=\"2024-03-31\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high, low = low, close = close)) \n\nTambién podemos añadir (en ambos tipos de gráficos) tendencias calculadas con distintas formas de medias móviles y bandas:\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(year(date)&gt;2022) %&gt;%  \n  ggplot(aes(x = date, y = close)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = SMA, n = 50, color = \"black\") +\n    geom_ma(ma_fun = SMA, n = 200, color = \"gray\")\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(year(date) &gt; 2022) %&gt;%  \n  ggplot(aes(x = date, y = close, open = open, high = high, low = low, close = close)) +\n  geom_candlestick() +\n  geom_bbands(ma_fun = SMA, sd = 2, n = 20) \n\nSe pueden incorporar todas las funcionalidades habituales de ggplot2 como escalas logarítmicas, geom_smooth(), etc.\nComo hemos visto se pueden utilizar las funciones de transformación de datos de tidyverse; además, tidyquant incluye las funciones tq_mutate() y tq_transmutate() con las que se realizan con mayor facilidad operaciones habituales con este tipo de datos como cambiar la periodicidad, obtener rentabilidades a distintos plazos, cálculos de tendencias mediante medias móviles, cálculos de volatilidad, etc. También se incluye la función tq_performance() para el análisis del comportamiento de una acción o una cartera."
  },
  {
    "objectID": "docs/Tema05ej1.html#tidyquant-obtener-datos",
    "href": "docs/Tema05ej1.html#tidyquant-obtener-datos",
    "title": "Tema 05. Ejercicio 1",
    "section": "",
    "text": "La biblioteca tidyquant ofrece varias funcionalidades para obtener, transformar y visualizar datos económicos y financieros fácilmente. Aquí solo utilizaremos unas pocas de sus capacidades; podéis encontrar una descripción completa aquí.\nExisten varias funciones para obtener datos: tq_index() (para índices bursátiles), tq_exchange() (para bolsas de valores) y tq_get() para datos económicos y financieros de varias fuentes en la web.\n\n\nLa web de FRED dispone de datos económicos de muchos países.\n\nBuscamos un dato concreto: p. e., inflación en España que aparece como “Inflation, consumer prices for Spain; Percent, Annual, Not Seasonally Adjusted”\nAsí, averiguamos el “símbolo” o nombre interno de la variable\n\n\nlibrary(tidyquant)\nlibrary(tidyverse)\ndatos &lt;- tq_get(\"FPCPITOTLZGESP\", get = \"economic.data\", from = \"1960-01-01\")\n\nObtenemos unos datos ordenados con la fecha y el valor numérico de la variable disponibles para trabajar con las funciones de tidyverse. Podemos representar la evolución temporal de esta variable para todo el periodo o una parte (p.e., usando funciones como year() de lubridate)\n\nggplot(datos) + geom_line(aes(x=date, y=price))\n\ndatos %&gt;% filter(year(date)&gt;2000) %&gt;%       \n  ggplot() + geom_line(aes(x=date, y=price))\n\n\n\n\nPara obtener datos de acciones, averiguamos el símbolo de una acción en Yahoo Finance; por ejemplo, “Telefonica, Equity - NYQ” y “Banco de Santander, S.A. - NYQ”\n\nacciones &lt;- tq_get(c(\"TEF\", \"SAN\"), get = \"stock.prices\", complete_cases = FALSE)\n\nTenemos los datos ordenados en formato largo para las acciones (primero la serie de una acción y luego la de la otra) con información del precio de apertura, cierre, máximo y mínimo de la sesión, volumen negociado, etc."
  },
  {
    "objectID": "docs/Tema05ej1.html#funciones-adicionales",
    "href": "docs/Tema05ej1.html#funciones-adicionales",
    "title": "Tema 05. Ejercicio 1",
    "section": "",
    "text": "Esta biblioteca también incluye funciones de análisis específicos, como geoms de ggplot2 para nuevos tipos de gráficos. Podemos representar los distintos precios de una o de varias empresas (“símbolos”) a la vez.\n\nGráficos de barras\n\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_barchart(aes(open = open, high = high, low = low, close = close))\n\nacciones %&gt;%\n  filter(month(date) == 10 & year(date) == 2024) %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_barchart(aes(open = open, high = high, low = low, close = close)) +\n  facet_wrap(~symbol)\n\n\nGráficos de velas\n\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high, low = low, close = close)) \n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(date &gt;= \"2024-02-01\" & date &lt;=\"2024-03-31\") %&gt;% \n  ggplot(aes(x = date, y = close)) +\n  geom_candlestick(aes(open = open, high = high, low = low, close = close)) \n\nTambién podemos añadir (en ambos tipos de gráficos) tendencias calculadas con distintas formas de medias móviles y bandas:\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(year(date)&gt;2022) %&gt;%  \n  ggplot(aes(x = date, y = close)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = SMA, n = 50, color = \"black\") +\n    geom_ma(ma_fun = SMA, n = 200, color = \"gray\")\n\nacciones %&gt;%\n  filter(symbol == \"TEF\") %&gt;% \n  filter(year(date) &gt; 2022) %&gt;%  \n  ggplot(aes(x = date, y = close, open = open, high = high, low = low, close = close)) +\n  geom_candlestick() +\n  geom_bbands(ma_fun = SMA, sd = 2, n = 20) \n\nSe pueden incorporar todas las funcionalidades habituales de ggplot2 como escalas logarítmicas, geom_smooth(), etc.\nComo hemos visto se pueden utilizar las funciones de transformación de datos de tidyverse; además, tidyquant incluye las funciones tq_mutate() y tq_transmutate() con las que se realizan con mayor facilidad operaciones habituales con este tipo de datos como cambiar la periodicidad, obtener rentabilidades a distintos plazos, cálculos de tendencias mediante medias móviles, cálculos de volatilidad, etc. También se incluye la función tq_performance() para el análisis del comportamiento de una acción o una cartera."
  },
  {
    "objectID": "docs/Tema05ej1.html#scraping-con-rvest",
    "href": "docs/Tema05ej1.html#scraping-con-rvest",
    "title": "Tema 05. Ejercicio 1",
    "section": "Scraping con rvest",
    "text": "Scraping con rvest\nInternet es un gran lugar para obtener datos. Podemos usar rvest para extraer los datos en tablas HTML de la web, pero a menudo requerirá una limpieza extensa antes de usarlo.\nEn la web http://www.boxofficemojo.com/alltime/weekends/ tenemos información sobre las películas con más recaudación en su fin de semana de estreno. Usando rvest podemos traer esta tabla a R.\n\nlibrary(tidyverse)\nlibrary(rvest)\nurl &lt;- \"http://www.boxofficemojo.com/alltime/weekends/\"\n\nPrimero, leemos el contenido de la página en HTML. La función read_html() proporcionada por rvest procesa el HTML:\n\nhtml_bom &lt;- read_html(url)\nhtml_bom\n\nEsto no es muy legible. Además, queremos extraer las tablas dentro del HTML; estas se llaman “table” en html y para esto usamos html_nodes():\n\ntables &lt;- html_bom %&gt;%\n  html_nodes(\"table\")\ntables\n\nEn este caso, solo hay 1 elementos de tipo tabla en esa página .\n\ntables[[1]]\n\nLa función html_table() extraerá los datos de esta tabla y los convertirá en un data frame. La opción header = TRUE indica a R que queremos usar la primera fila como nuestros nombres de variable.\n\nmovies &lt;- tables[[1]] %&gt;%\n  html_table(header = TRUE)\nstr(movies)\n\nEn otrs ocasiones, existen más de una tabla en una página web. Si son pocas se puede determinar cuál nos interesa mediante prueba y error. En particular, en esta caso sabemos que los datos tienen 200 observaciones y 9 columnas; si lo que leemos tiene una dimensiones (obtenidas con str()) muy diferentes no debe ser la tabla que buscamos. En cualquier caso, con muchas tablas en la página web, necesitaremos nuevas herramientas de programación que veremos en breve."
  },
  {
    "objectID": "docs/Tema05ej1.html#limpieza-de-datos",
    "href": "docs/Tema05ej1.html#limpieza-de-datos",
    "title": "Tema 05. Ejercicio 1",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nSi bien ahora tenemos los datos, podemos ver que son muy confusos:\n\nlos nombres de las variables contienen caracteres especiales, como asteriscos, paréntesis y espacios. Esto puede causar problemas, así que queremos cambiarlos.\nla mayoría de las columnas se almacenan como vectores de caracteres, aunque contienen información cuantitativa. En particular, hay columnas para dólares, porcentajes y fechas que están en el formato equivocado.\n\nPor tanto, no podemos analizar adecuadamente la información. Incluso un simple gráfico, no funcionará como se esperaba.\n\nggplot(\n  data = movies, \n  aes(x = Date, y = Opening)\n) + \n  geom_point(aes(size = `% of Total`))\n\nUsaremos parse_number() junto con el verbo mutate() para renombrar las columnas al mismo tiempo.\n\nmovies &lt;- movies %&gt;%\n  mutate(opening = parse_number(Opening),\n         percent_total = parse_number(`% of Total`)/100)\n\nAhora, cuando dibujamos los datos cuantitativos, obtenemos algo que tiene más sentido.\n\nggplot(data = movies, aes(x = Date, y = opening)) + \n  geom_point(aes(size = percent_total))"
  },
  {
    "objectID": "docs/Tema05ej1.html#fechas-con-lubridate",
    "href": "docs/Tema05ej1.html#fechas-con-lubridate",
    "title": "Tema 05. Ejercicio 1",
    "section": "Fechas con lubridate",
    "text": "Fechas con lubridate\nLas fechas están como caracteres en formato mes/día/año. En tidyverse, la biblioteca lubridate ofrece la función mdy() para convertir a tipo de fecha.\n\nmovies &lt;- movies %&gt;%\n  mutate(release_date = mdy(Date))\n\n\nggplot(data = movies, aes(x = release_date, y = opening/1e6)) + \n  geom_point(aes(color = percent_total)) +\n  scale_x_date() +\n  labs(y = \"Recaudación en el Día de Apertura (en millones de $)\",\n       x = \"Fecha de estreno\")"
  },
  {
    "objectID": "docs/Tema05ej1.html#vuestro-ejercicio-1",
    "href": "docs/Tema05ej1.html#vuestro-ejercicio-1",
    "title": "Tema 05. Ejercicio 1",
    "section": "Vuestro Ejercicio",
    "text": "Vuestro Ejercicio\n\nRepetir el ejercicio con la siguiente fuente de información: https://www.the-numbers.com/market/2023/top-grossing-movies. Es decir, debéis extraer los datos relevantes de la web, limpiarlos y dejarlos preparados para trabajar.\n\nNOTA: en ese caso, la tabla tiene dos filas al final que NO tienen información útil, sino que incluye totales (es decir, no tenemos inicialmente datos ordenados).\n\n\n\nUsando esos datos, realizar un BREVE análisis exploratorio de los datos. Crear las variables adicionales que consideréis necesarias con el tipo de datos adecuado. \nDescribid la variación de algunas variables (no todas) y algunas relaciones que consideréis relevantes (p.e., entre género y recaudación o entradas vendidas, entre recaudación y mes o época del años, etc.)."
  },
  {
    "objectID": "docs/Tema01ej.html",
    "href": "docs/Tema01ej.html",
    "title": "Tema 01. Visualización de Datos. Ejercicio.",
    "section": "",
    "text": "Apartado a)\nEl fichero pwt.csv contiene los datos de las Penn World Tables (una famosa fuente de datos macro-económicos). Instalad el paquete de R pwt10. En la ayuda de R, buscad pwt10.01 para una descripción de las primeras 52 columnas; la última es el continente al que pertenece el país.\nEn este apartado, reproduciremos este gráfico de The Economist, donde se relacionaba Corrupción y Desarrollo Humano\n\n\n\nPERO usando otras dos variables que tenga sentido relacionar.\n\nDebéis elegir la información de solo uno de los años disponibles.\nLa reproducción del gráfico es aproximada; p.e., no es necesario que el interior de los puntos esté vacio o colocar el \\(R^2\\)\n\nComentad brevemente la información que ofrece vuestro gráfico.\n\n\nApartado b)\nLa siguiente tabla con datos del PIB (constante a precios de 2015, en miles de millones de dólares) en 2020 para unos cuantos países:\n\n\n\npais\ncontinente\npib\n\n\n\n\nAngola\nAfrica\n81.40\n\n\nGermany\nEurope\n3459.66\n\n\nEgypt, Arab Rep.\nAfrica\n412.21\n\n\nSpain\nEurope\n1176.07\n\n\nFrance\nEurope\n2419.49\n\n\nUnited Kingdom\nEurope\n2830.29\n\n\nGhana\nAfrica\n62.79\n\n\nItaly\nEurope\n1746.02\n\n\nNigeria\nAfrica\n500.23\n\n\nSouth Africa\nAfrica\n338.05\n\n\n\n\n\n´ Mostrar un diagrama de caja de la distribución del PIB para cada continente, sin usar y usando escala logarítmica. Comentar la información que ofrecen ambos gráficos y discutir las razones para las diferencias (ej., posición central y dispersión de las distribuciones).\nNota: realizar algunos ajustes (mínimos) a los gráficos como dar color a los diagramas (asociado al continente), poner título al gráfico, los ejes, etc.\n\n\nApartado c)\nEl fichero hotels.csv contiene información sobre reservas de hoteles, donde cada fila corresponde con una reserva; la información detallada sobre las variables puede encontrarse aquí.\n\nApartado c.1)\nLa columna market_segment contiene información de a qué categoría de los segmentos de mercado pertenece la reserva: Aviation (reservas por aerolíneas), Complementary (reservas de cortesía/gratuitas), Corporate (reservas de Empresas), Direct (reservas directas), Groups (Grupos), Offline TA/TO (Agencia de Viajes/Tour Operador ‘offline’), Online TA (Agencia de Viajes de internter), Undefined (Sin definir). \nUna cadena hotelera está interesada en desarrollar promociones basadas en diferentes segmentos de mercado. Pero primero necesita saber cuántas de las transacciones ocurren para cada segmento de mercado y si esto dependía del tipo de hotel. La variable hotel indica el tipo de hotel: City Hotel (hotel urbano) o Resort Hotel (hotel de vacaciones).\nMostrar una visualización que permita a la cadena hotelera tener la información para tomar decisiones sobre sus promociones. Realizar los ajustes necesarios para que la visualización sea clara y fácil de interpretar: títulos, etiquetas, colores, etc.\n\n\nApartado c.2)\nUn directivo de la empresa afirma que deben centrarse en personas que reservan con antelación, y cree que las personas con hijos tienden a reservar con mayor anticipación. Realice un análisis que permita comprobar si esta afirmación es cierta o no.\nNota: para realizar este análisis, se puede usar la variable lead_time (número de días que transcurren entre la fecha de reserva y la fecha de llegada) y la variable children (número de niños).\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema01ej_123456789.R"
  },
  {
    "objectID": "docs/Tema07.html#introducción",
    "href": "docs/Tema07.html#introducción",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Introducción",
    "text": "Introducción\n\nMCO puede estimar modelos con muchos regresores (ej., polinomios e interacciones para relaciones no lineales), pero ¿qué variables incluimos?\nCuando crece el número de parámetros \\(\\small k\\) relativo al de observaciones \\(\\small n\\):\n\nmenor precisión (+ varianza) \\(\\Rightarrow\\) no solución única de MCO con \\(\\small k&gt;n\\)\nmodelo complejo y menos interpretable\\(\\Rightarrow\\) selección de variables\n\n\n\nSelección de variables: excluir variables irrelevantes y ajustar ese modelo reducido por mínimos cuadrados ordinarios\nRestricción de los coeficientes estimados puede reducir la varianza, a costa de un aumento insignificante del sesgo (Regresión Regularizada/Penalizada) \nReducción de la dimensionalidad: usar \\(\\small M&lt;k\\) combinaciones lineales (proyecciones) y estimar por mínimos cuadrados (PCR, PLS)"
  },
  {
    "objectID": "docs/Tema07.html#ajustes-mediante-penalización",
    "href": "docs/Tema07.html#ajustes-mediante-penalización",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Ajustes mediante penalización",
    "text": "Ajustes mediante penalización\n\nLos métodos de ajuste ofrecen una *estimación indirecta del error de prueba, en la muestra de entrenamiento mediante supuestos (erróneos?)\nEl \\(\\small SCR\\) de entrenamiento siempre se reduce si el modelo es más flexible \\(\\Rightarrow\\) añadir una penalización por número de parámetros\n\nCriterio de Información de Akaike: \\(\\small AIC = \\frac{1}{n}\\left( SCR + 2 k \\widehat{\\sigma}^2 \\right)\\)\n\n\\(\\small \\widehat{\\sigma}^2\\) un estimación de la varianza del error\n\nCriterio de Información Bayesiano: \\(\\small BIC =  \\frac{1}{n}\\left( SCR + log(n) k \\widehat{\\sigma}^2 \\right)\\)\n\\(\\small R^2-ajustado = 1- \\frac{SCR/(n-k-1)}{SCT/(n-1)}\\) \n\n\n\nValidación cruzada ofrece una estimación más directa pero es más costosa (computacionalmente, menor tamaño muestral para estimar)"
  },
  {
    "objectID": "docs/Tema07.html#métodos-de-regularización",
    "href": "docs/Tema07.html#métodos-de-regularización",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Métodos de regularización",
    "text": "Métodos de regularización\n\nEn MCO: \\(\\small \\min_{\\beta} SCR={\\sum_{i=1}^{n}\\left(y-\\widehat{y}\\right)^2}\\)\nEn Regresión Penalizada o Regularizada, se añade una restricción que limite (reduzca) los coeficientes estimados \\[\\small \\min_{\\beta} SCR \\text { sujeto a }R(\\beta) \\leq t\\]\n\ndonde \\(R(\\cdot)\\) es una medida del tamaño de los coeficientes\nNO se penaliza a la constante (media de \\(\\small Y\\)), solo el impacto de \\(\\small X\\)\n\nLa restricción limita la importancia de las \\(\\small X\\) para explicar \\(\\small Y\\): empeora el ajuste (sesgo), pero reduce la varianza \\(\\Rightarrow\\) previene “overfitting”\nPermite ajustar un modelo que contenga todos los regresores"
  },
  {
    "objectID": "docs/Tema07.html#métodos-de-regularización-cont.",
    "href": "docs/Tema07.html#métodos-de-regularización-cont.",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Métodos de regularización (cont.)",
    "text": "Métodos de regularización (cont.)\n\nReescribiendo el problema (Lagrangiano): \\(\\small \\min_{\\beta} SCR+\\lambda R(\\beta)\\)\n\\(\\lambda \\geq 0\\) es un parámetro de ajuste (“tuning parameter”)\n\n\n\n\n\n\n\n\n\nMétodo\nPenalización por tamaño = \\(R(\\boldsymbol{\\beta})\\)\nNorma\n\n\n\n\nMCO\n0\n\n\n\nLASSO\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\\(\\ell_1\\): \\(||\\boldsymbol{\\beta}||_1=\\sum_{j=1}^{k}|\\beta_j|\\)\n\n\nRidge Regression\n\\(\\lVert\\boldsymbol{\\beta}\\rVert_2^2 =\\sum_{j=1}^{k}\\beta_j^2\\)\n\\(\\ell_2\\): \\(||\\boldsymbol{\\beta}||_2=\\sqrt{\\sum_{j=1}^{k}\\beta_j^2}\\)\n\n\nRed Elásica\n\\(\\alpha\\lVert\\boldsymbol{\\beta}\\rVert_1 + (1-\\alpha)\\lVert\\boldsymbol{\\beta}\\rVert_2^2\\)"
  },
  {
    "objectID": "docs/Tema07.html#penalización-de-contracción",
    "href": "docs/Tema07.html#penalización-de-contracción",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Penalización de contracción",
    "text": "Penalización de contracción\n\n\n\nPara un \\(\\small \\lambda\\) dado:\n\n\\(\\small \\widehat{\\beta}^R_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}\\beta_j^2\\)\n\n\\[\n\\small\n\\widehat{\\beta}^L_{\\lambda} = \\arg \\min_\\beta SCR + \\lambda \\sum_{j=1}^{k}|\\beta_j|\n\\]\n\n\nTratamos de ajustarnos a los datos minimizando SCR, PERO se recompensa a los coeficientes cercanos a cero\nPara que todos los coeficientes estén en la misma escala (misma “cercanía a cero), debemos estandarizar los regresores: \\(\\small \\widetilde{x}_{ij} = \\frac{x_{ij}}{\\sqrt{ \\frac{1}{n}\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2}}\\)\n\nRecordar: en MCO, el coeficiente \\(\\small \\beta_j\\) cambia si cambiamos las unidades de \\(\\small X_j\\)"
  },
  {
    "objectID": "docs/Tema07.html#regularización-y-trade-off-sesgo-varianza",
    "href": "docs/Tema07.html#regularización-y-trade-off-sesgo-varianza",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Regularización y “Trade-off” sesgo-varianza",
    "text": "Regularización y “Trade-off” sesgo-varianza\n\n¿Por qué la regularización mejoraría el ajuste sobre MCO?\n\\(\\small \\lambda\\)= importancia de la penalización (cuanto se contraen los coeficientes)\n\n\\(\\small \\lambda\\) pequeño (cercano a MCO): mayor flexibilidad (\\(-\\) sesgo, \\(+\\) varianza)\n\\(\\small \\lambda &gt;&gt; 0\\), todos los coeficientes a cero: menor flexibilidad (\\(+\\) sesgo, \\(-\\) varianza)\n\nRegularización funciona mejor cuando MCO tiene alta varianza: intercambia un poco más de sesgo por una gran reducción de la varianza\n“Ridge Regression” sigue incluyendo todos los regresores (ningún coeficiente exactamente cero): puede complicar la interpretación con muchos\nLASSO (least absolute shrinkage and selection operator): también contrae hacia cero, algunos exactamente cero (selección de variables)"
  },
  {
    "objectID": "docs/Tema07.html#ridge-regression-y-lasso",
    "href": "docs/Tema07.html#ridge-regression-y-lasso",
    "title": "Tema 07 - Selección y Regularización",
    "section": "“Ridge Regression” y LASSO",
    "text": "“Ridge Regression” y LASSO\n\n\n\n\n\n\n\n\n“Ridge regression” domina con muchos regresores igualmente importantes\nLASSO con pocos regresores importantes y muchos inútiles\nLASSO es una alternativa a los contrastes de significatividad (sin formalización estadística)\n\n\n\n\nNotad que LASSO es un método orientado a la predicción: NO se debe usar para afirmaciones de causalidad (los coeficientes están sesgados)\nPERO se puede estimar por MCO la especificación de variables seleccionada por LASSO"
  },
  {
    "objectID": "docs/Tema07.html#eligiendo-el-hiper-parámetro-de-ajuste",
    "href": "docs/Tema07.html#eligiendo-el-hiper-parámetro-de-ajuste",
    "title": "Tema 07 - Selección y Regularización",
    "section": "Eligiendo el (hiper-)parámetro de ajuste",
    "text": "Eligiendo el (hiper-)parámetro de ajuste\n\nElegir un rango de valores para \\(\\small \\lambda\\)\nCalcular el error mediante validación cruzada para cada valor de \\(\\small \\lambda\\)\nSeleccionar el valor con menor error (probar varios rangos para encontrar forma de U)\nVolver a ajustar el modelo usando todas las observaciones y el valor del parámetro de ajuste seleccionado.\n\n\nVentaja sobre la selección de regresores: SOLO necesitamos ajustar un modelo para cada valor de \\(\\small \\lambda\\)\nRegla de parquedad paramétrica: dado un conjunto de modelos igualmente buenos (dentro de un error estándar del menor error), elegir el más simple"
  },
  {
    "objectID": "docs/Tema07.html#glmnet-para-regresión-lineal",
    "href": "docs/Tema07.html#glmnet-para-regresión-lineal",
    "title": "Tema 07 - Selección y Regularización",
    "section": "glmnet para regresión lineal",
    "text": "glmnet para regresión lineal\n\nlibrary(mosaicData)\nlibrary(glmnet)\n\nx &lt;- model.matrix(data = RailTrail, \n          volume ~ cloudcover + weekday + precip + poly(hightemp, 6))\n\nfit.lmreg &lt;- glmnet(x = x, y = RailTrail$volume, \n                    family=\"gaussian\", \n                    lambda=2, alpha=.5)\n\nfit.lmreg$beta\n\n\nElegimos el parámetro de regularización mediante validación cruzada\n\n\nset.seed(1)\ncv.glmnet(x, RailTrail$volume) %&gt;% plot()\ncv.glmnet(x, RailTrail$volume)"
  },
  {
    "objectID": "docs/Tema07.html#glmnet-para-regresión-logística",
    "href": "docs/Tema07.html#glmnet-para-regresión-logística",
    "title": "Tema 07 - Selección y Regularización",
    "section": "glmnet para regresión logística",
    "text": "glmnet para regresión logística\n\ncenso &lt;- read_csv(\"data/census.csv\") %&gt;%\n  mutate(across(where(is.character), ~parse_factor(.x)),\n         income = if_else(income == \"&gt;50K\", 1,  0))\n\nx &lt;- model.matrix(data = censo, \n      income ~ poly(age, 3) + log(hours_per_week)*sex +\n        education_1*race + occupation*workclass)\n\nfit.glmreg &lt;- glmnet(x = x, y = censo$income,\n                     family = \"binomial\", \n                     lambda=0.001, alpha=1)\nfit.glmreg$beta\n\n\nValidación cruzada para elegir parámetro de regularización\n\n\nset.seed(1)  \ncv.glmnet(x, censo$income)\ncv.glmnet(x, censo$income) %&gt;% plot()"
  },
  {
    "objectID": "docs/Tema09ej1.html",
    "href": "docs/Tema09ej1.html",
    "title": "Tema 09. Ejemplo 1",
    "section": "",
    "text": "En este ejemplo, utilizamos el conjunto de datos descuento.csv. Tenemos información de las ventas realizadas a un cliente y algunas características de éste:\n\n\n\n\n\n\n\n\nVariable\nTipo\nDescripción\n\n\n\n\nventas\nNumérica\nVentas registradas (en euros).\n\n\nrenta\nNumérica\nRenta disponible del cliente (en euros).\n\n\ndescuento\nCategórica\n¿Ha recibido descuento? (1 = sí, 0 = no).\n\n\nzona\nCategórica\nZona de residencia: “ciudad”, “capital” o “pueblo”.\n\n\nedad\nNumérica\nEdad del cliente (en años).\n\n\nmujer\nCategórica\nGénero del cliente (1 = mujer, 0 = hombre).\n\n\neduc\nNumérica\nNivel educativo del cliente (en años).\n\n\n\n\n\n\nCargamos los datos y les damos el tipo de variable adecuado\n\n\nlibrary(tidyverse)\ndescuento &lt;- read_csv(\"data/descuento.csv\") %&gt;% \n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))"
  },
  {
    "objectID": "docs/Tema09ej1.html#carga-de-datos",
    "href": "docs/Tema09ej1.html#carga-de-datos",
    "title": "Tema 09. Ejemplo 1",
    "section": "",
    "text": "Cargamos los datos y les damos el tipo de variable adecuado\n\n\nlibrary(tidyverse)\ndescuento &lt;- read_csv(\"data/descuento.csv\") %&gt;% \n        mutate(zona = parse_factor(zona), mujer = as.factor(mujer))"
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "href": "docs/Tema09ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 0: Partición en Entrenamiento y Prueba",
    "text": "Paso 0: Partición en Entrenamiento y Prueba\n\nUsamos initial_split() para generar el objeto que almacena las dos particiones\n\n\nlibrary(tidymodels)\n\nset.seed(123)\ndescuentoPart &lt;- initial_split(descuento, prop = 0.8)"
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-1-preparar-los-datos-y-especificación",
    "href": "docs/Tema09ej1.html#paso-1-preparar-los-datos-y-especificación",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\nCon árboles no necesitamos estandarizar ni incluir transformaciones no lineales ni discretizar (puesto que el procedimiento ya discretiza variables continuas y, por tanto, tiene en cuenta relaciones no lineales) ni crear dummies.\nVamos a estimar dos modelos de árboles: con la variable dependiente en niveles y en logaritmos\n\nreceta1 &lt;- descuentoPart %&gt;% training() %&gt;% \n  recipe(ventas ~ renta + descuento + zona + edad + mujer + educ)\n\nreceta2 &lt;- receta1 %&gt;% \n  step_log(ventas)"
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-2-entrenamiento",
    "href": "docs/Tema09ej1.html#paso-2-entrenamiento",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\n\nDefinimos un modelo de árboles de decisión, preparando para ajustar los hiperparámetros. Es igual para ambas especificaciones.\nCon la biblioteca rpart, podemos ajustar varios hiperparámetros. En este ejemplo, consideraremos solo el coste de complejidad. Los otros dos hiperparámetros (mínimo de observaciones en un nodo final y profundidad del árbol) son parcialmente sustitutivos del coste de complejidad: mayor complejidad equivale a árboles con más observaciones en el nodo final y/o mayor profundidad. Los valores de esto dos hiperparámetros no especificados se fijan en sus valores por defectos: min_n = 2 y tree_depth = 20.\n\n\nmodelo_arbol  &lt;- decision_tree(mode= \"regression\", engine = \"rpart\", \n                             cost_complexity = tune())\n\n\n\nPaso 2.B: Creación del flujo de trabajo\nCreamos los flujos de trabajo combinando la receta y modelo\n\nflujo_arbol1 &lt;- workflow() %&gt;%\n  add_recipe(receta1) %&gt;%      \n  add_model(modelo_arbol)\n\n\nflujo_arbol2 &lt;- workflow() %&gt;%\n  add_recipe(receta2) %&gt;%      \n  add_model(modelo_arbol)\n\n\n\nPaso 2.C: Estimación del flujo\n\nPaso 2.C.1: Ajuste del hiperparámetros\n\nDefinimos las particiones de validación cruzada en la muestra de entrenamiento que vamos a utilizar, para ambos casos:\n\n\nset.seed(9753)\ndescuento_entrenCV &lt;- descuentoPart %&gt;% training() %&gt;% \n                          vfold_cv(v=10)\n\n\n\nProceso de ajuste para la especificación en niveles\n\nDeberíamos realizar una búsqueda probando varios rangos y valores para el hiperparámetro.\n\n\narbol_grid1 &lt;- grid_regular(cost_complexity(range = c(0, 0.0005), trans = NULL), \n                                   levels = 21)\n\n\nflujo_arbol1_ajust &lt;- flujo_arbol1 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = arbol_grid1            )\n\nflujo_arbol1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nA veces, encontramos este tipo de situaciones “raras”. Como este modelo es poco complejo (pocas variables), el coste de complejidad es bajo; de hecho, el óptimo puede ser cero. Se podría probar fijar este a cero e intentar ajustar otro de los hiperparámetros. Recordad que en nuestro caso (por la poca potencia de nuestros ordenadores) no conviene intentar ajustar más de un hiperparámetro a la vez.\n\n\nflujo_arbol1_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_cc1 &lt;- flujo_arbol1_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nProceso de ajuste para la especificación en logaritmos\n\narbol_grid2 &lt;- grid_regular(cost_complexity(range = c(0, 0.0005), trans = NULL), \n                                   levels = 21)\n\n\nflujo_arbol2_ajust &lt;- flujo_arbol2 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = arbol_grid2            )\n\nflujo_arbol2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nflujo_arbol2_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_cc2 &lt;- flujo_arbol2_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nPaso 2.C.2: Finalizando y estimando\n\nModelo en niveles\n\nFinalizamos el flujo para estimar con todos los datos\n\n\nflujo_arbol1_final &lt;- flujo_arbol1 %&gt;% \n        finalize_workflow(mejor_cc1)  \n\n\nflujo_arbol1_final_est &lt;-  flujo_arbol1_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\n\n\nEn este caso, NO tenemos coeficientes estimados que mostrar. En su lugar podemos, mostrar un gráfico del árbol\n\n\nlibrary(rpart.plot)\narbol1 &lt;- flujo_arbol1_final_est %&gt;% extract_fit_parsnip() \nrpart.plot(arbol1$fit)  \n\n\n\n\n\n\n\n\nTambién podemos calcular y mostrar la importancia de cada variable según este modelo:\nlibrary(vip)\narbol1 %&gt;% vi() %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nVariable\nImportance\n\n\n\n\nmujer\n870671870\n\n\nedad\n577980853\n\n\nrenta\n372403114\n\n\neduc\n142939568\n\n\ndescuento\n91344763\n\n\nzona\n17168240\n\n\n\n\n\narbol1 %&gt;% vip()\n\n\n\nModelo en logaritmos\n\nflujo_arbol2_final &lt;- flujo_arbol2 %&gt;% \n        finalize_workflow(mejor_cc2)  \n\n\nflujo_arbol2_final_est &lt;-  flujo_arbol2_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\n\n\nlibrary(rpart.plot)\narbol2 &lt;- flujo_arbol2_final_est %&gt;% extract_fit_parsnip() \nrpart.plot(arbol2$fit)  \n\n\n\n\n\n\n\n\nlibrary(vip)\narbol2 %&gt;% vi() %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nVariable\nImportance\n\n\n\n\nedad\n74.8171777\n\n\nmujer\n38.6429128\n\n\nrenta\n19.5700764\n\n\neduc\n5.9275087\n\n\ndescuento\n4.0170028\n\n\nzona\n0.9764054\n\n\n\n\n\narbol2 %&gt;% vip()\n\n\n\nNOTA 1\nEn los modelos de regresión lineal y regresión logística y en sus versiones de regresión regularizada también podemos calcular la medida de importancia de cada variable. Se obtiene como el valor absoluto del coeficiente (siempre que todas las variables hayan sido estandarizadas) o el valor absoluto del estadístico \\(t\\).\n\n\nNOTA 2\n¿Qué árbol obtendríamos si fijamos manualmente el valor del coste de complejidad?\n\nflujo_arbol1_final2 &lt;- flujo_arbol1 %&gt;% \n        finalize_workflow(list(cost_complexity=0.05))\nflujo_arbol1_final2_est &lt;-  flujo_arbol1_final2 %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\narbol1.2 &lt;- flujo_arbol1_final2_est %&gt;% extract_fit_parsnip() \n\nrpart.plot(arbol1.2$fit) \n\nNotad que aumentar el coste de complejidad implica un árbol más sencillo; en particular, se utilizan menos variables, como sucede al aumentar la penalización en LASSO. Incluso el árbol más completo (con coste de complejidad cero) no utiliza todas las variables, porque algunas nunca son relevantes para realizar la partición en un nodo."
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-0-partición-en-entrenamiento-y-prueba-1",
    "href": "docs/Tema09ej1.html#paso-0-partición-en-entrenamiento-y-prueba-1",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 0: Partición en Entrenamiento y Prueba",
    "text": "Paso 0: Partición en Entrenamiento y Prueba\n\nUsamos la misma partición de antes"
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-1-preparar-los-datos-y-especificación-1",
    "href": "docs/Tema09ej1.html#paso-1-preparar-los-datos-y-especificación-1",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\n\nUsamos las mismas recetas"
  },
  {
    "objectID": "docs/Tema09ej1.html#paso-2-entrenamiento-1",
    "href": "docs/Tema09ej1.html#paso-2-entrenamiento-1",
    "title": "Tema 09. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\nDefinimos un modelo de “random forests”, preparando para ajustar los hiperparámetros. Es igual para ambas especificaciones.\n\nCon la biblioteca ranger, tenemos dos posibles hiperparámetros: número de regresores que se usan aleatoriamente en cada árbols, mtry, y mínmo número de observaciones en un nodo final, min_n. Si no los ajustamos ni fijamos su valor, se usan los valores por defecto: mtry\\(\\sqrt{k}\\), donde \\(k\\) es el número de regresores y min_n = 5 para regresión o 10 para clasificación.\n\n\nlibrary(ranger)\nmodelo_RF  &lt;- rand_forest(mode = \"regression\", \n                          trees = 100,\n                          mtry = tune()) %&gt;% \n                set_engine(\"ranger\", importance = \"permutation\")\n\n\n\nPaso 2.B: Creación del flujo de trabajo\nCreamos los flujos de trabajo combinando la receta y modelo\n\nflujo_RF1 &lt;- workflow() %&gt;%\n  add_recipe(receta1) %&gt;%      \n  add_model(modelo_RF)\n\n\nflujo_RF2 &lt;- workflow() %&gt;%\n  add_recipe(receta2) %&gt;%      \n  add_model(modelo_RF)\n\n\n\nPaso 2.C: Estimación del flujo\n\nPaso 2.C.1: Ajuste del hiperparámetros\n\nUsamos las particiones de validación cruzada anteriores.\n\n\n\nProceso de ajuste para la especificación en niveles\n\nDeberíamos realizar una búsqueda probando varios rangos y valores para el hiperparámetro.\n\n\nRF_grid1 &lt;- grid_regular(mtry(range = c(2, 6), trans = NULL), \n                                   levels = 5)\n\n\nflujo_RF1_ajust &lt;- flujo_RF1 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = RF_grid1            )\n\nflujo_RF1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nflujo_RF1_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_m1 &lt;- flujo_RF1_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nProceso de ajuste para la especificación en logaritmos\n\nRF_grid2 &lt;- grid_regular(mtry(range = c(2, 6), trans = NULL), \n                                   levels = 5)\n\n\nflujo_RF2_ajust &lt;- flujo_RF2 %&gt;% \n                        tune_grid(resamples = descuento_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = RF_grid2            )\n\nflujo_RF2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nflujo_RF2_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_m2 &lt;- flujo_RF2_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nPaso 2.C.2: Finalizando y estimando\n\nModelo en niveles\n\nFinalizamos el flujo para estimar con todos los datos\n\n\nflujo_RF1_final &lt;- flujo_RF1 %&gt;% \n        finalize_workflow(mejor_m1)  \n\n\nflujo_RF1_final_est &lt;-  flujo_RF1_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\n\n\nEn este caso, NO tenemos coeficientes estimados ni tampoco un único gráfico que mostrar. Podemos mostrar la importancia de cada variable según el modelo:\n\nRF1 &lt;- flujo_RF1_final_est %&gt;% extract_fit_parsnip() \nlibrary(vip)\nRF1 %&gt;% vi() %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nVariable\nImportance\n\n\n\n\nmujer\n4536817.17\n\n\nedad\n3437414.19\n\n\nrenta\n2201606.52\n\n\neduc\n81735.80\n\n\ndescuento\n41977.59\n\n\nzona\n13938.53\n\n\n\n\n\nRF1 %&gt;% vip()\n\n\n\nModelo en logaritmos\n\nflujo_RF2_final &lt;- flujo_RF2 %&gt;% \n        finalize_workflow(mejor_m2)  \n\n\nflujo_RF2_final_est &lt;-  flujo_RF2_final %&gt;%  \n              fit(data = descuentoPart %&gt;% training())\n\nRF2 &lt;- flujo_RF2_final_est %&gt;% extract_fit_parsnip() \nlibrary(vip)\nRF2 %&gt;% vi() %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nVariable\nImportance\n\n\n\n\nedad\n0.4169394\n\n\nmujer\n0.2332479\n\n\nrenta\n0.1037592\n\n\neduc\n0.0030944\n\n\ndescuento\n0.0026859\n\n\nzona\n0.0005298\n\n\n\n\n\nRF2 %&gt;% vip()"
  },
  {
    "objectID": "docs/Tema09.html#estratificación-para-asociaciones-no-lineales",
    "href": "docs/Tema09.html#estratificación-para-asociaciones-no-lineales",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Estratificación para asociaciones no lineales",
    "text": "Estratificación para asociaciones no lineales\n\n\n\nEjemplo: relación no lineal entre las ventas y la edad\n\n\nCuantos más particiones, mejor ajuste.\nPERO ¿dónde dividimos?, ¿cuántas particiones?\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsta cuestión también aplica a las interacciones entre variables para capturar heterogeneidad del efecto de una variable: ¿cuántas interacciones? ¿con cuántos intervalos?"
  },
  {
    "objectID": "docs/Tema09.html#árboles-de-decisión",
    "href": "docs/Tema09.html#árboles-de-decisión",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Árboles de decisión",
    "text": "Árboles de decisión\n\nUn árbol de decisión es un diagrama de flujo con reglas para segmentar el espacio de regresores en regiones más simples y clasificar observaciones"
  },
  {
    "objectID": "docs/Tema09.html#árboles-de-regresión",
    "href": "docs/Tema09.html#árboles-de-regresión",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Árboles de Regresión",
    "text": "Árboles de Regresión\n\n¿Cómo construimos estos árboles para una variable cuantitativa?\n\nDividir el espacio de predicción, \\(\\small x_1, x_2, \\dots, x_p\\) en regiones \\(\\small J\\) distintas y no superpuestas, \\(\\small R_1, R_2, \\dots, R_J\\)\n\ncada vez más homogéneas o “puras”: como todos los modelos, mismas características, mismo valor esperado de \\(y\\)\n\nCada observación que caiga en la región \\(\\small R_j\\) tiene el mismo valor predicho: la media de \\(\\small y\\) para las observaciones de entrenamiento en \\(\\small R_j\\), \\(\\small \\widehat{y}_{i\\in R_j}= \\bar{y}_{R_j}\\)\n\nEs INVIABLE considerar todas las particiones en \\(\\small J\\) regiones \nAlternativas heurísticas: un algoritmo “voraz” elige una opción localmente óptima en cada paso con la esperanza de llegar a una solución general óptima\n\n(en lugar de elegir la mejor partición para un paso futuro)"
  },
  {
    "objectID": "docs/Tema09.html#partición-binaria-recursiva",
    "href": "docs/Tema09.html#partición-binaria-recursiva",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Partición binaria recursiva",
    "text": "Partición binaria recursiva\n\nEn la parte alta, todas las observaciones pertenecen a una sola región\nSe divide sucesivamente cada región en dos ramas: \\(\\small R_1(j,s) = \\{X|X_j &lt; s\\}\\) y \\(\\small R_2(j,s) = \\{X|X_j \\geq s\\}\\)\n\nEn cada nodo, se consideran todos los regresores \\(\\small X_j\\) y todos los umbrales \\(s\\)\nSe calcula el error de predicción por particionar de esa manera \\(\\small SCR_{j,s} = \\sum_{i\\in R_1(j,s)}(y_i-\\widehat{y}_{R_1})^2 + \\sum_{i\\in R_2(j,s)}(y_i-\\widehat{y}_{R_2})^2\\)\nSOLO una partición en cada iteración: se elige \\(\\small j\\) y \\(\\small s\\) con menor \\(\\small SCR_{j,s}\\) \n\nRepetimos el proceso particionando cada región de la iteración anterior \nSe continua hasta que se cumpla un criterio de parada; p.e., ninguna región contiene más de \\(5\\) observaciones"
  },
  {
    "objectID": "docs/Tema09.html#podar-un-árbol-pruning",
    "href": "docs/Tema09.html#podar-un-árbol-pruning",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Podar un árbol (pruning)",
    "text": "Podar un árbol (pruning)\n\nEvitar árboles demasiados complejos (“overfitting”)\nHacer crecer un árbol “grande” con \\(\\small T_0\\) nodos terminales y podarlo para quedarnos con un sub-árbol con \\(\\small T\\) nodos terminales \\[\n\\small\nmin \\sum_{m=1}^T \\sum_{i \\in R_m} (y_i-\\widehat{y}_{R_m})^2 + \\alpha |T|\n\\] donde \\(\\small R_m\\) es la región de \\(\\small m\\)-nodo terminal\n\\(\\small \\alpha\\) es el hiperparámetro de coste de complejidad de la poda, elegido por validación cruzada\nDisyuntiva entre más o menos nodos finales: mejor ajuste (menor SCR) frente a mayor penalización por complejidad"
  },
  {
    "objectID": "docs/Tema09.html#árboles-de-clasificación",
    "href": "docs/Tema09.html#árboles-de-clasificación",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Árboles de clasificación",
    "text": "Árboles de clasificación\n\nPara un árbol de clasificación, se predice que cada observación pertenece a la clase más común en la región a la que pertenece en entrenamiento\nTambién se pueden obtener la proporción de una clase \\(\\small k\\) dentro de una región particular \\(\\small m\\) de nodos terminales: \\(\\small \\widehat{p}_{mk}\\)\nLa métrica usada para hacer crecer los árboles NO puede ser SCR\n\n\nÍndice de Gini: medida de la varianza entre clases \\(\\small\nG=\\sum_{k=1}^{K}\\widehat{p}_{mk}(1-\\widehat{p}_{mk})\\)\nEntropía (cruzada) \\(\\small\nD=\\sum_{k=1}^{K}\\widehat{p}_{mk}log(\\widehat{p}_{mk})\\)\n\n\nAmbos son medidas de “pureza” del nodo: un valor pequeño indica que la región contiene en su mayoría observaciones de una sola clase."
  },
  {
    "objectID": "docs/Tema09.html#algoritmos-para-árboles-e-hiperparámetros",
    "href": "docs/Tema09.html#algoritmos-para-árboles-e-hiperparámetros",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Algoritmos para árboles e hiperparámetros",
    "text": "Algoritmos para árboles e hiperparámetros\n\nMotores para árboles: rpart (defecto), spark y C5.0 (solo clasificación)\nDepende de varios hiperparámetros elegidos por tuning\n\nmin_n: mínimo número de observaciones en un nodo parar dividirse más\ntree_depth: máx. número de niveles de profundidad del árbol (no C5.0)\ncost_complexity: coste de complejidad (sólo rpart)\n\n\n\nmodelo_arbol  &lt;- decision_tree(mode = \"classification\", \n                               engine = \"rpart\", \n                               cost_complexity = .01)\n\n\nPodemos visualizar un modelo árbol estimado con la biblioteca rpart.plot\n\n\nlibrary(rpart.plot)\narbol &lt;- flujo_arbol_est %&gt;% extract_fit_parsnip() \nrpart.plot(arbol$fit)"
  },
  {
    "objectID": "docs/Tema09.html#comentarios",
    "href": "docs/Tema09.html#comentarios",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Comentarios",
    "text": "Comentarios\n\n\nPredicción: media o clase mayoritaria de las observaciones de entrenamiento en el nodo terminal que corresponde a una observación nueva\nImportancia de las variables: la biblioteca vip proporciona métricas sobre la influencia de cada predictor en las predicciones del modelo\n\nalgunas son específicas de un modelo: en árboles, la reducción total de la SCR o Gini debida a las particiones que usan una variable\notras generales: basadas en permutaciones, o en medidas de Shapley\n\n\n\nVentajas de los árboles de decisión:\n\najusta (no paramétricamente) relaciones no lineales/complejas\nno requieren dummies ni transformaciones no lineales \nfáciles de explicar y visualizar\n\n\n\nDesventajas: overfit (no robustos a cambios en los datos) y bajo poder de predicción"
  },
  {
    "objectID": "docs/Tema09.html#bagging",
    "href": "docs/Tema09.html#bagging",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Bagging",
    "text": "Bagging\n\nAgregación de Bootstrap (bagging): procedimiento general para reducir la varianza, promediando \\(\\small \\{x_i\\}_{i=1}^n iid \\sim (\\mu, \\sigma^2) \\Rightarrow \\bar{x} \\sim (\\mu, \\sigma^2/n)\\)\nPodemos tomar \\(B\\) re-muestras del único conjunto de entrenamiento\n\n\nEn lugar de un único árbol complejo, se combinan muchos árboles diversos que pueden reflejar patrones sutiles\nLa variación muestral en las condiciones de “entrenamiento” se genera mediante “bootstrap”"
  },
  {
    "objectID": "docs/Tema09.html#random-forest",
    "href": "docs/Tema09.html#random-forest",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "“Random forest”",
    "text": "“Random forest”\n\n\nEs un algoritmo específico de agregación de árboles que introduce aleatorización para eliminar correlación entre los árboles.\n\nSe construyen varios árboles en muestras de entrenamiento de bootstrap\nEn cada partición de un árbol, se seleccionan aleatoriamente \\(\\small m \\approx \\sqrt{k}\\quad\\) regresores del total\nSe mitiga la influencia de regresores fuertes, permitiendo una mayor diversidad en los árboles agregados\n\n\n\nMejor predicción a costa de la interpretación \\(\\Longrightarrow\\) métodos de interpretabilidad ex-post para aprendizaje automático: importancia, Shapley values, partial dependence plots (PDP)\n\nLa importancia se puede calcular como una media en los distintos árboles.\n\nDe manera similar a los p-valores o LASSO, la importacia destaca qué variables considerar en modelos más interpretables, como regresión o árboles"
  },
  {
    "objectID": "docs/Tema09.html#algoritmos-para-rf-e-hiperparámetros",
    "href": "docs/Tema09.html#algoritmos-para-rf-e-hiperparámetros",
    "title": "Tema 09 - Métodos basados en árboles",
    "section": "Algoritmos para RF e hiperparámetros",
    "text": "Algoritmos para RF e hiperparámetros\n\nMotores principales para RF en R: ranger, randomForest y spark\n\n\nDepende de trees, números de árboles, a considerar en la agregación (no genera “overfitting”) y de dos hiperparámetros\n\nmtry: número de variables a considerar en cada partición\nmin_n: igual que en árboles\n\n\n\nlibrary(ranger)\nmodelo_RF  &lt;- rand_forest(mode = \"regression\", trees = 100,\n                          mtry = 3, min_n = 5) %&gt;% \n              set_engine(\"ranger\", importance = \"permutation\")\n              # importance = \"impurity\" en clasificación\n\nRF &lt;- flujo_RF_est %&gt;% extract_fit_parsnip()\nRF$fit$variable.importance\nlibrary(vip)\nRF %&gt;% vip()"
  },
  {
    "objectID": "docs/Tema00ej1.html",
    "href": "docs/Tema00ej1.html",
    "title": "Tema 0. Introducción a R. Ejercicio 1",
    "section": "",
    "text": "En este ejercicio vamos a practicar los conceptos básicos de R. Debéis escribir un archivo de código de R con los comandos necesarios para responder a los siguientes ejercicios. Podéis encontrar una plantilla aquí\n\n\nApartado 1\nEl archivo Ventas1.xlsx contiene las ventas de dos tiendas, A y B, de Lunes a Viernes. Calcular las ventas totales (sumando ambas tiendas) para cada día, las ventas totales de ambas tiendas en toda la semana y las ventas medias de la semana de la tienda A.\nNOTA: se recomienda crear un proyecto de RStudio y guardar el archivo Ventas1.xlsx en la carpeta.\n\n\nApartado 2\n\nLos archivos Ventas2a.xlsx y Ventas2b.xlsx contiene el valor de las ventas de tres productos cada uno, a nivel nacional y a nivel internacional (en millones de euros). Combinar ambos conjuntos de datos en uno solo con las información de todos los productos.\n\n\nAñadir una columna con el valor total de las ventas (nacionales más internacionales) de cada producto.\n\n\nCalcular la media del valor de las ventas internacionales (media sobre todos los productos) y la media del valor de las ventas nacionales pero solo para los productos X, Y y R.\n\n\nSe quiere conocer el número de compradores de los productos a partir del valor de las ventas y la información de los precios de los productos disponible en la siguiente tabla:\n\n\n\n\n\nPrecioNac\nPrecioInt\n\n\n\n\nX\n5.2\n4.2\n\n\nY\n4.7\n4.3\n\n\nZ\n5.7\n4.2\n\n\nR\n6.1\n4.5\n\n\nS\n7.0\n4.9\n\n\nT\n6.7\n4.8\n\n\n\n\n\n\n\nApartado 3\n\nEl conjunto de datos mtcars está incluido en R por defecto; buscar en la ayuda de RStudio mtcars para conocer las variables que incluye. Comprobar la estructura con str() y visualizar las primeras observaciones con head().\n\nGenerar la variable (escalar) Datsun710_CV con los caballos de potencia del coche modelo Datsun 710.\nGenerar el vector Valiant_vector con toda la información (esto es, variables) disponibles sobre el coche modelo Valiant.\n\n\n\nGenerar el vector cilindros con la información para todos los modelos de coche de la variable sobre el número de cilindros. Generar el vector cambio_vector con la información de la variable de tipo de cambio (manual o automático) de todos los modelos de coche Mazda y Hornet.\n\n\nGenerar media_consumo_autom con el consumo medio de los coches con cambio automático. Generar media_consumo_autom_cyl4 con el consumo medio de los coches con cambio automático y cuatro cilindros.\n\n\n\nEntrega del ejercicio\nRellenad este FORMULARIO con vuestros datos y subid\n\nvuestro archivo de R\n\nIMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,\n\nTema00ej1_123456789.R"
  },
  {
    "objectID": "docs/Tema08ej1.html",
    "href": "docs/Tema08ej1.html",
    "title": "Tema 08. Ejemplo 1",
    "section": "",
    "text": "Usaremos el conjunto de datos RailTrail, que ya usamos previamente, sobre el volumen de usuarios de un camino ciclista (“via verde”).\n\nlibrary(tidyverse)\nlibrary(mosaicData)\nlibrary(kableExtra)\ndata(\"RailTrail\")"
  },
  {
    "objectID": "docs/Tema08ej1.html#datos",
    "href": "docs/Tema08ej1.html#datos",
    "title": "Tema 08. Ejemplo 1",
    "section": "",
    "text": "Usaremos el conjunto de datos RailTrail, que ya usamos previamente, sobre el volumen de usuarios de un camino ciclista (“via verde”).\n\nlibrary(tidyverse)\nlibrary(mosaicData)\nlibrary(kableExtra)\ndata(\"RailTrail\")"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "href": "docs/Tema08ej1.html#paso-0-partición-en-entrenamiento-y-prueba",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 0: Partición en Entrenamiento y Prueba",
    "text": "Paso 0: Partición en Entrenamiento y Prueba\nPartición en Entrenamiento y Prueba\n\nUsamos initial_split() para generar el objeto que almacena las dos particiones\n\n\nlibrary(tidymodels)\nset.seed(9753)\nrailtrailPart &lt;- railtrail %&gt;% \n                    initial_split(prop = .8)\n\n\nPodríamos extraer los data frame con cada conjunto de datos, de entrenamiento y de prueba. Pero esto no es necesario porque siempre podemos llamar a las funciones training() y testing().\n\n\nrailtrailEntren  &lt;- railtrailPart %&gt;% training()\nrailtrailPrueba  &lt;- railtrailPart %&gt;% testing()"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación",
    "href": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\nEn principio, consideraremos la siguiente especificación, es decir, variables incluidas en el modelo. Dado lo que hemos discutido anteriormente (que habríamos visto en el análisis exploratorio de datos), incluimos un polinomio para temperatura, una relación no lineal con la nubosidad e interacciones entre todas las variables continuas y el tipo de día de la semana.\n\\[\n\\begin{aligned}\nvolumen &= \\beta_0 + \\beta_1 hightemp + \\beta_2 hightemp^2 + \\dots + \\beta_{21} hightemp^{21}  \\\\\n        & + \\beta_{22} D_{cloudclover \\in (2.5,5]}+\\beta_{23} D_{cloudclover \\in (5,7.5]}+\\beta_{24} D_{cloudclover \\in (7.5,10]} \\\\\n        &+ \\beta_{25} precip + \\beta_{26} dayType + \\beta_{27} precip \\times dayType + u\n\\end{aligned}\n\\]\nEsta especificación se corresponde con la siguiente receta:\n\nreceta1 &lt;-railtrailPart %&gt;% training() %&gt;%             \n  recipe(volume ~  hightemp + cloudcover + precip +  dayType) %&gt;%\n  step_dummy(dayType) %&gt;% \n  step_poly(hightemp, degree = 21) %&gt;%   \n  step_cut(cloudcover, breaks = c(0, 2.5, 5, 7.5, 10), \n           include_outside_range = T)  %&gt;% \n  step_dummy(cloudcover) %&gt;% \n  step_interact(~precip:starts_with(\"dayType_\"))\n\nPodemos ver cómo quedan los datos preprocesados para usarlos luego en el modelo de esta forma:\n\ndatosPrep &lt;- receta1 %&gt;%  prep() %&gt;% bake(railtrailEntren)\ndatosPrep %&gt;% slice_head() %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nprecip\nvolume\ndayType_weekend\nhightemp_poly_1\nhightemp_poly_2\nhightemp_poly_3\nhightemp_poly_4\nhightemp_poly_5\nhightemp_poly_6\nhightemp_poly_7\nhightemp_poly_8\nhightemp_poly_9\nhightemp_poly_10\nhightemp_poly_11\nhightemp_poly_12\nhightemp_poly_13\nhightemp_poly_14\nhightemp_poly_15\nhightemp_poly_16\nhightemp_poly_17\nhightemp_poly_18\nhightemp_poly_19\nhightemp_poly_20\nhightemp_poly_21\ncloudcover_X.2.5.5.\ncloudcover_X.5.7.5.\ncloudcover_X.7.5.max.\nprecip_x_dayType_weekend\n\n\n\n\n0\n287\n0\n-0.2453388\n0.3215624\n-0.2978088\n0.2259474\n-0.1921686\n0.1818106\n-0.1878811\n0.1623743\n-0.1188715\n0.0997763\n-0.1085769\n0.096653\n-0.0650102\n0.0357273\n-0.0184597\n0.0074644\n-0.0030106\n0.0012088\n-0.0005804\n0.0002402\n-9.98e-05\n0\n0\n0\n0"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-2-entrenamiento",
    "href": "docs/Tema08ej1.html#paso-2-entrenamiento",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\nDefinimos un modelo lineal\n\nmodelo_lm1  &lt;- linear_reg(mode= \"regression\", engine = \"lm\", \n                             penalty = 0)\n\n\n\nPaso 2.B: Creación del flujo de trabajo\nCreamos el flujo de trabajo combinando la receta y modelo\n\nflujo_lm1 &lt;- workflow() %&gt;%\n  add_recipe(receta1) %&gt;%      \n  add_model(modelo_lm1)\n\n\n\nPaso 2.C: Estimación del flujo\n\nEstimamos el flujo\n\n\nflujo_lm1_est &lt;- flujo_lm1 %&gt;% \n                   fit(data = railtrailPart %&gt;% training()) \n\n\nLos resultados de esta estimación son:\n\n\nflujo_lm1_est %&gt;% extract_fit_parsnip() %&gt;% \n  tidy() %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n398.3618778\n30.45639\n13.0797462\n0.0000000\n\n\nprecip\n-101.8519213\n44.22143\n-2.3032256\n0.0260516\n\n\ndayType_weekend\n69.0130077\n30.19285\n2.2857404\n0.0271425\n\n\nhightemp_poly_1\n620.0779680\n100.48002\n6.1711570\n0.0000002\n\n\nhightemp_poly_2\n-231.1870251\n102.56389\n-2.2540781\n0.0292222\n\n\nhightemp_poly_3\n-319.5934391\n112.86361\n-2.8316785\n0.0069576\n\n\nhightemp_poly_4\n30.6658218\n104.43119\n0.2936462\n0.7704090\n\n\nhightemp_poly_5\n43.9761289\n98.81637\n0.4450288\n0.6584807\n\n\nhightemp_poly_6\n120.6375158\n105.39037\n1.1446730\n0.2585333\n\n\nhightemp_poly_7\n89.9817670\n110.15218\n0.8168860\n0.4183947\n\n\nhightemp_poly_8\n26.7967468\n112.40311\n0.2383986\n0.8126787\n\n\nhightemp_poly_9\n19.8361352\n102.83515\n0.1928926\n0.8479307\n\n\nhightemp_poly_10\n-50.3726593\n97.43376\n-0.5169939\n0.6077496\n\n\nhightemp_poly_11\n50.1886586\n89.13451\n0.5630665\n0.5762478\n\n\nhightemp_poly_12\n95.8849122\n89.00669\n1.0772775\n0.2872274\n\n\nhightemp_poly_13\n10.3773965\n94.83236\n0.1094289\n0.9133599\n\n\nhightemp_poly_14\n55.7038090\n89.93601\n0.6193716\n0.5388657\n\n\nhightemp_poly_15\n37.2235990\n90.04709\n0.4133793\n0.6813366\n\n\nhightemp_poly_16\n64.4296348\n92.57077\n0.6960041\n0.4900866\n\n\nhightemp_poly_17\n-11.1127383\n92.51757\n-0.1201149\n0.9049389\n\n\nhightemp_poly_18\n-91.7282722\n89.76033\n-1.0219244\n0.3124027\n\n\nhightemp_poly_19\n-184.3159907\n91.55332\n-2.0132092\n0.0502353\n\n\nhightemp_poly_20\n43.2073141\n90.75385\n0.4760934\n0.6363634\n\n\nhightemp_poly_21\n-66.3777436\n91.75642\n-0.7234125\n0.4732550\n\n\ncloudcover_X.2.5.5.\n0.5148961\n43.76892\n0.0117640\n0.9906671\n\n\ncloudcover_X.5.7.5.\n-42.2736984\n37.12645\n-1.1386411\n0.2610146\n\n\ncloudcover_X.7.5.max.\n-61.9777168\n35.36681\n-1.7524261\n0.0866671\n\n\nprecip_x_dayType_weekend\n-110.0796100\n243.06658\n-0.4528784\n0.6528616\n\n\n\n\n\n\n\n\n\nPredicción\n¿Cuál es el número de visitantes esperado un día con una temperatura máxima de 80ºF, con un nubosidad de 8.5, con una precipitación de 0.02 y que es fin de semana? ¿Cuál es un intervalo de confianza para la predicción?\n\nvalores &lt;- tibble(hightemp = 80, cloudcover = 8.5, \n                  precip = 0.02, dayType = \"weekend\")\npred &lt;- flujo_lm1_est %&gt;% predict(new_data = valores)\nCI   &lt;- flujo_lm1_est %&gt;% predict(new_data = valores, type = \"conf_int\")\n\npred %&gt;% bind_cols(CI) %&gt;% kbl() %&gt;% kable_classic()\n\n\n\n\n.pred\n.pred_lower\n.pred_upper\n\n\n\n\n518.8108\n420.7957\n616.8258"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación-1",
    "href": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación-1",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\nDefinimos la nueva receta:\n\nreceta2 &lt;-receta1 %&gt;%\n  step_log(volume) \n\nPodemos ver que efectivamente los nuevos datos incluyen la transformación en logaritmos:\n\ndatosPrep2 &lt;- receta2 %&gt;%  prep() %&gt;% bake(railtrailEntren)\ndatosPrep2 %&gt;% slice_head() %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nprecip\nvolume\ndayType_weekend\nhightemp_poly_1\nhightemp_poly_2\nhightemp_poly_3\nhightemp_poly_4\nhightemp_poly_5\nhightemp_poly_6\nhightemp_poly_7\nhightemp_poly_8\nhightemp_poly_9\nhightemp_poly_10\nhightemp_poly_11\nhightemp_poly_12\nhightemp_poly_13\nhightemp_poly_14\nhightemp_poly_15\nhightemp_poly_16\nhightemp_poly_17\nhightemp_poly_18\nhightemp_poly_19\nhightemp_poly_20\nhightemp_poly_21\ncloudcover_X.2.5.5.\ncloudcover_X.5.7.5.\ncloudcover_X.7.5.max.\nprecip_x_dayType_weekend\n\n\n\n\n0\n5.659482\n0\n-0.2453388\n0.3215624\n-0.2978088\n0.2259474\n-0.1921686\n0.1818106\n-0.1878811\n0.1623743\n-0.1188715\n0.0997763\n-0.1085769\n0.096653\n-0.0650102\n0.0357273\n-0.0184597\n0.0074644\n-0.0030106\n0.0012088\n-0.0005804\n0.0002402\n-9.98e-05\n0\n0\n0\n0"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-2-entrenamiento-1",
    "href": "docs/Tema08ej1.html#paso-2-entrenamiento-1",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\n\nVamos a usar el mismo modelo anterior\n\n\n\nPaso 2.B: Creación del flujo de trabajo\n\nActualizamos el flujo de trabajo con la nueva receta, bien añadiendo cada paso o bien actualizando la receta\n\n\nflujo_lm2 &lt;- workflow() %&gt;%\n  add_recipe(receta2) %&gt;%      \n  add_model(modelo_lm1)\n\nflujo_lm2 &lt;- flujo_lm1 %&gt;% \n  update_recipe(receta2) \n\n\n\nPaso 2.C: Estimación del flujo\n\nEstimamos el nuevo flujo\n\n\nflujo_lm2_est &lt;- flujo_lm2 %&gt;% \n                   fit(data = railtrailPart %&gt;% training()) \n\n\nLos resultados de esta estimación son:\n\n\nflujo_lm2_est %&gt;% extract_fit_parsnip() %&gt;% \n  tidy() %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.9435257\n0.0915221\n64.9408675\n0.0000000\n\n\nprecip\n-0.3120388\n0.1328863\n-2.3481628\n0.0234256\n\n\ndayType_weekend\n0.1668725\n0.0907302\n1.8392180\n0.0726370\n\n\nhightemp_poly_1\n1.9187719\n0.3019446\n6.3547143\n0.0000001\n\n\nhightemp_poly_2\n-0.7643930\n0.3082067\n-2.4801310\n0.0170322\n\n\nhightemp_poly_3\n-0.8602522\n0.3391576\n-2.5364380\n0.0148224\n\n\nhightemp_poly_4\n0.1559080\n0.3138180\n0.4968103\n0.6217961\n\n\nhightemp_poly_5\n-0.0950682\n0.2969453\n-0.3201539\n0.7503671\n\n\nhightemp_poly_6\n0.2940672\n0.3167004\n0.9285345\n0.3581964\n\n\nhightemp_poly_7\n0.1377186\n0.3310097\n0.4160560\n0.6793915\n\n\nhightemp_poly_8\n0.0218299\n0.3377738\n0.0646288\n0.9487623\n\n\nhightemp_poly_9\n0.0465628\n0.3090218\n0.1506780\n0.8809184\n\n\nhightemp_poly_10\n-0.3319480\n0.2927906\n-1.1337387\n0.2630437\n\n\nhightemp_poly_11\n0.0742108\n0.2678511\n0.2770599\n0.7830316\n\n\nhightemp_poly_12\n0.3632786\n0.2674670\n1.3582182\n0.1813183\n\n\nhightemp_poly_13\n0.0692958\n0.2849733\n0.2431658\n0.8090070\n\n\nhightemp_poly_14\n0.2291434\n0.2702597\n0.8478640\n0.4011025\n\n\nhightemp_poly_15\n-0.0870908\n0.2705935\n-0.3218511\n0.7490896\n\n\nhightemp_poly_16\n0.1971445\n0.2781772\n0.7087013\n0.4822480\n\n\nhightemp_poly_17\n-0.0064423\n0.2780173\n-0.0231723\n0.9816176\n\n\nhightemp_poly_18\n-0.2404118\n0.2697317\n-0.8912998\n0.3776166\n\n\nhightemp_poly_19\n-0.6493733\n0.2751197\n-2.3603300\n0.0227567\n\n\nhightemp_poly_20\n0.2433132\n0.2727173\n0.8921809\n0.3771494\n\n\nhightemp_poly_21\n-0.3602797\n0.2757300\n-1.3066393\n0.1981239\n\n\ncloudcover_X.2.5.5.\n-0.0377363\n0.1315265\n-0.2869102\n0.7755279\n\n\ncloudcover_X.5.7.5.\n-0.1314990\n0.1115658\n-1.1786675\n0.2448655\n\n\ncloudcover_X.7.5.max.\n-0.1947940\n0.1062780\n-1.8328715\n0.0735935\n\n\nprecip_x_dayType_weekend\n0.0459736\n0.7304203\n0.0629413\n0.9500983"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación-2",
    "href": "docs/Tema08ej1.html#paso-1-preparar-los-datos-y-especificación-2",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 1: Preparar los datos y Especificación",
    "text": "Paso 1: Preparar los datos y Especificación\n\nDebemos estandarizar las variables y debe ser antes de transformaciones no lineales de los regresores, como polinomios o interacciones. Por tanto, NO podemos simplemente añadir un paso de estandarización a la receta anterior.\nAdemás debemos tener cuidado con el orden de los pasos. Si se discretiza una variable continua, debemos hacerlo antes de estandarizar (o bien los puntos de corte deben ser con los nuevos valores, estandarizados). La estandarización debe ser antes de la transformación en polinomios.\n\n\nreceta1LASSO &lt;- railtrailPart %&gt;% training() %&gt;%             \n  recipe(volume ~  hightemp + cloudcover + precip +  dayType) %&gt;%\n  step_cut(cloudcover, breaks = c(0, 2.5, 5, 7.5, 10), \n           include_outside_range = T)  %&gt;% \n  step_scale(all_predictors(), -all_nominal()) %&gt;%\n  step_poly(hightemp, degree = 21) %&gt;%   \n  step_dummy(cloudcover) %&gt;% \n  step_dummy(dayType) %&gt;% \n  step_interact(~precip:starts_with(\"dayType_\"))\n\nreceta2LASSO &lt;- receta1LASSO %&gt;% \n  step_log(volume)"
  },
  {
    "objectID": "docs/Tema08ej1.html#paso-2-entrenamiento-2",
    "href": "docs/Tema08ej1.html#paso-2-entrenamiento-2",
    "title": "Tema 08. Ejemplo 1",
    "section": "Paso 2: Entrenamiento",
    "text": "Paso 2: Entrenamiento\n\nPaso 2.A: Definición del modelo\n\nDefinimos el modelo con el hiperparámetro para ajustar:\n\n\nmodelo_LASSO  &lt;- linear_reg(mode= \"regression\", engine = \"glmnet\", \n                             penalty = tune(), mixture = 1)\n\n\n\nPaso 2.B: Creación del flujo de trabajo\n\nCreamos los flujos de trabajo combinando las recetas y el modelo\n\n\nflujo_LASSO1 &lt;- workflow() %&gt;%\n  add_recipe(receta1LASSO) %&gt;%      \n  add_model(modelo_LASSO)\n\nflujo_LASSO2 &lt;- flujo_LASSO1  %&gt;%\n  update_recipe(receta2LASSO)\n\n\nPodemos comprobar que el flujo depende un parámetro a ajustar:\n\n\nflujo_LASSO1 %&gt;% extract_parameter_set_dials()\n\n\n\nPaso 2.C: Estimación del flujo\n\nPaso 2.C.1: Ajuste del hiperparámetros\n\nEn este caso, la estimación del flujo requiere más pasos, ya que debemos ajustar el hiperparámetro del modelo LASSO.\nDefinimos las particiones de validación cruzada en la muestra de entrenamiento que vamos a utilizar, para ambos casos:\n\n\nset.seed(9753)\nrailtrail_entrenCV &lt;- railtrailPart %&gt;% training() %&gt;% \n                          vfold_cv(v=10)\n\n\n\nProceso de ajuste del primer modelo\n\nDefinimos un primer rango y valores de búsqueda del hiperparámetro:\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 20), trans = NULL), \n                                   levels = 21)\n\n\nflujo_LASSO1_ajust &lt;- flujo_LASSO1 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nDado que lo que observamos, ampliamos el rango por la derecha probando muchos valores:\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(18, 68), trans = NULL), \n                                   levels = 51)\n\n\nflujo_LASSO1_ajust &lt;- flujo_LASSO1 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nNos centramos en un rango plausible probando más valores:\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(24, 29), trans = NULL), \n                                   levels = 51)\n\n\nflujo_LASSO1_ajust &lt;- flujo_LASSO1 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO1_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nNotad que hay varios valores con métricas muy similares. Nos quedamos con el mejor, pero serían igualmente válidos:\n\n\nflujo_LASSO1_ajust %&gt;% show_best(metric = \"rmse\")\nmejor_lambda1 &lt;- flujo_LASSO1_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nProceso de ajuste del segundo modelo\n\nProbamos un primer rango\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 5), trans = NULL), \n                                   levels = 21)\n\n\nflujo_LASSO2_ajust &lt;- flujo_LASSO2 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nVemos un cambio fuerte entorno a 0.2 miramos que pasa a su izquierda\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0, 0.2), trans = NULL), \n                                   levels = 21)\n\n\nflujo_LASSO2_ajust &lt;- flujo_LASSO2 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\n… y a su derecha\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0.1, 1.1), trans = NULL), \n                                   levels = 21)\n\n\nflujo_LASSO2_ajust &lt;- flujo_LASSO2 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nFocalizamos más en la parte a la izquierda de 0.3 (porque a la derecha, la métrica no varía: la penalización no hace cambiar el modelo)\n\n\nLASSO_grid &lt;- grid_regular(penalty(range = c(0.09, 0.11), trans = NULL), \n                                   levels = 51)\n\n\nflujo_LASSO2_ajust &lt;- flujo_LASSO2 %&gt;% \n                        tune_grid(resamples = railtrail_entrenCV, \n                                  metrics   = metric_set(rmse, mae),\n                                  grid      = LASSO_grid            )\n\nflujo_LASSO2_ajust %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nNos quedamos con el mejor\n\n\nmejor_lambda2 &lt;- flujo_LASSO2_ajust %&gt;% select_best(metric = \"rmse\")\n\n\n\nPaso 2.C.2: Finalizando y estimando\n\nPara el primer modelo\n\n\nflujo_LASSO_final1 &lt;- flujo_LASSO1 %&gt;% \n        finalize_workflow(mejor_lambda1)  \n\n\nflujo_LASSO_final1_est &lt;-  flujo_LASSO_final1 %&gt;%  \n              fit(data = railtrailPart %&gt;% training())\nflujo_LASSO_final1_est %&gt;%  extract_fit_parsnip() %&gt;% tidy() %&gt;% \n  kbl() %&gt;% kable_styling()\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n380.895481\n25.2\n\n\nprecip\n-7.442689\n25.2\n\n\nhightemp_poly_1\n424.152202\n25.2\n\n\nhightemp_poly_2\n-50.391223\n25.2\n\n\nhightemp_poly_3\n-95.487801\n25.2\n\n\nhightemp_poly_4\n0.000000\n25.2\n\n\nhightemp_poly_5\n0.000000\n25.2\n\n\nhightemp_poly_6\n0.000000\n25.2\n\n\nhightemp_poly_7\n0.000000\n25.2\n\n\nhightemp_poly_8\n0.000000\n25.2\n\n\nhightemp_poly_9\n0.000000\n25.2\n\n\nhightemp_poly_10\n0.000000\n25.2\n\n\nhightemp_poly_11\n0.000000\n25.2\n\n\nhightemp_poly_12\n0.000000\n25.2\n\n\nhightemp_poly_13\n0.000000\n25.2\n\n\nhightemp_poly_14\n0.000000\n25.2\n\n\nhightemp_poly_15\n0.000000\n25.2\n\n\nhightemp_poly_16\n0.000000\n25.2\n\n\nhightemp_poly_17\n0.000000\n25.2\n\n\nhightemp_poly_18\n0.000000\n25.2\n\n\nhightemp_poly_19\n0.000000\n25.2\n\n\nhightemp_poly_20\n0.000000\n25.2\n\n\nhightemp_poly_21\n0.000000\n25.2\n\n\ncloudcover_X.2.5.5.\n0.000000\n25.2\n\n\ncloudcover_X.5.7.5.\n0.000000\n25.2\n\n\ncloudcover_X.7.5.max.\n-19.908599\n25.2\n\n\ndayType_weekend\n5.727394\n25.2\n\n\nprecip_x_dayType_weekend\n0.000000\n25.2\n\n\n\n\n\n\n\n\nPara el segundo modelo\n\n\nflujo_LASSO_final2 &lt;- flujo_LASSO2 %&gt;% \n        finalize_workflow(mejor_lambda2)  \n\n\nflujo_LASSO_final2_est &lt;-  flujo_LASSO_final2 %&gt;%  \n              fit(data = railtrailPart %&gt;% training())\nflujo_LASSO_final2_est %&gt;%  extract_fit_parsnip() %&gt;% tidy() %&gt;% \n  kbl() %&gt;% kable_styling()\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n5.8649640\n0.0928\n\n\nprecip\n-0.0087859\n0.0928\n\n\nhightemp_poly_1\n1.2004631\n0.0928\n\n\nhightemp_poly_2\n-0.0171432\n0.0928\n\n\nhightemp_poly_3\n0.0000000\n0.0928\n\n\nhightemp_poly_4\n0.0000000\n0.0928\n\n\nhightemp_poly_5\n0.0000000\n0.0928\n\n\nhightemp_poly_6\n0.0000000\n0.0928\n\n\nhightemp_poly_7\n0.0000000\n0.0928\n\n\nhightemp_poly_8\n0.0000000\n0.0928\n\n\nhightemp_poly_9\n0.0000000\n0.0928\n\n\nhightemp_poly_10\n0.0000000\n0.0928\n\n\nhightemp_poly_11\n0.0000000\n0.0928\n\n\nhightemp_poly_12\n0.0000000\n0.0928\n\n\nhightemp_poly_13\n0.0000000\n0.0928\n\n\nhightemp_poly_14\n0.0000000\n0.0928\n\n\nhightemp_poly_15\n0.0000000\n0.0928\n\n\nhightemp_poly_16\n0.0000000\n0.0928\n\n\nhightemp_poly_17\n0.0000000\n0.0928\n\n\nhightemp_poly_18\n0.0000000\n0.0928\n\n\nhightemp_poly_19\n0.0000000\n0.0928\n\n\nhightemp_poly_20\n0.0000000\n0.0928\n\n\nhightemp_poly_21\n0.0000000\n0.0928\n\n\ncloudcover_X.2.5.5.\n0.0000000\n0.0928\n\n\ncloudcover_X.5.7.5.\n0.0000000\n0.0928\n\n\ncloudcover_X.7.5.max.\n-0.0272226\n0.0928\n\n\ndayType_weekend\n0.0000000\n0.0928\n\n\nprecip_x_dayType_weekend\n0.0000000\n0.0928\n\n\n\n\n\n\n\n\nNota: también podríamos poner los dos modelos juntos en la misma tabla, en columnas diferentes."
  },
  {
    "objectID": "Contenidos.html",
    "href": "Contenidos.html",
    "title": "Contenidos",
    "section": "",
    "text": "(09-Dic. a 15-Dic.)\n\nTema 10 - Más algoritmos de aprendizaje supervisado\nTema 10 - Ejemplo 1\nEjemplo de Proyecto Final"
  },
  {
    "objectID": "Contenidos.html#semana-14",
    "href": "Contenidos.html#semana-14",
    "title": "Contenidos",
    "section": "",
    "text": "(09-Dic. a 15-Dic.)\n\nTema 10 - Más algoritmos de aprendizaje supervisado\nTema 10 - Ejemplo 1\nEjemplo de Proyecto Final"
  },
  {
    "objectID": "Contenidos.html#semana-13",
    "href": "Contenidos.html#semana-13",
    "title": "Contenidos",
    "section": "Semana 13",
    "text": "Semana 13\n(02-Dic. a 08-Dic.)\n\nTema 08 - Ejercicio 2\n\nFecha límite de entrega: dom., 15-dic., 23:59h\n\nTema 09 - Métodos basados en árboles\nTema 09 - Ejemplo 1"
  },
  {
    "objectID": "Contenidos.html#semana-12",
    "href": "Contenidos.html#semana-12",
    "title": "Contenidos",
    "section": "Semana 12",
    "text": "Semana 12\n(25-Nov. a 01-Dic.)\n\nTema 08 - Ejemplo 1"
  },
  {
    "objectID": "Contenidos.html#semana-11",
    "href": "Contenidos.html#semana-11",
    "title": "Contenidos",
    "section": "Semana 11",
    "text": "Semana 11\n(18-Nov. a 24-Nov.)\n\nTema 07 - Selección y Regularización\nTema 08 - Modelización con tidymodels"
  },
  {
    "objectID": "Contenidos.html#semana-10",
    "href": "Contenidos.html#semana-10",
    "title": "Contenidos",
    "section": "Semana 10",
    "text": "Semana 10\n(11-Nov. a 17-Nov.)\n\nTema 06 - Ejercicio 1\n\nFecha límite de entrega: dom., 08-dic., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-9",
    "href": "Contenidos.html#semana-9",
    "title": "Contenidos",
    "section": "Semana 9",
    "text": "Semana 9\n(4-Nov. a 10-Nov.)\n\nTema 05 - Ejercicio\n\nFecha límite de entrega: dom., 17-nov., 23:59h\n\nTema 06 - Modelización: métodos estadísticos"
  },
  {
    "objectID": "Contenidos.html#semana-8",
    "href": "Contenidos.html#semana-8",
    "title": "Contenidos",
    "section": "Semana 8",
    "text": "Semana 8\n(28-Oct. a 3-Nov.)\n\nTema 05 - Análisis Exploratorio de Datos"
  },
  {
    "objectID": "Contenidos.html#semana-7",
    "href": "Contenidos.html#semana-7",
    "title": "Contenidos",
    "section": "Semana 7",
    "text": "Semana 7\n(21-Oct. a 27-Oct.)\n\nTema 03 - Ejercicio\nTema 04 - Introducción a Quarto\nTema 04 - Ejercicio\n\nFecha límite de entrega: dom., 03-nov., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-6",
    "href": "Contenidos.html#semana-6",
    "title": "Contenidos",
    "section": "Semana 6",
    "text": "Semana 6\n(14-Oct. a 20-Oct.)\n\nTema 03 - Datos relacionales"
  },
  {
    "objectID": "Contenidos.html#semana-5",
    "href": "Contenidos.html#semana-5",
    "title": "Contenidos",
    "section": "Semana 5",
    "text": "Semana 5\n(07-Oct. a 13-Oct.)\n\nTema 02 - Ejercicio 1"
  },
  {
    "objectID": "Contenidos.html#semana-4",
    "href": "Contenidos.html#semana-4",
    "title": "Contenidos",
    "section": "Semana 4",
    "text": "Semana 4\n(30-Sept. a 6-Oct.)\n\nTema 02 - Tratamiento de Datos"
  },
  {
    "objectID": "Contenidos.html#semana-3",
    "href": "Contenidos.html#semana-3",
    "title": "Contenidos",
    "section": "Semana 3",
    "text": "Semana 3\n(23-Sept. a 29-Sept.)\n\nTema 01 - Visualización de Datos\nTema 01 - Ejercicio\n\nFecha límite de entrega: dom., 06-oct., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-2",
    "href": "Contenidos.html#semana-2",
    "title": "Contenidos",
    "section": "Semana 2",
    "text": "Semana 2\n(16-Sept. a 22-Sept.)\n\nTema 0 - Ejercicio 1\n\nFecha límite de entrega: vie., 04-oct., 23:59h"
  },
  {
    "objectID": "Contenidos.html#semana-1",
    "href": "Contenidos.html#semana-1",
    "title": "Contenidos",
    "section": "Semana 1",
    "text": "Semana 1\n(09-Sept. a 15-Sept.)\n\nIntroducción\nTema 0 - Introducción a R y a RStudio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 12:45h\nMiércoles de 11h a 12:45h\nViernes de 11 a 12:45h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud\n\n\n\n\n\nDespacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es"
  },
  {
    "objectID": "index.html#pedro-albarrán",
    "href": "index.html#pedro-albarrán",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 19, Segundo (último) piso, Edificio 31 (Facultad de Ciencias Económicas y Empresariales)\ne-mail: albarran@ua.es\nTutorias:\n\nLunes de 11h a 12:45h\nMiércoles de 11h a 12:45h\nViernes de 11 a 12:45h\n\n(solicitada previamente con al menos 24 horas de antelación, por UACloud o email)\nTambién podéis usar UACloud"
  },
  {
    "objectID": "index.html#alberto-pérez",
    "href": "index.html#alberto-pérez",
    "title": "Técnicas para ‘Big Data’ en Economía (UA)",
    "section": "",
    "text": "Despacho 70, Segundo (último) piso, Edificio 34 (Ciencias Sociales)\ne-mail: alberto.perezbernabeu@ua.es"
  },
  {
    "objectID": "ProyectoFinal.html",
    "href": "ProyectoFinal.html",
    "title": "Proyecto Final",
    "section": "",
    "text": "Objetivos\nPara realizar este proyecto final, debéis proponer un tema de estudio usando datos y las técnicas que hemos visto en el curso. Más abajo os indico unas propuestas tanto de temas como de fuentes para obtener datos. También podéis proponerme un tema de estudio, usando datos de que dispongáis por trabajo, contactos, búsqueda propia, etc.\nEl resultado final debe ser un proyecto de análisis de datos que tenga sentido en el ámbito de economía, empresa, negocios, finanzas, etc. (“business analytics”). Se aplicarán los conocimientos adquiridos en el curso, quedando claras todas las etapas del análisis de datos:\n\n\n\nPor tanto, debe explicarse claramente:\n\nObjetivo del análisis: qué cuestión se analiza y su importancia\nDatos: qué datos se utilizan, su origen, por qué son adecuados para el objetivo del análisis\nProcesamiento de los datos (importación, limpieza y transformación): por qué es necesario para el análisis\nAnálisis exploratorio de datos: qué información básica aprendemos de los datos y cómo esto ayuda a especificar los modelos\nProceso de Modelización: cómo se especifican distintos modelos que ayudan a responder al objetivo y cómo se validan para obtener el mejor modelo final\nComunicar de manera efectiva mediante gráficos, resultados de estimación, etc. las implicaciones de los resultados obtenidos en el análisis para el objetivo. En particular, explicar cómo los resultados responden a la cuestión económica, financiera o decisión de empresa que se plantea cómo objetivo.\n\nLA INFORMACIÓN SOBRE EL PROYECTO FINAL SE IRÁ ACTUALIZANDO A LO LARGO DEL CURSO\n\n\nAlgunas propuestas de temas y fuentes de datos\n\nVentas de “Big Mart”. Se han recopilado datos de ventas de 1.559 productos para el 2013 en 10 tiendas en diferentes ciudades para la cadena de tiendas americana “Big Mart”. Además, se han definido determinados atributos de cada producto y tienda. El objetivo es construir un modelo predictivo o de clasificación para conocer las ventas de cada producto en una tienda concreta. Con este modelo, se intentará comprender las propiedades de los productos y tiendas que juegan un papel clave en las ventas. Los datos están aquí \nBlack Friday. “ABC Private Limited” quiere comprender el comportamiento de compra para varios productos de diferentes categorías. Se dispone de un resumen de compras de varios clientes y sus datos demográficos. Un modelo para predecir comprar o clasificar compras de gran volumen del cliente ayudará a crear una oferta personalizada para los clientes. Los datos [aquí]https://www.dropbox.com/scl/fi/7097vyravm1nmgtq3hu8d/02black.zip?rlkey=qy9jqypyhzcpiav01i9b4jg9k&dl=0) \nConcesión de préstamos. “Dream Housing Finance” desea automatizar el proceso de elegibilidad del préstamo a partir de datos del cliente proporcionados al llenar el formulario de solicitud en línea. Para automatizar este proceso, han planteado un problema a la hora de identificar los segmentos de clientes, que son susceptibles de recibir préstamos para poder dirigirse específicamente a estos clientes. Los datos y su descripción aquí \nClasificación de la calidad crediticia. Datos de una compañía de tarjetas de crédito alemana, aquí \nServicio de bicicletas. La empresa “Capital BikeShare” ofrece un servicio de bicicletas compartidas. Quiere saber a dónde van sus usuarios, cuándo viajan, qué paradas son las más populares, en qué días de la semana se realizan más viajes. Información aquí \nPrecios de las casas\n\nDisponemos de información describiendo (casi) todos los aspectos de las casas residenciales en Ames, Iowa, para predecir el precio final de cada casa. Datos y descripción aquí. \nDatos extraídos de la American Community Survey de 2011 con información sobre el parque de viviendas y las circunstancias económicas de cada área en California y Pennsylvania. Datos e información aquí. \nDatos se han extraído de los resultados públicos publicados cada semana en http://domain.com.au con información sobre precios de las casa en Melbourne, Australia. Datos e información aquí\n\nDelitos.\n\nDatos e información aquí sobre los crímenes cometidos en Chicago desde 2001. Se puede utilizar para predecir el tipo de crimen, incidencia de crímenes por tipo y zona, etc. Esta información se puede complementar con otras fuentes del mismo portal de datos de Chicago (en particular, datos de socioeconomicos de los vecindarios).\nTambién existe información para Boston aquí y aquí y más información en el mismo sitio (p.e., datos socioeconomicos de los vecindarios) \n\nPropinas en taxis de NY. Analizar los determinantes de que la propina sea alta, en función del lugar de origen, destino, etc. Los datos aquí. \nAirbnb. En este enlace están disponibles conjuntos de datos obtenidos de la web de Airbnb para diferentes ciudades (Alicante no está incluida, pero podéis hacer el “web scraping” si queréis…). Entre otras cosas, se puede analizar los determinantes de la satisfación de los usuarios. Notad que esta fuente da para varios trabajos, tanto por usar distintas ciudades (cuidado con trabajos “demasiado” similares) como porque, como con otros datos, se pueden analizar más de una cosa. \nPrecio de las acciones. Usando información sobre fundamentales de las acciones, se puede predecir el valor o determinar (clasificar) si están sobrevaloradas o infravaloradas. Podéis utilizar estos datos o buscar vuestros propios datos de otras empresas (por ejemplo, españolas). \nPredicción de Respuesta del Cliente y maximización de beneficios. Datos de una campaña de “mailing” directo a clientes con información sobre características demográficas de los clientes y su historial. El objetivo es predecir la respuesta de los clientes en caso de ser contactados para fines de donación. Al clasificar a los clientes, se puede maximizar el importe de la donación. Datos y descripción aquí. \nStock pairs es un estrategia de “trading” desarrollada por “Morgan Stanley” en los años 1980 (ver aquí). Si dos precios de acciones o índices bursátiles como Dow Jones y S&P 500 están históricamente correlados, la ratio de precios tiene un valor estable. Si la ratio de precio se desvía significativamente de ese valor indica que una está infravalorada y deberá subir. El objetivo es desarrollar un modelo que prediga una subida en función de valores pasados de la ratio. Se podrían utilizar dos series de precios de acciones cualquiera, PERO este trabajo es más complejo de lo que parece: se requiere información adicional de fundamentales, una modelización ARIMA apropiada, etc. Consultad conmigo ANTES de elegir esto. \nEste paquete de R acceso a los datos de productos y precios históricos de una serie de minoristas en línea.\nEste conjunto de datos contiene información sobre las ventas históricas de una compañía de supermercados.\nSe pueden utilizar encuestas oficiales para predecir la pobreza de los hogares. Si os interesa, preguntadme.\n\nOtras fuentes generales son:\n\nhttps://www.kaggle.com/datasets\nhttps://github.com/caesar0301/awesome-public-datasets\nhttps://www.kdnuggets.com/datasets/index.html\nhttps://github.com/rfordatascience/tidytuesday\nhttps://www.data.gov/\nhttps://data.worldbank.org/\nhttps://github.com/fivethirtyeight/data\nhttps://aws.amazon.com/datasets/\nhttps://cloud.google.com/bigquery/public-data/\nhttps://www.quandl.com/"
  }
]