---
# subtitle: "Análisis de Datos Multivariantes aplicado al Marketing"
# subtitle: "Muestreo y Análisis de Datos"
subtitle: "Técnicas para 'Big Data' en Economía - Curso 2023/24 \n\n Universidad de Alicante"
title    :  "Tema 10. Ejercicio."
author:  
    - "Pedro Albarrán"
#    - "Teresa Molina"
# institute: "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
   
# institute: 
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
format:
#   beamer:
#     logo: figure/by-nc-sa2.png
#     titlegraphic: figure/by-nc-sa.png
#     theme: Boadilla # Copenhagen # CambridgeUS #
#     outertheme: miniframes
#     colortheme: crane
#     section-titles: false
#     fontsize: 10pt
# #    header-includes:
# #      - \setbeameroption{show notes}
# #      # - \setbeameroption{show notes on second screen}
  # revealjs:
  #   logo: figure/by-nc-sa2.png
  #   titlegraphic: figure/by-nc-sa.png
  #   theme:  
  #     - serif # simple # default # moon # beige # sky #
  #     - custom.scss
  #   smaller: true # false #  
  #   scrollable: true
  #   embed-resources: true
  #   slide-number: true
  #   show-slide-number: all
  #   transition: slide # concave # 
  #   background-transition: fade
  #   progress: true
  html: 
    embed-resources: true
execute:
  enabled: true      # (no) ejecutar code chunks
  eval: false        # por defecto, evalúa y muestra códido de code chunks
  echo: true
  warning: false    # pero no los mensajes ni warnings
  message: false
knitr:
  opts_chunk:
    results: hide     # ni muestra resultados ni figuras
    fig.show: hide
lang: es
strip-comments: true
toc: false
css: styles.css
params:
  soln: false
---


# Introducción

### Datos

Usamos los datos del Censo de EE.UU.: 
```{r}
censo <- read_csv("data/census.csv") %>% 
  mutate(income=factor(income))
```

```{r echo=FALSE, eval=FALSE}
censo <- read_csv("data/census.csv") %>% 
  mutate(across(where(is.character),~as.factor(.x)))
```


<!--
https://medium.com/analytics-vidhya/machine-learning-application-census-income-prediction-868227debf12
-->

Tenemos información de 15 variables relevantes:

|                  |                                        |
|------------------|----------------------------------------|
|  age             |  edad                                  |
|  workclass       |  tipo de trabajo del individuo         |
|  fnlwgt          |  peso en el censo (no relevante)       |
|  education       |  nivel educativo                       |
|  education_1     |  años  de educación                    |
|  marital_status  |  estado civil                          |
|  occupation      |  profesión de la persona               |
|  relationship    |  relación con el principal miembro del hogar |
|  race            |  origen racial de la persona           |
|  sex             |  género                                |
|  capital_gain    |  ganancias de capital                  |
|  capital_loss    |  pérdidas de capital                   |
|  hours_per_week  |  horas trabajadas a la semana          |
|  native_country  |  país de origen                        |
|  Income          |  renta mayor o menor de 50 mil dólares |

### Análisis exploratorio de los datos

En este ejercicio NO vamos a desarrollar explícitamente el análisis exploratorio de datos. Pero **siempre** debemos conocer las características de nuestros datos, incluidas la distribución de valores de las variables y las relaciones entre ellas. Además, deberíamos haber realizado un proceso de **limpieza y transformación** de los datos, en parte sugerido por este análisis exploratorio.

### Partición en Entrenamiento y Prueba

```{r}
set.seed(9753)
censo_part <- censo %>% initial_split(prop = .8)
```

### Especificación: variables para los modelos

En este ejercicio, usaremos la misma especificación inicial: la categoría de renta va a depender edad, educación (*education_1*), ganancias de capital, horas trabajadas, género y raza.

En general, debería justificarse las variables incluidas (p.e., por los resultados del análisis exploratorio) y considerar variantes.

# Modelo de regresión logística con regularización


### Especificación

Definimos la receta con la especificación para este modelo. Recordamos convertir todos las variables explicativas cualitativas a dummies, centrar y escalar las variables explicativas numéricas. Además consideramos un polinomio de orden 6 inicialmente para la edad. 


```{r}
censo_receta_logit <- training(censo_part) %>%
  recipe(income ~ age + education_1 +  capital_gain + hours_per_week + sex + race) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_scale(all_numeric(), -all_outcomes()) %>% step_center(all_numeric(), -all_outcomes()) 
```

### Modelo

* Usamos el comando de regresión logística y especificamos que queremos ajustar (*tune*) el parámetro de penalización

```{r}
modelo_logit_tuned <- logistic_reg(mode= "classification", penalty = tune()) %>% 
  set_engine("glmnet")
```

* Combinamos datos y modelo en un flujo

```{r}
flujo_logit_tuned <- workflow() %>%  
  add_recipe(censo_receta_logit) %>% add_model(modelo_logit_tuned)
```

### Ajuste del hiperparámetro

* Definimos el rango para el hiperparámetro. Puede ser necesario repetir este paso cambiando el rango y/o el número de valores a considerar si luego no encontramos un óptimo.

```{r}
logit_grid <- grid_regular(penalty(range = c(0, 0.01), trans = NULL), levels = 26)
```

* Finalmente, procedemos con el ajuste del hiperparámetro, definiendo las particiones de la validación cruzada para el hiperparámetro y estimando todo.

```{r}
set.seed(9753)
censo_ent_cv <- training(censo_part) %>% vfold_cv(v=10)

logit_tuned <- flujo_logit_tuned %>% 
                  tune_grid( resamples = censo_ent_cv, 
                             metrics   = metric_set(roc_auc),
                             grid      = logit_grid          )
```

* Resultado del ajuste

```{r fig.show='asis'}
logit_tuned %>% autoplot()
logit_tuned %>% show_best("roc_auc")
mejor_lambda <- logit_tuned %>% select_best("roc_auc")
```

Vemos que en este caso la penalización óptima es cero. Probablemente porque tenemos pocas variables: quizás deberíamos considerar más variables, por ejemplo, interacciones.

### Estimación final

* Estimamos el modelo con el hiper-parámetro elegido usando TODOS los datos de la muestra de entrenamiento

```{r}
flujo_logit_final <- flujo_logit_tuned %>% finalize_workflow(mejor_lambda)
```


* Podemos mostrar el resulado de la estimación

```{r results='markup'}
flujo_logit_final %>%  fit(data = training(censo_part)) %>%  broom::tidy() %>% 
  kbl() %>% kable_classic()
```

* También mostrar la importancia de cada variable del modelo, que en este caso se corresponde con la magnitud del coefciente de cada variable (tras estandarizarlas para usar la misma "magnitud").

```{r fig.show='asis'}
library(vip)
flujo_logit_final %>%  fit(data = training(censo_part)) %>% extract_fit_parsnip() %>% vip()
```


### Métricas de error

* Finalmente, calculamos las métricas de error de predicción del modelo estimado, pero usando lógicamente la muestra de prueba.

```{r results='markup'}
logit_final_fit <- flujo_logit_final %>% last_fit(censo_part)
logit_final_fit %>% collect_metrics() %>% 
  kbl() %>% kable_classic()
```

* Esta información será de utilidad para comparar con otros modelos.

# Ejercicio 1: kNN

## Apartado a) 

* Preparar los datos según las necesidades para estimar el modelo kNN. 

NOTA: podemos usar `step_dummy()` con la opción `one_hot = TRUE` para que NO se omita un grupo por defecto en los factores

```{r echo=params$soln, eval=FALSE}
censo_receta_knn <- training(censo_part) %>%
  recipe(income ~ age + education_1 +  capital_gain + hours_per_week + sex + race) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot = T) %>% 
  step_scale(all_numeric(), -all_outcomes()) %>% step_center(all_numeric(), -all_outcomes()) 
```

`r if(!params$soln) {"<!--"}`
### Respuesta

Notad que en este algoritmo NO es necesario realizar transformaciones no lineales (polinomio) de edad.
`r if(!params$soln) {"-->"}`


## Apartado b)

* Obtener mediante validación cruzada el ajuste óptimo del número de vecinos. Nota: usaremos como distancia la norma L2 (`dist_power = 2`) y como motor la biblioteca `kknn`.

```{r eval=FALSE}
modelo_knn_tuned <- nearest_neighbor(mode= "classification", 
                                     neighbors = tune(), dist_power = 2) %>% 
                set_engine("kknn")
```

```{r echo=params$soln, eval=FALSE}
flujo_knn_tuned <- workflow() %>%  add_recipe(censo_receta_knn) %>%
                      add_model(modelo_knn_tuned)
```

* Probad primero con un rango de valores para los vecinos entre 60 y 100 en incrementos de 10 y mostrar el resultado. 

* Ajustar vuestro rango de búsqueda del valor óptimo, teniendo siempre en cuenta que kNN es muy muy lento.

```{r echo=params$soln, eval=FALSE}
knn_grid <- grid_regular(neighbors(range = c(60, 100), trans = NULL), levels = 5)

set.seed(9753)
censo_ent_cv <- training(censo_part) %>% vfold_cv(v=10)

knn_tuned <- flujo_knn_tuned %>% tune_grid( resamples = censo_ent_cv, 
                                                metrics   = metric_set(roc_auc),
                                                grid      = knn_grid           )
knn_tuned %>% autoplot()
```

NOTA: puede ser resultar conveniente hacer pruebas sin renderizar el documento .Qmd. 

```{r echo=params$soln, eval=FALSE}
knn_grid <- grid_regular(neighbors(range = c(120, 160), trans = NULL), levels = 5)

knn_tuned <- flujo_knn_tuned %>% tune_grid( resamples = censo_ent_cv, 
                                                metrics   = metric_set(accuracy, roc_auc),
                                                grid      = knn_grid               )

knn_tuned %>% autoplot()
knn_tuned %>% show_best("roc_auc")
mejor_k <- knn_tuned %>% select_best("roc_auc")
```

`r if(!params$soln) {"<!--"}`
### Respuesta

En el primer ajuste, vemos que el valor del hiperparámetro NO está en este rango: debemos extenderlo más allá de 100 vecinos. 

<center>
![](figure/Tema13_Ejerc_sol_1b1.png)
</center>

Tras varias pruebas intentando buscar la típica forma de U invertida en este caso encontraríamos el óptimo del hiperparámetro entre 130 y 150. (Preferimos los resultados de la AUC-ROC dado que es más general y no tiene los problemas de la *accuracy* con datos desbalanceados.)

<center>
![](figure/Tema13_Ejerc_sol_1b2.png)
</center>

`r if(!params$soln) {"-->"}`

## Apartado c)

* Estimar el modelo con el hiperparámetro elegido y mostrar las métricas de error en la muestra de prueba. ¿Qué interpretación podemos extraer sobre los resultados? ¿Qué ventajas y desventajas tiene este método respecto al anterior?

```{r echo=params$soln, eval=FALSE}
flujo_knn_final <- flujo_knn_tuned %>% finalize_workflow(mejor_k)

knn_final_fit <- flujo_knn_final %>% last_fit(censo_part)
knn_final_fit %>% collect_metrics()  %>% 
  kbl() %>% kable_classic()
```

`r if(!params$soln) {"<!--"}`
### Respuesta

Como ya sabemos kNN es un algoritmo no paramétrico, luego no necesitamos ningún tipo de supuesto sobre la relación entre la variable dependiente y las características.

En este caso, vemos una mejora en la capacidad de clasificación del modelo con una AUC-ROC de 0.8538103 que es mayor que la de la regresión logística. Sin embargo, las diferencias en este caso son pequeña. (Esto será una constante porque el modelo es muy simple: pocas variables.). La ganancia en capacidad de predicción se produce a costa de menor interpretabilidad: no podemos saber qué características son más importante para clasificar como renta alta y cuánto afectan a la clasificación. 
`r if(!params$soln) {"-->"}`

# Ejercicio 2: Árboles de clasificación

## Apartado a)

* Preparar los datos según las necesidades para estimar este modelo. 

```{r echo=params$soln, eval=FALSE}
censo_receta_arbol <- training(censo_part) %>%
  recipe(income ~ age + education_1 +  capital_gain + hours_per_week + sex + race) 
```

`r if(!params$soln) {"<!--"}`
### Respuesta
En este algorimo, no necesitamos hacer transformaciones no lineales ni centrar ni escalar variables numéricas ni generara dummies para las categorias de los factores
`r if(!params$soln) {"-->"}`

## Apartado b)

* Obtener mediante validación cruzada el ajuste óptimo del coste de complejidad.

```{r eval=FALSE}
modelo_arbol <- decision_tree(mode= "classification", cost_complexity = tune()) %>% 
  set_engine("rpart")
```

```{r echo=params$soln, eval=FALSE}
flujo_arbol <- workflow() %>%  add_recipe(censo_receta_arbol) %>% add_model(modelo_arbol)
```

* Nuevamente elegid cuidadosamente el rango de valores para el hiperparámetro y mostrar un gráfico final donde se aprecie con claridad que tenemos un óptimo.

```{r echo=params$soln, eval=FALSE}
arbol_grid <- grid_regular(cost_complexity(range = c(0, 0.01), trans = NULL), levels = 11)

set.seed(9753)
censo_ent_cv <- training(censo_part) %>% vfold_cv(v=10)

arbol_tuned <- flujo_arbol %>% tune_grid( resamples = censo_ent_cv, 
                                          metrics   = metric_set(roc_auc),
                                          grid      = arbol_grid                     )

arbol_tuned %>% autoplot()
arbol_tuned %>% show_best("roc_auc")
mejor_alpha <- arbol_tuned %>% select_best("roc_auc")
```


`r if(!params$soln) {"<!--"}`
### Respuesta

Nuevamente deberíamos repetir el proceso con distintos rangos y distintos incrementos en el rango relevante. Pero en este caso vemos que el óptimo del hiperparámetro se produce cuando no se penaliza la complejidad del árbol; por tanto, no se podará el árbol.

<center>
![](figure/Tema13_Ejerc_sol_2b.png)
</center>

`r if(!params$soln) {"-->"}`

## Apartado c)

* Estimar el modelo con el hiperparámetro elegido.

* Representar gráficamente el árbol obtenido y la importancia de cada variables. 

* Interpretar los resultados y discutir las diferencias, ventajas y desventajas respecto a los resultados de los métodos anteriores.

```{r echo=params$soln, eval=FALSE}
flujo_arbol_final <- flujo_arbol %>% finalize_workflow(mejor_alpha)

flujo_arbol_est <- flujo_arbol_final %>%  fit(data = training(censo_part)) 
#flujo_arbol_est %>% extract_fit_parsnip()

arbol <- flujo_arbol_est %>% extract_fit_parsnip() 
rpart.plot(arbol$fit) 

library(vip)
arbol %>% vip()
```

`r if(!params$soln) {"<!--"}`
### Respuesta

El árbol obtenido es bastante complicado (dado que no hemos podado).

<center>
![](figure/Tema13_Ejerc_sol_2c1.png)
</center>

Por tanto, resulta complicado obtener una fácil interpretación de los resultados, que es una de las ventajas de este algoritmo además de ser noparamétrico. Por ello, resulta útil analizar la importancia. 

<center>
![](figure/Tema13_Ejerc_sol_2c2.png)
</center>

Vemos que nuevamente las ganancias de capital son la información más importante para clasificar como de renta alta, seguidas a distancia de educación y de edad. A diferencia de la regresión logística en este caso horas trabajadas y sexo tienen una importancia menor. La raza es igualmente la variable menos relevante.

Como kNN este es un método no paramétrico. Además permite capturar relaciones no lineales entre la variable dependiente y las variables explicativas a diferencia de la regresión logística. También podríamos tener una representación sencilla del proceso de clasificación para interpretar fácilmente lo que pasa. Aunque en este caso, no sucede porque el árbol es demasiado complejo.

`r if(!params$soln) {"-->"}`

## Apartado d)

* Mostrar las métricas de error en la muestra de prueba.

```{r echo=params$soln, eval=FALSE}
arbol_final_fit <- flujo_arbol_final %>% last_fit(censo_part)
arbol_final_fit %>% collect_metrics()
```

`r if(!params$soln) {"<!--"}`
### Respuesta
En este caso, la ROC-AUC es 0.8474778: mejora a la regresión logística, pero no a kNN.
`r if(!params$soln) {"-->"}`


# Ejercicio 3: "Random Forests"


## Apartado a)

* Preparar los datos según las necesidades para estimar este modelo. 

```{r echo=params$soln, eval=FALSE}
censo_receta_arbol <- training(censo_part) %>%
  recipe(income ~ age + education_1 +  capital_gain + hours_per_week + sex + race) 
```

`r if(!params$soln) {"<!--"}`
### Respuesta
Como en los árboles, no necesitamos hacer transformaciones no lineales ni centrar ni escalar variables numéricas ni generara dummies para las categorias de los factores
`r if(!params$soln) {"-->"}`


## Apartado b)

* Obtener mediante validación cruzada el ajuste óptimo del número de variables seleccionadas aleatoriamente para hacer la partición en cada nodo. Usamos cien árboles para este método (esto es, se toman cien re-muestras de boostrap) y usamos la biblioteca `ranger`.

```{r eval=FALSE}
modelo_RF <- rand_forest(mode= "classification", mtry = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "impurity")
```

```{r echo=params$soln, eval=FALSE}
flujo_RF <- workflow() %>%  add_recipe(censo_receta_arbol) %>% add_model(modelo_RF)
```

* Nuevamente elegid cuidadosamente el rango de valores para el hiperparámetro y mostrar un gráfico final donde se aprecie con claridad que tenemos un óptimo.

```{r echo=params$soln, eval=FALSE}
RF_grid <- grid_regular(mtry(range = c(1, 5), trans = NULL), levels = 5)

set.seed(9753)
censo_ent_cv <- training(censo_part) %>% vfold_cv(v=10)

RF_tuned <- flujo_RF %>% tune_grid( resamples = censo_ent_cv, 
                                    metrics   = metric_set(accuracy, roc_auc),
                                    grid      = RF_grid                     )

RF_tuned %>% autoplot()
RF_tuned %>% show_best("roc_auc")
mejor_hiper <- RF_tuned %>% select_best("roc_auc")
```


`r if(!params$soln) {"<!--"}`
### Respuesta

El valor óptimo del hiperparámetro es 2, aunque 1 también entraría dentro de una desviación estándar de la ROC-AUC media. 

<center>
![](figure/Tema13_Ejerc_sol_3b.png)
</center>

`r if(!params$soln) {"-->"}`

## Apartado c)

* Estimar el modelo con el hiperparámetro elegido.

* Representar la importancia de cada variables. 

* Interpretar los resultados y discutir las diferencias, ventajas y desventajas respecto a los resultados de los métodos anteriores.

```{r echo=params$soln, eval=FALSE}
flujo_RF_final <- flujo_RF %>% finalize_workflow(mejor_hiper)

flujo_RF_est <- flujo_RF_final %>%  fit(data = training(censo_part)) 

library(vip)
flujo_RF_est %>% extract_fit_parsnip() %>% vip()

flujo_RF_est_fit <- extract_fit_parsnip(flujo_RF_est)$fit
flujo_RF_est_fit$variable.importance
```

`r if(!params$soln) {"<!--"}`
### Respuesta

<center>
![](figure/Tema13_Ejerc_sol_3c.png)
</center>

Este modelo añade a las ventajas de los árboles una mayor precisión en la clasificación dado que utiliza 100 árboles (aunque más sencillos) en lugar de uno. En principio, perderíamos respecto a los árboles la posibilidad de interpretar fácilmente el proceso, pero en este caso el árbol óptimo no era muy interpretable. Podemos recurrir a la importancia como forma alternativa de interpretación. El ránking de importancia es similar pero las diferencias relativas son diferente. Vemos que las ganancias de capital siguen siendo la información más importante, su importancia es menor que los modelos anteriores. Esto en parte es esperable dado que este algoritmo precisamente intenta evitar que una variable sea demasiado relevante. También el sexo es relativamente menos importante que las horas trabajadas en este modelo que en los árboles.

`r if(!params$soln) {"-->"}`


## Apartado d)

* Mostrar las métricas de error en la muestra de prueba.

```{r echo=params$soln, eval=FALSE}
RF_final_fit <- flujo_RF_final %>% last_fit(censo_part)
RF_final_fit %>% collect_metrics()
```

`r if(!params$soln) {"<!--"}`
### Respuesta

Este algoritmo tiene la mejor métrica de error de los considerados, 0.8628203, aunque como se ha discutido antes las diferencias son pequeñas porque estamos considerando modelos sencillos en cuanto al número de variables y sus interacciones.
`r if(!params$soln) {"-->"}`


# Ejercicio 4

* ¿Qué modelo eligiría? ¿Por qué?

`r if(!params$soln) {"<!--"}`
### Respuesta

Recordamos los resultados de la métrica de error (AUC-ROC en este caso, dado que es preferible a la *accuracy* por varios motivos)

|Logit      | kNN      | árboles    | RandomForest  |
|:---------:|:--------:|:----------:|:-------------:|
|0.8403095  | 0.8538103| 0.8474778  | 0.8632864     |

En cuanto a la capacidad de clasificación el mejor modelo es *Random Forest*. Este algoritmo además tiene ventajas porque permite modelizar la relación sin supuestos paramétricos y permite relaciones muy flexibles. Sin embargo, no ofrece muchas posibilidades de interpretación más allá de la importancia de las variables. Este desventaja la comparte con el resto de modelos, excepto regresión logística: aunque es menos flexible, nos permite interpretar el signo y en parte la magnitud con que cada variable afecta a la variable independiente. Si necesitasemos usar el modelo para intepretar en este caso la escasa menor capacidad predictiva de la regresión logística, podría estar justificada.
`r if(!params$soln) {"-->"}`


# Entrega

Rellenad este 
[FORMULARIO](https://docs.google.com/forms/d/e/1FAIpQLSeDCAi9CtQvZVOk7DiWeZKevOBDO_4uvWrKTbTR5xEaMrtarg/viewform) con vuestros datos y subid vuestro documento de Quarto .Qmd y un archivo comprimido con el documento de salida .html y su directorio relacionado.

IMPORTANTE: el nombre de los archivos DEBE EMPEZAR con vuestro número de DNI (el resto es libre): ej.,  `12345678_T13_ejerc.Qmd` y `12345678_T13_ejerc.zip`
