---
# subtitle: "Análisis de Datos Multivariantes aplicado al Marketing"
# subtitle: "Muestreo y Análisis de Datos"
subtitle: "Técnicas para 'Big Data' en Economía - Curso 2023/24 \n\n Universidad de Alicante"
title    :  "Tema 11 - kNN"
author:  
    - "Pedro Albarrán"
#    - "Teresa Molina"
institute: "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
   
# institute: 
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
format:
  # beamer:
  #   handout: false
  #   logo: figure/by-nc-sa2.png
  #   titlegraphic: figure/by-nc-sa.png
  #   theme:  Boadilla # Copenhagen # CambridgeUS #
  #   outertheme: miniframes
  #   colortheme: crane
  #   section-titles: false
  #   fontsize: 10pt
  #   header-includes: |
  #       \setbeamertemplate{footline}
  #       {
  #       \leavevmode%
  #       \hbox{%
  #       \begin{beamercolorbox}[wd=.30\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
  #       \usebeamerfont{author in head/foot}\insertshortauthor%
  #       \end{beamercolorbox}%
  #       \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
  #       \usebeamerfont{title in head/foot}\insertshorttitle%
  #       \end{beamercolorbox}%
  #       \begin{beamercolorbox}[wd=.15\paperwidth,ht=2.25ex,dp=1ex,center]{date in head/foot}%
  #       \usebeamerfont{date in head/foot}\insertframenumber{} / \inserttotalframenumber
  #       \end{beamercolorbox}}%
  #       }
  #      # - \setbeamertemplate{navigation symbols}{}
  #      # - \setbeamertemplate{caption}[numbered]
  #      # - \setbeamertemplate{headline}[page number]
  #      # - \setbeameroption{show notes}
  #      # - \setbeameroption{show notes on second screen}
  revealjs:
    logo: figure/by-nc-sa2.png
    titlegraphic: figure/by-nc-sa.png
    theme:  
        - beige # sky # serif # simple # default # moon #  
        - custom.scss
    smaller: true
    scrollable: true
    embed-resources: true
    slide-number: true
    show-slide-number: all
    transition: slide # concave # 
    background-transition: fade
    progress: true
    height: 800
    width: 1200
    # width: 3000
    # height: 2000
    # margin: 0.05
execute:
  enabled: true      # (no) ejecutar code chunks
  eval: false        # por defecto, evalúa y muestra códido de code chunks
  echo: true
  warning: false    # pero no los mensajes ni warnings
  message: false
knitr:
  opts_chunk:
    results: hide     # ni muestra resultados ni figuras
    fig.show: hide
lang: es
strip-comments: true
toc: true
toc-depth: 1
toc-expand: false
toc-title: "Contenidos"
css: styles.css
---


```{r setup, include=FALSE}
#```{r setup, message=FALSE, warning=FALSE, include=FALSE} 
# include=F es suficiente para no incluir mensajes, etc.

# Opciones por defecto para los fragmentos de código
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, 
                      warning = FALSE, message = FALSE,
                      results = "hide", fig.show="hide")
# se muestra y evalúa el código,
# no se muestran mensajes, ni avisos (warnings)
# no se muestran los resultados de código (tampoco gráficos)
#     en los códigos que considere necesarios los mostraré

# Elimino todo del Entorno (del documento)
rm(list = ls())       

# Cargo todas las bibliotecas necesarias
# (se podría hacer cuando cada una sea necesaria)
library(tidyverse)
# library(tidymodels)
# library(printr)
# library(skimr)
# library(dlookr)
# library(broom)
library(kableExtra)
# library(rpart.plot)
# library(vip)

#fijo el directorio de trabajo
#setwd("/home/albarran/Dropbox/MAD/00.TEC")
library(rmarkdown)
#render("filename.Rmd")     
#browseURL("filename.html")
```

## k-NN ('k-nearest neighbors')
 
 * Métodos paramétricos = supuesto funcional para la **esperanza condicional** 
 
    + variable numérica $\small E[y|\mathbf{X}=x_0]=f(x_0)=\beta_0+\beta_1 x_0$
    
    + variable categórica: $\small \Pr(y=j|\mathbf{X}=x_0) =f_j(x_0)=\Lambda(\beta_{0j}+\beta_{1j} x_0)$


<!--
   + variable binaria: $\small E[y|\mathbf{X}=x_0]=\Pr(y=1|\mathbf{X}=x_0) =f(x_0)=\Lambda(\beta_{0}+\beta_{1} x_0)$

-->
 
 * k-NN estima la esperanza condicional de forma no parámetrica <!--(predice sin construir un modelo)-->
 
 * Idea: el valor esperado de $\small y$ para una observación debe ser "similar" al de otras observaciones "cercanas" (por su valor en  $\small \mathbf{X}$)

    + mismo valor de $\small x_0$, mismo valor esperado de $\small y$
    
    + $\small f(\mathbf{X})$ no se supone conocida y fija

<!--    
## Algoritmo k-NN

* Datos unos datos de entrenamiento $\small\{\mathbf{X}_{n\times p}, y_{n\times 1} \}$ y un parámetro $\small k>0$ entero
    
* Para una nueva observación $\small \mathbf{x^*}$ (prueba)


1. Identificar $\small D(\mathbf{x^*})$: las $\small k$ observaciones en los datos de entrenamiento más cercanas, según una medida de distancia (típicamente la norma $\small ||x^*-x_i||_2$ 

2. Estimar la esperanza/probabilidad condicional de $\small y$ con las observaciones de $\small D(\mathbf{x^*})$ y obtener

    * la media para $\small y$ numérica: $\small E[y|\mathbf{X}=x^*] \approx \frac{1}{k}\sum_{i\in D(\mathbf{x^*})} y_i$

    * la clase mayoritaria para categórica: $\small \Pr[y=j|\mathbf{X}=x^*] \approx \frac{1}{k}\sum_{i\in D(\mathbf{x^*})} I(y_i = j)$

3. Asignárselo como valor predicho a $\mathbf{x^*}$

-->

## Algoritmo k-NN 

:::: {style="display: grid; grid-template-columns: 1fr 1fr; grid-column-gap: 10px; "}

::: {}

* Dada una muestra de entrenamiento y una nueva observación $\small \mathbf{x^*}$

1. Identificar $\small k>0$ observaciones cercanas según una norma, ej., $\small ||x^*-x_i||_2$ 

2. Se asigna a $\small y^*$ la media o la clase mayoritaria de las observaciones cercanas

:::


::: {}

<center>
![](figure/knn_cropped-1.png){width=80%}
</center>

:::

::::

<!--
* No necesita un proceso de entrenamiento previo: lo hace sobre la marcha.

* Simple y fácil de entender 

* Puede tardar en calcular predicciones (procesa en el momento)
-->

* El valor "óptimo" de $k$ se elige mediante validación cruzada.

    * $\small k$ bajo (= algoritmo demasiado flexible): alta varianza y sesgo bajo

    * Al aumentar $\small k$ (menos flexible), menor varianza, pero mayor sesgo

## Algoritmo k-NN: comentarios


* Su utilidad depende de la geometría de los datos

  + conviene centrar y reescalar los datos 
  + probar varias medidas de distancia: valor absoluto $\small |x^*-x_i|$ , norma <!--(`dist_power`)-->

<!--`step_scale(all_numeric(), -all_outcomes())`-->

<!--     
     + si una variable tiene una escala ancha puede perjudicar todo el proceso.
-->


* La distancia solo se puede calcular para variables continuas: convertir factores en dummies (una para cada categoría) <!--: `step_dummy_multi_choice()`)-->
 
* NO es necesario incluir transformaciones no lineales de los regresores (ej., polinomios, interacción, etc.)  en la receta 

<!-- el algoritmo no-paramétrico se encarga de la no-linealidad -->

* LASSO (modelo lineal) puede no ser informativo sobre la elección de variables para este algoritmo

<!--
diferentes variables vs supuestos vs flexibilidad
-->




* Implementación en R con bibliotecas `class` y `kknn`<!--, con interfaz único en `tidymodels` para regresión y clasificación-->


```{r, echo=FALSE, eval=FALSE}
install.packages("class")
install.packages("kknn")
```

   
```{r echo=FALSE, eval=FALSE}
modelo_knnR1  <- nearest_neighbor(mode = "regression",neighbors = 5, dist_power = 2) %>% 
                          set_engine("class")
modelo_knnC1  <- nearest_neighbor(mode = "classification", neighbors = tune(), dist_power = 2) %>% 
                          set_engine("kknn")
```

<!--

## k-NN con `tidymodels`

```{r eval=FALSE}
library(tidymodels)
censo <- read_csv("data/census.csv") %>% mutate(income = factor(income))
set.seed(7482)
censo_part <- censo %>% initial_split(prop = .8)

censo_receta_knn1 <- training(censo_part) %>%
  recipe(income ~ age + education_1 +  capital_gain + hours_per_week + sex + race) %>% 
  step_dummy_multi_choice(all_nominal(), -all_outcomes()) %>% 
  step_scale(all_numeric(), -all_outcomes()) %>% step_center(all_numeric(), -all_outcomes()) 

censo_modelo_knn1  <- nearest_neighbor(mode = "classification", neighbors = 5, 
                                       dist_power = 2) %>% set_engine("kknn")

censo_flujo_knn1_est  <- workflow() %>% add_recipe(censo_receta_knn1) %>% 
                      add_model(censo_modelo_knn1) %>% fit(data = training(censo_part)) 

censo_flujo_knn1_est %>% predict(testing(censo_part)) %>% 
  bind_cols(testing(censo_part)) %>% accuracy(income, .pred_class) 
```

<!--
## k-NN con `tidymodels` (cont.)
-->

```{r echo=FALSE, eval=FALSE}
library(mosaicData)
set.seed(9753)
RailTrail_part <- RailTrail %>% initial_split(prop = .8)

RailTrail_receta_knn1 <- training(RailTrail_part) %>%
  recipe(volume ~ cloudcover + precip + avgtemp) %>% 
  step_scale(all_numeric(), -all_outcomes())

RailTrail_modelo_knn1  <- nearest_neighbor(mode = "regression",
                                       neighbors = 5, dist_power = 2) %>% 
                          set_engine("kknn")

RailTrail_flujo_knn1 <- workflow() %>% add_recipe(RailTrail_receta_knn1) %>% 
                      add_model(RailTrail_modelo_knn1)

RailTrail_flujo_knn1_est  <- RailTrail_flujo_knn1 %>% fit(training(RailTrail_part)) 

RailTrail_flujo_knn1_est %>% predict(testing(RailTrail_part)) %>% 
  bind_cols(testing(RailTrail_part)) %>% metrics(volume, .pred) 
```

<!--
```{r eval=FALSE}
set.seed(9753)
RailTrail_cv <- RailTrail_entren %>% vfold_cv(v=10)

RailTrail_modelo_knn1  <- nearest_neighbor(mode = "regression",
                                           neighbors = tune(), dist_power = 2) %>% 
  set_engine("kknn")

RailTrail_flujo_knn1 <- workflow() %>% add_recipe(RailTrail_receta_knn1) %>% 
  add_model(RailTrail_modelo_knn1)


vecinos_grid <- grid_regular(neighbors(range = c(1, 15), trans = NULL),     # rango
                           levels = 15)          

vecinos_tuned <- RailTrail_flujo_knn1 %>% 
  tune_grid(
    resamples = RailTrail_cv, 
    metrics   = metric_set(rmse),
    grid      = vecinos_grid
  )

vecinos_tuned %>% show_best()
```
-->
