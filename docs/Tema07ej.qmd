---
# subtitle: "Análisis de Datos Multivariantes aplicado al Marketing"
# subtitle: "Muestreo y Análisis de Datos"
subtitle: "Técnicas para 'Big Data' en Economía - Curso 2023/24 \n\n Universidad de Alicante"
title    :  "Tema 7. Ejercicio."
author:  
    - "Pedro Albarrán"
#    - "Teresa Molina"
# institute: "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
   
# institute: 
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
format:
#   beamer:
#     logo: figure/by-nc-sa2.png
#     titlegraphic: figure/by-nc-sa.png
#     theme: Boadilla # Copenhagen # CambridgeUS #
#     outertheme: miniframes
#     colortheme: crane
#     section-titles: false
#     fontsize: 10pt
# #    header-includes:
# #      - \setbeameroption{show notes}
# #      # - \setbeameroption{show notes on second screen}
  # revealjs:
  #   logo: figure/by-nc-sa2.png
  #   titlegraphic: figure/by-nc-sa.png
  #   theme:  
  #     - serif # simple # default # moon # beige # sky #
  #     - custom.scss
  #   smaller: true # false #  
  #   scrollable: true
  #   embed-resources: true
  #   slide-number: true
  #   show-slide-number: all
  #   transition: slide # concave # 
  #   background-transition: fade
  #   progress: true
  html: 
    embed-resources: true
execute:
  enabled: true      # (no) ejecutar code chunks
  eval: false        # por defecto, evalúa y muestra códido de code chunks
  echo: true
  warning: false    # pero no los mensajes ni warnings
  message: false
knitr:
  opts_chunk:
    results: hide     # ni muestra resultados ni figuras
    fig.show: hide
lang: es
strip-comments: true
toc: false
css: styles.css
---

```{r setup, include=FALSE}
#```{r setup, message=FALSE, warning=FALSE, include=FALSE} 
# include=F es suficiente para no incluir mensajes, etc.

# Opciones por defecto para los fragmentos de código
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, 
                      warning = FALSE, message = FALSE,
                      results = "hide", fig.show="hide")
# se muestra y evalúa el código,
# no se muestran mensajes, ni avisos (warnings)
# no se muestran los resultados de código (tampoco gráficos)
#     en los códigos que considere necesarios los mostraré

# Elimino todo del Entorno (del documento)
rm(list = ls())       

# Cargo todas las bibliotecas necesarias
# (se podría hacer cuando cada una sea necesaria)
library(tidyverse)
# library(tidymodels)
# library(printr)
# library(skimr)
# library(dlookr)
# library(broom)
library(kableExtra)
# library(rpart.plot)
# library(vip)

#fijo el directorio de trabajo
#setwd("/home/albarran/Dropbox/MAD/00.TEC")
library(rmarkdown)
#render("filename.Rmd")     
#browseURL("filename.html")
```


## Datos

La Comisión de Planificación del Valle del Pionero (PVPC) recolectó datos en Florencia, Massachusetts por un período de noventa días. Los recolectores de datos configuraron un sensor láser que registra cuando un usuario del camino ciclista ("via verde") pasa por la estación de recogida de datos.

```{r, echo=TRUE, eval=TRUE}
library(mosaicData)
data("RailTrail")
```

El PVPC quiere entender la relación entre el número de ciclistas diarios (es decir, el número de ciclistas y caminantes que usan el carril bici en un día dado) y una colección de variables explicativas, incluyendo la temperatura, lluvia, nubosidad y el día de la semana. Para esto, estimamos el siguiente modelo de regresión:

```{r, echo=FALSE, eval=TRUE}
modelo1 <- lm(volume ~ hightemp + cloudcover + weekday + precip, 
             data = RailTrail)
library(equatiomatic)
```

```{r, echo=FALSE, eval=TRUE, results='asis'}
extract_eq(modelo1,  intercept = "\\beta_0", greek = "\\beta", 
            raw_tex = TRUE, ital_vars = TRUE)
```


```{r, echo=TRUE, eval=TRUE}
modelo1 <- lm(volume ~ hightemp + cloudcover + weekday + precip, 
             data = RailTrail)
```

## Tablas de resultados en Quarto

Para mostrar en Quarto tablas con estadísticos descriptivos, resultados de una estimación de estimación, etc. podemos utilizar dos bibliotecas:

* `broom` ofrece, entre otras, la función `tidy()` que convierte los resultados en un *data frame*

* `kableExtra` ofrece varias funciones que extienden la función `kable()` permitiendo más formatos de tablas (ver [ayuda](https://haozhu233.github.io/kableExtra/), en particular [aquí](https://haozhu233.github.io/kableExtra/awesome_table_in_html.html#Alternative_themes))

En el documento de Quarto, se debe incluir la opción `results='markup'` para que la tabla aparezca en el documento de salida.

```{r, echo=TRUE, eval=TRUE, results='markup'}
library(broom)
library(kableExtra)
modelo1 %>% tidy() %>% kbl() %>% kable_classic()
```

Notad que tras usar `tidy()` tenemos un conjunto de datos. Por tanto, podemos usar comandos conocidos para manipular la tabla, p.e., no mostrar todas las columnas. 

```{r, results='markup'}
modelo1 %>% tidy() %>% select(term:std.error) %>% kbl() %>% kable_paper()
```


```{r, echo=FALSE, eval=FALSE, results='hide'}
m1 <- modelo1 %>% tidy() %>% select(term:std.error) 
modelo2 %>% tidy() %>% select(term:std.error) %>% full_join(m1, by = "term")
```

También podemos mostrar resultados usando el comando `modelsummary()` de la biblioteca del mismo nombre. Además nos permite mostrar los resultados de varios modelos en la misma tabla. Igual que con `kableExtra`,  la celda de código debe tener la opción `results: markup`. 

Consideramos el siguiente modelo:

```{r, echo=FALSE, eval=TRUE, results='asis'}
modelo2 <- lm(volume ~ hightemp + cloudcover + weekday + precip
              + spring + summer, data = RailTrail)
extract_eq(modelo2,  intercept = "\\beta_0", greek = "\\beta", 
            raw_tex = TRUE, ital_vars = TRUE)
```

```{r}
#| results: markup
#| eval: true
library(modelsummary)
modelo2 <- lm(volume ~ hightemp + cloudcover + weekday + precip
              + spring + summer, data = RailTrail)

modelsummary(list("Modelo 1" = modelo1, "Modelo 2" = modelo2), 
             gof_map = c("nobs", "r.squared", "adj.r.squared", "F", "rmse") )
```


<!--

En lo que sigue, trabajaréis con un coeficiente concreto dependiendo de la última cifra de vuestro DNI o similar: 

* si es 1, 4 o 7, con el de `hightemp`
* si es 2, 5 o 8, con el de `cloudcover`
* si es 3, 6 o 9, con el de `weekday`
* si es 0, con el de `precip`

-->

## Acceso a coeficientes de una estimación

Se puede acceder a los coeficientes de estimados por `lm()` con la función `coef()`, a la matriz de varianza-covarianza de los coeficientes con `vcov`. Los coeficientes y errores estándar también se pueden obtener a partir de `summary()` en el elemento `coefficients`.

Se puede acceder a la varianza del error con `summary(modelo)$sigma**2`. 

```{r, echo=TRUE, eval=FALSE}
coef(modelo1) 
vcov(modelo1)   

sum.modelo1 <- summary(modelo1)

sum.modelo1$coefficients[,1:2]
sum.modelo1$sigma**2 

## Un coeficiente concreto y su Error Estándar
coef(modelo1)[1]
summary(modelo1)$coefficients[1,1]

sqrt(vcov(modelo1)[1,1])
summary(modelo1)$coefficients[1,2]
```


## Vuestro Ejercicio

### Apartado 1

Para este apartado, trabajaréis con un coeficiente concreto del primer modelo (Modelo 1) estimado anteriormente. El coeficiente dependerá de la última cifra de vuestro DNI o similar: 

  * si es 1, 4 o 7, con el de `hightemp`
  * si es 2, 5 o 8, con el de `cloudcover`
  * si es 3, 6 o 9, con el de `weekday`
  * si es 0, con el de `precip`

a) Suponemos que los errores del modelo siguen una distribución normal. Por tanto, $\widehat{\beta} \sim N\left(\beta, Var(\widehat{\beta})\right)$ y $(n-k)*s^2 / Var(\varepsilon) \sim \chi^2_{(n-k)}$, donde $n$ es el número de observaciones,  $k$ es el número de coeficientes (incluida la constante) y  $s^2$ es la estimación de la varianza del error. Calcular el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error.

    Recordad que en R, los valores críticos se obtienen con `qnorm()` y `qchisq()`
    
<!--    
    de la siguiente manera:

    * el de una normal estándar que deja a su izquierda una probabilidad $a$, $0<a<1$: `qnorm(a)`

    * el de una $\chi ^2$ con $q$ grados de libertad que deja a su izquierda una probabilidad $a$, $0<a<1$: `qchisq(a, q)`
-->


```{r echo=FALSE}
# b ~ N(B, Var(b))
# IC = b +/- z_{a/2} *se(b) 
sum.modelo1 <- summary(modelo1)
coef(modelo1)[5] + qnorm(0.975)*sqrt(vcov(modelo1)[5,5])*c(-1,1)
# coef(modelo1)[5] - 1.96*sqrt(vcov(modelo1)[5,5])
# coef(modelo1)[5] + 1.96*sqrt(vcov(modelo1)[5,5])

# también se podría usar valores críticos de la t con 
coef(modelo1)[5] + qt(0.975, 85)*sqrt(vcov(modelo1)[5,5])*c(-1,1)
# que es lo que ofrece
confint(modelo1, 5, level=0.95)


## ii)
# (n-k) * S^2 / Var(e) ~ chi2(n-k)
# n-k son los grados de libertad: 
#    observaciones menos parámetros estimados antes de calcular S^2
# IC = [(n-k) S^2 / chi2(n-k, 1 - a/2) , (n-k) S^2 / chi2(n-k, a/2)]


n <- nobs(modelo1)
k <- length(modelo1$coefficients)
(n-k)*sum.modelo1$sigma**2/qchisq(0.975, n-k)
(n-k)*sum.modelo1$sigma**2/qchisq(0.025, n-k)

(n-k)*sum.modelo1$sigma**2/c(qchisq(0.975, n-k), qchisq(0.025, n-k))
```


b) Utilizar bootstrap para obtener el intervalo de confianza al 95% para vuestro coeficiente y el intervalo de confianza al 95% para la varianza del error. Debéis fijar como semilla vuestro DNI para realizar un bucle como el visto en clase.


```{r echo=FALSE, eval=FALSE}
#### La opción más simple y directa 
#### dado lo que se muestra explicitamente 
t0 <-  Sys.time()   # mido tiempo de ejecución, no se pedia para entrega
set.seed(60000000)
n <- nobs(modelo1)
boot <- list() 
for(i in 1:1000){
  mod <- RailTrail %>% 
    sample_n(size = n, replace = TRUE) %>%
    lm(data = . , volume ~ hightemp + cloudcover + weekday + precip) 
  
  boot[[i]] <- list(coef=coef(mod)[5], sigma2 = summary(mod)$sigma**2)
}

boot_df <- boot %>% bind_rows()
sort(boot_df[[1]])[c(25,975)]
sort(boot_df[[2]])[c(25,975)]
Sys.time()-t0  #tiempo de ejecución
```

```{r echo=FALSE, eval=FALSE}
#### NO COMENTAR-NO VISTO EN CLASE
#### La opción más simple y directa 
#### dado lo que se muestra explicitamente 
t0 <-  Sys.time()   # mido tiempo de ejecución, no se pedia para entrega

mis_estad <- function(coef) {
  mod <- RailTrail %>% 
        sample_n(size = n, replace = TRUE) %>%
        lm(data = . , volume ~ hightemp + cloudcover + weekday + precip) 
  sol <- list(coef=coef(mod)[coef], sigma2 = summary(mod)$sigma**2)
  return(sol)
}

set.seed(60000000)
n <- nrow(RailTrail)
boot <- 1:1000 %>% map(~mis_estad(5))

boot_df <- boot %>% bind_rows()

sort(boot_df[[1]])[c(25,975)]
sort(boot_df[[2]])[c(25,975)]
Sys.time()-t0  #tiempo de ejecución
```



```{r, echo=FALSE, eval=FALSE}
# NO forma parte de la entrega: solo demostración
# Se debe ejecutar despues del primer método

# distribucion teorica para el coeficiente bajo normalidad y bootstrap (rojo)
p1 <- ggplot(data = data.frame(x = boot_df[[1]]), aes(x)) +
  stat_function(fun = dnorm, n = 101, args = list(mean = coef(modelo1)[5], sd = sqrt(vcov(modelo1)[5,5])))+
  ylab("")+
  scale_y_continuous(breaks = NULL)+
  geom_density( color="red")

p1


# distribucion teorica para sigma^2 bajo normalidad y bootstrap (rojo)
p2 <- ggplot(data = data.frame(x = 85*boot_df[[2]]/summary(modelo1)$sigma**2), aes(x))+
  scale_y_continuous(breaks = NULL)+
  stat_function(fun = dchisq, args = list(df = 85))+
  geom_density(color="red")

p2
```

```{r, echo=FALSE, eval=FALSE}
# NO forma parte de la entrega: solo demostración
ggplot(data = data.frame(x = 0:40), aes(x))+
   scale_y_continuous(breaks = NULL)+
    stat_function(fun = dchisq, args = list(df = 5))+
    stat_function(fun = dchisq, args = list(df = 10), color="blue")+
    stat_function(fun = dchisq, args = list(df = 20), color="red")

```

c) Comentar BREVEMENTE las diferencias en los intervalos de confianza de ambos apartados. <!--(Podéis incluirlo como breve comentario en vuestro archivo .R)-->


```{r echo=FALSE}
#### 3. 
## aunque no hay grande diferencias en las distribuciones, 
## sí existen algunas diferencias sobre todo en el límite inferior del intervalo de confianza
## podemos infraestimar la incertidumbre sobre la estimación por suponer normalidad
```

<!--
Como os he comentado en clase, debéis entregar un ejercicio para antes del jueves 21 de noviembre a las 23:00h.
-->

### Apartado 2

Realizamos un análsis exploratorio de los datos y encontramos la siguiente forma para la relación *no lineal* entre el número de visitantes y la temperatura.
```{r fig.show='asis'}
RailTrail %>% ggplot(aes(x=hightemp, y=volume)) + geom_point() + geom_smooth()
```

Presentar en una tabla los resultados de estimar el Modelo 2 anterior y añadir primero la temperatura al cuadrado, después también la temperatura al cubo y finalmente además la temperatura elevada a la cuarta potencia. Comentar qué modelo elegirías, es decir, qué grado del polinomio en temperatura captura mejor la relación no lineal descrita anteriormente. ¿Podríamos tener una relación no lineal distinta de la descrita por un polinomio?

```{r, echo=FALSE}
model3.1 <- lm(volume ~  hightemp + I(hightemp^2) + cloudcover + weekday + precip + spring + summer, 
             data = RailTrail)
model3.2 <- lm(volume ~  hightemp + I(hightemp^2) +  I(hightemp^3) + cloudcover + weekday + precip + spring + summer, 
             data = RailTrail)
model3.3 <- lm(volume ~ hightemp + I(hightemp^2) +  I(hightemp^3) +  I(hightemp^4) + cloudcover + weekday + precip + spring + summer, 
             data = RailTrail)

modelsummary(list("Modelo 2" = modelo2, "Pol. grado 2" = model3.1, 
                  "Pol. grado 3" = model3.2, "Pol. grado 4" = model3.3))
```


### Apartado 3

Realizamos un nuevo análisis exploratorio para la relación entre el número de visitas y la nubosidad (como porcentaje de cielo cubierto por nubes, en una escala continua de 0 a 10).

```{r fig.show='asis'}
RailTrail %>% ggplot(aes(y=volume, x=cloudcover))+geom_point()+geom_smooth()
```

Nuevamente, vamos a presentar en una tabla el modelo 2 y varios variantes sobre ese modelo. Como el gráfico sugiere que no existe relación hasta una nubosidad de 7.5, no vamos incluir `cloudcover` sino que la vamos a discretizar. En la primera variante, vamos a incluir solo un *dummy* para `cloudcover>7.5`. En la segunda variante, vamos a dividir a su vez el rango entre 0 y 7.5 (grupo de referencia omitido en la variante anterior); además de la *dummy* anterior, vamos incluir otra *dummy* para valores de `cloudcover` mayores que 5 y menores o iguales que 7.5. Finalmente, vamos a volver a dividir el rango omitido en el paso anterior (0-5), y vamos a incluir una tercer *dummy* para valores de `cloudcover` mayores que 2.5 y menores o iguales que 7.5.

Estas *dummies* se puede crear de varias formas, entre ellas:
  
  1. Usando el comando `ifelse()` (o `if_else()`) para crear las *dummies* en el conjunto de datos antes de estimar.

  2. Usando los comandos `cut()` (o `cut_width()`, `cut_interval()`, etc.) para discretizar una variable continua generando un factor con categorías dadas por los puntos de corte: ej., `cut(cloudcover, breaks=c(-1, 7.5,10))`
    
  3. Alternativamente, escribiendo directamente la condición que cumple la *dummy* al especificar la fórmula: ej. `volume ~  hightemp  + (cloudcover>7.5) + weekday`
  

Discutir si es preferible la especificación con `cloudcover` como variable continua o alguna de las que usa categorías discretas de esa variable (cuál de ellas) y por qué. 

```{r echo=FALSE}
modelo4.1 <- lm(volume ~  hightemp  + (cloudcover>7.5) + 
                  weekday + precip  + spring + summer, 
             data = RailTrail) 

modelo4.2 <- lm(volume ~  hightemp  + (cloudcover>5 & cloudcover<=7.5) + (cloudcover>7.5) + 
                  weekday + precip  + spring + summer, 
             data = RailTrail) 

modelo4.3 <- lm(volume ~  hightemp  + (cloudcover>2.5 & cloudcover<=5) + 
                  (cloudcover>5 & cloudcover<=7.5) + (cloudcover>7.5) +
                  weekday + precip  + spring + summer, 
             data = RailTrail) %>% summary()

modelsummary(list("Modelo 2" = modelo2, "Dos Rangos" = modelo4.1, "
                  Tres Rangos" = modelo4.2, "Cuatro Rangos" = modelo4.3))
```


```{r echo=FALSE, eval=FALSE}
RailTrail %>% ggplot(aes(y=volume, x=precip))+geom_point()+geom_smooth()

lm(volume ~  hightemp  + cloudcover + weekday + I(precip>0)  + 
     spring + summer, 
             data = RailTrail) %>% summary()

lm(volume ~  hightemp  + cloudcover + weekday + I(precip>0 & precip<=0.5)  + I(precip>0.5)  + 
     spring + summer, 
             data = RailTrail) %>% summary()

lm(volume ~  hightemp  + cloudcover + weekday + I(precip>0 & precip<=0.5) + I(precip>0.5 & precip<=1)  + I(precip>1)  + 
     spring + summer, 
             data = RailTrail) %>% summary()
```


### Apartado 4

Finalmente, vamos a considerar otra variante del Modelo 2 donde los efectos de la temperatura (`hightemp`) y de la nubosidad (`cloudcover`) no son constantes, sino que su efecto es heterogéneo en función de otros factores. En particular, estimaremos el siguiente modelo

```{r echo=FALSE, eval=TRUE, results='markup'}
modelo5.1 <- lm(volume ~  hightemp*(summer + spring + weekday) + cloudcover*weekday+precip, 
             data = RailTrail)
extract_eq(modelo5.1,  intercept = "\\beta_0", greek = "\\beta", 
            raw_tex = TRUE, wrap = TRUE, ital_vars = TRUE)
```


```{r echo=TRUE}
modelo5.1 <- lm(volume ~  hightemp*(summer + spring + weekday) + cloudcover*weekday + precip, 
             data = RailTrail)
```


```{r echo=FALSE, eval=TRUE, results='hide'}
modelsummary(list("Modelo 2" = modelo2, "Efectos Heterogéneos" = modelo5.1))
```

Presentar en una tabla los resultado de estimar el modelo 2 y este modelo, para explicar cuál de los dos preferiría. Discutir si pensáis que existe evidencia de que la temperatura y la nubosidad afectan de manera diferente a las visitas en función de otros factores. 

### Apartado 5

Comentar **brevemente** si tiene sentido considerar efectos no lineales y heterogéneos en el Modelo 2. Sin realizar ninguna estimación nueva, discutir **brevemente** si consideraría un modelo que incluye *a la vez* más de una de las variantes consideradas a la vez (ej., no linealidad y efectos heterogéneos en `hightemp`). ¿Cuántas combinaciones consideraría? ¿Cómo decidiría sobre las combinaciones a probar y sobre el mejor modelo?


### Entrega

Rellenad este 
[FORMULARIO](https://docs.google.com/forms/d/e/1FAIpQLSds_Q4-s7gcn0LKvBuUqQF0fzq1OF1NUTI4u1VKV25ic_BM7w/viewform) con vuestros datos y subid 


  - vuestro archivo de .qmd

  - el resultado de renderizarlo: bien un archivo autocontenido .html (o .pdf o .docx) o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.


IMPORTANTE: el nombre de los ficheros que subáis DEBE seguir el siguiente formato que incluye vuestro número de DNI: ej.,

  * Tema07ej_123456789.qmd
  
  * Tema07ej_123456789.zip
