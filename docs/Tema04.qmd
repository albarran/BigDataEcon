---
title: "Tema 04 - Análisis Exploratorio de Datos (AED)"
subtitle: "Proceso para conocer y entender nuestros datos"
author:  
    - "Pedro Albarrán"
    - "Alberto Pérez"
institute: "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
format:
  revealjs:
    logo: figure/by-nc-sa2.png
    titlegraphic: figure/by-nc-sa.png
    theme:  
        - beige
        - custom.scss
    smaller: true
    scrollable: true
    embed-resources: true
    slide-number: true
    show-slide-number: all
    transition: slide
    background-transition: fade
    progress: true
    height: 800
    width: 1200
    show-notes: false
    notes-format: html
execute:
  enabled: true
  eval: false
  echo: true
  warning: false
  message: false
  output: false
  fig.show: hide
lang: es
strip-comments: true
toc: true
toc-depth: 1
toc-expand: false
toc-title: "Contenidos"
css: styles.css
---

```{r}
#| label: setup
#| include: false


# Elimino todo del Entorno
rm(list = ls())

# Cargo bibliotecas necesarias
library(tidyverse)
library(kableExtra)
library(skimr)
library(dlookr)
library(janitor)
library(corrplot)
library(GGally)
```

```{r}
#| label: generar-datos
#| echo: false
#| eval: false

source("Tema04datos.R")

```

# Introducción al AED

## De los datos en bruto a la información

![](figure/data-science-explore.svg){width=70% fig-align="center"}

::: {style="font-size: 95%;"}

- El AED es una fase inicial importante, con dos objetivos:

  1. Conocer nuestros datos e identificar problemas → Preprocesamiento 
  
      - qué variables, tipo de información, calidad (información faltante, inconsistencias, problemas en combinación de datos)

  2. Análisis descriptivo: identificar patrones y encontrar escenarios de análisis

- NO hay una "receta": el proceso es diferente con distintos datos o con los mismos datos para diferentes objetivos

  - Es un proceso iterativo para descubrir información

:::

## Caso de Estudio: PYMES Europeas

- Una consultora analiza 500 PYMES europeas fundadas entre 1980-2020 para:

  - Evaluar salud financiera y solvencia
  - Identificar patrones de productividad
  - Analizar riesgo crediticio
  - Ofrecer recomendaciones de inversión

- Fuente de datos: [pymes_europa.csv](https://raw.githubusercontent.com/albarran/00datos/main/pymes_europa.csv)

  + información: [diccionario_pymes.csv](https://raw.githubusercontent.com/albarran/00datos/main/diccionario_pymes.csv)


::::{.notes}

  - 28 variables (identificación, financieras, productividad, riesgo)
  - Sectores: Tecnología, Manufactura, Servicios, Construcción, etc.
  - Países: España, Alemania, Francia, Italia, Portugal, y Europa del Este
  - Período: Empresas fundadas entre 1980-2020
  
::::

- Objetivo del AED:

  - Limpiar y preprocesar los datos
  - Entender los datos (distribuciones y relaciones entre variables)
  - Descubrir patrones (riesgo de las empresa, diferencias por sector y país)

# Primera Aproximación

## Contexto y reconomicimiento de los datos

::: {style="font-size: 95%;"}
- Contexto: conocimiento previo de los datos (fuente, cómo están almacenados, etc.)

- Cargar los datos

```{r}
#| echo: false
# Cargar datos
pymes <- read_csv("data/pymes_europa.csv")

# Diccionario de datos
diccionario <- read_csv("data/diccionario_pymes.csv")
```

```{r}
library(rio)
pymes <- import("data/pymes_europa.csv")
```

- **Reconocimiento inicial de las características**: ¿todo como esperamos?

  - número de observaciones y de variables 
  - tipo de cada variable 
  - visualizar los datos

:::: {.notes}
- contexto: 
  - fuente (de dónde han salido)
  - cómo están almacenados (.csv, .xlsx, ...)

- Reconocimiento
```{r}
#| eval: false
View(pymes)
head(pymes)
names(pymes)
dim(pymes)

str(pymes)
```
::::


- **Consultar** el "diccionario" de datos 

  - Descripción de cada variable y unidades de medida 
  - Tipo de variable esperado

```{r}
diccionario <- read_csv("data/diccionario_pymes.csv")
```


::::{.notes}

```{r}
#| echo: false
diccionario |> 
  select(variable, descripcion, tipo) |> 
  slice(1:10) |> 
  kable()
```
::::

:::

## Identificar Problemas de Calidad en los Datos


1. Verificar que las variables la información y el tipo adecuado

    - Algunas variables deberían ser numéricas:

```{r}
#| echo: false
# ¿Qué tipos tenemos?
sapply(pymes, class) |> head(10)
```

```{r}
pymes <- pymes |>
  mutate( anio_fundacion = as.numeric(anio_fundacion),
          empleados = as.numeric(empleados),
          liquidez_ratio = as.numeric(liquidez_ratio)  )
```

```{r}
#| echo: false
#| eval: false
pymes <- pymes |> 
  mutate(across(c(anio_fundacion, empleados, liquidez_ratio), ~parse_number(.x)))
```



:::: {.notes}
- `anio_fundacion` es carácter (debería ser numérica)
- `empleados` es carácter (debería ser numérica)  
- `liquidez_ratio` es carácter (debería ser numérica)

::::


2. Detectar inconsistencias en texto, fechas, unidades, etc.

    - Ej.: en sector, "Tecnología", "tecnologia", "TECNOLOGÍA" son la misma categoría
  
    - este tipo de problemas se puede descubrir más adelante.

```{r}
#| echo: false
table(pymes$sector)
```

```{r}
# Homogeneizar texto
pymes <- pymes |> 
  mutate( sector = str_to_lower(sector),
          sector = str_replace_all(sector, "tecnologia", "tecnología"),
          sector = str_replace_all(sector, "farmaceutico", "farmacéutico"),
          sector = str_replace_all(sector, "energia", "energía") )
```


## Identificar Problemas (cont.)

::: {style="font-size: 95%;"}

3. Las variables con información **categórica** deben ser **factores**

```{r}
#| echo: false
#| eval: false
pymes <- pymes |>
  mutate(
    sector = as.factor(sector),
    pais = as.factor(pais),
    tipo_propiedad = as.factor(tipo_propiedad),
    tamano_ciudad = as.factor(tamano_ciudad),
    rating_credito = factor(rating_credito, 
                           levels = c("AAA", "AA", "A", "BBB", "BB", 
                                     "B", "CCC", "CC", "C", "D"),
                           ordered = TRUE)
  )
```

```{r}
pymes <- pymes |>
  mutate(across(c(sector, pais, tipo_propiedad, tamano_ciudad), 
                ~parse_factor(.x))) |>
  mutate(rating_credito = factor(rating_credito, 
                           levels = c("AAA", "AA", "A", 
                                      "BBB", "BB", "B", 
                                      "CCC", "CC", "C", "D"),
                           ordered = TRUE)
  )
```


:::: {.notes}
```{r}
#| eval: false
# Verificar
pymes |> select(where(is.factor)) |> str()
```
::::


4. Identificar Valores Faltantes (NAs)

```{r}
#| echo: false
# Resumen de NAs
pymes |> 
  summarise(across(everything(), ~sum(is.na(.)))) |>
  pivot_longer(everything(), names_to = "variable", values_to = "NAs") |>
  filter(NAs > 0) |>
  arrange(desc(NAs)) |>
  kable()
```

```{r}
pymes |> summary()
```

:::: {.notes}
Interpretación:

- Variables financieras: empresas que no reportan información
- `ebitda`, `beneficio_neto`: ~40 empresas sin datos
- `roe` tiene NAs porque depende de `beneficio_neto`

::::

- Podríamos decidir borrar o reemplazar los `NAs`, pero se suele preferir decidir al modelizar


:::

## Identificar Problemas (y 3)

4. Detectar y eliminar filas duplicadas

:::: {.notes}

y filas vacias?

::::

```{r}
#| echo: false

# ¿Hay duplicados completos?
sum(duplicated(pymes))

# Ver duplicados
dups <- duplicated(pymes) | duplicated(pymes, fromLast = TRUE)

pymes |>
  filter(dups) |>
  arrange(empresa_id) |>
  select(empresa_id, sector, pais, ingresos, empleados) |>
  head(10) |>
  kable()

```


```{r}
sum(duplicated(pymes))
pymes <- pymes |> distinct()
```



5. Variables que contienen información redundante

    - Ej., `activos_total` y `total_recursos` son `pasivos + patrimonio_neto` (igualdad contable)

```{r}
#| echo: false
# Verificar relación contable: Activos = Pasivos + Patrimonio
pymes |>
  mutate(diferencia = abs(activos_total - (pasivos + patrimonio_neto))) |>
  summarise(
    max_diferencia = max(diferencia, na.rm = TRUE),
    media_diferencia = mean(diferencia, na.rm = TRUE)
  ) |>
  kable()

all.equal(pymes$total_recursos, pymes$pasivos + pymes$patrimonio_neto)
```

```{r}
pymes <- pymes |> select(-total_recursos)
```

6. Renombrar variables (para mayor claridad), generar nuevas

7. ¿Mantenemos solo algunas variables u observaciones?

8. Otras...

- NO ES UNA RECETA: más adelante podemos volver atrás, para rehacer o tomar decisiones


:::: {.notes}

**Resumen de Limpieza Realizada**

Preprocesamiento completado:

- Tipos de variables corregidos (texto → numérico)
- Inconsistencias de texto homogeneizadas
- Variables categóricas convertidas a factores
- Duplicados eliminados
- Variables redundantes eliminadas
- NAs identificados (mantener por ahora)

Datos limpios: Ahora podemos comenzar el análisis exploratorio

```{r}
# Dimensiones finales
dim(pymes)
```

::::

:::: {.notes}
* Dos *tipos* de preguntas siempre serán útiles  para hacer descubrimientos dentro de sus datos

1. ¿Qué tipo de **variación** tiene cada variable? (análisis univariante)
    
2. ¿Qué tipo de relaciones se produce entre las variables (**covariación**)? (análisis multivariante)

* La respuesta implica analizar distribuciones, numérica y/o gráficamenente.

    + El análisis es diferente si las variables son numéricas o categóricas
::::


# Análisis de Variación ("univariante")

## Patrones de variación en los datos

- Queremos entender cómo cambian los valores de una variable entre distintas observaciones (p. e., ventas de diferentes empresas), es decir, su **distribución**

  - diferentes técnicas según el tipo de variable (numérica o categórica).

. . .

::: {style="font-size: 95%;"}

- Aspectos a observar en la distribución

  - Inconsistencias: categorías erróneas (“unknown”), valores fuera de rango
  
  - Concentración de valores: ceros, números redondos o repeticiones excesivas → ¿errores o patrones reales?
  
  - Categorías: ¿tienen sentido? ¿agrupar de manera diferente? ¿reagrupar si hay pocas observaciones?
  
  - Continuas: dispersión o asimetría (usar log?); ¿discretizar (ej. grupos de edad)?
  
  - Valores inusuales (“atípicos” o “outliers”): no encajan en el patrón general
  
    - ¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?

:::

:::: {.notes}

Notar que el análisis es diferente para variables categóricas y numéricas: es conveniente describirlas por separado en un documento final


Detectar inconsistencias en la distribución de valores o en las categorías: p.e., “unknown” en job de Bank

Valores frecuentes, concentración en valores concretos (p.e., ceros, números “redondos”, etc.): ¿por qué se producen? ¿son “esperables”?

 
¿Tienen sentido las categorías de las variables cualitativas?
agrupar valores con pocas observaciones
crear categorías más “finas”o más agregadas (ej. de países a continentes)
 
¿Sería preferible discretizar alguna variable continua? Ej., grupos de edad

Variables con alta dispersión o distribución asimétrica (logs?)

 
Variables con información redundante, homogeneizar valores, normalidad(?)
 
Valores inusuales (“atípicos” o “outliers”): no encajan en el patrón general

¿cambian los resultados del análisis sin ellos? ¿Qué los ha causado?

::::



## Variables Categóricas

- Describimos la distribución con **frecuencias y proporciones**: con `summary()`, `table()`, `mode()`  o con `summarize()`, `count()`
  
```{r}
table(pymes$sector)

pymes |> count(sector, sort = TRUE) |> mutate(prop = n / sum(n))
```

```{r}
#| echo: false
prop.table(table(pymes$sector))
```

- Este análisis puede detectar situaciones donde queremos **agrupar categorías**: 
  
    - dos clases similares 
    - clases con pocas observaciones (análisis más difícil: visualizaciones desequilibradas, resultados poco confiables) 
  
:::: {.notes}  
  - Estadísticos poco confiables (muestra pequeña)
  - Visualizaciones desequilibradas
  - Riesgo de overfitting en modelos posteriores
  - Dificultan comparaciones robustas
::::

```{r}
library(forcats)
pymes <- pymes |>
  mutate(sector_agrupado = fct_lump_min(sector, min = 5, 
                                  other_level = "Otros"), 
         sector_agrupado = fct_collapse(sector, 
                                  Grupo1 = c("manufactura", "textil"),
                                  Grupo2 = c("servicios", "comercio")))
```


## Variables Categóricas: Visualización

::: {style="font-size: 95%;"}

::::{.notes}
- Los gráficos ayudan a entender y explicar mejor la distribución de los datos.
::::

- Para distribuciones discretas, la mejor visualización de la distribución de los datos es un histograma.

```{r}
# frecuencias absolutas
ggplot(data = pymes) + geom_bar(aes(x = tipo_propiedad))  
# frecuencias relativas (proporciones)
ggplot(data = pymes)+ geom_bar(aes(x = tipo_propiedad, 
                                   y = after_stat(prop), group = 1))

# Variantes
pymes |> count(tipo_propiedad) |> ggplot() + 
  geom_bar(aes(x = tipo_propiedad, y = n), stat = "identity")

ggplot(data = pymes) + geom_bar(aes(x = tipo_propiedad)) +
  theme(axis.text.x = element_text(angle = 90))

# barra vertical
ggplot(data = pymes) + geom_bar(aes(x = "", fill = tipo_propiedad))
```


```{r}
#| echo: false
pymes |> count(tipo_propiedad) |> mutate(prop = n / sum(n)) |>
  ggplot() + geom_bar(aes(x = tipo_propiedad, y = prop), 
                      stat = "identity")
```

```{r}
#| echo: false
ggplot(data = pymes) + 
  geom_bar(aes(x = pais, y = after_stat(count/sum(count))))
```


- Observación: la mayor parte de las PYMEs son empresas familiares o S.L.

:::

## Variables Cuantitativas

::: {style="font-size: 95%;"}
- Estadísticas descriptivas básicas con `summary()`
```{r}
summary(pymes)
```

- Información adicional con funciones para estadísticos (rango, varianza, cuartiles, asimetría) 

```{r}
summary(pymes$ingresos)
pymes |>
  summarise(
    media = mean(ingresos, na.rm = TRUE),
    mediana = median(ingresos, na.rm = TRUE),
    sd = sd(ingresos, na.rm = TRUE),
    min = min(ingresos, na.rm = TRUE),
    max = max(ingresos, na.rm = TRUE),
    q25 = quantile(ingresos, 0.25, na.rm = TRUE),
    q75 = quantile(ingresos, 0.75, na.rm = TRUE),
    NAs = sum(is.na(ingresos)))
```

- Interés particular en amplia variabilidad, distribución asimétrica

:::

## Variables Cuantitativas: Visualización

- Para distribuciones numéricas, la visualización de la distribución de los datos puede realizarse con un histograma, con la densidad o ambos.

```{r}
ggplot(pymes) + geom_histogram(aes(x = empleados), bins = 30)

ggplot(pymes, aes(x=empleados)) + 
  geom_histogram(aes(y=after_stat(density)), bins = 30) + 
  geom_density()
```

- Recordar: usar varios anchos de intervalo. Esto es **discretizar** la variable continua de formas distintas

- Si observamos una distribución muy asimétrica, considerar escala logarítmica

```{r}
ggplot(pymes, aes(x = ingresos)) + geom_histogram(bins = 30) 
ggplot(pymes, aes(x = ingresos)) + geom_histogram(bins = 30) + 
  scale_x_log10()
```

 
## Variables Cuantitativas: Visualización con Boxplots

- Los gráficos de caja pueden ser útiles sobre la dispersión, identificar outliers y comparar distribuciones

```{r}
ggplot(pymes, aes(y = roe)) +
  geom_boxplot()
```

![](figure/eda-boxplot.png){width=75% fig-align="center"}

:::: {.notes}
**Identificar Outliers: Método IQR**

Método estándar: IQR (Rango Intercuartílico)

```{r}



# Calcular límites
Q1 <- quantile(pymes$roe, 0.25, na.rm = TRUE)
Q3 <- quantile(pymes$roe, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
limite_inf <- Q1 - 1.5 * IQR
limite_sup <- Q3 + 1.5 * IQR

# Contar outliers
pymes <- pymes |>
  mutate(roe_outlier = roe < limite_inf | roe > limite_sup)

table(pymes$roe_outlier)
```

Decisión: NO eliminar automáticamente, investigar causa


Outliers pueden ser:

- Errores de medición → corregir o eliminar
- Casos reales extremos → mantener o analizar por separado
- Empresas excepcionales → insights valiosos
::::

## Herramientas Automáticas

- `datasummary_skim()`: vista rápida de todas las variables (o algunas seleccionada), distinguiendo automáticamente por tipo 

  - útil para uso personal, no necesariamente para incluir en informe final

::::{.notes}

- inspirada en `skim()` de `skimr`

    - devuelve un `data frame`

    - Ventajas: Visión rápida, histogramas inline, NAs, estadísticos

- DataExplorer
- El paquete janitor contiene herramientas para limpieza de datos

::::

```{r}
library(modelsummary)
pymes |> datasummary_skim()
```

```{r}
#| echo: false
pymes |> select(activos_total:patrimonio_neto) |> datasummary_skim()
pymes |> datasummary_skim(type = "categorical")
```

- `DataExplorer`

```{r}
#| eval: false
library(DataExplorer)
plot_bar(pymes)        # para TODAS las variables categóricas
plot_histogram(pymes)  # para TODAS las variables numéricas

create_report(pymes)
```

- `dlookr` ofrece heramientas para diagnóstico y exploración de datos 

::::{.notes}
- devolviendo *data frame* (para usar con `kable()`)

```{r}
#| echo: false
#| eval: false
library(dlookr)       # en MacOS, puede pedir instalar XQuartz
diagnose(pymes) |>
  select(variables, types, missing_count, missing_percent, unique_count) |>
  head(10) |>
  kable()

describe(pymes, campaign:y)

pymes |> describe() |>
  select(described_variables, skewness, mean, p25, p50, p75) |> 
  filter(!is.na(skewness)) |> arrange(desc(abs(skewness)))

pymes |>
  group_by(pais) |> 
  describe(empleados, activos_total, pasivos) 

pymes |> normality() |>
  filter(p_value <= 0.01) |> arrange(abs(p_value))

pymes |> plot_normality()


pymes |> eda_web_report()
pymes |> eda_paged_report()
pymes |> eda_paged_report(output_format = "pdf")
```

::::

# Análisis de Covariación ("multivariante")

## Análisis de Covariación 

::::{.notes}
- La variación describe el comportamiento *dentro* de una variable
::::

- La covariación describe **relaciones entre variables**: tendencia a que los valores de una variable dependan de la otra

- Estudiamos la **distribución condicional** de una variable $\small{Y}$ dados los valores de otra $\small{X}$

  - Si $\small{\Pr(Y|X=x_1) = \Pr(Y|X=x_0) =  \Pr(Y) \Rightarrow}$ $\small{Y}$ NO depende de $\small{X}$

    - p.e., el valor esperado de $\small{Y}$ será el mismo para distintos valores de $\small{X}$
    
  - Si la probabilidad condicional de que $\small{Y}$ tome valores altos (o bajos) depende de lo que sabemos de $\small{X}$, se puede **predecir** (su valor esperado) a partir del valor de $\small{X}$


- Punto de partida para formular modelos que explican **patrones complejos** de los datos

::::{.notes}

  - ¿qué explica la relación sugerida por el patrón de covariación? 
  
  - ¿cómo de fuerte es la relación?
  
  - ¿otras variables pueden afectar a la relación? ¿varían por subgrupos?


- ¿es la covariación una relación causal? 

::::


- La forma de visualizar la posible existencia de relaciones depende del *tipo de variables*


## Una variable numérica y una categórica

::: {style="font-size: 95%;"}

- ¿Es diferente la distribución de Y (continua) por categorías de X? 

  - Cuidado: podemos necesitar *escala logarítmica*
  
  - También ajustes como reordenar las categorías de un factor (`forcats`), rotar los ejes, etc.

- Podemos usar histogramas o densidades, en un mismo gráfico o con facetas

```{r}
g0 <- ggplot(pymes, aes(x = ingresos)) +  scale_x_log10()
g0 + geom_density(aes(color = tamano_ciudad))
g0 + geom_density() + facet_wrap(~sector)
```

```{r}
#| echo: false
#| eval: false
ggplot(pymes, aes(x = ingresos, color = tamano_ciudad)) + 
  geom_density() + scale_x_log10()
ggplot(pymes) + geom_density(aes(x = ingresos)) + 
  facet_wrap(~sector) + scale_x_log10()
```


- Con muchos grupos o uno muy pequeño, es difícil notar diferencias 
```{r}
pymes <- pymes |> mutate(rating = fct_collapse(rating_credito, 
                        "Rating Alto" = c("AAA", "AA", "A", "BBB"),
                        "Rating Bajo" = c("BB", "B", "CCC", "CC", "C", "D")))
ggplot(pymes, aes(x = ingresos, color = rating)) +     # color = rating_credito
            geom_density() + scale_x_log10()
```

```{r}
#| echo: false
#| eval: false
ggplot(pymes, aes(x = ingresos, color = rating_credito)) + 
  geom_density() + scale_x_log10()
pymes <- pymes |> mutate(rating = fct_collapse(rating_credito, 
                        "Rating Alto" = c("AAA", "AA", "A", "BBB"),
                        "Rating Bajo" = c("BB", "B", "CCC", "CC", "C", "D")))
ggplot(pymes, aes(x = ingresos, color = rating)) +
            geom_density() + scale_x_log10()

```


- También con gráficos de caja (menos información pero más fácil de comparar)  

  - ¿cómo se vería este gráfico si no hubiesemos homogeneizado `sector`?

```{r}
ggplot(pymes, aes(x = sector, y = ingresos, fill = sector)) +
  geom_boxplot() + scale_y_log10()
```

:::

## Una variable numérica y una categórica (cont.)

::: {style="font-size: 95%;"}

- También podemos calcular estadísticos concretos de la distribución de Y para distintos valores de X

```{r}
pymes |> group_by(sector) |>
  summarise(media = mean(ingresos, na.rm = TRUE),
            mediana = median(ingresos, na.rm = TRUE),
            n = n(),
            sd = sd(ingresos, na.rm = TRUE))
pymes |> group_by(rating) |>
  summarise(media = mean(ingresos, na.rm = TRUE),
            mediana = median(ingresos, na.rm = TRUE),
            n = n(),
            sd = sd(ingresos, na.rm = TRUE))
```

- NOTA: una regresión simple equivale a calcular la media de la variable continua por grupos

$$
\scriptsize
E[Y|X]=\beta_0+\beta_1 X \Rightarrow 
\begin{cases} 
E[Y|X=0] &=\beta_0 \\
E[Y|X=1]&=\beta_0+\beta_1
\end{cases}
$$

```{r}
lm(data = pymes, ingresos ~ sector) |> summary()
lm(data = pymes, ingresos ~ rating) |> summary()
```


- ¿Y mediante la correlación? NO tiene sentido cuando una variable es categórica 

```{r}
#| eval: false
pymes |> select(ingresos, rating) |> cor()
```

:::

## Dos variables categóricas

- Partimos de la distribución conjunta de frecuencias absolutas

```{r}
#| echo: false
table(pymes$sector, pymes$tipo_propiedad)

pymes |> ggplot(aes(x=tipo_propiedad)) + geom_bar(aes(fill=sector)) 
pymes |> ggplot(aes(x=tipo_propiedad)) + geom_bar()+ facet_wrap(~sector)
``` 

```{r}
pymes |> count(sector, tipo_propiedad) |>
  pivot_wider(names_from = tipo_propiedad, values_from = n)

pymes |> ggplot(aes(x=tipo_propiedad)) + geom_bar(aes(fill=sector), 
                                                  position="dodge")
```

- Pero es más informativo la tabla o visualización de la distribución condicional de frecuencias relativas de una variable dada la otra

  - ¿Hay la misma proporción de los tipos de propiedad en distintos sectores?

```{r}
datos <- pymes |> count(sector, tipo_propiedad) |> 
  group_by(sector) |> mutate(prop= n/sum(n)) |> select(-n) 

datos |> pivot_wider(names_from = sector, values_from = prop) 
datos |> ggplot() + geom_bar(aes(x=sector, y=prop, fill = tipo_propiedad), 
                      stat = "identity")

ggplot(pymes, aes(x = sector, fill = tipo_propiedad)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent)
```

::::{.notes}

- la distribución condicional es bastante diferente para varias categorías

- están relacionadas

::::

```{r}
#| echo: false

table(pymes$sector, pymes$tipo_propiedad) |> prop.table(margin = 2)
pymes |> count(sector, tipo_propiedad) |> 
  group_by(tipo_propiedad) |> mutate(prop= n/sum(n)) |> select(-n) |> 
  pivot_wider(names_from = sector, values_from = prop)  

pymes |> ggplot(aes(x=sector)) + geom_bar(aes(fill=tipo_propiedad), position = "fill") 

pymes |> count(sector, tipo_propiedad) |> 
  group_by(sector) |> mutate(prop= n/sum(n)) |> 
  ggplot() + geom_bar(aes(x=sector, y=prop, fill = tipo_propiedad), 
                      stat = "identity")
```

## Dos variables numéricas

- La forma obvia de visualizar relaciones entre variables continuas es un gráfico de dispersión; añadir `smoothers` ayuda a apreciar un patrón en los puntos

```{r}
ggplot(pymes, aes(x = activos_total, y = ingresos)) +
  geom_point() + geom_smooth(method = "lm", se = TRUE) +
  scale_x_log10() +  scale_y_log10() 
```
::::{.notes}
  - Observamos una relación positiva entre activos e ingresos, pero en logaritmos
  
  - la relación es NO lineal
::::

* Con `GGally` obtenemos una primera visión de conjunto

  - PERO la automatización no permite ajustes (ej., escala logarítmica)

```{r}
#| eval: false
library(GGally)
#pymes |> select(where(is.numeric)) |> ggpairs()
pymes |> select(empleados:ingresos) |> ggpairs()
```

- Otra posibilidad: discretizar una variable continua y usar las técnicas anteriores

```{r}
#| echo: true
pymes |> mutate(empleados_group = cut(empleados, 
                                      breaks=seq(0, 250, by=25))) |>
  ggplot() + geom_boxplot(aes(y = ingresos, x = empleados_group)) + 
             scale_y_log10()

``` 

::::{.notes}
- no existe relación entre ingresos y empleados
::::

## Dos variables numéricas: correlación 

- Podemos estimar modelos de regresión con dos variables continuas

```{r}
#| echo: true
summary(lm(data = pymes, ingresos ~ activos_total) )
``` 

- Y también correlaciones para dos (o múltiples) variables
```{r}
pymes |>
  select(activos_total, ingresos, empleados, 
         beneficio_neto, roe, roa) |>
  cor(use = "complete.obs")
```

```{r}
#| echo: false
cor(pymes$ingresos, pymes$activos_total, use = "complete.obs")

library(dlookr)
pymes |> correlate()
pymes |> select(ingresos, activos_total) |>  correlate() 
pymes |> group_by(pais) |>  correlate() 
```

::::{.notes}

Interpretación:

- Correlación alta entre `activos_total` e `ingresos` (0.82)

- `ROE` y `ROA` moderadamente correlacionados

- `empleados` correlacionado con tamaño financiero

::::


- O visualizar las correlaciones

```{r}
datos <- pymes |>
  select(activos_total, pasivos, patrimonio_neto, ingresos, 
         ebitda, beneficio_neto, liquidez_ratio, roe, roa,
         deuda_patrimonio, empleados)

datos |> correlate() |> plot()

library(corrplot)
datos |> cor() |> corrplot()
datos |> cor() |> corrplot.mixed()

``` 

```{r}
#| echo: false

library(corrplot)
datos |> cor(use = "complete.obs") |> corrplot()
datos |> cor(use = "complete.obs") |> corrplot.mixed()
```


# Transformación: Motivación desde el AED

## Crear Variables Derivadas

::: {style="font-size: 95%;"}

::::{.notes}
El AED puede sugerir transformación o creación de variables 
::::

1. Usar logaritmos para variables con distribución asimétrica

::::{.notes}
- **Antigüedad** de la empresa:

- Tenemos `anio_fundacion` pero queremos analizar madurez
- Análisis temporal reveló que empresas fundadas en diferentes décadas se comportan diferente
- Para comparaciones: necesitamos años desde fundación, no año absoluto

```{r}
# Calcular antigüedad
pymes <- pymes |>
  mutate(antiguedad = 2024 - anio_fundacion)
```

**Ahora podemos**:
- Comparar empresas jóvenes (< 5 años) vs consolidadas (> 15 años)
- Analizar relación antigüedad-rentabilidad
- Identificar si hay "valle de la muerte" para PYMEs
::::

2. **Agrupación por tamaño**: la distribución de empleados tiene un rango muy amplio 

```{r}
pymes |> ggplot() + geom_histogram(aes(x = empleados))
pymes <- pymes |>
  mutate(tamano_empresa = cut(empleados, breaks = c(0, 10, 50, 250, Inf),
                 labels = c("Micro", "Pequeña", "Mediana", "Grande"),
                 include.lowest = TRUE) )
```

- *Disyuntiva*: Discretizar simplifica comunicación (Pequeña vs. Mediana) pero pierde información (tratamo igual a 11 y 49 empleados)

::::{.notes}
  - Facilita comparaciones "Micro vs Pequeña vs Mediana"
  - Tratamos igual empresas de 11 y 49 empleados
  - Mantener ambas (continua para análisis, categórica para comunicación)
::::

::::{.notes}
Caso 3: Productividad laboral

**Motivación del AED**:

Del análisis bivariante vimos:
- Ingresos correlacionados con empleados (r = 0.65)
- Pero la relación no es proporcional
- Queremos medir eficiencia: ingresos por empleado

```{r}
# Crear variable de productividad
pymes <- pymes |>
  mutate(productividad_laboral = ingresos / empleados)
```

Esta variable derivada permite:
- Comparar eficiencia entre empresas de distinto tamaño
- Identificar empresas sobre/sub-performando
- Analizar productividad por sector (tech vs manufactura)

**Insight del AED posterior**: Tecnología tiene productividad 3x mayor que Manufactura
::::

3. **Agrupar categorías de rating financiero**: el análisis univariante mostraba algunas categorías con pocas observaciones y otras con comportamiento similar

::::{.notes}
**Decisión de negocio**: Crear tres grupos significativos

```{r}
# Agrupar ratings bajos
pymes <- pymes |>
  mutate(
    rating_agrupado = fct_collapse(rating_credito,
      "Grado Inversión" = c("AAA", "AA", "A", "BBB"),
      "Grado Especulativo" = c("BB", "B"),
      "Alto Riesgo" = c("CCC", "CC", "C", "D")
    )
  )
```


**Justificación**:
- "Grado Inversión": bajo riesgo, acceso fácil a financiación
- "Grado Especulativo": riesgo moderado, típico de muchas PYMES
- "Alto Riesgo": problemas financieros serios, requiere atención

Esta agrupación:
- Es robusta estadísticamente (suficientes observaciones)
- Tiene sentido de negocio (convención del mercado)
- Facilita visualización y comunicación
- Mantiene poder predictivo (verificado en análisis bivariante)

```{r}
# Visualización agrupada
ggplot(pymes, aes(x = rating_agrupado, fill = rating_agrupado)) +
  geom_bar() 
```
::::


* Agrupar cuando:

  1. El análisis previo mostró que es necesario

  2. Tiene sentido de negocio

  3. Las categorías agrupadas tienen comportamiento similar

  4. Mejora la robustez sin perder información crítica

::::

::::{.notes}
Relación Rating - Variables Financieras

```{r}
# Ratio deuda/patrimonio por rating
ggplot(pymes, aes(x = rating_agrupado, y = deuda_patrimonio, 
                  fill = rating_agrupado)) +
  geom_boxplot() +
  scale_fill_manual(values = c("green3", "gold2", "red2")) +
  coord_cartesian(ylim = c(0, 3)) +
  theme_minimal() +
  labs(title = "Ratio Deuda/Patrimonio por Categoría de Riesgo",
       x = "Categoría de Riesgo", y = "Ratio Deuda/Patrimonio") +
  theme(legend.position = "none")
```

Insight: Empresas de alto riesgo tienen mayor endeudamiento

::::

<!--
# Más Aplicaciones Prácticas

## Análisis de Productividad Laboral

Calcular productividad: ingresos por empleado

```{r}


# Crear variable de productividad
pymes <- pymes |>
  mutate(productividad_laboral = ingresos / empleados)
```

```{r}


#| fig-show: asis
#| fig-width: 10
#| fig-height: 6

# Productividad por sector
pymes |>
  filter(!is.na(productividad_laboral)) |>
  ggplot(aes(x = sector_agrupado, y = productividad_laboral, 
             fill = sector_agrupado)) +
  geom_boxplot() +
  scale_y_log10(labels = scales::comma) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  labs(title = "Productividad Laboral por Sector",
       x = "Sector", 
       y = "Ingresos por Empleado (miles €, escala log)")
```

Insight: Tecnología lidera en productividad laboral

## Análisis de Innovación y Rentabilidad

¿Las empresas que invierten más en innovación son más rentables?

```{r}


#| fig-show: asis
#| fig-width: 10
#| fig-height: 6

# Relación innovación-ROE
pymes |>
  filter(!is.na(innovacion_pct), !is.na(roe)) |>
  ggplot(aes(x = innovacion_pct, y = roe)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  theme_minimal() +
  labs(title = "Relación entre Inversión en I+D y Rentabilidad",
       x = "Inversión en I+D (% ingresos)",
       y = "ROE (%)")
```

```{r}



# Correlación
cor.test(pymes$innovacion_pct, pymes$roe, use = "complete.obs")
```

Conclusión: Correlación positiva débil pero significativa

## Análisis de Exportaciones por País

¿Qué países tienen empresas más orientadas a la exportación?

```{r}



# Exportaciones promedio por país
pymes |>
  filter(!is.na(exportaciones_pct)) |>
  group_by(pais) |>
  summarise(
    n = n(),
    exportaciones_media = mean(exportaciones_pct),
    exportaciones_mediana = median(exportaciones_pct)
  ) |>
  arrange(desc(exportaciones_media)) |>
  kable(digits = 1)
```

:::: {.notes}
```{r}
#| eval: false
# Discretizar exportaciones
pymes <- pymes |>
  mutate(
    perfil_exportador = case_when(
      exportaciones_pct == 0 ~ "No exporta",
      exportaciones_pct < 25 ~ "Exportador ocasional",
      exportaciones_pct < 50 ~ "Exportador moderado",
      exportaciones_pct >= 50 ~ "Exportador principal"
    ),
    perfil_exportador = factor(perfil_exportador, 
                               levels = c("No exporta", "Exportador ocasional",
                                        "Exportador moderado", "Exportador principal"))
  )
```
::::

## Análisis por Tamaño de Empresa

```{r}



# Características por tamaño
pymes |>
  group_by(tamano_empresa) |>
  summarise(
    n = n(),
    ingresos_promedio = mean(ingresos, na.rm = TRUE),
    roe_promedio = mean(roe, na.rm = TRUE),
    deuda_patrimonio_promedio = mean(deuda_patrimonio, na.rm = TRUE)
  ) |>
  kable(digits = 1)
```

Insight:

- Empresas más grandes: mayores ingresos (obvio)
- ROE similar entre tamaños
- Grandes empresas: mayor acceso a financiación (menor deuda/patrimonio)

## Análisis Temporal: Antigüedad

```{r}


#| fig-show: asis
#| fig-width: 10
#| fig-height: 6

# ROE por antigüedad
pymes |>
  filter(!is.na(roe), !is.na(antiguedad)) |>
  ggplot(aes(x = antiguedad, y = roe)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "loess", color = "red", se = TRUE) +
  theme_minimal() +
  labs(title = "Rentabilidad por Antigüedad de la Empresa",
       x = "Antigüedad (años)",
       y = "ROE (%)")
```

Patrón: Empresas jóvenes más volátiles, consolidadas más estables

## Análisis de Riesgo: Morosidad

```{r}


#| fig-show: asis
#| fig-width: 10
#| fig-height: 6

# Morosidad por rating de riesgo
pymes |>
  filter(!is.na(morosidad_dias)) |>
  ggplot(aes(x = rating_agrupado, y = morosidad_dias, 
             fill = rating_agrupado)) +
  geom_boxplot() +
  scale_fill_manual(values = c("green3", "gold2", "red2")) +
  theme_minimal() +
  labs(title = "Días de Morosidad por Categoría de Riesgo",
       x = "Categoría de Riesgo", y = "Días de morosidad promedio") +
  theme(legend.position = "none")
```

Conclusión: Clara relación entre rating y morosidad

## Análisis Geográfico: Patrones por País

```{r}



# Comparación de indicadores por país (top 5)
pymes |>
  filter(pais %in% c("España", "Alemania", "Francia", "Italia", "Portugal")) |>
  group_by(pais) |>
  summarise(
    n = n(),
    roe_medio = mean(roe, na.rm = TRUE),
    deuda_patr_medio = mean(deuda_patrimonio, na.rm = TRUE),
    liquidez_media = mean(liquidez_ratio, na.rm = TRUE),
    innovacion_media = mean(innovacion_pct, na.rm = TRUE)
  ) |>
  arrange(desc(roe_medio)) |>
  kable(digits = 2)
```

Insights:

- Alemania: mejor ROE y menor endeudamiento
- España e Italia: mayor endeudamiento
- Diferencias significativas en innovación

## Análisis Multivariante: Sector × País

```{r}



# Interacción sector-país (top combinaciones)
pymes |>
  filter(sector_agrupado != "Otros",
         pais %in% c("España", "Alemania", "Francia", "Italia")) |>
  group_by(sector_agrupado, pais) |>
  summarise(
    n = n(),
    roe_medio = mean(roe, na.rm = TRUE)
  ) |>
  filter(n >= 10) |>
  arrange(desc(roe_medio)) |>
  head(10) |>
  kable(digits = 1)
```

Conclusión: Hay interacciones importantes sector-país

## Caso de Negocio: Scoring de Empresas

Crear un score simple para priorizar empresas de inversión

```{r}


# Score basado en múltiples criterios
pymes <- pymes |>
  mutate(
    score_rentabilidad = case_when(
      is.na(roe) ~ 0,
      roe >= 15 ~ 3,
      roe >= 10 ~ 2,
      roe >= 5 ~ 1,
      TRUE ~ 0
    ),
    score_liquidez = case_when(
      is.na(liquidez_ratio) ~ 0,
      liquidez_ratio >= 2 ~ 3,
      liquidez_ratio >= 1.5 ~ 2,
      liquidez_ratio >= 1 ~ 1,
      TRUE ~ 0
    ),
    score_deuda = case_when(
      is.na(deuda_patrimonio) ~ 0,
      deuda_patrimonio < 0.5 ~ 3,
      deuda_patrimonio < 1 ~ 2,
      deuda_patrimonio < 1.5 ~ 1,
      TRUE ~ 0
    ),
    score_total = score_rentabilidad + score_liquidez + score_deuda
  )
```

-->

# Herramientas de AED Automatizado y uso de IA

## La Promesa de la Automatización

- El AED manualmente consume tiempo. Se pueden automatizar partes del proceso, **pero con precaución**

- Ventajas de herramientas automatizadas: Velocidad, Exahaustividad, *Primera* Exploración

::::{.notes}
- Velocidad: generan reportes completos en segundos/minutos
- Exhaustividad: revisan sistemáticamente todas las variables
- Reproducibilidad: mismo código → mismos resultados
- Punto de partida: excelente para primera exploración
::::

- Limitaciones críticas:

  - Ruido: muchos gráficos irrelantes
  
  - No entienden contexto de negocio
  
  - Interpretación superficial ->  No sugieren acciones específicas

- Herramientas de AED Automatizado

  - Herramientas interactivas: `GWalkR`, `explore`, [`Radiant`](https://radiant-rstats.github.io/docs/) (también [online](https://vnijs.shinyapps.io/radiant/))

  - Informes completos automatizados con `DataExplorer`, `dlookr`, `smartEDA`, `DataMaid`

::::{.notes}

- explorar datos y/o realizar visualizaciones y tableros interactivos

- Radiant  tanto para análisis exploratorio, visualización y transformación como para algunas modelizaciones

```{r}
#| eval: false
#| echo: false

# GWalkR: Interfaz tipo Tableau
library(GWalkR)
gwalkr(pymes)

# explore: Exploración guiada
library(explore)
explore(pymes)
```

::::

  

:::: {.notes}

**DataExplorer: reporte HTML completo**

```{r}
#| eval: false
library(DataExplorer)
# Reporte completo automatizado
create_report(pymes, 
              output_file = "reporte_pymes.html",
              y = "rating_agrupado")
```

Genera automáticamente:

- Estructura del dataset
- Variables con missing values
- Distribuciones univariantes
- Correlaciones
- Análisis bivariante con variable objetivo

*Útil para*: Primera exploración, compartir con no-técnicos

*Limitación*: 100+ páginas sin priorización


**dlookr: Diagnóstico y análisis**

Además de `diagnose()` y `describe()`
```{r}
#| eval: false
library(dlookr)
# Reporte web interactivo
pymes |> 
  mutate(across(where(is.character), as.factor)) |> 
  eda_web_report(
    target = "rating_agrupado",
    output_file = "eda_pymes.html",
    author = "Tu Nombre"
  )
```

Incluye:

- Diagnóstico de calidad
- Análisis univariante y bivariante
- Tests estadísticos automáticos
- Transformaciones sugeridas

*Útil para*: Exploración técnica detallada

*Limitación*: Requiere entender estadística para interpretar tests

**smartEDA: Análisis exploratorio inteligente**

```{r}
#| eval: false
#| echo: false
library(SmartEDA)
# Reporte completo
ExpReport(pymes, 
          Target = "rating_agrupado",
          op_file = "SmartEDA_pymes.html",
          op_dir = "output/")

# Función útil: Resumen ejecutivo
ExpData(data = pymes, type = 1)  # Overview
ExpData(data = pymes, type = 2)  # Structure
```

*Útil para*: Balance entre detalle y usabilidad
::::


::::{.notes}

Cuándo usar cada herramienta

| Situación | Herramienta recomendada |
|-----------|------------------------|
| Primera exploración de datos nuevos | `DataExplorer::create_report()` |
| Diagnóstico técnico de calidad | `dlookr::diagnose()` |
| Estadísticos rápidos con gráficos | `skimr::skim()` |
| Exploración interactiva | `explore::explore()` o `GWalkR` |
| Reportes para stakeholders | `SmartEDA::ExpReport()` |
| Análisis profundo experto | **Manual (lo que hemos hecho)** |

::::

## IA Generativa para análisis de datos

::: {style="font-size: 90%;"}

-  El usuario debe introducir un *prompt* efectivo (no solo "analiza")
```
Analiza pymes_europa.csv. Variables clave: ingresos, roe, sector, país. 
Contexto: PYMES europeas 2020-2024. ROE típico: 8-12%. 
Pregunta: ¿Qué características tienen empresas con ROE > 15%?
Dame: limpieza, descriptivos, visualizaciones, análisis por sector
```

- Fortalezas

  - Genera código estándar rápidamente y lo documenta
  
  - Sugiere análisis adicionales
  
  - Explica conceptos estadísticos

::::{.notes}
1. **Generar código estándar rápidamente**
   - "Crea un boxplot de ingresos por sector"
   - "Calcula correlaciones entre variables financieras"

2. **Sugerir análisis adicionales**
   - "También podrías analizar la distribución por país"
   - "Verifica si hay outliers usando el método IQR"

3. **Explicar conceptos**
   - "¿Qué significa un p-valor < 0.05?"
   - "¿Cómo interpreto un coeficiente de correlación negativo?"

4. **Documentación automática**
   - Genera comentarios para el código
   - Crea descripciones de hallazgos
::::

- **Limitaciones críticas**:

  1. No conoce tu contexto de negocio 
  
  2. Análisis superficial y sin identificar patrones específicos del dominio
  
  3. Riesgo de errores
  
     - Puede "inventar" patrones inexistentes
     - Confunde correlación con causalidad
     - Interpretaciones estadísticamente incorrectas
  
  4. Limitaciones técnicas: datos < 100-200MB, resultados dependen del prompt
  
::::{.notes}

1. **No conoce tu contexto de negocio**
   ```
   ❌ IA: "Un ROE de 5% es bajo"
   ✓ Experto: "5% es normal en retail pero bajo en tech"
   ```

2. **Análisis superficial**
   - Hace análisis estándar (correlaciones, medias, etc.)
   - NO identifica patrones sutiles específicos del dominio
   - NO formula hipótesis de negocio interesantes

3. **Riesgo de "hallucinations"**
   ```
   ❌ IA podría "inventar" patrones que no existen
   ❌ Interpretaciones estadísticamente incorrectas
   ❌ Confundir correlación con causalidad
   ```

4. **Limitación de tamaño**
   - ChatGPT: datasets < 100-200MB funcionan bien
   - Para datos grandes: necesitas estrategias (sampling, agregación)

5. **Dependencia de prompts**
   - Resultado depende de cómo preguntes
   - Requiere conocer qué preguntar (¡conocimiento previo!)

::::

::::{.notes}
**Ejemplo práctico con IA**

**Prompt efectivo**:
```
"Analiza pymes_europa.csv. Variables clave: ingresos, roe, 
sector, pais. 

Contexto: son PYMES europeas 2020-2024. Un ROE típico es 
8-12%. Sectores principales: Manufactura, Servicios, Tecnología.

Pregunta de negocio: ¿Qué características tienen las empresas 
con ROE > 15%?

Dame: (1) Limpieza necesaria, (2) Estadísticos descriptivos, 
(3) Visualizaciones clave, (4) Análisis por sector"
```

**Por qué es bueno**:
- Da contexto de negocio
- Define rangos normales
- Pregunta específica de negocio
- Solicita análisis estructurado

**Prompt malo**:
```
"Analiza este dataset"
```
→ Resultado: análisis genérico sin valor

::::


::::{.notes}

**SIEMPRE**:

1. **Verifica el código generado**
   - ¿Usa las variables correctas?
   - ¿Maneja NAs apropiadamente?
   - ¿Las transformaciones tienen sentido?

2. **Valida interpretaciones**
   ```r
   # IA sugiere: "La correlación es 0.85, muy fuerte"
   # TÚ verificas: ¿Es espuria? ¿Hay outliers influyendo?
   
   # IA dice: "No hay diferencias entre sectores"
   # TÚ verificas: ¿Usó el test apropiado? ¿Suficiente muestra?
   ```

3. **Cuestiona recomendaciones**
   - ¿Tienen sentido de negocio?
   - ¿Están respaldadas por los datos?
   - ¿Consideran el contexto del problema?

::::

:::

## Filosofía: Automatización Inteligente

::::{.notes}
**El modelo 80/20 para AED moderno**

**20% del tiempo: Automatización**
- Herramientas de autoEDA para exploración inicial
- IA para generar código estándar
- Reportes automatizados para stakeholders

**80% del valor: Análisis experto**
- Interpretación basada en conocimiento del dominio
- Decisiones sobre limpieza y transformaciones
- Formulación de hipótesis de negocio
- Validación y crítica de hallazgos
- Recomendaciones accionables

**Flujo de trabajo recomendado**

::::


:::: {.notes}
   ```r
   # 5 minutos
   pymes |> skim()
   pymes |> diagnose()
   create_report(pymes)
   ```
::::


1. Exploración rápida (automática)


2. Identificar áreas de interés
   - ¿Qué variables tienen problemas?
   - ¿Qué relaciones parecen interesantes?
   - ¿Qué no tiene sentido de negocio?

3. Análisis manual profundo **(lo que hicimos)**
   - Limpieza contextualizada
   - Visualizaciones específicas
   - Interpretación experta

::::{.notes}
4. **Usar IA como asistente**
   ```
   "Ayúdame a crear una visualización que compare 
   ROE por sector para empresas con >50 empleados, 
   destacando el top 10% en cada sector"
   ```
::::

4. SIEMPRE validación crítica de resultados de IA y documentar
  
    - Verifica el código (piensa y re-pregunta)
  
    - Valida las decisiones e interpretaciones (piensa y re-pregunta)

    - Cuestiona las recomendaciones (piensa y re-pregunta)

:::: {.notes}

Validar y documentar

   - Verificar todos los hallazgos importantes
   - Documentar decisiones y justificaciones
   - Crear narrativa de negocio

::::

## Advertencias Importantes

### NO hagas esto:

❌ Usar reportes automatizados como análisis final

❌ Confiar ciegamente en interpretaciones de IA

❌ Incluir todas las visualizaciones automáticas

❌ Olvidar validar hallazgos automáticos


Desarrolla criterio para saber cuándo confiar en automatización


### SÍ haz esto:

✓ Usar automatización como punto de partida

✓ Validar críticamente todo *output* automático

✓ Combinar velocidad de herramientas con *expertise* humano

✓ Mantener el contexto de negocio en el centro

**Regla de oro**: La automatización acelera, el expertise guía. Nunca al revés.


::::{.notes}

✓ Documentar por qué una herramienta sugirió algo
::::

::::{.notes}
**Ejemplo: Análisis Híbrido**

Flujo real de un análisis profesional:

```r
# 1. Exploración automática (5 min)
pymes |> skim()
diagnose(pymes) |> filter(missing_percent > 10)

# 2. Pregunta a IA (2 min)
"Sugiere visualizaciones para entender la relación 
entre tamaño de empresa y rentabilidad"

# 3. Código generado por IA (revisado por ti)
ggplot(pymes, aes(x = empleados, y = roe)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess") +
  scale_x_log10()

# 4. TÚ interpretas con contexto de negocio (15 min)
# Observas que empresas 20-50 empleados tienen ROE más alto
# Investigas por qué: ¿eficiencia operativa? ¿sectores?
# Validas con análisis adicional por sector
# Formulas hipótesis de negocio

# 5. TÚ decides acción (5 min)
# "Recomendar a inversores: PYMES 20-50 empleados 
# en sector Servicios muestran mejor rentabilidad..."
```
::::

:::: {.notes}
**Recursos para profundizar**

- *autoEDA en R*: [Journal of Statistical Software paper](https://journal.r-project.org/archive/2019/RJ-2019-033/)
- *IA para análisis*: [ChatGPT for EDA guide](https://www.analyticsvidhya.com/blog/2023/04/analyzing-data-using-chatgpt/)
- *Limitaciones de LLMs*: [Statistical Modeling blog](https://statmodeling.stat.columbia.edu/2024/06/24/forking-paths-in-llms-for-data-analysis/)

::::



::::{.notes}
**Distribución del Score de Inversión**

```{r}


#| fig-show: asis
#| fig-width: 10
#| fig-height: 5

# Visualizar distribución del score
ggplot(pymes, aes(x = factor(score_total))) +
  geom_bar(fill = "steelblue") +
  theme_minimal() +
  labs(title = "Distribución del Score de Inversión (0-9)",
       x = "Score Total", y = "Número de empresas")
```

```{r}
# Top empresas por score
pymes |>
  filter(score_total >= 8) |>
  select(empresa_id, sector_agrupado, pais, roe, 
         liquidez_ratio, deuda_patrimonio, score_total) |>
  arrange(desc(score_total)) |>
  head(10) |>
  kable(digits = 2)
```
::::

:::: {.notes}
**Resumen**

El AED es fundamental para cualquier proyecto de datos:

---

**Lo que logramos en este AED**

1. **Conocimos nuestros datos profundamente**
   - 500 empresas, 28 variables, múltiples sectores y países
   - Identificamos y corregimos 11 tipos de problemas de calidad

2. **Identificamos patrones de negocio**
   - Tecnología lidera en productividad e innovación
   - Alemania muestra las PYMES más sólidas financieramente
   - Rating crediticio correlaciona fuertemente con endeudamiento

3. **Formulamos hipótesis de investigación**
   - Inversión en I+D asociada con mejor rentabilidad
   - Tamaño óptimo: 20-50 empleados para máxima eficiencia
   - Exportación y éxito correlacionados en ciertos sectores

---

**Lecciones clave**

**NO existe una receta única para AED**:

- Cada dataset es diferente (industria, escala, problemas)
- Cada objetivo requiere enfoques distintos (predicción vs descripción)
- Es un proceso iterativo: descubrimiento → pregunta → análisis → descubrimiento

**El proceso importa tanto como el resultado**:

- Documentar decisiones (por qué agrupaste, por qué eliminaste)
- Justificar transformaciones (qué motivó crear nuevas variables)
- Ser transparente sobre limitaciones (qué NO pudimos responder)

---

**Sobre herramientas automatizadas e IA**

**Lo que aprendimos**:

- Herramientas de autoEDA: excelente punto de partida (regla 80/20)
- IA generativa: útil para código y documentación
- Pero: interpretación requiere expertise y contexto de negocio
- Validación humana es siempre necesaria

**Enfoque profesional**:

1. Usa automatización para velocidad inicial
2. Aplica criterio experto para profundidad
3. Valida hallazgos críticamente
4. Mantén contexto de negocio en el centro
5. Documenta proceso y decisiones

---

**La limpieza consume tiempo, pero es inversión**

**Tiempo típico en proyectos reales**:

- Limpieza de datos: 40-50% del tiempo
- Exploración y análisis: 30-40% del tiempo
- Modelización: 10-20% del tiempo
- Comunicación de resultados: 10-15% del tiempo

¿Por qué invertir tanto en limpieza y AED?

**Porque datos limpios = análisis confiable**

- Decisiones de negocio incorrectas por datos sucios: costosas
- "Garbage in, garbage out" es real
- AED previene sorpresas desagradables después
- Tiempo en AED ahorra tiempo (y dinero) después

---

**Próximos pasos naturales**

Después del AED, típicamente:

1. **Feature engineering**: crear variables más sofisticadas
2. **Modelización**: predicción, clasificación, clustering
3. **Validación**: dividir datos train/test, cross-validation
4. **Deployment**: poner modelos en producción
5. **Monitoreo**: verificar que modelos siguen funcionando

Pero todo comienza con un buen AED.

---

**Un AED bien hecho es como...**

- **Médico**: Examen completo antes de diagnóstico
- **Detective**: Investigar escena del crimen antes de acusar
- **Arquitecto**: Estudiar terreno antes de diseñar edificio

No se puede saltear. No hay atajos. Vale la pena hacerlo bien.

**Siguiente paso**: Con datos limpios y entendidos, estamos listos para modelizar. Pero esa es otra historia...

::::


