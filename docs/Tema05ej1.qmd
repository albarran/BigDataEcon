---
# subtitle: "Técnicas para 'Big Data' en Economía - Curso 2023/24 \n\n Universidad de Alicante"
# subtitle: "Análisis de Datos Multivariantes aplicado al Marketing - Curso 2023/24 \n\n Universidad de Alicante"
# subtitle: "Muestreo y Análisis de Datos - Universidad de Alicante"
# subtitle: "Econometría II - Curso 2023/24 \n\n Universidad de Alicante"
title    :  "Tema 05. Ejercicio 1"
author:  
    - "Pedro Albarrán"
#    - "Teresa Molina"
# institute: "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
   
# institute: 
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
#     - "Dpto. de Fundamentos del Análisis Económico. Universidad de Alicante"
format:
#   beamer:
#     logo: figure/by-nc-sa2.png
#     titlegraphic: figure/by-nc-sa.png
#     theme: Boadilla # Copenhagen # CambridgeUS #
#     outertheme: miniframes
#     colortheme: crane
#     section-titles: false
#     fontsize: 10pt
# #    header-includes:
# #      - \setbeameroption{show notes}
# #      # - \setbeameroption{show notes on second screen}
  # revealjs:
  #   logo: figure/by-nc-sa2.png
  #   titlegraphic: figure/by-nc-sa.png
  #   theme:  serif # simple # default # moon # beige # sky #
  #   smaller: false
  #   scrollable: true
  #   embed-resources: true
  #   slide-number: true
  #   show-slide-number: all
  #   transition: slide # concave # 
  #   background-transition: fade
  #   progress: true
  html: 
    embed-resources: true
execute:
  enabled: true      # (no) ejecutar code chunks
  eval: false        # por defecto, evalúa y muestra códido de code chunks
  #| echo: FALSE
  warning: false    # pero no los mensajes ni warnings
  message: false
knitr:
  opts_chunk:
    results: hide     # ni muestra resultados ni figuras
    fig.show: hide
lang: es
strip-comments: true
toc: false
# css: styles.css
---


```{r setup}
#| include: FALSE
library(kableExtra)
library(knitr)
```


<!-- * En este ejercicio vamos a practicar los conceptos básicos de R. Debéis escribir un archivo de código de R con los comandos necesarios para responder a los siguientes ejercicios. Podéis encontrar una plantilla [aquí](Tema00ej1_12345678.R) -->



```{r}
#| echo: FALSE
################################################################################
# extract R code
# knitr::purl("Tema01_ejerc.Rmd", output = "Tema01_ejerc_sol1.R", documentation = 1)
################################################################################


############################################################
## Ejercicio Tema 01
## NOMBRE: (reemplaza esto con tu Nombre y Apellido(s))
## DNI:    (reemplaza esto con tu DNI, o similar)
############################################################
```


# Apartado 1

##`tidyquant`

La biblioteca `tidyquant` ofrece varias funcionalidades para obtener, transformar y visualizar datos económicos y financieros fácilmente. Aquí solo utilizaremos unas pocas de sus capacidades; podéis encontrar una descripción completa [aquí](https://business-science.github.io/tidyquant/).

## Obtener datos

Existen varias funciones para obtener datos: `tq_index()` (para índices bursátiles), `tq_exchange()` (para bolsas de valores) y `tq_get()` para datos económicos y financieros de varias fuentes en la web. En particular veremos como obtener datos macroeconómicos de muchos países disponibles en [FRED](https://fred.stlouisfed.org/) y datos de acciones a través de [Yahoo Finance](https://es.finance.yahoo.com/).

### Datos económicos de FRED, 

  + Se busca un dato (concreto) de, por ejemplo, inflación en España: "Inflation, consumer prices for Spain; Percent, Annual, Not Seasonally Adjusted"
  
  + Así, averiguamos el "símbolo" o nombre interno de la variable

```{r}
#| eval: false
#| echo: true
datos <- tq_get("FPCPITOTLZGESP", get = "economic.data", from = "1960-01-01")
```

Obtenemos unos **datos ordenados** con la fecha y el valor numérico de la variable disponibles para trabajar con las funciones de `tidyverse`. Podemos representar la evolución temporal de esta variable para todo el periodo o una parte (p.e., usando funciones como `year()` de `lubridate`)

```{r}
#| eval: false
#| echo: true
ggplot(datos) + geom_line(aes(x=date, y=price))

datos %>% filter(year(date)>2000) %>%       
  ggplot() + geom_line(aes(x=date, y=price))
```


### Datos Financieros

Para obtener datos de acciones, averiguamos el símbolo de una acción en [Yahoo Finance](https://es.finance.yahoo.com/); por ejemplo, "Telefonica, Equity - NYQ" y "Banco de Santander, S.A. - NYQ"

```{r}
#| eval: false
#| echo: true
acciones <- tq_get(c("TEF", "SAN"), get = "stock.prices", complete_cases = FALSE)
```

Tenemos los datos ordenados en formato largo para las acciones (primero la serie de una acción y luego la de la otra) con información del precio de apertura, cierre, máximo y mínimo de la sesión, volumen negociado, etc.

## Funciones adicionales

Esta biblioteca también incluye funciones de análisis específicos, incluyendo `geoms` de `ggplot2` para nuevos tipos de gráficos.

* Gráficos de barras

```{r}
#| eval: false
#| echo: true
acciones %>%
  filter(symbol == "TEF") %>% 
  ggplot(aes(x = date, y = close)) +
  geom_barchart(aes(open = open, high = high, low = low, close = close))


acciones %>%
  ggplot(aes(x = date, y = close)) +
  geom_barchart(aes(open = open, high = high, low = low, close = close)) +
  facet_wrap(~symbol)
```

* Gráficos de velas

```{r}
#| eval: false
#| echo: true
acciones %>%
  filter(symbol == "TEF") %>% 
  ggplot(aes(x = date, y = close)) +
  geom_candlestick(aes(open = open, high = high, low = low, close = close)) 

acciones %>%
  filter(symbol == "TEF") %>% 
  filter(month(date) == 10 & year(date) == 2024) %>% 
  ggplot(aes(x = date, y = close)) +
  geom_candlestick(aes(open = open, high = high, low = low, close = close)) 
```

También podemos añadir (en ambos tipos de gráficos) tendencias calculadas con distintas formas de medias móviles y bandas:

```{r}
#| eval: false
#| echo: true
acciones %>%
  filter(symbol == "TEF") %>% 
  filter(year(date)>2022) %>%  
  ggplot(aes(x = date, y = close)) +
    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +
    geom_ma(ma_fun = SMA, n = 50, color = "black") +
    geom_ma(ma_fun = SMA, n = 200, color = "gray")

acciones %>%
  filter(symbol == "TEF") %>% 
  filter(year(date) > 2022) %>%  
  ggplot(aes(x = date, y = close, open = open, high = high, low = low, close = close)) +
  geom_candlestick() +
  geom_bbands(ma_fun = SMA, sd = 2, n = 20) 
```

Se pueden incorporar todas las funcionalidades habituales de `ggplot2` como escalas logarítmicas, `geom_smooth()`, etc.

Como hemos visto se pueden utilizar las funciones de transformación de datos de `tidyverse`; además, `tidyquant` incluye las funciones `tq_mutate()` y `tq_transmutate()` con las que se realizan con mayor facilidad operaciones habituales con este tipo de datos como cambiar la periodicidad, obtener rentabilidades a distintos plazos, cálculos de tendencias mediante medias móviles, cálculos de volatilidad, etc. También se incluye la función `tq_performance()` para el análisis del comportamiento de una acción o una cartera.

# Vuestro ejercicio

Elegid una serie de datos de Yahoo Finance y una de FRED (que NO sean las del ejemplo). Debéis escribir un apartado de un documento .qmd que combine código para realizar las siguientes tareas y vuestros comentarios sobre las conclusiones que se derivan.

  a. Cargar los datos 
    
  b. Realizar un breve análisis descriptivo de la serie financiera de Yahoo Finance, incluyendo un gráfico de velas o de barras para todo el periodo y para algún subperiodo que consideréis relevante. Comentar brevemente.
    
  c. Realizar un breve análisis descriptivo de la serie macroeconómica de FRED y un gráfico con su evolución temporal. Comentar brevemente.
    
  d. Combinar la serie económica y la financiera en un único conjunto de datos. Realizar un análisis gráfico y numérico de la covariación de ambas series. Comentar brevemente. 
  
    NOTA: combinar estas dos series implica poner ambas en la misma frecuencia: la serie financiera es diaria y la macroeconómica será, dependiendo de vuestra elección, anual, trimestral o mensual. Aunque se pueden usar funciones de `tidyquant` para esto, podéis usar funciones de `tidyverse` que conocemos. Simplemente tenéis que calcular la media mensual, trimestral o anual de los datos diarios.

No os olvidéis de incluir algunos (breves pero descriptivos) comentarios en vuestro código sobre qué hacéis y por qué.


```{r Solucion}
#| eval: false
#| echo: false

# Se pueden elegir cualquier par de series
# Pero debería haber alguna justificación o lógica económica en la elección
# Si queremos analizar una relación, debería haber unos mínimos motivos a priori 
# para que investigar una posible relación
# (no se penalizará si no sucede, pero hacer notar que el análisis de datos es esto)

library(quantmod)

# Serie financiera
getSymbols('AAPL',src='yahoo')   # Apple en NY
candleChart(AAPL, up.col = "black", dn.col = "red", theme = "white")
plot(AAPL$AAPL.Open)
plot(AAPL$AAPL.Volume)

summary(AAPL)
# para estas series tiene sentido hablar de la media y mediana
# pero más de lo que mida volatilidad: difencia entre max y min / 3quartil-1quaril
# o varianza..
var(AAPL)
cov(AAPL)
# aunque es mejor solo la diagonal y aun mejor la desviacion típica
# pero esto es algo avanzado
sqrt(var(AAPL))

# Gráfico de la evolución a muy largo plazo 
# (cualquiera de estas u otras opciones son válidas)
# se pueden identificar tendencias en la evolución de precios y volumen comerciado
# se pueden identificar periodos de altos/bajos precios o volumen, de volatilidade, etc
# Dado esto se puede intentar analizar un periodo específico o buscar diferencias entre dos periodos
# Por ejemplo, cambios en la volatilidad

# Tambien se puede hacer un gráfico para un periodo reciente y ver mejor
# el gráfico de velas
candleChart(AAPL[-(1:4150),], up.col = "black", dn.col = "red", theme = "white")
# en este periodo reciente se aprecia mejor el gráfico
# para este periodo y accion, fin de junio/ medidos septiembre 2023
# se aprecia un cambio claro a mitad del periodo: 
# un periodo estable de subidas y bajadas, hasta agosto
# entonces hay una caida brusca de precios. 
# tras esto no solo es más frecuente caidas en los precios 
# y mayor volumen de negociacion, sobre todo en periodo de caidas
# tambien aumentan las variaciones de precios intra-sesión

datos <- AAPL[-(1:4150),]
datos$AAPL.Dif <- abs(datos$AAPL.High-datos$AAPL.Close)
n <- length(datos$AAPL.Open)
# n0 <- ceiling(n/2)
datos1 <- datos[1:22,]
datos2 <- datos[23:n,]
summary(datos1)
summary(datos2)

diag(var(datos1))
diag(var(datos2))
# La varianza es claramente mayor


getSymbols("FPCPITOTLZGESP", src = 'FRED') # inflación
x <- as.numeric(FPCPITOTLZGESP)
plot(FPCPITOTLZGESP)
# nuevamente se pueden identificar tendencias de largo plazo, 
# periodos de alta/baja inflacion, etc

# confirmar esto con medias, varianzas,etc en general o por subperiodos
# como antes

# algunos breves comentarios con sentido


getSymbols("IRLTLT01ESA156N", src = "FRED") # tipos de interés
y <- as.numeric(IRLTLT01ESA156N)

# es importante que las series tengas la misma frecuencia
# y la misma longitud. De hecho el mismo periodo temporal
plot(x[-c(1:20)], y)
var(cbind(x[-c(1:20)], y))

cov(x[-c(1:20)], y)
cor(x[-c(1:20)], y)

# algunos breves comentarios con sentido

```

<!-- IMPORTANTE: El archivo .R debe ofrecer un código REPRODUCIBLE, ejecutable en cualquier ordenador solo cambiando el directorio de trabajo y tener las misma estructura donde se encuentran los datos. Notad que los nombres de archivos de datos deben corresponderse con los que entregáis y debe quedar claro donde se fija el directorio de trabajo y cuál es la estructura de directorios. -->


# Apartado 2

## *Scraping* con `rvest`

Internet es un gran lugar para obtener datos. Podemos usar `rvest` para extraer (en inglés, *scrap* significa literalmente raspar o rascar una superficie) los datos en tablas HTML de la web, pero a menudo requerirá una limpieza extensa antes de que se puedan usar adecuadamente.

Considerar la siguiente lista de los fines de semana de apertura de taquillas más grandes:

(http://www.boxofficemojo.com/alltime/weekends/)

Usando `rvest` podemos traer esta tabla a R.

```{r,  echo=TRUE}
library(tidyverse)
library(rvest)
url <- "http://www.boxofficemojo.com/alltime/weekends/"
```

Primero, necesitaremos leer el contenido de la página en HTML. La función `read_html()` proporcionada por `rvest` procesa el HTML:
```{r, echo=TRUE}
html_bom <- read_html(url)
class(html_bom)
html_bom
```

Desafortunadamente, esto no es muy legible. Lo que queremos es extraer los datos que están incrustados en las tablas HTML. Empecemos por tomar esas tablas que están dentro de los elementos del html llamados "table". Para ello podemos utilizar `html_nodes()`:
```{r, echo=TRUE}
tables <- html_bom %>%
  html_nodes("table")
tables
```

<!--
En este caso, había 6 elementos de tabla en esa página (la mayoría de ellos usados para crear los bordes). Sólo nos interesa el grande con todos los datos. Este es el quinto elemento de la lista (nota: averiguadpo por prueba y error).
```{r, eval=FALSE, echo=TRUE}
tables[[5]]
```
-->

En este caso, solo hay 1 elementos de tabla en esa página .
```{r, echo=TRUE}
tables[[1]]
```


La función `html_table()` extraerá los datos de esta tabla y los convertirá en un *data frame*. La opción `header = TRUE` indica a R que queremos usar la primera fila como nuestros nombres de variable.
```{r, echo=TRUE}
movies <- tables[[1]] %>%
  html_table(header = TRUE)
str(movies)
```
En algunas ocasiones, existen más de una tabla en una página web. Si son pocas se puede determinar cuál nos interesa mediante prueba y error. En particular, en esta caso sabemos que los datos tienen 200 observaciones y 9 columnas; si lo que leemos tiene una dimensiones (obtenidas con `str()`) muy diferentes no debe ser la tabla que buscamos. En cualquier caso, con muchas tablas en la página web, necesitaremos nuevas herramientas de programación que veremos en breve.

<!--
En este caso sólo teníamos 6 tablas, así que no fue demasiado difícil usar prueba y error para averiguar cuál era la que queríamos. Pero también podríamos ser un poco más sistemáticos.

Usemos `lapply()` para extraer las 6 tablas, en un objeto de tipo lista con una longitud de 6:
```{r, eval=FALSE, echo=TRUE}
list_of_tables <- lapply(tables, html_table, fill = TRUE)
class(list_of_tables)
length(list_of_tables)
str(list_of_tables)
```

Puesto que `html_table()` asigna las tablas HTML a *data frames* en R, cada uno de los seis elementos de la lista list_of_tables es un *data frame*. Sin embargo, algunas de las tablas son más grandes que otras.

```{r, eval=FALSE, echo=TRUE}
lapply(list_of_tables, class)
lapply(list_of_tables, dim)
```

Es obvio desde la propia página web que la tabla que queremos tiene 9 variables y 214 filas. Sólo (el quinto elemento)[http://www.imdb.com/title/tt0119116/] de nuestra lista cumple con ese criterio.
-->

## Limpieza de datos

Si bien ahora tenemos los datos, podemos ver que son muy confusos:

  * los nombres de las variables contienen caracteres especiales, como asteriscos, paréntesis y espacios. Esto puede causar problemas, así que queremos cambiarlos.
  
  * la mayoría de las columnas se almacenan como vectores de caracteres, aunque contienen información cuantitativa. En particular, hay columnas para dólares, porcentajes y fechas que están en el formato equivocado.

Debido a este desajuste, si intentamos dibujar los datos, esto no funcionará como se esperaba.

```{r, echo=TRUE}
ggplot(
  data = movies, 
  aes(x = Date, y = Opening)
) + 
  geom_point(aes(size = `% of Total`))
```

<!--
Nota que cuando los nombres de la variables tienen caracteres "raros" se debe utilizar \` para marcar el inicio y el final del nombre. Esto incluye cualquier caracter no alfanumerico en cualquier posición del nombre de la variable y también los números al comienzo del nombre de una variable. Aquí esto sucede tanto por símbolo \% como por el espacio. Otros caracteres no alfanumericos son cualquier simbolo de puntuación, barras o letras como la ñ. 
-->

<!--
La función `parse_number()` del paquete `readr` es extremadamente útil para limpiar signos de dólar, comas y signos de porcentaje en los valores (Ojo, esto es diferente de los caracteres raros en el nombre mencionado antes). 
-->
Usaremos `parse_number()` junto con el verbo `mutate()` para renombrar las columnas al mismo tiempo.
```{r, echo=TRUE}
movies <- movies %>%
  mutate(opening = parse_number(Opening),
         percent_total = parse_number(`% of Total`)/100)
str(movies)
```

Ahora, cuando dibujamos los datos cuantitativos, obtenemos algo que tiene más sentido.

```{r, echo=TRUE}
ggplot(data = movies, aes(x = Date, y = opening)) + 
  geom_point(aes(size = percent_total))
```

<!--
### Ejercicio

También crear una nueva variable llamada `num_theaters` que almacena el número de teatros como un entero, y otras dos más con el promedio y el total recaudado. Responde [aquí](https://docs.google.com/forms/d/e/1FAIpQLScJhX5F219jttLOAReSpiT5Mg7aO7-clheg2170DFsprTTp5A/viewform)
```{r, eval=FALSE, echo=FALSE}
movies <- movies %>%
  mutate(num_theaters = as.integer(parse_number(Theaters)))
movies <- movies %>%
  mutate(avg_gross = parse_number(Average),
         total_gross = parse_number(`Total Gross`))
```

Notad que es conveniente usar el tipo de datos enteros cuando estamos seguro de que la variable contiene ese tipo de valores porque se ahorra espacio de almacenamiento. Sin embargo, hay ciertos "límites" a los valores que se pueden representar como enteros: ver `help(integer)`.
-->

## Fechas con `lubridate`

Desafortunadamente, las fechas siguen siendo un problema. Echemos un vistazo a esas fechas:
```{r, eval=FALSE, echo=TRUE}
movies %>%
  select(Date) %>%
  str()
```

Vemos que las fechas están en formato mes/día/año. Ya hemos visto anterioreme el paquete `lubridate` que proporciona funcionalidad para trabajar con fechas. Podemos utilizar la función `mdy()` para convertir el vector de caracteres en una clase de fecha.
```{r, echo=TRUE}
library(lubridate)
movies <- movies %>%
  mutate(release_date = mdy(Date))
str(movies)
```

```{r, eval=FALSE, echo=FALSE}
ggplot(data = movies, aes(x = release_date, y = opening)) + 
  #queremos un gráfico de dispersión, y usaremos tanto el color como el tamaño para mostrar porcentaje total
  geom_point(aes(color = percent_total, size = percent_total)) +
  # truco para combinar color y tamaño en una sola leyenda 
  guides(color = guide_legend("Porcentaje Total"), 
         size = guide_legend("Porcentaje Total")) +
  # Formatear el eje y para mostrar la cantidad en $.
  scale_y_continuous(name = "Recaudación en el Día de Apertura", labels = scales::dollar) +
  # etiquetamos tambien el ejer de las x (podemos omitir el argumento `name`)
  scale_x_date("Fecha de estreno")
```

```{r, echo=TRUE}
ggplot(data = movies, aes(x = release_date, y = opening/1e6)) + 
  geom_point(aes(color = percent_total), size = 4) +
  scale_y_continuous(name = "Recaudación en el Día de Apertura (en millones de $)") +
  scale_x_date("Fecha de estreno")
```


## Vuestro Ejercicio

1. Repetir el ejercicio con la siguiente fuente de información: [https://www.the-numbers.com/market/2024/top-grossing-movies](https://www.the-numbers.com/market/2024/top-grossing-movies). Es decir, debéis extraer los datos relevantes de la web, limpiarlos y dejarlos preparados para trabajar,

<!--; también realizar un gráfico (a vuestra elección) similar al anterior.-->

<!--
    Debéis enviar un archivo de guión .R respondiendo a [este formulario](https://docs.google.com/forms/d/e/1FAIpQLSfl1vrJhI_fXjbkLv_OJxgJezCycNC_PF-tiUMfnuAepx_NGA/viewform). Como es habitual, el nombre del archivo debe empezar con vuestro número de DNI (el resto es libre): ej., 12345678_P04.R.
-->

<!--
    a. Extraer los datos relevantes de la web, limpiar/transformar los datos en brutos y dejarlos "cargados" para su posterior análisis. Este es un ejemplo "simple" de lo que se conoce como [ETL](https://es.wikipedia.org/wiki/Extract,_transform_and_load). 
    b. Realizar un gráfico (a vuestra elección) similar al anterior.\newline\newline
    
    Debéis enviar un archivo de guión .R respondiendo a [este formulario](https://docs.google.com/forms/d/e/1FAIpQLSfl1vrJhI_fXjbkLv_OJxgJezCycNC_PF-tiUMfnuAepx_NGA/viewform). Como es habitual, el nombre del archivo debe empezar con vuestro número de DNI (el resto es libre): ej., 12345678_P04.R.
-->
  
2. Usando esos datos, realizar un BREVE análisis exploratorio de los datos. Crear las variables adicionales que consideréis necesarias con el tipo de datos adecuado. <!--Crear dos variables adicionales: año y mes de estreno. Notad que el mes debe ser tratada como factor; el año puede ser numérica o categórica.-->

    Describid la variación de algunas variables (no necesariamente todas) y algunas relaciones que consideréis relevantes.

<!--
    NOTA: no os compliquéis mucho: hay pocas variables (podéis querer generar alguna) y no hay mucha información para extraer "grandes" conclusiones. Centraros en practicar lo que se discutió en la práctica, describiendo la variación de (algunas) las variables y de las posibles relaciones entre ellas que consideréis más relevantes. 
-->  


# Entrega del ejercicio

Rellenad este [FORMULARIO](https://docs.google.com/forms/d/e/1FAIpQLScPBd-tHyUQ92nxYyn0-2eUQI_KZgg-0pgO248_56o4U5fN0g/viewform) con vuestros datos usando vuestra cuenta institucional de Google Cloud (@gcloud.ua.es) y subid 

  - vuestro archivo de .qmd

  - el resultado de compilarlo: bien un archivo .html autocontenido o bien un archivo .html y el directorio relacionado con el mismo nombre; en ambos casos, se recomienda comprimir todo para enviarlo.

IMPORTANTE: el nombre de los ficheros que subáis DEBE  seguir el  siguiente formato que incluye vuestro número de DNI: ej.,

 * Tema05ej1_123456789.qmd
 
 * Tema05ej1_123456789.zip
  
